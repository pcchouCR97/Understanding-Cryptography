{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to Quantum Algorithm!","text":"<p>This is a collection of my learnings and projects on quantum optimization and machine learning. You can start (Optimization) from here and (Machine Learning) from here. But don't worry, I also provide a overview and practical implementation of the classical optimization and machine learning methodoloies. </p>"},{"location":"#real-world-quantum-applications","title":"Real-World Quantum Applications","text":""},{"location":"#quantum-phase-estimation","title":"Quantum Phase Estimation","text":"<ul> <li>Shor's Algorithm:   In this Jupyter notebook, I implemented Shor\u2019s algorithm from scratch using only Qiskit\u2019s basic quantum gates \u2014 no built-in libraries. Successfully factor N = 15.</li> </ul>"},{"location":"#grover-search","title":"Grover Search","text":"<p>Coming soon! </p>"},{"location":"#quantum-optimization","title":"Quantum Optimization","text":"<ul> <li>Air Traffic Controller Problem:   This notebook applies quantum optimization (VQE) to a realistic aircraft scheduling problem, considering real aircraft types, wake turbulence, and safety constraints.   It demonstrates how quantum algorithms can tackle complex logistics problems \u2014 with future potential in operational aviation systems.</li> </ul>"},{"location":"#learning-notes","title":"Learning Notes","text":""},{"location":"#quantum-optimization-and-machine-learning","title":"Quantum Optimization and Machine Learning","text":"<p>If you are familiar with classical optimization or machine learning methods, you can start quantum world, please follow any one of these links down below.</p>"},{"location":"#optimization","title":"Optimization","text":"<ul> <li>Quadratic Unconstrained Binary Optimization (QUBO)</li> <li>Adiabatic Quantum Computing &amp; Quantum Annealing (AQQA)</li> <li>Quantum Approximate Optimization Algorithm (QAOA)</li> <li>Grover Adaptive Search (GAS)</li> <li>Variational Quantum Eignesolver (VQE)</li> </ul>"},{"location":"#machine-learning","title":"Machine Learning","text":"<ul> <li>Quantum Support Vector Machines (QSVM)</li> <li>Quantum Neural Networks (QNN)</li> <li>Quantum Hybrid Architectures (QHybrid)</li> <li>Quantum Generative Adversarial Networks (QGANs) </li> </ul>"},{"location":"#classical-optimization-and-machine-learning","title":"Classical Optimization and Machine Learning","text":"<p>If you are not familiar with both, you are welcome to start with any one of classical methods below.</p>"},{"location":"#optimization_1","title":"Optimization","text":""},{"location":"#machine-learning_1","title":"Machine Learning","text":"<ul> <li>Support Vector Machines (SVM)</li> </ul>"},{"location":"ClscOptML/CML/SVM/","title":"Support Vector Machine (SVM)","text":"<p>Support Vector Machine (SVM) is a supervised machine learning algorithm used for classification and regression tasks. While it can handle regression problems, SVM is particularly well-suited for classification tasks. </p> <p>SVM aims to find the optimal hyperplane in an N-dimensional space to separate data points into different classes. The algorithm maximizes the margin between the closest points of different classes.</p> <p>The key idea behind the SVM algorithm is to find the hyperplane that best separates two classes by maximizing the margin between them. This margin is the distance from the hyperplane to the nearest data points (support vectors) on each side.</p> <p>A support vector machines takes inputs in an n-dimentional Euclidean space (\\mathbb{R}^{n}) and classifies them according to which side of a hyperplane they are on. This hyperplane fully defines the behavior of the SVM, which can be defined by adjustable parameteres \\overrightarrow{w} and the constant b.</p> <p>         SVM Margin     </p>"},{"location":"ClscOptML/CML/SVM/#svm-terminology","title":"SVM Terminology","text":"<ul> <li>Hyperplane: A decision boundary separating different classes in feature space, represented by the equation wx + b = 0 in linear classification.</li> <li>Support Vectors: The closest data points to the hyperplane, crucial for determining the hyperplane and margin in SVM.</li> <li>Margin: The distance between the hyperplane and the support vectors. SVM aims to maximize this margin for better classification performance.</li> <li>Hard Margin: A maximum-margin hyperplane that perfectly separates the data without misclassifications.</li> <li>Soft Margin: Allows some misclassifications by introducing slack variables, balancing margin maximization and misclassification penalties when data is not perfectly separable.</li> <li>Kernel: A function that maps data to a higher-dimensional space, enabling SVM to handle non-linearly separable data.</li> </ul>"},{"location":"ClscOptML/CML/SVM/#mathematical-theory","title":"Mathematical Theory","text":"<p>Let the datapoints in our training dataset be \\overrightarrow{w} \\in \\mathbb{R}^{n} and their expected label by y_{j} = \\{1, -1 \\}. Also, we assume these datapoints can be perfectly separated by a hyperplane.</p> <p>When we train a classifier, we are interested in getting a low generalization error. In our case, we acheve this by looking into a hyperplane that can maximize the distance from itself to the training datapoints. For example, if our separating hyperplane is too close to one of the training datapoints, we risk another datapoint of the same class crossing to the other side of the hyperplane and being misclassified.</p> <p>         Figure. Both hyperplanes separate the two categories, but the continuous line is closer to the datapoints than the dashed line.     </p> <p>There are two ways that could help us achieve:</p> <ol> <li>We can consider the distance from a separating hyperplane H to all the points in the training dataset, and then try to find a way to tweak H to maximize that distance while making sure that H still separates the data properly.</li> <li>Instead, we can associate to each data point a unique hyperplane that is parallel to H and contains that datapoint. The parallel hyperplane that goes through the point that is closest to H will itself be a separating hyperplane - and so will be its reflection over H.</li> </ol> <p>         Figure. The solid black line represents a separating hyperplane \\( H \\). The red dashed line is parallel hyperplane which goes through the closest point to \\( H \\), and it's reflection over \\( H \\) is the other dashed line.     </p> <p>This pair of hyperplanes \u2014 the parallel plane that goes through the closest point and its reflection \u2014 will be the two equidistant parallel hyperplanes, which are the furthest apart from each other while still separating the data. The distance between them is also know as the margin and it is what we aim to maximize.</p> <p>The equation for the linear hyperplane can be written as:</p>  \\overrightarrow{w} \\cdot \\overrightarrow{x} + b = 0.  <p>where:</p> <ul> <li>\\overrightarrow{w} is the normal vector to the hyperplane.</li> <li>b is the offset or bias term,  representing the distance of the hyperplane from the origin along the normal vector \\overrightarrow{w}.</li> </ul> <p>Any hyperplane that is parallel to H can be described as \\overrightarrow{w} \\cdot \\overrightarrow{x} + b = C for some constant C. And the reflection of this plane is \\overrightarrow{w} \\cdot \\overrightarrow{x} + b = -C. That is, for some constant C, the hyperplane and its reflection can be characterized as </p>  \\overrightarrow{w} \\cdot \\overrightarrow{x} + b = \\pm C.  <p>If we set \\tilde{w} = \\overrightarrow{w}/C and \\tilde{b} = b/C, the equation can be rewritten as </p>  \\tilde{w} \\cdot \\overrightarrow{x} + \\tilde{b} = \\pm 1,  <p>for some values of \\overrightarrow{w} and b. Also, we know that the distance between these two hyperplanes is 2/||w||. Therefore, we can describe our problem as maximizing 2/||w|| while subjecting to the constraint of \\tilde{w} \\cdot \\overrightarrow{x} + \\tilde{b} = \\pm 1.</p> <p>Since we assume that there are no points inside the margin, the hyperplane \\tilde{w} \\cdot \\overrightarrow{x} + \\tilde{b} = 0 will properly separate the data, if for all the positive entries, \\tilde{w} \\cdot \\overrightarrow{x} + \\tilde{b} = \\geq 1, while all the negative ones will satisfy \\tilde{w} \\cdot \\overrightarrow{x} + \\tilde{b} = \\leq -1. We conclude this as </p>  y_{i}(\\overrightarrow{w} \\cdot \\overrightarrow{x_{j}}) \\leq 1,  <p>since we are considering y_{j} = 1 when the j-th example belongs to the positive class and y_{j} = -1 when it belongs to the negative one.</p> <p>         Figure. The hyperplane that could have been returned by an SVM is represented by a black solid line, and the lines in dashed lines are the equidistant parallel hyperplanes that are the furthest apart from each other while still separating the data. The margin is thus half of the thickness of the colored region     </p>"},{"location":"ClscOptML/CML/SVM/#hard-margin","title":"Hard Margin","text":"<p>Therefore we can write our optimization problem as </p>  \\begin{array}{ll} \\text{Minimize} &amp; ||w||,\\\\ \\text{Subject to} &amp; y_{i}(\\overrightarrow{w} \\cdot \\overrightarrow{x_{j}} + b) \\geq 1, \\end{array}  <p>where each j defines an individual constraint. We can also write our problem as </p>  \\begin{array}{ll} \\text{Minimize} &amp; \\frac{1}{2}||w||^{2},\\\\ \\text{Subject to} &amp; y_{i}(\\overrightarrow{w} \\cdot \\overrightarrow{x_{j}} + b) \\geq 1, \\end{array}  <p>this is also called as hard-margin training since we are allowing no elements in the training dataset to be misclassified or even to be inside the margin. This expression can save us from troubles due to Euclidean norm in most of the optimization algorithms.</p>"},{"location":"ClscOptML/CML/SVM/#soft-margin","title":"Soft Margin","text":"<p>With hard-margin training, we need our training data to be perfectly separable by a hyperplane because, otherwise, we will not find any feasible solutions to the optimization problem that we have just defined. Alternatively, we can use the technique called soft-margin training</p> <p>In contrast to the hard-margin training, Soft-margin classification is more flexible, allowing for some misclassification through the use of slack variables (\\xi). we will use </p>  y_{i}({w} \\cdot {x_{j}} + b) \\geq 1 - \\xi_{j}.  <p>When \\xi_{j} &gt; 0, we will allow \\overrightarrow{x_{j}} to be close to the hyperplane or even on the wrong side of the space. The larger the value of \\xi_{j} is, the further into the wrong side \\overrightarrow{x_{j}} will be.</p> <p>Since we would these \\xi_{j} to be as small as possible, we need to include them into the cost function. Thus,</p>  \\begin{array}{ll} \\text{Minimize} &amp; \\frac{1}{2}||w||^{2} + C\\sum_{j} \\xi_{j}, \\\\ \\text{Subject to} &amp; y_{i}(\\overrightarrow{w} \\cdot \\overrightarrow{x_{j}} + b) \\geq 1 - \\xi_{j},\\\\ &amp; \\xi_{j} \\geq 0, \\end{array}  <p>where C&gt;0, a hyperparameter for a penalty term, is a hyperparameter that can be chosen by us. The larger the value of C is, the less misclassification is allowed. If there is a hyperplane that can perfectly separate the data, setting C to a huge value would be equivalent to doing hard-margin training. You may think to make C as larger as possible, but this can make our model prone to overfitting.</p> <p>The soft-margin training problem can be equivalently written in terms of some optimizable parameters \\alpha_{j} as follows:</p>  \\begin{array}{ll} \\text{Maximize} &amp; \\sum_{j}\\alpha_{j} - \\frac{1}{2}\\sum_{j,k}y_{i}y_{k}\\alpha_{j}\\alpha_{k}(\\overrightarrow{x_{j}} \\cdot \\overrightarrow{x_{k}}),\\\\ \\text{Subject to} &amp; 0 \\leq \\alpha_{j} \\leq C,\\\\ &amp; \\sum_{j}\\alpha_{j}y_{j} = 0. \\end{array}  <p>This formulation of the SVM soft-margin training problem is, most of the time, easier to solve in practice. Once we get the \\alpha_{j} values, it is also possible to go back to the original formulation. For instance, it holds that </p>  \\overrightarrow{w} = \\sum_{j}\\alpha_{j}y_{j}\\overrightarrow{x_{j}}.  <p>Notice that \\overrightarrow{w} only depends on the training point \\overrightarrow{x_{j}}, for which \\alpha_{j} \\neq 0. These vectors are call support vectors.</p>"},{"location":"ClscOptML/CML/SVM/#kernel","title":"Kernel","text":"<p>Then we will have to use the technique called kernel trick, which maps the original space \\mathbb{R}^{n} into a higher dimensional space \\mathbb{R}^{N}. This higher dimensional space is called feature space and we refer to the function \\phi : \\mathbb{R}^{n} \\rightarrow \\mathbb{R}^{N} as a feature map.</p> <p>         Figure. The original data cannot be separated by a hyperplane linearly. The separating hyperplane is represented by a dashed line in (b) after applying the kernel trick     </p> <p>For example, figure above shows that a kernel trick is implemented to map 1-dimensional real line into a 2-dimensional plane with the function </p>  F(x) = (x,x^{2})  <p>To use the kernel trick, the single and only computation that we need to perform in the feature space is </p>  k(x,y) = \\phi(\\overrightarrow{x})\\phi(\\overrightarrow{y}).  <p>This is also know as a kernel function. The kernel functions are functions that can be represented as inner product in some space.</p> <p>SVM transforms the data points into feature space such that they can be seperated linearly. Here are some types of kernels:</p> <ol> <li>Linear Kernel: Maps data into linear space.</li> <li>Polynomial Kernel: Maps data into polynimial space.</li> <li>Radial Basis Function (RBF) Kernel: Maps data into a space based on distance between data points.</li> </ol> <p>Note</p> <p>The kernel trick allows computations involving a high-dimensional feature space through inner products (\\phi(x),\\phi(y)) without explicitly transforming the data, enabling efficient classification.</p>"},{"location":"ClscOptML/CML/SVM/#types-of-support-vector-machine","title":"Types of Support Vector Machine","text":"<p>Linear SVM: Used when data is linearly separable, meaning a straight line (in 2D) or a hyperplane (in higher dimensions) can clearly separate the classes. It finds the optimal hyperplane that maximizes the margin between different classes.</p> <p>Non-Linear SVM: Applied when data is not linearly separable. It uses kernel functions to map data into a higher-dimensional space where a linear boundary can be found. This allows for more complex decision boundaries.</p>"},{"location":"ClscOptML/CML/SVM/#references","title":"References","text":"<p>[1]. Geeksforgeeks: https://www.geeksforgeeks.org/support-vector-machine-algorithm/</p> <p>[2]. Combarro, E. F., &amp; Gonz\u00e1lez-Castillo, S. (2023). A practical guide to quantum machine learning and quantum optimisation: Hands-on approach to modern quantum algorithms. Packt Publishing.</p> <p>[3]. What are support vector machines (SVMs)? https://www.ibm.com/think/topics/support-vector-machine.</p> <p>[4]. Support vector machineBy Larhmam - Own work, CC BY-SA 4.0, Link</p>"},{"location":"Cs/P_NP/","title":"P and NP Problems","text":"<p>In computational complexity, we classify problems based on how efficiently they can be solved or verified.</p>"},{"location":"Cs/P_NP/#ppolynomial-time-polynomial-time-solvable","title":"P(Polynomial time): Polynomial-Time Solvable","text":"<p>The class P consists of problems that can be solved in polynomial time. That is, there exists an algorithm whose runtime is bounded by O(n^k) for some constant k, where n is the size of the input.</p> <p>Example: Checking whether a number is even \u2014 this is solvable directly and efficiently, so it belongs to P.</p>"},{"location":"Cs/P_NP/#npnondeterministic-polynomial-time-polynomial-time-verifiable","title":"NP(Nondeterministic Polynomial time): Polynomial-Time Verifiable","text":"<p>A problem is in NP if, for every \"yes\" instance, there exists a witness (or certificate) such that the correctness of the answer can be verified in polynomial time. You might not know how to find the solution efficiently, but if someone gives you a proposed answer, you can verify it quickly.</p> <p>Example: Determining whether a large number has a small factor \u2014 solving this is hard, but given a factor, you can verify it quickly using multiplication.</p>"},{"location":"Cs/P_NP/#witness","title":"Witness","text":"<p>A witness is evidence that certifies a \"yes\" answer. In NP problems, it's the input that helps confirm the solution.</p>"},{"location":"Cs/P_NP/#quantum-complexity-and-examples","title":"Quantum Complexity and Examples","text":"<ul> <li> <p>Shor\u2019s algorithm solves the factoring problem in polynomial time on a quantum computer. Since factoring is in NP, and Shor's algorithm solves it efficiently, it also lies in BQP (Bounded-Error Quantum Polynomial time). However, factoring is not known to be NP-complete.</p> </li> <li> <p>Grover\u2019s algorithm provides a quadratic speedup for unstructured search, reducing O(N) to O(\\sqrt{N}), but this still remains exponential in \\log N, so it does not solve NP-complete problems efficiently.</p> </li> </ul>"},{"location":"Cs/P_NP/#interpretation","title":"Interpretation","text":"<ul> <li>If solving a problem takes O(n^3), it belongs to P.</li> <li>If verifying a solution takes O(n^2), but finding it is hard, the problem lies in NP.</li> </ul> <p>In short, the distinction between P, NP, and BQP is not about how to solve problems directly, but about how to classify their difficulty \u2014 whether solving or verifying solutions can be done efficiently.</p>"},{"location":"Cs/P_NP/#references","title":"References","text":"<p>[1] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"Cs/computational_complexity/","title":"The big O notation","text":""},{"location":"Cs/computational_complexity/#intorduction","title":"Intorduction","text":""},{"location":"Cs/computational_complexity/#big-o-notation-o","title":"Big-O Notation (O)","text":"<p>Big-O gives an upper bound on a function\u2019s growth. It describes the worst-case scenario \u2014 the maximum amount of time or space an algorithm might use. If we write 'f(n) = O(g(n))', it means that for large enough 'n', 'f(n)' does not grow faster than 'g(n)' (ignoring constant factors).</p>"},{"location":"Cs/computational_complexity/#big-omega-notation","title":"Big-Omega Notation (\u03a9)","text":"<p>Big-Omega gives a lower bound. It tells us the minimum resources required \u2014 the best-case performance. If 'f(n) = \\Omega(g(n))', it means 'f(n)' grows at least as fast as 'g(n)' for large 'n'.</p>"},{"location":"Cs/computational_complexity/#big-theta-notation","title":"Big-Theta Notation (\u0398)","text":"<p>Big-Theta gives a tight bound, meaning it describes the exact growth rate. If 'f(n) = \\Theta(g(n))', then 'f(n)' grows at the same rate as 'g(n)' up to constant factors. This implies both 'O(g(n))' and '\\Omega(g(n))' hold.</p>"},{"location":"Cs/computational_complexity/#computational-complexity","title":"Computational complexity","text":"<p>From Fast to Slow:</p>  \\begin{array}{|c|c|l|} \\hline \\textbf{Complexity} &amp; \\textbf{Meaning} &amp; \\textbf{Example} \\\\ \\hline O(1)       &amp; \\text{Constant time}   &amp; \\text{Access array by index} \\\\ O(\\log n)  &amp; \\text{Logarithmic}     &amp; \\text{Binary search} \\\\ O(n)       &amp; \\text{Linear}          &amp; \\text{Loop through list} \\\\ O(n \\log n)&amp; \\text{Linearithmic}    &amp; \\text{Merge sort, heap sort} \\\\ O(n^2)     &amp; \\text{Quadratic}       &amp; \\text{Bubble sort, nested loops} \\\\ O(n^3)     &amp; \\text{Cubic}           &amp; \\text{3 nested loops} \\\\ O(2^n)     &amp; \\text{Exponential}     &amp; \\text{Subset generation} \\\\ O(n!)      &amp; \\text{Factorial}       &amp; \\text{Brute-force permutation sorting} \\\\ \\hline \\end{array}  <p>In general:</p> <ul> <li>Good: O(1), O(log\u202fn), O(n)</li> <li>Acceptable: O(n log\u202fn)</li> <li>Bad: O(n\u00b2) and worse for large n</li> </ul>"},{"location":"Cs/computational_complexity/#olog-n-halving-until-you-find-it","title":"O(log\u202fn) \u2014 Halving Until You Find It","text":"<p>Binary search appears when you repeatedly cut a sorted set in half and only follow the half that matters.</p> <p>A perfect real-life example is the Guess the Number game. Imagine someone picks a number between 1 and 100. You don\u2019t guess randomly \u2014 instead, you always choose the middle number and ask if the target is higher or lower. Each time, you eliminate half of the remaining options. In just a few guesses, you zero in on the correct number.</p> <p>This strategy works because the problem size shrinks exponentially \u2014 from 100 to 50 to 25 and so on. After around log\u2082(n) steps, there\u2019s only one number left. That\u2019s why binary search runs in O(log\u202fn) time.</p>"},{"location":"Cs/computational_complexity/#on-log-n-divide-and-touch-everything","title":"O(n log n) \u2014 Divide and Touch Everything","text":"<p>O(n log n) arises when an algorithm splits the data repeatedly and still needs to process every element at each level of splitting. For example, in merge sort, the data is divided in half each time \u2014 this creates log\u202fn levels of recursion. But at every level, the algorithm still needs to go through all n elements to merge them. That\u2019s why the total time becomes:</p>  \\text{(log n levels)} \\times \\text{(n elements per level)} = O(n \\log n)"},{"location":"Cs/computational_complexity/#o2n-problems-of-choice","title":"O(2\u207f) \u2014 Problems of Choice","text":"<p>A classic example is the 0/1 Knapsack problem. Given <code>n</code> items, each with a value and weight, you decide for each one whether to include it in your bag without exceeding a weight limit. Every item presents two choices \u2014 take it or not \u2014 leading to 2^n possible combinations. That\u2019s why brute-force knapsack is exponential.</p> <p>A more relatable version is your closet in the morning. Imagine you own <code>n</code> shirts. Each day, you can either wear or not wear each shirt (ignoring fashion logic). That leads to 2^n outfit combinations \u2014 one for every possible subset of shirts.</p>"},{"location":"Cs/computational_complexity/#on-problems-of-ordering","title":"O(n!) \u2014 Problems of Ordering","text":"<p>On the other hand, O(n!) arises when the task is to examine every possible ordering of <code>n</code> items. A textbook case is the Traveling Salesman Problem (TSP): a salesman must visit <code>n</code> cities once and return to the start, aiming for the shortest route. Every route is a unique permutation of the cities \u2014 and there are n! of them.</p> <p>A real-world analogy? Think of planning a talent show with <code>n</code> singers. You must decide who performs in which order. Each different sequence is a new possibility \u2014 and the total number of such lineups is again n!.</p> <p>So in short, 2\u207f shows up when you\u2019re picking any combination (yes/no for each item). n! appears when you\u2019re deciding all possible orders of things. In algorithm analysis, two of the steepest time complexities are O(2^{n}) and O(n!), both representing explosive growth as input size increases. But they arise from different types of problems.</p>"},{"location":"Cs/computational_complexity/#references","title":"References","text":"<p>[1] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/","title":"Jop shop problem","text":""},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#problem-definition-and-conventions","title":"Problem definition and conventions","text":"<p>A Jop shop problem (JSP) consists of </p> <ol> <li>A set of jobs \\mathcal{J} = \\{j_{1},\\cdots,j_{N}\\} that be scheduled on a set of machines \\mathcal{M} = \\{m_{1},\\cdots,m_{N}\\}. </li> <li>Each job consists of a sequence of operations that must by performed in a predefined order j_{n} = \\{ O_{n1}\\rightarrow O_{n2}\\rightarrow \\cdots O_{nL_{n}} \\} of total of L_{n} operations. </li> <li>Each operation O_{nj}, j = 1,\\cdots L_{n} has integer execution time p_{nj}.</li> <li>And O_{nj} has to be executed by an assigned machine m_{qnj} \\in \\mathcal{M}, q = 1,\\cdots, M, assigned machine. </li> </ol> <p>There can only be one operation tunning on any given machine at any given point in time and each opeariton of a job needs to complete before the following one can start. The usual objective is to schedule all operations in a valide sequence while minimizing the makespan (i.e., the completion time of the last running job). We will denote \\mathcal{T} the minimum possible makespan associated with a given JSP instance.</p> <p>As defined above, the JSP variant we consider is denoted \\text{J}M|p_{nj}\\in [p_{\\text{min}},\\cdots,p_{\\text{max}}]|C_{max} in the \\alpha|\\beta|\\gamma notationm where p_{\\text{min}} and p_{\\text{max}} are the smallest and largest execution times allowed, respectively. In this notation, \\text{J}M stands for job-shop type on M on mahcines, and C_\\text{max} means we are optimizing the makespan. For notational convenience, we enumerate the operations in a lexicographical order in such a way that </p>  \\begin{array}{ll} J_{1} = &amp; \\{ O_{1}\\rightarrow \\cdots \\rightarrow O_{k_{1}} \\},\\\\ J_{2} = &amp; \\{ O_{k_{1}+1}\\rightarrow \\cdots \\rightarrow O_{k_{2}} \\},\\\\ \\cdots = &amp; \\\\ J_{N} = &amp; \\{ O_{k_{N-1}+1}\\rightarrow \\cdots \\rightarrow O_{k_{N}} \\}. \\end{array} \\tag{1}  <ol> <li>Given the running index overall operations i \\in {1,\\cdots,k_{N}}, we let q_{i} be the index of the machine m_{q_i} responsible for executing operation O_{i}.</li> <li>We define I_{m} to be the set of indices of all of the operations that have to be executed on machine m_{m}, i.e., I_{m} = \\{i:q_{i} = m \\}. The execution time of operation O_{i} is now simply denoted p_i.</li> <li>A job j can use the same machine more than oncem or use only a fraction of the M available machines. Auturs in 1 define a ratio of \\theta that specifies the fraction of the total number of mahcines that is used by each job, assuming no repetition when \\theta &lt; 1. For example, a ratio of 0.5 means that each job uses only 0.5M distinct machines.</li> </ol>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#quantum-annealing-formulation","title":"Quantum annealing formulation","text":"<p>In this work, we seek a suitable formulation of the JSP for a quantum annealing optimizer. The optimizer is best described as an oracle that solves an Ising problem with a given probability. This Ising problem is equivalent to a quadratic unconstrained binary optimization (QUBO) problem.</p> <p>The optimizer is expected to find the global minimum with some probability which itself depends on the problem and the device\u2019s parameters.</p> <p>We distinguish between the optimization version of the JSP, in which we seek a valid schedule with a minimal makespan, and the decision version which is limited to validating whether or not a solution exists with a makespan smaller than or equal to a user-specified timespan T.</p> <p>We focus exclusively on the decision version and later describe how to implement a full optimization version based on a binary search.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#qubo-problem-formulation","title":"QUBO Problem Formulation","text":"<p>We assign a set of binary variables for each operation, corresponding to the various possible discrete starting times the operation can have </p>  x_{i,t} = \\begin{cases}  1, &amp; \\text{operation } O_i \\text{ starts at time } t, \\\\ 0, &amp; \\text{otherwise}. \\tag{2} \\end{cases}  <ol> <li>Here t is bounded from above by the timespan T, which represents the maximum time we allow for the jobs to complete. The timespan itself is bounded from above by the total work of the problem, that is, the sum of the execution times of all operations.</li> </ol>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#constraints","title":"Constraints","text":""},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#an-operation-must-start-once-and-only-once","title":"An operation must start once and only once","text":"<p>An opeartion must start once and only once leads to the constraint and assocaited penalty function </p>  \\bigg(\\sum_{t}x_{i,t} = 1 \\ \\text{for each}\\ i \\bigg) \\rightarrow \\sum_{i}\\bigg( \\sum_{t} x_{i,t} - 1\\bigg)^{2}. \\tag{3}"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#there-can-only-be-one-job-running-on-each-machine-at-any-given-point-in-time","title":"There can only be one job running on each machine at any given point in time","text":"<p>There can only be one job running on each machine at any given point in time, which expressed as quadratic constraints yields</p>  \\sum_{(i,t,k,t')\\in R_{m}} x_{i,t}x_{k,t'} = 0 \\ \\text{for each} \\ m, \\tag{4}  <p>where R_{m} = A_{m} \\cup B_{m} and </p>  \\begin{array}{ll} A_{m} = &amp; \\{(i,t,k,t'): (i,k) \\in I_{m} \\times I_{m},\\\\         &amp; i \\neq k, 0 \\leq t, t'\\leq T,0 &lt; t'-t &lt; p_{i}\\},\\\\ B_{m} = &amp; \\{(i,t,k,t'): (i,k) \\in I_{m} \\times I_{m},\\\\         &amp; i &lt; k, t' = t, p_{i} &gt; 0, p_{j}&gt;0\\}. \\end{array}  <ul> <li>The set A_{m} is defined so that the constraint forbids operation O_{j} from starting at t' if there is another operation O_{i} still running. This happens if O_{i} started at time t and t' - t is less than p_{i}.</li> <li>The set B_{m} is defined so that two jobs J cannot start at the same time, unless at least of of them has an execution time equal to zero.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#enforced-order-of-the-operations-within-a-job","title":"Enforced order of the operations within a job","text":"<p>The order of the operations within a job are enforced with </p>  \\sum_{k_{n-1}&lt;i&lt;k_{n}, t+p_{i} &gt; t} x_{i,t}x_{i+1,t'} \\ \\text{for each}\\ n, \\tag{5}  <p>which counts the number of precedence voilations between consecutive operations only.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#hamiltonian","title":"Hamiltonian","text":"<p>The resulting classical objective function (Hamiltonian) is given by </p>  H_{T}(\\overline{x}) = \\eta h_{1}(\\overline{x}) + \\alpha h_{2}(\\overline{x}) + \\beta h_{3}(\\overline{x}), \\tag{6}  <p>where</p> <p>The order of the operations within a job are enforced with:</p>  h_{1}(\\overline{x}) = \\sum_{n}\\bigg( \\sum_{k_{n-1}&lt;i&lt;k_{n}, \\ t+p_{i} &gt; t} x_{i,t}x_{i+1,t'}\\bigg), \\ \\text{for each}\\ n, \\tag{7}  <p>There can only be one job running on each machine at any given point in time:</p>  h_{2}(\\overline{x}) = \\sum_{m}\\bigg( \\sum_{(i,t,k,t')\\in R_{m}} x_{i,t}x_{k,t'} \\bigg), \\ \\text{for each}\\ m, \\tag{8}  <p>An operation must start once and only once:</p>  h_{3}(\\overline{x}) = \\sum_{i}\\bigg( \\sum_{t} x_{i,t} - 1\\bigg)^{2}, \\tag{10}  <p>and the penalty constants \\eta, \\alpha and \\beta are required to be larger than 0 to ensure that unfeasible solution do not have a lower energy then the ground state(s). </p> <p>As expected for a decision problem, we note that the minimum of H_{T} is 0 and it is only reached if a schedule satisfies all of the constraints. The index of H_T explicitly shows the dependence of the Hamiltonian on the timespan T, which addects the number of variables involved.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#appendix","title":"Appendix","text":"<p>1. R_m \u2013 The Set of Conflicting Job Pairs on Machine m $$ R_m = A_m \\cup B_m $$ - R_m contains pairs of operations that cannot run simultaneously on machine m. - It is formed by combining two subsets:   - A_m (Jobs overlapping in time)   - B_m (Jobs starting at the same time)</p> <p>2. A_m \u2013 Overlapping Job Constraint $$ A_m = {(i,t,k,t') : (i,k) \\in I_m \\times I_m, \\quad i \\neq k, \\quad 0 \\leq t, t' \\leq T, \\quad 0 &lt; t' - t &lt; p_i } $$ - Ensures that if an operation O_i is running, no other operation O_k can start before O_i finishes. - t' - t &lt; p_i \u2192 If O_i starts at t, then O_k cannot start at t' if O_i is still running. - Example:   - O_1 starts at t = 2 and has p_1 = 4.   - Another job O_2 cannot start before t = 6 (2 + 4) on the same machine.</p> <p>3. B_m \u2013 Simultaneous Start Constraint $$ B_m = {(i,t,k,t') : (i,k) \\in I_m \\times I_m, \\quad i &lt; k, \\quad t' = t, \\quad p_i &gt; 0, \\quad p_j &gt; 0 } $$ - Prevents two jobs from starting at the exact same time unless one has zero execution time. - t' = t \u2192 If O_i and O_k both try to start at t, at least one must have p = 0. - Example:   - If O_1 and O_2 are scheduled at t = 3, at least one must be a dummy job (p = 0).</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#1-what-is-i_m-times-i_mi_m-times-i_m","title":"1. What is I_m \\times I_m?","text":"<ul> <li>I_m is the set of operations assigned to machine m.</li> <li>I_m \\times I_m means all possible pairs of operations on the same machine.</li> </ul> <p>\ud83d\udc49 Example: - Suppose Machine 1 has 3 operations: I_1 = \\{O_1, O_2, O_3\\}. - Then, I_1 \\times I_1 creates pairs of operations:   $$   I_1 \\times I_1 = {(O_1, O_1), (O_1, O_2), (O_1, O_3), (O_2, O_1), (O_2, O_2), (O_2, O_3), (O_3, O_1), (O_3, O_2), (O_3, O_3) }   $$ - This includes all possible combinations (even pairs with themselves, but in constraints we usually exclude those).</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#2-simple-example-of-a_ma_m-overlapping-jobs-constraint","title":"2. Simple Example of A_m (Overlapping Jobs Constraint)","text":"<p>Definition: $$ A_m = {(i,t,k,t') : (i,k) \\in I_m \\times I_m, \\quad i \\neq k, \\quad 0 &lt; t' - t &lt; p_i } $$ - If job O_i is running, another job O_k cannot start until O_i finishes.</p> <p>\ud83d\udc49 Example: - Machine 1 has I_1 = \\{O_1, O_2\\}. - Durations: O_1 takes 3 time units. - O_1 starts at t = 2. - O_2 tries to start at t' = 3. - Since O_1 is still running (from t=2 to t=5), O_2 must wait. - Valid pairs in A_m:   $$   (O_1,2,O_2,3), (O_1,2,O_2,4)   $$   because 0 &lt; (t' - t) &lt; p_1 (i.e., 0 &lt; 3-2 &lt; 3).</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#3-simple-example-of-b_mb_m-simultaneous-start-constraint","title":"3. Simple Example of B_m (Simultaneous Start Constraint)","text":"<p>Definition: $$ B_m = {(i,t,k,t') : (i,k) \\in I_m \\times I_m, \\quad i &lt; k, \\quad t' = t, \\quad p_i &gt; 0, \\quad p_k &gt; 0 } $$ - Two operations cannot start at the same time unless one has p = 0 (dummy operation).</p> <p>\ud83d\udc49 Example: - Machine 2 has I_2 = \\{O_3, O_4\\}. - Both jobs try to start at t = 1. - If p_3 &gt; 0 and p_4 &gt; 0, then this is not allowed. - Valid pairs in B_m:   $$   (O_3,1,O_4,1)   $$   since both jobs attempt to start at the same time.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#final-summary","title":"Final Summary","text":"Set Purpose Example I_m \\times I_m All operation pairs on the same machine \\{(O_1, O_2), (O_2, O_3)\\} for I_m = \\{O_1, O_2, O_3\\} A_m Prevents overlapping execution If O_1 runs from t=2 to t=5, O_2 cannot start at t=3 B_m Prevents two jobs starting together If O_3 and O_4 both try to start at t=1, it is not allowed <p>This ensures that machines are used efficiently, preventing job conflicts. </p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#understanding-the-precedence-constraint","title":"Understanding the Precedence Constraint","text":"<p>The given constraint ensures that operations within the same job follow the correct order.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#mathematical-formulation","title":"Mathematical Formulation","text":"<p>$$ \\sum_{k_{n-1} &lt; i &lt; k_n,  t + p_i &gt; t'} x_{i,t} x_{i+1,t'} = 0 $$ for each job n.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#what-it-means","title":"What It Means","text":"<ul> <li>x_{i,t} \u2192 Operation O_i starts at time t.</li> <li>x_{i+1,t'} \u2192 Next operation O_{i+1} starts at time t'.</li> <li>t + p_i &gt; t' \u2192 Operation O_{i+1} must not start before O_i finishes.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#how-it-works","title":"How It Works","text":"<ul> <li>If O_i starts at t, then O_{i+1} must start at t' such that:   $$   t' \\geq t + p_i   $$</li> <li>If O_{i+1} starts too early (before O_i finishes), the constraint is violated.</li> <li>The sum counts the number of violations\u2014the goal is to keep this zero.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#example","title":"Example","text":"<ul> <li>Suppose Job 1 has two operations:</li> <li>O_1 runs from t = 2 to t = 5 (p_1 = 3).</li> <li>O_2 must not start before t' = 5.</li> <li>If O_2 starts at t' = 4, it violates the constraint.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#understanding-why-the-constraint-must-equal-0-and-why-i_m-times-i_mi_m-times-i_m-is-not-used","title":"Understanding Why the Constraint Must Equal 0 and Why I_m \\times I_m is Not Used","text":""},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#1-meaning-of-the-constraint-0-0","title":"1. Meaning of the Constraint = 0","text":"<p>$$ \\sum_{k_{n-1} &lt; i &lt; k_n,  t + p_i &gt; t'} x_{i,t} x_{i+1,t'} = 0 $$ - This ensures that no precedence violations occur in job sequencing. - If this sum is greater than 0, it means at least one operation starts before its predecessor finishes, which is incorrect. - Setting it to 0 guarantees that every operation waits for the previous one to finish.</p>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#2-why-not-use-i_m-times-i_mi_m-times-i_m","title":"2. Why Not Use I_m \\times I_m?","text":"<ul> <li>I_m \\times I_m deals with machine constraints, ensuring no two operations run at the same time on the same machine.</li> <li>The current constraint only enforces job order (i.e., within the same job, not across different jobs).</li> <li>Here, we only consider consecutive operations within a single job, which is why we sum over job indices i and not machine assignments.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#key-difference","title":"Key Difference","text":"Constraint Type Ensures R_m = A_m \\cup B_m (uses I_m \\times I_m) Only one job runs on a machine at a time This precedence constraint (no I_m \\times I_m) Operations within a job happen in the correct order"},{"location":"Projs/Projs_Opt/Proj_Flow_Shop_Scheduling/#references","title":"References","text":"<p>[1]. D. Venturelli, D. Marchand, and G. Rojo, \"Quantum Annealing Implementation of Job-Shop Scheduling\", arXiv:1506.08479v2</p> <p>[2]. Job Shop Scheduling Dwave</p>"},{"location":"Projs/Projs_Opt/Proj_Nurse_Scheduling/","title":"Nurse Scheduling","text":"<p>The Nurse Scheduling Problem (NSP) involves creating a rotating roster for nurses in a hospital while ensuring compliance with constraints related to their availability and workload. In its simplest form, a two-shift system assigns nurses to either day or night shifts, ensuring balanced coverage and adherence to scheduling requirements.</p> <p>In this example, we impose two hard constraints to ensure a feasible schedule. The first constraint, known as the shift constraint, mandates a minimum number of nurses assigned to each shift. The second, the nurse constraint, ensures that each nurse receives a minimum rest period between consecutive shifts. These constraints are essential for maintaining adequate staffing levels while preventing excessive workload for individual nurses.</p> <ol> <li> <p>Shift constraints require that a sufficient number of nurses be assigned to each shift. However, the necessary number may depend on the experience of the assigned nurses, as more experienced nurses may be capable of performing more work during their shift.</p> </li> <li> <p>By contrast, nurse constraints represent the need to satisfy the appropriate working condition for each nurse. This includes time between shifts to get enough rest as well as days off and scheduled vacations.</p> </li> </ol> <p>We will apply the following constraints to our instance of NSP:</p> <ol> <li>Upper and lwer limit of the number of breaks.</li> <li>The number of nurses in duty for each shift slot.</li> <li>Upper and lower limit of time interval between two days of duty.</li> </ol>"},{"location":"Projs/Projs_Opt/Proj_Nurse_Scheduling/#method","title":"Method","text":"<p>The basic idea behind the quantum annealing can be found in Adiabatic Quantum and Quantum Annealing (AQQA). The basic fundation of adiabatic quantum optimization can be described on the time-dependent Schrodinger equation</p>  \\hat{H}(t) \\lvert\\psi(t)\\rangle = i \\hbar \\frac{\\partial \\lvert\\psi(t)\\rangle}{\\partial t}  <p>where: 1. \\hbar is the reduced Planck's constant, 2. \\lvert\\psi(t)\\rangle = \\psi(x,t) is the wave function, 3. \\hat{H}(t) is the Hamiltonian operator, time-dependent. 4. i is the imaginary unit.</p> <p>A generic form of this Hamiltonian is </p>  H(t) = A(t)H_{0} + B(t)H_{1}  <p>with t \\in [0, T] and T the final evolution time. And A(t), B(t) are monotonic and satisfy A(0) = 1, B(0) = 0 and A(T) = 0, B(T) = 1.</p>"},{"location":"Projs/Projs_Opt/Proj_Nurse_Scheduling/#ising-model-formulation-of-nsp","title":"Ising model formulation of NSP","text":"<p>A common approach to casting combinatorial optimization as an Ising model is to first express the problem as quadratic unconstrained binary optimization (QUBO).</p> <p>Consider a set of N nurses labeled as n=1,\\cdots, N and a schedule consisting of D working days labelled as d = 1,\\cdots, D. Using the binary variable q_{n,d} \\in {0,1}, let q_{n,d} = 1 specify the assignment of nurse n to day d. We then consider specific instances of the shift and nurse constraints discussed above.</p> <p>Three types of constraints are:</p> <ol> <li>Hard shift constraint: we require that the schedule must ensure at least 1 nurse is assigned each working each day.</li> <li>Hard nurse constraint: the schedule must ensure no nurse works two or more consecutive days.</li> <li>Soft nurse constraint: requires that all nurses should have approximately even work schedules.</li> </ol> <p>We construct objective functions that correspond to each shift and nurse constraint and then use the sum of these terms to express the QUBO form. </p> <ol> <li>We introduce composite indices i(n,d) and j(n,d) as functions of the nurse n and the day d.</li> <li>We construct the hard nurse constraint by introducing a symmetric, real-valued matrix J such that J_{i(n,d),j(n,d+1)} = a and zero otherwise.</li> <li>The positive correlation constant a enforces the nurse constraint by penalizing a schedule for nurse n to work two consecutive days.</li> <li>The resulting objectuve function is quadratic, i.e., J_{i,j}q_{i}q_{j} and takes its minimal when the hard nurse constraint is satisfied. Note that the nurse constraint can be modified by changing the entries of the matrix J.</li> </ol>"},{"location":"Projs/Projs_Opt/Proj_Nurse_Scheduling/#level-of-efforts","title":"Level of efforts","text":"<p>We express the hard shift constraint in terms of the required workforce W(d) needed on each day d and the level of effort E(n) available from each nurse n. </p> <ol> <li>We seek an equality solution for this constraint by introducing a quadratic function that penalizes schedules with too many or too few nurses assigned.</li> <li>In the same fashion, a quadratic penalty is also used on the soft nurse constraint for failing to account for nurse preferences in the work schedule.</li> <li>We use F(n) to specify the number of work days that each nurse wishes to be scheduled and G(n,d) to define a prederence for nurse n to work on day d.</li> </ol> <p>Here is an simple example of the preference function in the product G(n,d) = h_{1}(n)h_{2}(d), in such a way that </p>  h_1(n) = \\begin{cases}  3, &amp; \\text{busy} \\\\  2, &amp; \\text{moderate} \\\\  1, &amp; \\text{idle},  \\end{cases}  <p>In addition, they can also have options whether they may work on weekend/ night or not by tuning h_{2}(d):</p>  h_2(d) = \\begin{cases}  2, &amp; \\text{weekend or night} \\\\  1, &amp; \\text{weekday}, \\end{cases}  <p>The formulation can be more sophisticaed by including three-shift systems, distinction of weekdays and weekends regarding burden, or day-off request with priority. We simply requre the minimum duty days F(n) for all nurses are equal to or greater than [D/N], where [x] (x \\in R) means the integer part of x.</p> <p>Therefore, we can have a QUBO form of </p>  \\begin{array}{ll} H_{1}(q) &amp; = \\sum_{n,n'}^{N}\\sum_{n,d'}^{D}J_{i(n,d),j(n',d')}q_{i(n,d)}q_{j(n',d')}\\\\ &amp; + \\lambda \\sum_{d}^{D}\\bigg( \\sum_{n}^{N} E(n)q_{i(n,d)} - W(d) \\bigg)^{2}\\\\ &amp; + \\gamma  \\sum_{n}^{N}\\bigg( \\sum_{d}^{D} h_{1}(n)h_{2}(d)q_{i(n,d)} - F(n) \\bigg)^{2} \\end{array}  <p>where the positive real-valued numbers \\lambda and \\gamma tune the relative significance of each term. The objective function has its mnimum when all the constraints are satisfied and takes on a positive value otherwise. </p> <ol> <li>We assum that the functions E(n), F(n), and W(d) are integer-valued functions of n or d but this is not required.</li> <li>We require the minimum duty days F(n) for all nurses n are equal to or greater than [D/N], where [x] (x \\in R) means the integer part of x.  </li> </ol> <p>Next, we would have to transform this QUBO in to a Ising model.</p>"},{"location":"Projs/Projs_Opt/Proj_Nurse_Scheduling/#reference","title":"Reference","text":"<p>[1]. Nurse Scheduling - by Dwave. https://cloud.dwavesys.com/leap/examples/254188327.</p>"},{"location":"Projs/Projs_Opt/Proj_Portfolio_Optimization/","title":"Portfolio Optimization","text":"<p>The portfolio Optimization is a problem looks into identify the optimal number of shares of each stock to purchase in order to minimize risk(variance) and maximize returns, while staying under some specified spending budget.</p>"},{"location":"Projs/Projs_Opt/Proj_Portfolio_Optimization/#problem-definition","title":"Problem Definition","text":"<p>Consider a set of n types of stockds to choose from, with an average monthly return per dollar spent of r_i for wach stock i. Let \\sigma_{i,j} be the covariance of the returns of stocks i and j. For a spending budget of B dollars, let x_i denote the number of shares of stock i purchased at price p_i per share. </p> <p>The problem and be formaulated as </p>  \\begin{array}{ll} \\text{minimize or maximize} &amp; \\text{objective function}\\\\ \\text{subject to} &amp; \\text{constraint(s)} \\end{array}  <p>For example, if we choose n=3, our decision vriables must satisfied </p>  \\sum_{i=1}^{n=3} x_{i} \\leq \\text{budget},\\ x_{i}\\geq 0.  <p>Let's follow saome assumptions below: 1.  Fraction share is NOT acceptable. 2.  No short-selling is allowed. 3.  No transcation costs.</p> <p>We denote an average monthly return per dollar spent of r_i for wach stock i, then the return (profit) on x_i dollars invested in stock i is r_{i}x_{i} and the total (random) return on our investment is \\sum_{i=1}^{3}r_{i}x_{i}. </p> <p>The expected return on our investment is then \\mathbb{E}[\\sum_{i=1}^{3} r_{i}x_{i}] = \\sum_{i=1}^{3}\\overline{r_{i}}x_{i}, where \\overline{r_{i}} is the expected value of the r_{i}. Since we want to have an expected return of at least $ 50.00, x_{i}'s must be such that:</p>  \\sum_{i=1}^{3}\\overline{r_{i}}x_{i} \\geq 50.00.  <p>Now, lets try to minimize the risk. The risk can be closely approximated by minimizing the variance of the return of the investment portfolio. The variance is given by:</p>  \\begin{array}{ll} \\text{Var}[\\sum_{i=1}^{3}r_{i}x_{i}] &amp; = \\mathbb{E}\\bigg[\\bigg(\\sum_{i=1}^{3}r_{i}x_{i} - \\sum_{i=1}^{3}\\overline{r_{i}}x_{i}  \\bigg)\\bigg]\\\\ &amp; = \\mathbb{E}\\bigg[\\bigg(\\sum_{i=1}^{3}(r_{i} - \\overline{r_{i}})x_{i}\\bigg)\\bigg(\\sum_{j=1}^{3}(r_{j} - \\overline{r_{j}})x_{j}\\bigg)\\bigg]\\\\ &amp; = \\sum_{i=1}^{3}\\sum_{j=1}^{3}x_{i}x_{j}\\mathbb{E}[(r_{i} - \\overline{r_{i}})(r_{j} - \\overline{r_{j}})] \\\\  &amp; = \\sum_{i=1}^{3}\\sum_{j=1}^{3}x_{i}x_{j}\\sigma_{ij}, \\end{array}  <p>where \\sigma_{ij} is the covariance of the return of stock i with stock j. Therefore, our problem can be defined, in a general form, as:</p>  \\begin{array}{ll} \\text{min} &amp; \\sum_{i}^{I}\\sum_{j}^{J} x_{i}x_{j}\\sigma_{ij}, \\\\ \\text{subject to} &amp; \\sum_{i}^{I} x_{i} \\leq B, \\\\ &amp; \\sum_{i}^{I} x_{i} \\geq R, \\\\ &amp; x_{i} \\geq 0, \\forall i.  \\end{array}  <p>where B is the total budget, R is the expected return after a time period.</p> <p>We can also write our formula into a matrices and vectors,</p> <p>$$</p> <p>$$</p> <p>where x is the decision vector of size n (n is the number of stocks), e is an n-vector of ones, \\overline{r} is the n-vector of expected returneds of the stocks, and Q is the n\\times n covariance matrix (whose i-jth element Q_{ij} = \\sigma{ij})</p>"},{"location":"Projs/Projs_Opt/Proj_Portfolio_Optimization/#constructing-hamiltonian","title":"Constructing Hamiltonian","text":"<p>From the problem definination, we can construct our Hamiltonian by introducing penalty terms from our constraints listed above.</p>  H = \\sum_{i}\\sum_{j}x_{i}x_{j}\\sigma_{ij} + \\lambda_{1}\\bigg(\\sum_{i}x_{i}-B\\bigg)^{2} + \\lambda_{2}\\bigg(R-\\sum_{i}\\overline{r_i}x_{i} \\bigg)^{2}  <p>where \\lambda_{1} and \\lambda_{2} are penalty coefficients.</p>"},{"location":"Projs/Projs_Opt/Proj_RNA_Folding/","title":"RNA Folding","text":"<p>RNA folding refers to the process by which a single-stranded RNA molecule folds into a specific three-dimensional structure based on its sequence of nucleotides.</p>"},{"location":"Projs/Projs_Opt/Proj_RNA_Folding/#quantum-computing-goal-in-rna-folding","title":"Quantum computing goal in RNA Folding","text":"<p>The quantum applicatopm is to optimize the RNA folding process. The focus is on representing RNA folding as a combinatorial optimization problem that can be solved using quantum annealing. This involves:</p> <ul> <li>Encoding RNA sequence and rules into a quantum system.</li> <li>Using quantum algorithm (quantum annealing or others) to explore possible conformations and identify the optimal folding pattern that minimizes energy.</li> </ul> <p>Representation of RNA Sequence:</p> <ol> <li>The RNA sequence consists of A (Adenine), U (Uracil), G (Guanine), and C (Cytosine).</li> <li>Hydrogen bonds form between A-U and G-C pairs.</li> <li>The goal is to determine which of these pairs should be formed to minimize the overall energy.</li> </ol> <p>Predicting the existence of stems is important to predicting the properties of the RNA molecule. However, prediction is complicated by two important factors.</p> <p>In predicting the stems of an RNA molecule, we build a quadratic model with three contributing factors.</p>"},{"location":"Projs/Projs_Opt/Proj_RNA_Folding/#pseudoknot","title":"Pseudoknot","text":"<p>Second, the intertwining phenomenon known as a pseudoknot is less energetically favorable. In Figure 2, we see an example of such a pseudoknot, where one side of a stem occurs in between the two sides of a different stem. The use of a quadratic objective allows us to make pseudoknots less likely to occur in optimal solutions, increasing overall accuracy. Specifically, we include a quadratic term for each pair of stems that, if present, form a pseudoknot. The positive coefficient on this quadratic term discourages the forming of pseudoknots without explicitly disallowing the</p>"},{"location":"Projs/Projs_Opt/Proj_RNA_Folding/#problem-formulation","title":"Problem Formulation","text":"<p>In predicting the stems of an RNA molecule, we build a quadratic model with three contributing factors.</p> <ol> <li>Each potential stem is encoded as a binary variable, linearly weighted by the negative square of the length, k.</li> <li>Each potential pseudoknot is encoded as a quadratic term, weighted by to the product of the two lengths times a positive parameter c.</li> <li>Overlapping stems are not allowed. Potential overlaps give rise to constraints in the model.</li> </ol> <p>The model can be formulated as:</p>  \\begin{array}{ll} \\text{minimize} &amp; \\sum_{i} -k_{i}^{2}x_{i} + c \\sum_{(i,j)\\in S} k_{i}k_{j}x_{i}x_{j}\\\\ \\text{subject to} &amp; x_{i} + x_{j} \\leq 1, \\text{for all pairs of overlapping stems, $i$ and $j$} \\end{array}  <p>Here, each x_{i} is a binary variable indicating the inclusion/ exclusion of the i^{th} stem. Each constant k_{i} is the length of said stem. The indexing set S is the set of all pairs stems that from a pseudoknot.  -   c is a tunable parameter adjusting the impact of pseudoknots. It is set to 0.3 by default. If c=0, the affect of pseudoknots is ignored, while c&gt;1 eliminates all pseudoknots from optimial solutions. This formulation (and default choice of c) is loosely based on [1].</p> <p>Overlap in RNA stems happens when two different stem structures try to use the same nucleotide(s) in their base pairing. Since a single nucleotide cannot be part of two different base pairs at the same time, the two stems compete for that region of the RNA sequence</p>"},{"location":"Projs/Projs_Opt/Proj_RNA_Folding/#code-overview","title":"Code Overview","text":"<ol> <li>Preprocessing the RNA sequence to extract all possible stems, pseudoknots, and overlaps.</li> <li>Building the model and sending it to a hybrid solver to find a solution.</li> <li>Post-processing the solution to print appropriate information and create the plot.</li> </ol> <p>A majority of the code is dedicated to step 1. Here, possible bonds are stored in a binary matrix, and the matrix is searched for possible stems. Possible stems (each corresponding to a decision variable) are stored in a dictionary structure that reduces the number of comparisons necessary when searching for pseudoknots and overlaps.</p>"},{"location":"Projs/Projs_Opt/Proj_RNA_Folding/#reference","title":"Reference","text":"<p>[1] RNA Folding</p> <p>[2] Fox DM, MacDermaid CM, Schreij AM, Zwierzyna M, Walker RC. \"RNA folding using quantum computers,\" PLOS Computational Biology.</p> <p>[3] Kai, Zhang, et al. \"An efficient simulated annealing algorithm for the RNA secondary structure prediction with Pseudoknots,\" BMC Genomics.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/","title":"Credit Risk Glossory","text":"<p>Imagine you are manaing credit portfolio of 10 million, which has 100 bonds, each of them worth 100,000 dollar across 100 diffferent firms. And we and to estimate the loss under systemetic shock.</p> <p>Assumptions:</p> <ul> <li> <p>Each bond has:</p> <ul> <li>Baseline default probability of p_{k}^{0} = 1\\%.</li> <li>Recovery rate of 40\\%.</li> <li>Correlation to system factor \\rho_{k} = 0.2.</li> </ul> </li> <li> <p>System factor realization (for example, recession) = z = 1.</p> </li> </ul>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#default","title":"Default?","text":"<p>A default occurs when a borrower fails to meet debt obligations, such as interest or principal payments on a bond or loan.</p> <ul> <li>In a portfolio, if a bond issuer goes bankrupt, it defaults.</li> <li>The loss is calculated as:</li> </ul> <p>Loss = (1 - Recovery Rate) \u00d7 Exposure</p> <p>For example, with a 40% recovery on a $100,000 bond:</p> <p>Loss = (1 - 0.4) \u00d7 100,000 = 60,000</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#credit-portfolio","title":"Credit Portfolio?","text":"<p>A credit portfolio consists of credit-risky financial assets, including:</p> <ul> <li>Corporate bonds</li> <li>Bank loans</li> <li>Credit derivatives (e.g. CDS)</li> </ul> <p>Such portfolios are exposed to the risk of borrower default.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#baseline-default-probability-p_k0p_k0","title":"Baseline Default Probability p_k^0?","text":"<p>This is the unconditional probability that a firm will default, assuming normal market conditions.</p> <ul> <li>Estimated from credit ratings, CDS spreads, or historical default rates.</li> <li>Example: A BB-rated firm may have p_k^0 = 0.01 (1% default probability).</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#systemic-factor-correlation-rho_krho_k","title":"Systemic Factor Correlation \\rho_k?","text":"<p>\\rho_k measures how strongly asset k's default risk is correlated with the macroeconomy.</p> <ul> <li>If \\rho_k is close to 0 \u2192 risk is mostly firm-specific.</li> <li>If \\rho_k is close to 1 \u2192 risk is strongly tied to macro conditions.</li> </ul> <p>Typical values:</p> <ul> <li>\\rho_k = 0.1\u20130.2: Low to moderate sensitivity.</li> <li>\\rho_k = 0.3\u20130.5: High sensitivity to economic downturns.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#systemic-factor-realization-zz","title":"Systemic Factor Realization z?","text":"<p>The variable z ~ N(0,1) models the macroeconomic environment:</p> <ul> <li>z = 0: Normal conditions</li> <li>z = -1: Recession (1 standard deviation below mean)</li> <li>z = -2: Financial crisis or deep recession</li> </ul> <p>This is used to simulate default probabilities under stress.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#why-gaussian-conditional-independence","title":"Why Gaussian Conditional Independence?","text":"<p>The Gaussian Conditional Independence (GCI) model allows:</p> <ul> <li>Simulation of losses across many economic scenarios.</li> <li>Estimation of expected loss, VaR, and CVaR.</li> <li>Modeling of systemic vs. idiosyncratic risks.</li> <li>Regulatory capital and stress-testing applications.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#cdf-cumulatuve-distribution-function","title":"CDF (Cumulatuve Distribution Function)?","text":"<p>The cumulative distribution function of a real-valued random variable  X is the function given by</p>  F(x) = \\mathbb{P}[X\\leq x].  <p>This means </p> <p>The probability that the random variable X is less than or equal to some value x. It's the area under the probability curve to the left of x.</p> <p>Let's say X \\sim \\mathcal{N}(0,1), where 0 is the mean and 1 is the variance ,i.e., standard normal distribution where mean \\mu = 0, symmetrical bell curve. We wonder what's the chance a standard normal vairable is \\leq 0? That is, F(1) = \\mathbb{P}[X\\leq 0]? The answer is 50% since the curve is symmetric around 0. $$ F(0) = \\Phi(0) = 0.5 $$</p> <p>A simple example that we can analogy is the exam scores. Let's say your exam score X, which is a random variable, you don't know yet. And we have X \\sim \\mathcal{N}(70,10^{2}), which means that the average score \\mu = 70 and standard deviation \\sigma = 10. Now, you want to know that </p> <p>What's the chance your score is less than 85? </p> <p>That will be  $$ \\mathbb{P}[X\\leq x] = \\mathbb{P}[X\\leq 85], $$ where X is your future score which you don't know yet, x= 85 is the specific score you are comparing to. And the result will be $$ Z = \\frac{X - \\mu}{\\sigma} = \\frac{85 - 70}{10} = 1.5 $$ thus, we plug back to our CDF function </p>  \\Phi(z) = \\frac{1}{\\sqrt{2\\pi}}\\int_{\\infty}^{z} e^{-\\frac{t^{2}}{2}} dt = \\Phi(1.5) \\approx 0.9332  <p>This means there's a 93.3\\% chance your score \\leq 85.</p> <p>Here, we define a standardized variable from a normal distribution: $$ Z = \\frac{X - \\mu}{\\sigma} $$ where X is the raw value (this can be return, credit score), \\mu is the mean of the distrubtion, \\sigma is the standard deviation, Z \\sim \\mathcal{N}(0,1): always stardard normal</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#loss-given-default","title":"Loss given default","text":"<p>A Loss Given Default (LGD) for asset k means the fraction of value you loss if asset k defaults.  $$ \\lambda_{k} = 1 - \\text{Recovery Rate}. $$ For example, if a bond pays back 40\\% when defaulting, we have a \\text{Recovery Rate} of 0.4. Thus, \\lambda_{k} = 1 - 0.4 = 0.6. This means that you lose 60\\% of the value upon default.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#why-use-cdf-for-risk-estimation","title":"Why use CDF for Risk Estimation?","text":"<p>Because Value-at-Risk (VaR) is defined as a quantile, which is the inverse of the CDF.</p> <p>\"Find the smallest x such that at least \\alpha % of losses are below it\"</p>  \\text{VaR}_{\\alpha} = \\text{inf}\\{x | F_{L}(x)\\geq \\alpha \\}  <p>Therefore, if you already know F_{L}(x), you can </p> <p>find VaR by solving:</p>  F_{L}(x^{*}) = \\alpha \\rightarrow x^{*} = \\text{VaR}_{\\alpha}  <p>and find CVaR:</p>  \\text{CVaR}_{\\alpha} = \\mathbb{E}[L|L\\leq\\text{VaR}_{\\alpha}]  <p>Then you average all loeese up to the VaR threshold.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#recover-rate","title":"Recover Rate","text":"<p>The recovery rate is the percentages of defaulted debt that a lender can recover.[2]</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#bernoulli-variable","title":"Bernoulli Variable","text":"<p>A Bernoulli variable is a random variable with only two outcomes:</p> <ul> <li>1 if event happens, e.g. default.</li> <li>0 if event does not happen</li> </ul>  D_k \\sim \\text{Bernoulli}(p_{k}(z))  <p>This means that:</p> <ul> <li>D_k = 1: asset k defaults with probability p_{k}(z)</li> <li>D_k = 0: asset k survivies with probability 1 - p_{k}(z)</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#uncentainty-models","title":"Uncentainty Models","text":"<p>In finance, an uncertainty model referes to any mathematical or probabilistic framework used to quantify and manage unknowns espeically future outcomes that are not deterministic.</p> <p>We know that Finance is full of randomness, such as returns, defaults, interest rate, asset prices, and uncertainty models helps you describe, simulate, and price that radomness.</p> <p>Below are some common types of uncertainty models:</p> <ul> <li>Probabilistic models: This model uses distributuions to describe outcomes. For example: Value-at-Risk (VaR), default models. </li> <li>Stochastic models: This model uses random variables/ processes to model time evolution. For example: Black\u2013Scholes model for option pricing.</li> <li>Scenario-based model: This model define possible future paths or economic regiimes. For example, stress testing. </li> <li>Bayuesian models: This model combines prior beliefs with observed data. For example: Portfolio updating, risk estimation.</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#latent-variables-and-observables","title":"Latent Variables and Observables","text":"<p>Latent variables in finance refer to hidden forces\u2014such as investor sentiment, creditworthiness, or real earnings quality\u2014that influence market behavior but cannot be directly measured or retrieved from any financial terminal. Unlike observable quantities like stock prices, volumes, or P/E ratios, latent variables are not directly recorded. Instead, they must be inferred from patterns in observable data, which makes them essential yet elusive components in financial modeling.</p> <ul> <li>Observable variable: You see it directly, i,e,. stock price, trading volume, P/E ratio.</li> <li>Latent variable: Sits in the background, driving what you see, but you cannot measure it with a single gauge.</li> </ul> <p>These variables are typically abstract, multidimensional, and expressed only indirectly through their impact on observable metrics. For instance, a rise in market fear may cause VIX to spike, bond yields to fall, and equity prices to decline. None of these alone fully captures fear, but together they imply its presence. The problem is worsened by noise\u2014macroeconomic surprises, news shocks, and irregular market reactions\u2014making latent signals hard to isolate or measure cleanly.</p> <p>To extract latent variables, finance relies on statistical inference tools. Principal Component Analysis (PCA) can uncover dominant hidden drivers behind correlated movements. Factor models help decompose asset returns into exposure to unobserved risks. Kalman filters track time-varying latent states under noisy conditions. These techniques don\u2019t let us see the latent variables directly\u2014but they allow us to reconstruct and quantify them, enabling more robust understanding of markets and better decision-making under uncertainty.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_glossary/#reference","title":"Reference","text":"<p>[1]. https://en.wikipedia.org/wiki/Cumulative_distribution_function</p> <p>[2]. https://www.investopedia.com/terms/r/recovery-rate.asp</p> <p>[3]. https://en.wikipedia.org/wiki/Bernoulli_distribution</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/","title":"Credit Risk Analysis","text":""},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#problem-definition","title":"Problem definition","text":"<p>Suppose we are managing a credit risk porfolio with K assets. The default probability of every asset k follows the Gaussian Conditional Independnce model, i.e., given a value z sampled from a latent random variable Z following a standard normal distribution, the default probability of asset k can be described as</p>  p_{k}(z) = \\Phi \\bigg(\\frac{\\Phi^{-1}(p_{k}^{0} - \\sqrt{\\rho_k}z)}{\\sqrt{1-\\rho_{k}}} \\bigg)  <p>where \\Phi denotes the cumulative distribution function of Z, p_{k}^{0} is the default probability of asset k for z = 0 and \\rho_{k} is the sensitivity of the default probability of asset k with respect to Z. By giving a concrete realization of Z the individual default events are assumed to be independent from each other. </p> <p>Then, the topic we are interested in is measuring the total loss </p>  L = \\sum_{k=1}^{K}\\lambda_{k}X_{k}(Z)  <p>where \\lambda_k denotes the loss given default of asset k, and X_{k}(Z) denotes a Bernoulli variable representing the default event of asset k.</p> <p>In reality, we are insterested in the expected value \\mathbb{E}[L], the Value at Risk (VaR) of L and the Conditional Value at Risk of L. The VaR and CVaR are defined as </p>  \\text{VaR}_{\\alpha}(L) = \\text{inf}\\{x|\\mathbb{P}[L\\leq x] \\geq 1 - \\alpha\\}  <p>with confidence level \\alpha \\in [0,1], and </p>  \\text{CVaR}_{\\alpha}(L) = \\mathbb{E}[L|L \\geq \\text{VaR}_{\\alpha}(L)].  <p>where:</p> <ul> <li>number of qubits used to represent Z, denoted by n_z,</li> <li>truncation value for Z, denoted by z_\\text{max}, i.e., Z is assumed to take 2^{n_z} equidistant values in \\{-z_\\text{min}, \\cdots, z_\\text{max} \\},</li> <li>the base default probabilities for each asset p_0^{k} \\in (0,1), k = 1, \\cdots, K,</li> <li>sensitivities of the default probabilities with respect to Z, denoted by \\rho_k \\in [0,1),</li> <li>loss given default for asset k, denoted by \\lambda_k</li> <li>confidence level for VaR/CVaR \\alpha \\in [0,1]</li> </ul>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#uncertainty-model","title":"Uncertainty model","text":"<p>An uncertainty model is a methematical model that is used to quantify and manage unknowns espeically future outcomes that are not determinstic. Here, in our risk analysis, this uncertainty model can be achieved by creating a quantum state in a register of n_z qubits that represents Z following a standard normal distribution. This state is then used to control single qubit Y-rotations on a second qubit register of K qubits, where a |1\\rangle state of qubit k represents the default even of asset k. We can encode our quantum state |\\psi\\rangle into </p>  |\\psi\\rangle = \\sum_{i=0}^{2^{n_z}-1}\\sqrt{p_{z}^{i}}|z_{i}\\rangle \\bigotimes_{k=1}^{K}\\bigg( \\sqrt{1-p_{k}(z_{i})}|0\\rangle + \\sqrt{p_{k}(z_i)}|1\\rangle \\bigg),  <p>where we denote by z_i the i-th value of the discretized and truncated Z.</p> <p>See Qiskit GCI for how to construct this model using Qiskit. </p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#linear-approximation","title":"Linear Approximation","text":"<p>From Amplitude Estimation, we know that we want to encode a function p(x) </p>  p_{k}(z) = \\Phi \\bigg(\\frac{\\Phi^{-1}(p_{k}^{0} - \\sqrt{\\rho_k}z)}{\\sqrt{1-\\rho_{k}}} \\bigg)  <p>into a rotational angle in a quantum circuit</p>  \\theta_{k}(z) = 2\\text{sin}^{-1}(\\sqrt(p_k)(z)).  <p>This angle is needed to prepare a qubit state:</p>  \\sqrt{1-p_{k}(z)}|0\\rangle + \\sqrt{p_{k}(z)}|1\\rangle  <p>since the quantum gate Ry work with linear functions of the input register, we approximate around z = 0:</p>  \\theta_{k}(\\theta) \\approx \\text{slope}_k \\cdot z + \\text{offset}_k  <p>From [2], we can approximate using </p>  \\theta_k(z) = 2 \\arcsin\\left( \\sqrt{p_k(z)} \\right)  <p>Then you approximate this \\theta as:</p>  \\theta_k(z) \\approx \\underbrace{\\theta_k(0)}_{\\text{offset}} + \\underbrace{ \\left. \\frac{d\\theta_k}{dz} \\right|_{z=0} }_{\\text{slope}} \\cdot z"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#step-by-step","title":"Step by step","text":""},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#1-linear-dependency-between-risk-and-latent-factor","title":"1. Linear Dependency Between Risk and Latent Factor","text":"<p>From paper Regulatory Capital Modelling for Credit Risk, we know that given a firm k, the default probabilites and the latent vairable can be linearlized as </p>  X_k = a_{k} Z_{k} + b_k  <p>where X_k is the individual risk variables, Z is the latent variable, a_k, b_k are constants. </p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#2-default-event-modeling","title":"2. Default event Modeling","text":"<p>A firm defaults if its latent variable fall below a threshold:</p>  \\text{Firm Default if } X_{k} \\leq \\Phi^{-1}(p_{k}^{0})  <p>where p^{0}_{k} is the baseline (unconditional) default probability.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#3-conditional-default-probability-as-a-function-of-z","title":"3. Conditional Default Probability as a Function of Z","text":"<p>From above, the conditional probability that firm k defaults given Z = z is:</p>  p_{k}(z) = \\Phi\\bigg(\\frac{\\Phi^{-1}(p_{k}^{0}) - \\sqrt{\\rho_k}z}{\\sqrt{1-\\rho_{k}}} \\bigg)  <p>where \\Phi(z) is a standard normal CDF. This models how worsening economy (negative z) increases default probability.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#4-rotation-mapping-for-quantum-circuit","title":"4. Rotation Mapping for Quantum Circuit","text":"<p>In quantum, we want to prepare qubit amplitudes based on probabilities. Thus, we map p_{k}(z) into a rotation angle:</p>  \\theta_{k}(\\theta) = 2 \\text{sin}^{-1}(\\sqrt{p_{k}(z)})  <p>we must let rotation angle build qubit state with correct probability p_{k}(z).</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#5-problem-with-angle-rotation","title":"5. Problem with Angle Rotation","text":"<p>It's clear that above formula is nonlinear in z and \\text{sin}^{-1} introduces another nonlinearity. This is too complex for us for direct quantum control.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#6-linear-approximation-using-taylor-expansion","title":"6. Linear Approximation Using Taylor Expansion","text":"<p>We want to approximate \\theta_{k}(z) by first-order Taylor expansion around z = 0:</p>  \\theta_k(z) \\approx \\underbrace{\\theta_k(0)}_{\\text{offset}} + \\underbrace{ \\left. \\frac{d\\theta_k}{dz} \\right|_{z=0} }_{\\text{slope}} \\cdot z  <p>where \\theta_{k}(0) = 2 \\text{sin}^{-1}(\\sqrt{p_{k}(0)}) is the offset and \\frac{d\\theta_k}{dz} is the slope computed using chain rule.</p> <p>Here we go through the details of chain rule. We want to expand: </p>  \\theta_{k}(z) = 2 \\text{sin}^{-1}\\sqrt{p_{k}(z)}  <p>where </p>  p_{k}(z) = \\Phi\\bigg(\\frac{\\Phi^{-1}(p_{k}^{0}) - \\sqrt{\\rho_k}z}{\\sqrt{1-\\rho_{k}}} \\bigg)  <p>we compute the chain rule by </p>  \\frac{d\\theta_{k}}{dz} = \\frac{d\\theta_{k}}{dp_k} \\times \\frac{dp_{k}}{dz}  <p>where</p>  \\frac{d\\theta_{k}}{dp_k}= \\frac{d}{dp_k}\\bigg( 2 \\text{sin}^{-1}(\\sqrt{p_{k}(z)}) \\bigg) = \\frac{1}{\\sqrt{p_k(1- p_k)}}  <p>then \\frac{dp_{k}}{dz} is </p>  \\frac{dp_{k}}{dz} = \\frac{d}{dz}\\Phi\\bigg(\\frac{\\Phi^{-1}(p_{k}^{0}) - \\sqrt{\\rho_k}z}{\\sqrt{1-\\rho_{k}}} \\bigg) = -\\sqrt{\\rho_k} \\times \\frac{1}{1-\\rho_k} \\times \\phi \\bigg(\\frac{\\Phi^{-1}(p_{k}^{0}) - \\sqrt{\\rho_k}z}{\\sqrt{1-\\rho_{k}}} \\bigg)  <p>where \\phi(\\cdot) is the standard normal PDF. Since we expand our function around z = 0, </p>  \\psi = \\frac{\\Phi^{-1}(p_{k}^{0}) - \\sqrt{\\rho_k}0}{\\sqrt{1-\\rho_{k}}} = \\frac{\\Phi^{-1}(p_{k}^{0})}{\\sqrt{1-\\rho_{k}}}  <p>thus, </p>  \\left. \\frac{d\\theta_k}{dz} \\right|_{z=0}  = -\\sqrt{\\rho_k} \\times \\frac{1}{1-\\rho_k} \\times \\phi(\\psi)  <p>the final form of \\frac{d\\theta_{k}}{dz} = \\frac{d\\theta_{k}}{dp_k} \\times \\frac{dp_{k}}{dz} will be </p>  \\text{slope} = \\bigg(\\frac{1}{\\sqrt{p_k(0)(1 - p_{k}(0))}} \\bigg) \\times \\bigg( -\\sqrt{\\rho_k} \\times \\frac{1}{1-\\rho_k} \\times \\phi(\\psi)\\bigg)  <p>note that p_{k}(0) = \\Phi(\\psi) and \\phi(psi) is the standard normal pdf evaluated at \\psi.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#7-final-linear-form-for-quantum-amplitude-encoding","title":"7. Final Linear Form for Quantum Amplitude Encoding","text":"<p>After approximation:</p>  \\theta_{k}(z) \\approx \\text{offset}_{k} + \\text{slop}_{k} \\cdot z  <p>The quantum circuit can easily implement rotation \\text{RY}(\\theta_{k}) using only a simple linear function of the quantum register represenattaing z. In short,</p>  Z \\xrightarrow{ X_k = a_{k} Z_{k} + b_k} X_k \\xrightarrow{\\Phi(\\cdot)} p_{k}(Z) \\xrightarrow{2 \\text{sin}^{-1}\\sqrt{\\cdot}} \\theta_{k}(z) \\xrightarrow{\\text{Linear Approx}} \\text{Quantum Rotatopm RY}"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#8-scaling","title":"8. Scaling","text":""},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#motivation-why-do-we-shift-and-scale","title":"Motivation: Why Do We Shift and Scale?","text":"<p>In quantum circuits (like Qiskit's GCI model), quantum registers naturally hold integer states:</p>  i \\in [0, 2^n-1]  <p>But the real-world credit risk model operates in a continuous real domain:</p>  z \\in [-c, c]  <p>Our goal is to correctly map quantum integer states i to real systemic risk factors z and preserve the real-world meaning: systemic factor z drives default probabilities and quantum rotations.</p> <p>Adjusting for integer to normal range ensures that quantum integers correctly simulate real-world systemic risk factors in [-c,c].</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#step-1-shifting-centering","title":"Step 1: Shifting (Centering)","text":"<p>Problem:</p> <ul> <li>Quantum integers start from 0.</li> <li>Real z domain is centered at 0 ( -c to c).</li> </ul> <p>Solution:</p> <ul> <li>Shift i so that the middle integer maps to z = 0.</li> <li>Use shift:</li> </ul>  \\text{shift} = \\frac{2^n-1}{2}  <ul> <li>Adjust offset:</li> </ul>  \\text{offset} += \\text{real slope} \\times (-\\text{normal_max_value})"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#step-2-scaling-stretchingcompressing","title":"Step 2: Scaling (Stretching/Compressing)","text":"<p>Problem:</p> <ul> <li>Integer domain [0, 2^n-1] is not the same size as real [-c, c].</li> </ul> <p>Solution:</p> <ul> <li>Scale slope to match step sizes:</li> </ul>  \\text{scale factor} = \\frac{2c}{2^n-1}  <ul> <li>Adjust slope:</li> </ul>  \\text{slope} *= \\text{scale factor}"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#super-simple-example","title":"Super Simple Example","text":"<p>Given:</p> <ul> <li>c = 3</li> <li>n = 3 qubits \u2192 2^3 = 8 states</li> <li>Real slope = -0.02</li> <li>Real offset = 0.1</li> </ul> <p>Correct Process:</p> <ol> <li>Shift:</li> </ol>  \\text{offset} += (-0.02) \\times (-3) = 0.1 + 0.06 = 0.16  <ol> <li>Scale:</li> </ol>  \\text{scale factor} = \\frac{6}{7} \\approx 0.857   \\text{new slope} = (-0.02) \\times 0.857 \\approx -0.01714  <p>Now i=0 maps to z=-3 and i=7 maps to z=+3 correctly. Makesure you always adjust offset using real (unscaled) slope and only scale slope once after shifting. Thus, real-world meaning is preserved while quantum integers are mapped correctly into physical systemic factors z. Combininig shift and scale:</p>  z(i) = \\frac{2c}{2^{n}-1}\\bigg(i - \\frac{2^{n}-1}{2}\\bigg)  <p>Now the ==quantum states |i\\rangle==s behave as if they are sampling real z \\in [-c,c].</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#normal-distribution-quantum-circuit-modeling","title":"Normal Distribution Quantum Circuit Modeling","text":"<p>The probability density function of a normal distribution is defined as </p>  \\mathbb{P}(X = x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} e^{-\\frac{(x - \\mu)^2}{\\sigma^2}}  <p>Note that \\sigma^{2} is the variance. This is fro consistency with multivariate distributions, where the uppercase sigma \\Sigma is associated with the covariance.</p> <p>The circuit considers the discretized version of the normal distribution on 2^{\\text{num_qubits}} equidistant points, x_i, truncated to \\text{bonds}. For a one-dimensional random variable, which means the <code>num_qubits</code> is a single integer, it applies the operation </p>  \\mathcal{P}_X |0\\rangle^n = \\sum_{i=0}^{2^n - 1} \\sqrt{\\mathbb{P}(x_i)} |i\\rangle  <p>where n is <code>num_qubits</code>. The circuit loads the square root of the probabilities into the qubit amplitudes such that the sampling probability, which is the square of the amplitude, equals the probability of the distribution.</p> <p>In the multi-dimensional case, the distribution is defined as</p>  \\mathbb{P}(X = x) = \\frac{1}{\\sqrt{2\\pi\\Sigma^{2}}} e^{-\\frac{(x - \\mu)^2}{\\Sigma}}  <p>where \\Sigma is the covariance. To specify a multivariate normal distribution <code>num_qubits</code> is a list of integers, each specifying how many qubits are used to discretize the respective dimension. The arguments \\mu and \\sigma in this case are a vector and square matrix.</p> <p>If for instance, <code>num_qubits = [2, 3]</code> then \\mu is a 2d vector and \\sigma is the 2 \\times 2 covariance matrix. The first dimension is discretized using 2 qubits, hence on 4 points, and the second dimension on 3 qubits, hence 8 points. Therefore the random variable is discretized on 4 \\times 8 = 32 points.</p> <p>Since, in general, it is not yet known how to efficiently prepare the qubit amplitudes to represent a normal distribution, this class computes the expected amplitudes and then uses the <code>QuantumCircuit.initialize</code> method to construct the corresponding circuit.</p> <p>This circuit is for example used in amplitude estimation applications, such as finance [1, 2], where customer demand or the return of a portfolio could be modeled using a normal distribution.</p>"},{"location":"Projs/Projs_Opt/Proj_credit_risk_problem/#references","title":"References","text":"<p>[1]. https://qiskit-community.github.io/qiskit-finance/tutorials/09_credit_risk_analysis.html</p> <p>[2]. https://arxiv.org/abs/1412.1183</p>"},{"location":"Projs/Projs_Opt/Proj_iterative_amplitude_estimation/","title":"Iterative Amlitude Estimation","text":""},{"location":"Projs/Projs_Opt/Proj_iterative_amplitude_estimation/#quantum-amplitude-estimation","title":"Quantum Amplitude Estimation","text":"<p>An Operator \\mathcal{Q} is defined as </p>  \\mathcal{Q} = \\mathcal{A}\\mathcal{S}_{0}\\mathcal{A}^{\\dagger}\\mathcal{S}_{\\psi_{0}}  <p>where \\mathcal{S}_{\\psi_{0}} = \\mathbb{I} - 2 |\\psi_{0}\\rangle \\langle\\psi_{0}|\\otimes|0\\rangle\\langle0| and \\mathcal{S}_{0} = \\mathbb{I} - 2|0\\rangle_{n+1}\\langle0|_{n+1}.</p> <p>The cononical QAE follows the form of QPE: it usese m ancilla qubits - initialized in equal superposition - to represent the final result, it defines the number of quantum samples as M = 2^{m} and applies geometrically increasing powers of \\mathcal{Q} controlled by the ancillas. Followed by performing the QFT before they are measured. Then the measured integer y\\in \\{0,\\cdots,M-1 \\} is mapped to an angle \\tilde{\\theta_{a}} = y\\pi/M. Thereafter, the resulting estimate of a is defined as \\tilde{a} = \\text{sin}^{2}(\\tilde{\\theta_{a}}). The with a probability of at least 8/\\pi^{2} \\approx 81\\%, the estimate \\tilde{a} satisfies</p>  |a - \\tilde{a}| \\leq \\frac{2\\pi\\sqrt{a(1-a)}}{M}+\\frac{\\pi^{2}}{M^{2}},  <p>which implies the quadratic speedup over a classical MC simulation with an estimation error \\epsilon = \\mathcal{O}(1/M).</p> <p>All variants of QAE without QPE are based on the fact that </p>  \\mathcal{Q}^{k} \\mathcal{A}|0\\rangle_{n}|0\\rangle = \\text{cos}((2k+1)\\theta_{a})|\\psi_{0}\\rangle_{n}|0\\rangle + \\text{sin}((2k+1)\\theta_{a})|\\psi_{1}\\rangle_{n}|1\\rangle,  <p>where \\theta_{a} is defiend as a = \\text{sin}^{2}(\\theta_{a}). The probability of measuring |1\\rangle in the last qubit is given by</p>  \\mathbb{P}[|1\\rangle] = \\text{sin}^{2}((2k+1)\\theta_{a})."},{"location":"Projs/Projs_Opt/Proj_iterative_amplitude_estimation/#iterative-quantum-amplitude-estimation","title":"Iterative Quantum Amplitude Estimation","text":"<p>We use thee quantum computer to approximate \\mathbb{P}[|1\\rangle] = \\text{sin}^{2}((2k+1)\\theta_{a}) for the last qubit in \\mathcal{Q}^{k} \\mathcal{A}|0\\rangle_{n}|0\\rangle for different power k.</p> <p>Suppose a confidence interval [\\theta_{i},\\theta_{u}] \\subseteq [0, \\pi/2] for \\theta_{a} and a power k of \\mathcal{Q} as well as an esitmate for \\text{sin}^{2}((2k+1)\\theta_{a}). From trigonometric, we transform our estimate from \\text{sin}^{2}((2k+1)\\theta_{a}) into estimate for \\text{cos}^{2}((4k+2)\\theta_{a}) from the fact \\text{sin}^{2} = (1-\\text{cos}(2x))/2.</p> <p>One-to-one</p> <p>Here, we are trying to estimate \\theta_{a}, where: $$ a = \\text{sin}^{2}(\\theta_{a}) \\Rightarrow \\text{cos}((4k+2)\\theta_{2a}) $$ But \\text{cos} is not one-to-ont over [0,2\\pi]. To uniquely determine \\theta_{a} from \\text{cos}((4k+2)\\theta_{a}), we must ensure the possible value of ((4k+2)\\theta_{a}) {\\text{mod} \\ 2\\pi} fall entirely within either [0,\\pi] or [\\pi, 2\\pi]</p> <p>The one-to-one facts allows us to invert the cosine. If ((4k+2)\\theta_{a})_{\\text{mod} \\ 2\\pi} falls into [0,\\pi], cosine is decreasing, we said that inverse is unique, vice versa. An Iterative Amplitude Estimation picks a k such that </p>  ((4k+2)[\\theta_{l},\\theta_{u})] \\ {\\text{mod} \\ 2\\pi} \\subset [0,\\pi] \\ \\text{or} \\ [\\pi, 2\\pi]  <p>IAE:  -   Applying controlled Grover operations Q^{k}. -   Measuring \\text{cos}(K_{i}\\theta) -   Inverting to recover \\theta -   Narrowing your estimate iteratively</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/","title":"Quantum Amplitude Estimiation Introduction","text":"<p>Suppose a unitary operator \\mathcal{A} acts on a register of (n+1) qubits such that</p>  \\mathcal{A}|0 \\rangle_{n+1} = \\sqrt{1-a} |\\psi_{0} \\rangle_{n} |0\\rangle + \\sqrt{a}|\\psi_{1}\\rangle_{n}|1\\rangle,  <p>for some normalized states |\\psi_{0}\\rangle_{n} and |\\psi_{1}\\rangle_{n}, where a \\in [0,1] is unknown.</p> <p>Amplitude estimation allows us to efficiently estimate the value of a, i.e., the probability of measuring |1\\rangle in the last qubit. [2] This is done using an operator Q and Quantum Phase Estimation (QPE) [3], which helps approximate certain eigenvalues of Q.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#1-we-need-some-qubits","title":"1. We need some qubits!","text":"<p>Quantum Phase Estimation requires m additional qubits and M = 2^{m} applications of the operator Q. These m qubits are first put into an equal superposition using Hadamard gates. Then, this superposition is used to control different powers of Q\u2014each counting qubit controls a different Q^{2^j}.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#2-lets-do-the-inverse-fourier-transform","title":"2. Let\u2019s do the inverse Fourier transform","text":"<p>After applying the inverse Quantum Fourier Transform (QFT) to the m counting qubits, we measure them. This gives an integer outcome y \\in \\{0,\\dots,M-1\\}, which we map classically to an estimate \\widetilde{a}.</p> <p>The estimator \\widetilde{a} satisfies:</p>  \\begin{array}{ll} |a - \\widetilde{a}| &amp;\\leq \\frac{2\\sqrt{a(1-a)\\pi}}{M} + \\frac{\\pi^{2}}{M^{2}} \\\\ &amp;\\leq \\frac{\\pi}{M} + \\frac{\\pi^{2}}{M^{2}} = O(M^{-1}), \\end{array}  <p>with probability at least \\frac{8}{\\pi^2} \\approx 0.811. Below figure is the quantum circuit for constructing a Qauntum Amplitude Estimation.</p> <p>         Quantum circuit for amplitude estimation. \\(H\\) and is the Hadamard gate and \\(F^{\\dagger}_{m}\\) denotes the inverse Quantum Fourier Transform on m qubits.     </p> How to read this quantum circuit? <p>There are three sections in this quantum circuit:</p> <ol> <li> <p>Top m qubits:     These are the counting qubits (labeled from 0 to j to m{-}1 in the figure). They are used in the Quantum Counting Algorithm and Grover's Algorithm. Each qubit starts in the state |0\\rangle and is passed through a Hadamard gate. After the Hadamard transformation, the m qubits form an equal superposition:</p>  \\frac{1}{\\sqrt{2^{m}}} \\sum_{k=0}^{2^{m}-1} |k\\rangle.  <p>For example, if m = 2, we have an equal superposition state |\\psi\\rangle of:</p>  |\\psi\\rangle = \\frac{1}{2}(|0\\rangle+|1\\rangle+|2\\rangle+|3\\rangle).  </li> <li> <p>Middle n qubits:     This register is initialized as |0\\rangle^{\\otimes n} (denoted as |0\\rangle_n in the figure). It is used to encode computational basis states |i\\rangle drawn from a probability distribution p_i.</p> </li> <li> <p>Bottom 1 qubit (ancilla):     This single ancilla qubit encodes the value of the function f(i) \\in [0, 1] via a controlled rotation.</p> </li> </ol> What is operator A? <p>Operator A acts on the bottom n+1 wires:</p>  A|0\\rangle^{\\otimes (n+1)} \\mapsto \\sum_{i} \\sqrt{p_i}\\, |i\\rangle_{n} \\left( \\sqrt{1 - f(i)}\\,|0\\rangle + \\sqrt{f(i)}\\,|1\\rangle \\right)  <p>This operation prepares the quantum probability distribution and encodes the function f(i) into the amplitude of the ancilla qubit. A simultaneously acts on the n qubits representing the computational basis state |i\\rangle and the single ancilla qubit used to encode f(i).</p> What is operator Q? <p>Operator Q is the Grover diffusion operator, used in amplitude amplification. Each m qubit controls a different power of Q, which acts on the bottom n+1 register. Specifically:</p> <ul> <li>Q^{2^0} is controlled by counting qubit 0  </li> <li>Q^{2^j} is controlled by counting qubit j </li> <li>Q^{2^{m-1}} is controlled by the last counting qubit m{-}1</li> </ul> <p>These controlled powers of Q are part of the standard phase estimation procedure.</p> Inverse QFT F^{\\dagger}_{m}? <p>The inverse quantum Fourier transform, denoted F^{\\dagger}_{m}, is applied to the top m qubits. It is used to decode the phase information acquired during the controlled-Q operations. The eigenphase encodes the amplitude:</p>  a = \\mathbb{E}[f(X)]  <p>which is the expected value of the function f(i) under the distribution p_i. This step extracts the amplitude estimate after phase accumulation.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#3-finding-expected-value-the-quantum-way","title":"3. Finding Expected Value, the Quantum Way","text":"<p>In this section, we demonstrate how to use amplitude estimation to approximate the expected value of a discrete random variable encoded in a quantum state.</p> <p>Suppose we have the quantum state</p>  |\\psi\\rangle_{n} = \\sum_{i = 0}^{N-1} \\sqrt{p_{i}}\\,|i\\rangle_{n},  <p>where the probability of measuring the basis state |i\\rangle_{n} is p_{i} \\in [0,1], with \\sum_{i=0}^{N-1} p_{i} = 1 and N = 2^{n}. The state |i\\rangle_{n} represents one of N possible outcomes of a bounded discrete random variable X.</p> <p>For example, |i\\rangle might represent a discretized interest rate or the value of a portfolio. If n = 2, then i \\in \\{0, 1, 2, 3\\}, which could correspond to an interest rate of 0%, 1%, 2%, or 3%, respectively.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#4-apply-a-function-to-extract-useful-info","title":"4. Apply a Function to Extract Useful Info","text":"<p>Let\u2019s say we have a function f: \\{0, \\dots, N{-}1\\} \\rightarrow [0, 1] and define an operator:</p>  F: |i\\rangle_{n} |0\\rangle \\mapsto |i\\rangle_{n} \\left( \\sqrt{1 - f(i)}\\,|0\\rangle + \\sqrt{f(i)}\\,|1\\rangle \\right),  <p>which applies a controlled rotation on an ancilla qubit based on the value of f(i). </p> <p>Now apply this operator (F) to the quantum state |\\psi\\rangle_{n} |0\\rangle (|\\psi\\rangle_{n} = \\sum_{i = 0}^{N-1} \\sqrt{p_{i}}\\,|i\\rangle_{n}), and we get:</p>  \\sum_{i=0}^{N-1} \\sqrt{p_i}\\,|i\\rangle_{n} \\left( \\sqrt{1 - f(i)}\\,|0\\rangle + \\sqrt{f(i)}\\,|1\\rangle \\right).  <p>At this point, the probability of measuring |1\\rangle in the last qubit is:</p>  \\sum_{i=0}^{N-1} p_i f(i) = \\mathbb{E}[f(X)],  <p>which is exactly what we want to estimate. To do this, we simply square the amplitude of the last qubit |1\\rangle.</p> <p>Now for a few useful choices of f(i):</p> <ul> <li>If you use f(i) = i / (N - 1), you\u2019re estimating the normalized mean \\mathbb{E}[X / (N - 1)], and from that, you can recover \\mathbb{E}[X].</li> <li>If you use f(i) = i^2 / (N - 1)^2, you can estimate \\mathbb{E}[X^2] and then compute the variance:</li> </ul> <p>$$   \\text{Var}(X) = \\mathbb{E}[X^2] - \\left(\\mathbb{E}[X]\\right)^2   $$</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#5-how-to-evaluate-risk-measures-such-as-var-and-cvar","title":"5. How to evaluate risk measures such as VaR and CVaR","text":""},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#var","title":"VaR","text":"<p>For a given confidence level \\alpha \\in [0,1]. \\text{VaR}_{\\alpha}(X) (X is a random variable, can be loss or value) can be defined as the smallest value x \\in \\{0,\\cdots,N-1\\} such that \\mathbb{P}[X \\leq x]\\geq (1-\\alpha), which simply implies that with 1-\\alpha probability, losses will not exceed x. To find \\text{VaR}_{\\alpha}(X) on a quantum computer, we define the function </p>  f_l(i) =  \\begin{cases} 1 &amp; \\text{if } i \\leq l \\\\ 0 &amp; \\text{otherwise} \\end{cases}  <p>where l \\in \\{0,\\cdots,N-1\\}. Applying F_l, i.e. the operator corresponding to f_l. to |\\psi\\rangle_{n}|0\\rangle leads to the state $$ \\sum_{i = l+1}^{N-1}\\sqrt{p_i}|i\\rangle_{n}|0\\rangle+ \\sum_{i = 0}^{l}\\sqrt{p_i}|i\\rangle_{n}|1\\rangle. $$ The probability of measuring |1\\rangle for the last qubit is  $$ \\sum_{i=0}^{l}p_{i} = \\mathbb{P}[X \\leq l]. $$ Then use the binary search on l \\in \\{0,\\cdots,N-1 \\} in at most n steps to find the smallest l_{\\alpha} such that: $$ \\mathbb{P}[X \\leq l_{\\alpha}] \\geq 1 - \\alpha $$ This gives you the \\text{VaR}_{\\alpha}(X). This allows us to estimate \\text{VaR}_{\\alpha}(X) as before with accuracy O(M^{-1}).</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#cvar","title":"CVaR","text":"<p>\\text{CVaR}_{\\alpha}(X) is the conditional expectation of X restricted to \\{0,\\cdots,l_{\\alpha}\\}, where we compute l_{\\alpha} = \\text{VaR}_{\\alpha}(X) as before. To estimate CVaR we apply the operator F that corresponds to the function  $$ f(i) = \\frac{i}{l_{\\alpha}} \\cdot f_{l_{\\alpha}}(i) $$ to |\\psi\\rangle|0\\rangle, which leads to the state $$ \\bigg(\\sum_{i = l_{\\alpha}+1}^{N-1}\\sqrt{p_i}|i\\rangle_{n}|0\\rangle+ \\sum_{i = 0}^{l}\\sqrt{1 - \\frac{i}{l_{\\alpha}}}\\sqrt{p_i}|i\\rangle_{n}|1\\rangle\\bigg)|0\\rangle + \\sum_{i=0}^{l_{\\alpha}}\\sqrt{\\frac{i}{l_{\\alpha}}}\\sqrt{p_i}|i\\rangle_{n}|1\\rangle. $$ The probability of measuring |1\\rangle for the last qubit equals  $$ \\sum_{i=0}^{l_{\\alpha}}\\frac{i}{l_{\\alpha}}p_{i}, $$ which we approcimate using amplitude estimation. However, we know that \\sum_{i=0}^{l_{\\alpha}}p_{i} \\neq 1 but \\mathbb{P}[X\\leq l_{\\alpha}] as evaluated during the VaR estimation. Therefore, we mst normalize the probability of measuring |1\\rangle to get $$ \\text{CVaR}{\\alpha}(X) = \\frac{l. $$ We also multiplied by }}{\\mathbb{P}[X \\leq l_{\\alpha}]}\\sum_{i=0}^{l_{\\alpha}}\\frac{i}{l_{\\alpha}}p_{il_{\\alpha}, otherwise we would estimate \\text{CVaR}_{\\alpha}(\\frac{X}{l_{\\alpha}}). Even though we replace \\mathbb{P}[X \\leq l_{\\alpha}] by an estimation, the error on CVaR, shows that we still achieve a quadratic speed up compated to classical Monte Carlo methods.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#construction-of-quantum-circuit","title":"Construction of Quantum Circuit","text":"<p>Approximating \\mathbb{E} using amplitude estiamtion requires the operator F for f(x) = x/(N-1). In general, representing F for the expected value or for the CVaR either additional ancillas to pre-compute the (discretized) function f into qubits, using quantum arithmetic, before applying the rotation (ref)/ And the exact number of ancillas depends on the desired accuracy of the approximation of F. </p> <p>In the following, paper [1] will show how to approximate F without ancillas using polynomially many gates, at the cost of a lower - but still faster than classical - rate of convergence. Note that the operator required for estimating VaR is easier to construct and we can always achieve the optimal rate of convergence as discussed later.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#polynomial-approximate-quantum-circuit-without-ancillas","title":"Polynomial Approximate Quantum Circuit without Ancillas","text":"<p>The contribution in paper paper [1]. rests on the fact that an operator  $$ P: |x\\rangle_{n}|0\\rangle \\mapsto |x\\rangle_{n}(\\text{cos}(p(x))|0\\rangle + \\text{sin}(p(x))|1\\rangle) $$ for a given polynomial p(x) = \\sum_{j=0}^{k}p_{j}x^{j} of order k, can be efficiently constructed using multi-controlled Y-rotations.</p> <p>(image) *Here, we use qiskit for illustration, since Qiskit doesn't have native Ry-controlled gate with 2+ controlls, we use \\text{MCX}(q_{0},q_{1}) \\mapsto R_y(4a) \\mapsto \\text{MCX}(q_{0},q_{1}). See Qiskit Quantum library, for more infomation.</p> <p>In the single qubit operations with n-1 control qubits, it can be exactly constructed using O(n) gates and O(n) ancillas or O(n^{2}) gates without ancilla. Here, peper [1] uses O(n) gates and O(n) ancillas. Since the binary variable representation of p, leads to at most n^{k} terms, the operator P can be constructed using O(n^{k+1}) gates and O(n) ancillas.</p> <p>For every analytic function f, there exists a sequence of polynomials such that the approximation error converges exponentially fast to zero with increasing order of the polynomials [4]. </p> <p>If we can find a polynomial p(y) such that \\text{sin}^{2}(p(y)) = y, then we can set y=f(x), and the previous discussion provides a way to construct the operator F. Since the expected value is linear, we may choose to estimate \\mathbb{E}[c(f(X) - \\frac{1}{2}) + \\frac{1}{2}] instead of \\mathbb{E}[f(X)] for a parameter c\\in(0,1], and then map the result back to an estimatior for \\mathbb{E}[f(X)]. The rationale behind this choice is that \\text{sin}^{2}(y+\\frac{\\pi}{4}) = y+\\frac{1}{2} + O(y^3).</p> What is \\mathbb{E}[c(f(X) - \\frac{1}{2}) + \\frac{1}{2}] and Why? <p>By the linearity of expected value, we may define a function g(X) such that $$ g(X) := c(f(X) - \\frac{1}{2}) + \\frac{1}{2} \\Rightarrow \\mathbb{E}[g(X)] = c\\mathbb{E}[f(X)] + (\\frac{1}{2}+\\frac{c}{2}) $$ therefore, you can estiamte \\mathbb{E}[g(X)] (via amplitude estimation), you can solve for  $$ \\mathbb{E}[f(X)] = \\frac{1}{c}(\\mathbb{E}[g(X)]-\\frac{1}{2})+\\frac{1}{2}. $$ Paper [1] wants to approximate  $$ \\text{sin}^{2}\\bigg(cp(y) + \\frac{\\pi}{4} \\bigg) \\approx \\bigg( y - \\frac{1}{2}\\bigg) + \\frac{1}{2} $$</p> <ol> <li>The \\text{sin}^{2} term is how amplitude is encoded in a quantum circuit.</li> <li>We can map term \\bigg( y - \\frac{1}{2}\\bigg) + \\frac{1}{2} without ancilla on a quantum circuit. </li> </ol> Why this weird-looking expression? <p>Paper [1] wants to approximate  $$ \\text{sin}^{2}\\bigg(cp(y) + \\frac{\\pi}{4} \\bigg) \\approx \\bigg( y - \\frac{1}{2}\\bigg) + \\frac{1}{2} $$ And the reason is that 1. Function \\text{sin}^{2}(y+\\frac{\\pi}{4} \\approx y + \\frac{1}{2}) when y is small (Taylor expression). By doing this,</p> Why do we use c(f(x) - \\tfrac{1}{2}) + \\tfrac{1}{2} and how does it relate to amplitude estimation? <p>Quantum amplitude estimation (QAE) measures probabilities of the form: $$ a = \\sin^2(\\theta) \\quad \\Rightarrow \\quad \\theta = \\sin^{-1}(\\sqrt{a}) $$ To encode a desired probability a \\in [0,1], we prepare the state: $$ R_y(2\\theta)|0\\rangle = \\cos(\\theta)|0\\rangle + \\sin(\\theta)|1\\rangle $$ which yields: $$ P(|1\\rangle) = \\sin^2(\\theta) = a  (\\text{Born rule}) $$ So to encode a function f(x) as a measurable amplitude, we must construct a function p(x) such that: $$ \\sin^2(p(x)) = f(x) \\quad \\Rightarrow \\quad p(x) = \\sin^{-1}(\\sqrt{f(x)}) $$ But since arbitrary functions are hard to implement on quantum circuits, we use a polynomial approximation of this p(x). Instead of encoding f(x) directly, we approximate a more convenient form: $$ c(f(x) - \\tfrac{1}{2}) + \\tfrac{1}{2} $$ Why this form? Because of the Taylor expansion: $$ \\sin^2(y + \\tfrac{\\pi}{4}) = \\tfrac{1}{2} + y - \\tfrac{4y^3}{6} + \\cdots \\Rightarrow \\boxed{\\sin^2(y + \\tfrac{\\pi}{4}) \\approx \\tfrac{1}{2} + y} \\text{ for small } y $$ This motivates encoding: $$ \\sin^2(cp(f(x)) + \\tfrac{\\pi}{4}) \\approx c(f(x) - \\tfrac{1}{2}) + \\tfrac{1}{2} $$ - f(x) - \\tfrac{1}{2}: centers the value around 0 - c \\in (0,1]: scales down for small-angle accuracy - + \\tfrac{1}{2}: shifts result back to [0,1]</p> <p>This form enables accurate encoding of f(x) into amplitude using polynomially approximated quantum rotations.</p> <p>Thus, we want to find p(y) such that c(y - \\frac{1}{2}) + \\frac{1}{2} is sufficiently well approximated by \\text{sin}^{2}(cp(y)+\\frac{\\pi}{4}). Thus, we try to solve p(y) for  $$ c(y - \\frac{1}{2}) + \\frac{1}{2} = \\text{sin}^{2}(cp(y)+\\frac{\\pi}{4}) $$ we have  $$ p(y) = \\frac{1}{c}\\bigg(\\text{sin}^{-1}\\bigg(\\sqrt{c\\bigg( y - \\frac{1}{2}\\bigg) + \\frac{1}{2}}\\bigg)-\\frac{\\pi}{4}\\bigg) $$ and we choose p(y) as Taylor approximation of above equation around y = 1/2. From Taylor approximation, term y-1/2 makes a approximation an odd function and thus all sum of even function are zero. This approximation of order 2u+1 leads to a maximal approximation error for above equation of </p>  \\frac{c^{2u+3}}{(2u+3)2^{u+1}}+O(c^{2u+5}),  <p>for all y\\in[0,1].</p> Why are we constructing p(x) like this? <p>Amplitude estimation measures the probability: $$ a = \\sin^2(\\theta) \\Rightarrow \\theta = \\sin^{-1}(\\sqrt{a}) $$ To encode a target probability a \\in [0,1], we compute this angle \\theta and apply the rotation gate: $$ R_y(2\\theta)|0\\rangle = \\cos(\\theta)|0\\rangle + \\sin(\\theta)|1\\rangle $$ This creates a quantum state where the amplitude of |1\\rangle is \\sin(\\theta), so measuring the ancilla gives: $$ P(|1\\rangle) = \\sin^2(\\theta) = a $$ Therefore, to prepare an amplitude that reflects f(x), we construct p(x) such that: $$ p(x) = 2 \\cdot \\sin^{-1}(\\sqrt{f(x)}) $$ This lets amplitude estimation recover \\mathbb{E}[f(X)] through quantum measurement.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#convergence","title":"Convergence","text":""},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation/#reference","title":"Reference","text":"<ol> <li> <p>Quantum Amplitude Amplification and Estimation. Brassard et al., 2002. https://arxiv.org/abs/quant-ph/0005055</p> </li> <li> <p>Quantum Amplitude Amplification and Estimation, G. Brassard, P. Hoyer, M. Mosca, and A. Tapp, arXiv:0005055 (2000). https://arxiv.org/abs/quant-ph/0005055</p> </li> <li> <p>Quantum measurements and the Abelian Stabilizer Problem, A. Y. Kitaev (1995), https://arxiv.org/abs/quant-ph/9511026</p> </li> <li> <p>L. N. L. N. Trefethen, Approximation theory and approximation practice (2013), ISBN 1611972396.</p> </li> </ol>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/","title":"Constructing Quantum Circuit","text":""},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#constructing-quantum-circuit-in-amplitude-estimation","title":"Constructing Quantum Circuit in Amplitude Estimation","text":""},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#why-this-quantum-circuit-lets-start-over","title":"Why This Quantum Circuit? Let's Start Over","text":"<p>You may wonder, in the Paper [1]., why we are using such a specific structure for our quantum circuit. Let\u2019s step back and unpack the logic from the ground up.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#measuring-the-amplitude","title":"Measuring the Amplitude","text":"<p>In quantum mechanics, consider a single-qubit state of the form $$ |\\psi\\rangle = \\alpha |0\\rangle + \\beta |1\\rangle $$ where \\alpha, \\beta \\in \\mathbb{C} and the normalization condition holds: $$ |\\alpha|^2 + |\\beta|^2 = 1. $$ According to the Born rule, the amplitude of the state |1\\rangle is \\beta, but what we can actually measure is the probability: $$ P(|1\\rangle) = |\\beta|^2. $$ Probabilities must be real and non-negative. So we compute the square of the magnitude: $$ P = |\\text{amplitude}|^2 = (\\text{Re}[\\beta])^2 + (\\text{Im}[\\beta])^2. $$</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#encoding-fxfx-into-a-quantum-state","title":"Encoding f(x) into a Quantum State","text":"<p>Now here\u2019s the key idea. We want to encode a classical function f(x) into a quantum circuit in such a way that we can extract information about it via measurement. Specifically, we want the measurement probability of a certain basis state (say |1\\rangle) to be equal to f(x).</p> <p>So we aim to construct a quantum state such that: $$ |\\beta|^{2} = \\sin^2(p(x)) = f(x) $$ In this setup, p(x) is some function that encodes f(x) via the sine-squared map. Inverting this, we get: $$ p(x) = \\sin^{-1}\\left(\\sqrt{f(x)}\\right) $$ This is what we mean when we say \"encoding\" f(x) \u2014 we are constructing a rotation angle p(x) such that the probability of measuring |1\\rangle becomes exactly f(x).</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#but-why-polynomial-approximation","title":"But Why Polynomial Approximation?","text":"<p>The challenge is: arbitrary functions p(x) are generally hard to implement in quantum circuits directly. Quantum gates are discrete, hardware has finite resolution, and arbitrary-angle rotations are not feasible.</p> <p>So instead of directly implementing: $$ p(x) = \\sin^{-1}(\\sqrt{f(x)}) $$ we approximate it with a low-degree polynomial \u2014 something we can construct in a circuit using basic gates.</p> <p>That\u2019s the whole idea: translate classical functions into quantum-measurable quantities through amplitude encoding, using inverse trigonometric maps and approximations that play nicely with quantum hardware.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#ok-polynomial-approximation-but-why-it-looks-ugly","title":"Ok Polynomial Approximation, but why it looks ugly?","text":"<p>You certainly will have this type of question, why its must be this form c</p> <p>The form  $$ c(f(x)-\\frac{1}{2})+\\frac{1}{2} $$ is choosen carefully. We want to measure using \\text{sin}^{2}, so we manipulate the sine function to behave linearly. Let's start with the identity of \\text{sin}^{2}(\\theta): $$ \\text{sin}^{2}(\\theta) = \\frac{1-\\text{cos}(2\\theta)}{2} $$ therefore, $$ \\text{sin}^{2}(y+\\frac{\\pi}{4}) = \\frac{1-\\text{cos}(2y+\\frac{\\pi}{2})}{2} $$ and you must know that \\text{cos}(2y+\\frac{\\pi}{2}) = -\\text{sin}(2y), therefore $$ \\text{sin}^{2}(\\theta) = \\frac{1-\\text{cos}(2\\theta)}{2} = \\frac{1+\\text{sin}(2y)}{2}. $$ Now we expand \\text{sin}(2y) at y=0 using Taylor series expansion: $$ \\text{sin}(2y) = 2y - \\frac{(2y)^{3}}{3!} + \\frac{(2y)^{5}}{5!} - \\cdots = 2y - \\frac{4y^{3}}{3} + \\frac{8y^{5}}{15} - \\cdots $$ therefore $$ \\frac{1+\\text{sin}(2y)}{2} = \\frac{1}{2} + y - \\frac{2y^{3}}{3} + \\frac{4y^{5}}{15}. $$ now we only consider the linear term and omit the high order term, we have  $$ \\frac{1+\\text{sin}(2y)}{2} = \\frac{1}{2} + y $$ By replacing y into our f, we approximate  $$ \\frac{1+\\text{sin}(2y)}{2} = \\frac{1}{2} + y = f(x) + \\frac{1}{2} $$</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#ok-but-why-do-we-shift-function","title":"Ok but why do we shift function","text":"<p>You might wonder \u2014 doesn't shifting by \\frac{1}{2} push things into a nonlinear region?</p> <p>Actually, we do it on purpose.</p> <p>Taylor expansion is a local approximation \u2014 it's most accurate around the point it's expanded at. Since we expand \\sin^2(y + \\frac{\\pi}{4}) around y = 0, we need the input to stay close to 0.</p> <p>But in our case, f(x) \\in [0, 1], so we center it by subtracting \\frac{1}{2}: $$ f(x) - \\frac{1}{2} \\in [-0.5, 0.5] $$ Then, we scale with a small constant c to shrink the range: $$ c(f(x) - \\frac{1}{2}) \\in [-0.5c, 0.5c] $$ This keeps the input near 0 and improves the accuracy of the Taylor expansion.</p> <p>Finally, we add \\frac{1}{2} back to ensure the result is still within [0,1].</p> <p>     Linearization of \\(\\sin^2(y + \\pi/4)\\) near \\(y=0\\)     </p> <p>Now you may understand the key poltnominal approximation trick in paper [1]..</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Q_circuit/#reference","title":"Reference","text":"<ol> <li>Quantum Risk Analysis</li> </ol>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Var_n_CVaR/","title":"VaR and CVaR","text":""},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Var_n_CVaR/#estimating-var-with-qae","title":"Estimating VaR with QAE","text":"<p>A state \\psi\\rangle_{n} representing the distribution of a random variable X \\in \\{0,cdots, N-1\\}. To estimate VaR, you want to find a threshold l_\\alpha such that:</p>  \\mathbb{P}[X \\leq l_{\\alpha}] \\geq \\alpha  <p>so they define an operator F_{l} that flips an ancilla qubit if x\\leq l. Then we can use quantum amplitude etimation (QAE) to estimate:</p>  \\mathbb{P}[X \\leq l]  <p>and use a bisection search to find the smallest l such that the probability \\leq \\alpha. The result gives you \\text{VaR}_{\\alpha}(X)</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Var_n_CVaR/#estimating-cvar-using-var","title":"Estimating CVaR using VaR","text":"<p>Once you found the cutoff l_\\alpha, you now want </p>  \\text{CVaR}_{\\alpha}(X) = \\mathbb{E}[X|X\\leq l_{\\alpha}]  <p>you use the same circuit F_{l} to mark the tail region (where X \\leq l_{\\alpha}) and conditionally apply the operator F that encodes the function X into an amplitude. Then use QAE to copmute </p>  \\mathbb{E}[X|X\\leq l_{\\alpha}]"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Var_n_CVaR/#bisection-search","title":"Bisection Search","text":"<p>Suppose a university uses SAT scores to determine admissions. You want to estimate the cutoff SAT score such that 95% of applicants score below that value. This is essentially finding the 95th percentile in the score distribution. Your goal is to find the smallest SAT score such that </p>  \\text{admitted_perventage(score)} \\leq 95%  <p>Let's start with an initial score range with <code>low_scroe = 1000</code> (konwn to admit ~0%) and <code>high_score = 1600</code> (known to admit ~ 100%). Then we compute the middle </p>  \\text{mid_score} = \\frac{1000 + 1600}{2} = 1300  <p>then we plug in this <code>mid_score</code> into our Iterative Quantum Amplitude Estimation to evalute the probability. Suppose we have a out come of <code>80%</code>, which doesn't meet our requirement. Then we start a new search in upper half by updating the <code>lower_score = 1300</code>. Repeat this process untill, for example, we found a <code>mid = 1450</code> get <code>92%</code> and <code>mid = 1500</code> and get 96%. We then set the <code>high_score = 1500</code>. We repeat this process untill the interval is sufficiently small, for example, <code>score = 1492</code> and we get a probability of 95%.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_Var_n_CVaR/#cvar","title":"CVaR","text":"<p>FromConditional Value at Risk (investopedia) Since CVaR values are derived from the calcualtion of VaR itself, factors such as the shape of the distribution of retrun, the cut-off level used, and the periodicity of the data, and the assumptions about stochastic volatility, will affect the value of CVaR. Once the VaR has been calculated, we can derive our CVaR as </p>  \\text{CVaR}_{\\alpha} = \\frac{1}{1-\\alpha}\\int_{-1}^{\\text{VaR}_{\\alpha}} xp(x)dx  <p>where p(x)dx is the probability density of getting a return with value x, c is the cut-off point on the discritubtion where tha analyst sets the \\text{VaR} breakpoint, and lastly, \\text{VaR} is the agree-upon \\text{VaR} level. We can write this in a discrete form as </p>  \\text{CVaR}_{\\alpha} = \\frac{1}{1-\\alpha}\\sum_{x\\geq \\text{VaR}_{\\alpha}} xp(x)dx  <p>Definition: Conditional Value at Risk is the expected (average) loss, assuming that the loss has already exceeded the VaR threshold.</p> <p>Interpretation: </p> <p>\u201cIf the portfolio ends up in the worst 5% of outcomes, I expect an average loss of $3,500.\u201d</p> <p>Example: Continuing with the same portfolio: - 1-day 95% VaR = $2,000 - 1-day 95% CVaR = $3,500</p> <p>This means: If your loss does exceed $2,000, then on average, you could lose $3,500.</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_conv_accuracy/","title":"Convergence and Accuracy","text":""},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_conv_accuracy/#approximation-error","title":"Approximation Error","text":"<p>The Taylor approximation of order 2u+1 leads to a maximal approximation error for equation </p>  p(y) = \\frac{1}{c}\\bigg(\\text{sin}^{-1}\\bigg(\\sqrt{c\\bigg( y - \\frac{1}{2}\\bigg) + \\frac{1}{2}}\\bigg)-\\frac{\\pi}{4}\\bigg)  <p>to</p>  \\frac{\\pi}{M} + \\frac{c^{2u+3}}{(2u+3)2^{u+1}} + O(c^{2u+5})  <p>for all y\\in [0,1].Using amplitude estimation to estimate \\mathbb{E}[c(f(x) - \\frac{1}{2}) + \\frac{1}{2}] leads to a maximal error </p>  \\frac{\\pi}{M} + \\frac{c^{2u+3}}{(2u+3)2^{u+1}} + O(c^{2u+5} + M^{-2})  <p>where we ignore the higher order terms in the follwoing. Also, \\pi/M is the QAE resolution limit, \\frac{c^{2u+3}}{(2u+3)2^{u+1}} is the polynomial approximation error, and O(\\cdot) is the higher-order terms. Since our estimation uses cf(x), we have to consider the scaled error c\\epsilon, where \\epsilon&gt;0 denotes the resulting estimation error for \\mathbb{E}[f(X)]. Therefore,</p>  c\\epsilon  = \\frac{\\pi}{M} + \\frac{c^{2u+3}}{(2u+3)2^{u+1}}  <p>leads to</p>  c\\epsilon  - \\frac{c^{2u+3}}{(2u+3)2^{u+1}} = \\frac{\\pi}{M}.  <p>By minimizing the number of required M (M is the number of quantum queries or evaluation steps used in amplitude estimation) to achieve a target error \\epsilon, resulting in c^{*} = \\sqrt{2}\\epsilon^{\\frac{1}{2u+2}}. Plugging c^{*} back to above equation gives</p>  \\sqrt{2}\\bigg(1- \\frac{1}{2u+3}\\bigg)\\epsilon^{1+\\frac{1}{2u+2}} = \\frac{\\pi}{M}.  <p>From formula</p>  c\\epsilon  - \\frac{c^{2u+3}}{(2u+3)2^{u+1}} = \\frac{\\pi}{M}.  <p>we wants to minimize the error, which the first error is QAE error and the second one is Taylor truncation error. By setting these two the same, </p>  \\frac{c^{2u+3}}{(2u+3)2^{u+1}} = \\frac{\\pi}{M},  <p>we know that c \\varpropto M^{\\frac{-1}{2u+3}}. Since we already know that Quantum Amplitude Estimation has a error of</p>  \\epsilon  = |a - \\widetilde{1}| \\leq \\frac{\\pi}{M} + \\frac{\\pi^2}{M^2} = O(M^{-2})  <p>therefore, </p>  \\epsilon \\varpropto \\frac{1}{M}\\cdot M^{\\frac{-1}{2u+3}} = M^{-(1-\\frac{1}{2u+3})} = M^{-\\frac{2u+2}{2u+3}} = O(M^{-\\frac{2u+2}{2u+3}}).  <p>For u = 0, we get O(M^{-\\frac{2}{3}}), which is already better than the classical convergence rate of O(M^{-\\frac{1}{2}}). As u increase, we can get the convergence rate of nearly O(M^{-1}).</p>"},{"location":"Projs/Projs_Opt/Proj_quantum_amplitude_estimation_conv_accuracy/#variance","title":"Variance","text":"<p>When we evaluate variance \\text{Var}(X) = \\mathbb{E}[X^{2}] - \\mathbb{E}[X]^{2}, we apply the same idea but using \\text{sin}^{2}(y) \\varpropto y^{2}. The resulting convergence rate is again equal to O(M^{-\\frac{2u+2}{2u+3}}).</p>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/","title":"Air Traffic Control Problem - Optimal Runway Allocation for Single-Plane Assignments in a Multi-Runway Airport","text":"<ul> <li>Photo by Jeffry S.S. on Pexels</li> <li>Photo from Forbes</li> </ul> <p>The optimized runway schedule efficiently sequences aircraft operations, with Runway 1 managing Plane 1\u2019s landing and taxiing before Plane 4 lands while Plane 3 taxis, allowing Plane 3 to take off immediately after separation; Runway 2 coordinating Plane 6\u2019s taxi and takeoff while Plane 2 approaches and lands, ensuring Plane 8 is positioned for takeoff as soon as Plane 2 clears; and Runway 3 handling Plane 7\u2019s taxi and departure, followed by Plane 5\u2019s landing and Plane 9\u2019s final approach, maintaining continuous runway usage without interference or delays.</p> <p>This study presents a quantum-optimized scheduling framework for air traffic control, maximizing runway throughput while ensuring conflict-free sequencing of landings, taxiing, and takeoffs. Simulation results demonstrate optimized multi-runway utilization, where aircraft operations are strategically sequenced to prevent bottlenecks while adhering to FAA wake separation constraints. The scheduling model allows overlapping of non-conflicting phases, such as taxiing and approach, ensuring seamless transitions and minimizing idle runway time. Visualizations highlight how departures and arrivals are structured to maintain continuous runway availability, reducing congestion and enhancing operational efficiency. This quantum-driven scheduling framework offers scalability and real-time adaptability, making it a promising solution for high-density air traffic management. As quantum computing continues to evolve, this approach holds the potential to revolutionize air traffic control, improving global airspace efficiency, reducing delays, and optimizing fuel consumption through smarter, adaptive scheduling strategies. Applying a quadratic unconstrained binary optimization (QUBO) formulation, the approach natively adapts to quantum computing architectures.</p> <p>Beyond classical algorithms, this notebook explores quantum annealing techniques for Air Traffic Control optimization. The problem is encoded using binary variables (0 and 1). In quantum annealing, the objective is to find the minimum energy state by formulating the problem into a Hamiltonian form (Ising problem - Wiki). The Hamiltonian for this problem is given by:</p> <p>$$ H_{T}(\\bar{x}) = \\alpha h_1({\\bar{x}})+ \\beta h_2({\\bar{x}}) + \\gamma h_3({\\bar{x}}) + \\delta h_4({\\bar{x}}) $$</p> <p>where $\\alpha, \\beta, \\gamma, \\delta, \\epsilon$ are penalty parameters set to sufficiently large values $(&gt;0)$ to ensure that infeasible solutions do not have lower energy than the ground state(s).</p> <p>The goal is to find the minimum possible makespan associated with a given set of operational instances.</p> In\u00a0[1]: Copied! <pre># import docplex model\nfrom docplex.mp.model import Model\n</pre> # import docplex model from docplex.mp.model import Model <p>Here, we first define the flights in our air traffic control problem. We consider a single runway and five planes, each with specific operations.</p> In\u00a0[2]: Copied! <pre># Create CPLEX model \nmdl = Model(\"ACT Hamiltonian\")\n\n# Define time horizon (assuming max 12-time units for simplicity)\nT = 11 # 12 can have sep &gt; 2, bit it's still ok\n</pre> # Create CPLEX model  mdl = Model(\"ACT Hamiltonian\")  # Define time horizon (assuming max 12-time units for simplicity) T = 11 # 12 can have sep &gt; 2, bit it's still ok In\u00a0[3]: Copied! <pre># Define airplanes (jobs) with categorized flight patterns (operations)\n# These number are not arbitrary, do not reflect to the real scenario. \noperation_schedule = {\n    \"Plane1\":{\n        # --- Landing at runway #1\n        1: {\n            0: {\"phase\": \"Final approach\", \"time\": 2},\n            1: {\"phase\": \"Landing\", \"time\": 1},\n            2: {\"phase\": \"Taxiing to gate\", \"time\": 3},\n        }\n    },\n    \"Plane2\":{\n        # --- Landing at runway #2\n        2: {\n            3: {\"phase\": \"Final approach\", \"time\": 3},\n            4: {\"phase\": \"Landing\", \"time\": 1},\n            5: {\"phase\": \"Taxiing to gate\", \"time\": 2},\n        },\n    },\n    \"Plane3\":{\n        # --- Takeoff at runway #1\n        1: {\n            6: {\"phase\": \"Taxiing to runway\", \"time\": 4},\n            7: {\"phase\": \"Takeoff\", \"time\": 1},\n            8: {\"phase\": \"Departure\", \"time\": 2}\n        }\n    },\n    \"Plane4\":{\n        # --- Landing at runway #1\n        1:{\n            9: {\"phase\": \"Final approach\", \"time\": 2},\n            10: {\"phase\": \"Landing\", \"time\": 1},\n            11: {\"phase\": \"Taxiing to gate\", \"time\": 3}\n        },\n    },\n    \"Plane5\":{\n        # --- Landing at runway #3\n        3: {\n            12: {\"phase\": \"Final approach\", \"time\": 4},\n            13: {\"phase\": \"Landing\", \"time\": 1},\n            14: {\"phase\": \"Taxiing to gate\", \"time\": 3}\n        }\n    },\n    \"Plane6\":{\n        # --- Takeoff at runway #2\n        2: {\n            15: {\"phase\": \"Taxiing to runway\", \"time\": 5},\n            16: {\"phase\": \"Takeoff\", \"time\": 1},\n            17: {\"phase\": \"Departure\", \"time\": 2}\n        },\n    },\n    \"Plane7\":{\n        # --- Takeoff at runway #3\n        3: {\n            18: {\"phase\": \"Taxiing to runway\", \"time\": 5},\n            19: {\"phase\": \"Takeoff\", \"time\": 1},\n            20: {\"phase\": \"Departure\", \"time\": 2}\n        }        \n    },\n    \"Plane8\":{\n        # --- Takeoff at runway #2\n        2: {\n            21: {\"phase\": \"Taxiing to runway\", \"time\": 6},\n            22: {\"phase\": \"Takeoff\", \"time\": 1},\n            23: {\"phase\": \"Departure\", \"time\": 1}\n        }        \n    },\n    \"Plane9\":{\n        # --- Landing at runway #3\n        3: {\n            24: {\"phase\": \"Final approach\", \"time\": 5},\n            25: {\"phase\": \"Landing\", \"time\": 1},\n            26: {\"phase\": \"Taxiing to gate\", \"time\": 3}\n        }        \n    },\n}\n</pre> # Define airplanes (jobs) with categorized flight patterns (operations) # These number are not arbitrary, do not reflect to the real scenario.  operation_schedule = {     \"Plane1\":{         # --- Landing at runway #1         1: {             0: {\"phase\": \"Final approach\", \"time\": 2},             1: {\"phase\": \"Landing\", \"time\": 1},             2: {\"phase\": \"Taxiing to gate\", \"time\": 3},         }     },     \"Plane2\":{         # --- Landing at runway #2         2: {             3: {\"phase\": \"Final approach\", \"time\": 3},             4: {\"phase\": \"Landing\", \"time\": 1},             5: {\"phase\": \"Taxiing to gate\", \"time\": 2},         },     },     \"Plane3\":{         # --- Takeoff at runway #1         1: {             6: {\"phase\": \"Taxiing to runway\", \"time\": 4},             7: {\"phase\": \"Takeoff\", \"time\": 1},             8: {\"phase\": \"Departure\", \"time\": 2}         }     },     \"Plane4\":{         # --- Landing at runway #1         1:{             9: {\"phase\": \"Final approach\", \"time\": 2},             10: {\"phase\": \"Landing\", \"time\": 1},             11: {\"phase\": \"Taxiing to gate\", \"time\": 3}         },     },     \"Plane5\":{         # --- Landing at runway #3         3: {             12: {\"phase\": \"Final approach\", \"time\": 4},             13: {\"phase\": \"Landing\", \"time\": 1},             14: {\"phase\": \"Taxiing to gate\", \"time\": 3}         }     },     \"Plane6\":{         # --- Takeoff at runway #2         2: {             15: {\"phase\": \"Taxiing to runway\", \"time\": 5},             16: {\"phase\": \"Takeoff\", \"time\": 1},             17: {\"phase\": \"Departure\", \"time\": 2}         },     },     \"Plane7\":{         # --- Takeoff at runway #3         3: {             18: {\"phase\": \"Taxiing to runway\", \"time\": 5},             19: {\"phase\": \"Takeoff\", \"time\": 1},             20: {\"phase\": \"Departure\", \"time\": 2}         }             },     \"Plane8\":{         # --- Takeoff at runway #2         2: {             21: {\"phase\": \"Taxiing to runway\", \"time\": 6},             22: {\"phase\": \"Takeoff\", \"time\": 1},             23: {\"phase\": \"Departure\", \"time\": 1}         }             },     \"Plane9\":{         # --- Landing at runway #3         3: {             24: {\"phase\": \"Final approach\", \"time\": 5},             25: {\"phase\": \"Landing\", \"time\": 1},             26: {\"phase\": \"Taxiing to gate\", \"time\": 3}         }             }, } In\u00a0[4]: Copied! <pre># Let's recall how to get dictionary element first\nfor plane in operation_schedule:\n    print(f\"Plane: {plane}\")\n    for runway in operation_schedule[plane]:\n        print(f\" -&gt; Availiable Runway: {runway}\")\n        for operation in operation_schedule[plane][runway]:\n            print(f\"  -&gt; operations {operation} \" + f\"{operation_schedule[plane][runway][operation]}\")\n            \n    \n</pre> # Let's recall how to get dictionary element first for plane in operation_schedule:     print(f\"Plane: {plane}\")     for runway in operation_schedule[plane]:         print(f\" -&gt; Availiable Runway: {runway}\")         for operation in operation_schedule[plane][runway]:             print(f\"  -&gt; operations {operation} \" + f\"{operation_schedule[plane][runway][operation]}\")                   <pre>Plane: Plane1\n -&gt; Availiable Runway: 1\n  -&gt; operations 0 {'phase': 'Final approach', 'time': 2}\n  -&gt; operations 1 {'phase': 'Landing', 'time': 1}\n  -&gt; operations 2 {'phase': 'Taxiing to gate', 'time': 3}\nPlane: Plane2\n -&gt; Availiable Runway: 2\n  -&gt; operations 3 {'phase': 'Final approach', 'time': 3}\n  -&gt; operations 4 {'phase': 'Landing', 'time': 1}\n  -&gt; operations 5 {'phase': 'Taxiing to gate', 'time': 2}\nPlane: Plane3\n -&gt; Availiable Runway: 1\n  -&gt; operations 6 {'phase': 'Taxiing to runway', 'time': 4}\n  -&gt; operations 7 {'phase': 'Takeoff', 'time': 1}\n  -&gt; operations 8 {'phase': 'Departure', 'time': 2}\nPlane: Plane4\n -&gt; Availiable Runway: 1\n  -&gt; operations 9 {'phase': 'Final approach', 'time': 2}\n  -&gt; operations 10 {'phase': 'Landing', 'time': 1}\n  -&gt; operations 11 {'phase': 'Taxiing to gate', 'time': 3}\nPlane: Plane5\n -&gt; Availiable Runway: 3\n  -&gt; operations 12 {'phase': 'Final approach', 'time': 4}\n  -&gt; operations 13 {'phase': 'Landing', 'time': 1}\n  -&gt; operations 14 {'phase': 'Taxiing to gate', 'time': 3}\nPlane: Plane6\n -&gt; Availiable Runway: 2\n  -&gt; operations 15 {'phase': 'Taxiing to runway', 'time': 5}\n  -&gt; operations 16 {'phase': 'Takeoff', 'time': 1}\n  -&gt; operations 17 {'phase': 'Departure', 'time': 2}\nPlane: Plane7\n -&gt; Availiable Runway: 3\n  -&gt; operations 18 {'phase': 'Taxiing to runway', 'time': 5}\n  -&gt; operations 19 {'phase': 'Takeoff', 'time': 1}\n  -&gt; operations 20 {'phase': 'Departure', 'time': 2}\nPlane: Plane8\n -&gt; Availiable Runway: 2\n  -&gt; operations 21 {'phase': 'Taxiing to runway', 'time': 6}\n  -&gt; operations 22 {'phase': 'Takeoff', 'time': 1}\n  -&gt; operations 23 {'phase': 'Departure', 'time': 1}\nPlane: Plane9\n -&gt; Availiable Runway: 3\n  -&gt; operations 24 {'phase': 'Final approach', 'time': 5}\n  -&gt; operations 25 {'phase': 'Landing', 'time': 1}\n  -&gt; operations 26 {'phase': 'Taxiing to gate', 'time': 3}\n</pre> In\u00a0[5]: Copied! <pre># Define binary variables x[i,t] (1 if operation i starts at time t, 0 otheRwise)\nx = {(i,t,runway): mdl.binary_var(name=f\"x_{i}_{t}_{runway}\") \n     for plane in operation_schedule \n     for runway in operation_schedule[plane] \n     for i in operation_schedule[plane][runway] \n     for t in range(T)}\n#print(x)\n\n# Total of T x i length of binary variable\nprint(f\"Total number of binary variables: {len(x)}\")\n</pre> # Define binary variables x[i,t] (1 if operation i starts at time t, 0 otheRwise) x = {(i,t,runway): mdl.binary_var(name=f\"x_{i}_{t}_{runway}\")       for plane in operation_schedule       for runway in operation_schedule[plane]       for i in operation_schedule[plane][runway]       for t in range(T)} #print(x)  # Total of T x i length of binary variable print(f\"Total number of binary variables: {len(x)}\") <pre>Total number of binary variables: 297\n</pre> <p>In this step, we formulate the Quadratic Unconstrained Binary Optimization (QUBO) model for Air Traffic Control using Quantum Annealing.</p> <p>To make sure every opeartions in every plane is executed, We can construct a formula as</p> <p>$$ \\sum_{i} \\sum_{t} x_{i,t,r} = 1, \\forall r \\in R_\\text{assigned runway} $$</p> <p>therefore, we can write our penalty term as</p> <p>$$ h_1 = \\sum_{r} \\bigg( \\sum_{i} \\sum_{t} x_{i,t,r} - 1 \\bigg)^{2} $$</p> In\u00a0[6]: Copied! <pre># Constraint 1: Runway Utilization \u2013 Only one aircraft can occupy a runway at any given time for takeoff or landing.\n\nh_1 = mdl.sum(\n    (mdl.sum(x[i, t, r] \n             for r in operation_schedule[plane] \n             if i in operation_schedule[plane][r]  # Ensure operation i exists on runway r\n             for t in range(T)) - 1) ** 2\n    for plane in operation_schedule\n    for r in operation_schedule[plane] \n    for i in operation_schedule[plane][r]  # Only iterate over valid i for runway r\n)\n\n# print h_1\n#print(h_1)\n</pre> # Constraint 1: Runway Utilization \u2013 Only one aircraft can occupy a runway at any given time for takeoff or landing.  h_1 = mdl.sum(     (mdl.sum(x[i, t, r]               for r in operation_schedule[plane]               if i in operation_schedule[plane][r]  # Ensure operation i exists on runway r              for t in range(T)) - 1) ** 2     for plane in operation_schedule     for r in operation_schedule[plane]      for i in operation_schedule[plane][r]  # Only iterate over valid i for runway r )  # print h_1 #print(h_1) <p>To enforce the correct sequence of operations within a job, each aircraft (job $n$) must complete operation $O_i$ before starting $O_{i+1}$. To penalize violations of this rule, we introduce a penalty term:</p> <p>$$ \\sum_{k_{n-1}&lt;i&lt;k_{N},\\ t+p_{i}&gt;t'} x_{i,t,r} x_{i+1,t',r}, \\quad \\text{for each plane } (n), \\text{ for each runway } (r) $$</p> <p>The corresponding penalty function $h_2$ is given by:</p> <p>$$ h_2 = \\sum_{r} \\sum_{n} \\sum_{k_{n-1}&lt;i&lt;k_{N},\\ t+p_{i}&gt;t'} x_{i,t,r} x_{i+1,t',r} $$</p> <p>This ensures that no aircraft starts a new operation before completing the previous one.</p> <p>Here, careful handling of the $i$ indexing is required. Since each job consists of three operations $O_1, O_2, O_3$, we must omit the last operation $O_3$ in each job, as it has no successor. Failing to exclude the last operation may result in out-of-bounds indexing errors.</p> In\u00a0[7]: Copied! <pre># Constraint 2: An aircraft's next operation cannot begin until the previous one is completed.\nh_2 = mdl.sum(\n    x[i,t,r] * x[i+1,t_prime,r]\n    for plane in operation_schedule\n    for r in operation_schedule[plane] \n    for i in list(operation_schedule[plane][r].keys())[:-1] # Opeartionas with in each job k_{n-1} &lt; i &lt; k_{N}\n    for t in range(T)\n    for t_prime in range(T)\n    if t + operation_schedule[plane][r][i][\"time\"] &gt; t_prime\n)\n#print(h_2)\n</pre> # Constraint 2: An aircraft's next operation cannot begin until the previous one is completed. h_2 = mdl.sum(     x[i,t,r] * x[i+1,t_prime,r]     for plane in operation_schedule     for r in operation_schedule[plane]      for i in list(operation_schedule[plane][r].keys())[:-1] # Opeartionas with in each job k_{n-1} &lt; i &lt; k_{N}     for t in range(T)     for t_prime in range(T)     if t + operation_schedule[plane][r][i][\"time\"] &gt; t_prime ) #print(h_2) <p>For any plane, there must be no gap between each flight pattern $$ \\sum_{k_{n-1}&lt;i&lt;k_{N},\\ t+p_{i}\\neq t'} x_{i,t} x_{i+1,t'},\\ \\text{for each runway ($r$)} $$ and we can have a penalty term $(h_3)$ of $$ h_3 = \\sum_{r}\\bigg({\\sum_{k_{n-1}&lt;i&lt;k_{N},\\ t+p_{i} \\neq t'} x_{i,t} x_{i+1,t'}}\\bigg) $$</p> In\u00a0[8]: Copied! <pre># Constraint 3: For any plane, no gap between each flight pattern.\n# To ensure the order of the operations within a job are enforced.\nh_3 = mdl.sum(\n    x[i,t,r] * x[i+1,t_prime,r]\n    for plane in operation_schedule\n    for r in operation_schedule[plane] \n    for i in list(operation_schedule[plane][r].keys())[:-1] # Opeartionas with in each job k_{n-1} &lt; i &lt; k_{N}\n    for t in range(T)\n    for t_prime in range(T)\n    if t + operation_schedule[plane][r][i][\"time\"] != t_prime\n)\n#print(h_3)\n</pre> # Constraint 3: For any plane, no gap between each flight pattern. # To ensure the order of the operations within a job are enforced. h_3 = mdl.sum(     x[i,t,r] * x[i+1,t_prime,r]     for plane in operation_schedule     for r in operation_schedule[plane]      for i in list(operation_schedule[plane][r].keys())[:-1] # Opeartionas with in each job k_{n-1} &lt; i &lt; k_{N}     for t in range(T)     for t_prime in range(T)     if t + operation_schedule[plane][r][i][\"time\"] != t_prime ) #print(h_3) <p>For every landing or takeoff phase, we must ensure separation constraints by excluding cases where the next runway usage starts before the required separation time $t_{sep}$. That is, $$ \\sum_{(i,k,k,t')\\in R_w}x_{\\text{i},t,r} \\ x_{\\text{k},t',r}, \\text{for each runway $r$} $$ where $ \\text{Rw}_m = i_\\text{takeoff} \\ \\cup \\ i_\\text{landing}$. We can have a penalty term $(h_4)$ of $$ h_4 = \\sum_{r} \\bigg( \\sum_{(i,k,k,t')\\in R_w}x_{\\text{i},t,r} \\ x_{\\text{k},t',r}\\bigg) $$ where $R_w = \\{(i,k,k,t'): I_{m}^{r} \\times I_{m}^{r},\\ t_\\text{landing}+t_{sep} + p_i &gt; t'\\}$ $t'$: the next operation starts at time $t'$.</p> <p>Here is the step by step on how construct this set:</p> <ol> <li>Sum over all runways $(r)$.</li> <li>Identify all operations $(i, k)$ that require separation (Landing/Takeoff).</li> <li>Ensure that if i happens at $t$, then $k$ must not start at $t'$ unless $t' \u2265 t + t_\\text{sep}.$</li> <li>Penalize cases where two operations are scheduled too closely on the same runway.</li> </ol> In\u00a0[9]: Copied! <pre># Let's See how to extract operations that using runway (no matter which runway)\nRunway = [i \n          for plane in operation_schedule \n          for runway in operation_schedule[plane] \n          for i, operation in operation_schedule[plane][runway].items() if operation[\"phase\"] in [\"Landing\", \"Takeoff\"]]\nprint(Runway)\n</pre> # Let's See how to extract operations that using runway (no matter which runway) Runway = [i            for plane in operation_schedule            for runway in operation_schedule[plane]            for i, operation in operation_schedule[plane][runway].items() if operation[\"phase\"] in [\"Landing\", \"Takeoff\"]] print(Runway) <pre>[1, 4, 7, 10, 13, 16, 19, 22, 25]\n</pre> In\u00a0[10]: Copied! <pre># constraint 4: Aircraft must adhere to wake turbulence separation.\n\n# runway must be cleared with at least t_sep = 1 time unit before next landing or taking off\nt_sep = 1\n\nRw = [(i,t,k,t_prime,r)\n      for r in {r for plane in operation_schedule for r in operation_schedule[plane]}  # Iterate over unique runways\n      for plane1 in operation_schedule\n      if r in operation_schedule[plane1]  # Ensure runway exists for this plane\n      for i, operation1 in operation_schedule[plane1][r].items() if operation1[\"phase\"] in [\"Landing\", \"Takeoff\"]\n      for plane2 in operation_schedule  # Compare with all planes, including same-plane conflicts\n      if r in operation_schedule[plane2]  # Ensure runway exists for this plane\n      for k, operation2 in operation_schedule[plane2][r].items() if operation2[\"phase\"] in [\"Landing\", \"Takeoff\"]\n      #---\n      if i != k \n      for t in range(T)\n      for t_prime in range(T) if t_prime &lt; t + operation_schedule[plane1][r][i][\"time\"] + t_sep # makesure only one plane using the runway at the time\n      #---\n      ]\n\n# Show runway conflict combinations: no runway separation cases.\n#print(f\"Runway conflicts cases (i,t,k,t',r):\\n{Rw}\") \nh_4 = mdl.sum(x[i,t,r] * x[k,t_prime,r] for (i,t,k,t_prime,r) in Rw) \n                      \n#print(h_4)\n</pre> # constraint 4: Aircraft must adhere to wake turbulence separation.  # runway must be cleared with at least t_sep = 1 time unit before next landing or taking off t_sep = 1  Rw = [(i,t,k,t_prime,r)       for r in {r for plane in operation_schedule for r in operation_schedule[plane]}  # Iterate over unique runways       for plane1 in operation_schedule       if r in operation_schedule[plane1]  # Ensure runway exists for this plane       for i, operation1 in operation_schedule[plane1][r].items() if operation1[\"phase\"] in [\"Landing\", \"Takeoff\"]       for plane2 in operation_schedule  # Compare with all planes, including same-plane conflicts       if r in operation_schedule[plane2]  # Ensure runway exists for this plane       for k, operation2 in operation_schedule[plane2][r].items() if operation2[\"phase\"] in [\"Landing\", \"Takeoff\"]       #---       if i != k        for t in range(T)       for t_prime in range(T) if t_prime &lt; t + operation_schedule[plane1][r][i][\"time\"] + t_sep # makesure only one plane using the runway at the time       #---       ]  # Show runway conflict combinations: no runway separation cases. #print(f\"Runway conflicts cases (i,t,k,t',r):\\n{Rw}\")  h_4 = mdl.sum(x[i,t,r] * x[k,t_prime,r] for (i,t,k,t_prime,r) in Rw)                         #print(h_4)  <p>This is a essential part for constructing runway sepeartion constraint</p> <pre>for r in {r for plane in operation_schedule for r in operation_schedule[plane]} # Iterate over unique runways\n</pre> <ul> <li><code>{r for plane in operation_schedule for r in operation_schedule[plane]}</code>:</li> <li>First <code>for plane in operation_schedule</code> -&gt;  Iterates over all planes.</li> <li>Second <code>for r in operation_schedule[plane]</code> -&gt;  Extracts all runways used by that plane.</li> <li><code>{}</code> creates a set, so duplicate runways are automatically removed.</li> </ul> <p>This implementation ensures:</p> <ol> <li>we process each runway once, no matter how many planes use it.</li> <li>Prevents redundant calculations when checking separation constraints.</li> </ol> <p>The resulting classical objective function (Hamiltonian) is given by $$ H_{T}(\\bar{x}) = \\alpha h_1({\\bar{x}})+ \\beta h_2({\\bar{x}}) + \\gamma h_3({\\bar{x}}) + \\delta h_4({\\bar{x}}) $$ where $\\alpha, \\beta, \\gamma$, and $\\delta$ are penalty parameters that must be set to a large number to $(&gt;0)$ in order to ensure that unfeasible solutions do not have larger a lower energy than the ground state(s).</p> In\u00a0[11]: Copied! <pre># Select penalty parameters\nalpha = 1.5 # Each operation must be executed once and only once.\nbeta = .5 # An aircraft's next opeartion cannot begin until the previous one is completed.\ngamma = 1.1 # For any plane, no gap between each flight pattern.\ndelta = .7 # Aircraft must adhere to wake turbulence seperation.\n</pre> # Select penalty parameters alpha = 1.5 # Each operation must be executed once and only once. beta = .5 # An aircraft's next opeartion cannot begin until the previous one is completed. gamma = 1.1 # For any plane, no gap between each flight pattern. delta = .7 # Aircraft must adhere to wake turbulence seperation. In\u00a0[12]: Copied! <pre># Establish Hamiltonian (objective function)\nH_T = (alpha * h_1 + beta * h_2 + gamma * h_3 + delta * h_4)\nmdl.minimize(H_T)\n\n# Solve model\nsolution = mdl.solve()\n\nprint(solution)\n</pre> # Establish Hamiltonian (objective function) H_T = (alpha * h_1 + beta * h_2 + gamma * h_3 + delta * h_4) mdl.minimize(H_T)  # Solve model solution = mdl.solve()  print(solution) <pre>solution for: ACT Hamiltonian\nobjective: 6.3\nstatus: OPTIMAL_SOLUTION(2)\nx_0_0_1=1\nx_1_2_1=1\nx_2_3_1=1\nx_3_4_2=1\nx_4_7_2=1\nx_5_8_2=1\nx_6_2_1=1\nx_7_6_1=1\nx_8_7_1=1\nx_9_2_1=1\nx_10_4_1=1\nx_11_5_1=1\nx_12_3_3=1\nx_13_7_3=1\nx_14_8_3=1\nx_15_0_2=1\nx_16_5_2=1\nx_17_6_2=1\nx_18_0_3=1\nx_19_5_3=1\nx_20_6_3=1\nx_21_3_2=1\nx_22_9_2=1\nx_23_10_2=1\nx_24_4_3=1\nx_25_9_3=1\nx_26_10_3=1\n\n</pre> In\u00a0[13]: Copied! <pre># Extract solution values\nschedule = []\nfor var in mdl.iter_variables():\n    if var.solution_value &gt; 0.5:  # Operation is scheduled\n        name_parts = var.name.split(\"_\")  # Example: \"x_1_3_1\" -&gt; [\"x\", \"1\", \"3\", \"1\"]\n        op_id = int(name_parts[1])  # Operation index\n        start_time = int(name_parts[2])  # Start time\n        runway = int(name_parts[3])  # Runway\n        schedule.append((op_id, start_time,runway))\n\n#print(schedule)\n</pre> # Extract solution values schedule = [] for var in mdl.iter_variables():     if var.solution_value &gt; 0.5:  # Operation is scheduled         name_parts = var.name.split(\"_\")  # Example: \"x_1_3_1\" -&gt; [\"x\", \"1\", \"3\", \"1\"]         op_id = int(name_parts[1])  # Operation index         start_time = int(name_parts[2])  # Start time         runway = int(name_parts[3])  # Runway         schedule.append((op_id, start_time,runway))  #print(schedule)  In\u00a0[14]: Copied! <pre>import pandas as pd\n\n# Convert to DataFrame\ndf = pd.DataFrame(schedule, columns=[\"Operation\", \"Start Time\", \"Runway\"])\n# Assign duration based on operation_schedule (default to 1 if not found)\ndf[\"Duration\"] = df[\"Operation\"].apply(lambda op: next(\n    (operation_schedule[plane][runway][op][\"time\"] \n     for plane in operation_schedule \n     for runway in operation_schedule[plane] \n     if op in operation_schedule[plane][runway]), 1))  # Default to 1 if not found\n\n# Assign plane labels\ndf[\"Plane\"] = df[\"Operation\"].apply(lambda op: next(\n    (plane for plane in operation_schedule \n     for runway in operation_schedule[plane] \n     if op in operation_schedule[plane][runway]), \"Unknown\"))\n\n# Assign runway labels\ndf[\"Runway\"] = df[\"Operation\"].apply(lambda op: next(\n    (runway for plane in operation_schedule \n     for runway in operation_schedule[plane] \n     if op in operation_schedule[plane][runway]), \"Unknown\"))\n\n# Assign phase labels\ndf[\"Phase\"] = df[\"Operation\"].apply(lambda op: next(\n    (operation_schedule[plane][runway][op][\"phase\"] \n     for plane in operation_schedule \n     for runway in operation_schedule[plane] \n     if op in operation_schedule[plane][runway]), \"Unknown\"))\n\nprint(df)\n</pre> import pandas as pd  # Convert to DataFrame df = pd.DataFrame(schedule, columns=[\"Operation\", \"Start Time\", \"Runway\"]) # Assign duration based on operation_schedule (default to 1 if not found) df[\"Duration\"] = df[\"Operation\"].apply(lambda op: next(     (operation_schedule[plane][runway][op][\"time\"]       for plane in operation_schedule       for runway in operation_schedule[plane]       if op in operation_schedule[plane][runway]), 1))  # Default to 1 if not found  # Assign plane labels df[\"Plane\"] = df[\"Operation\"].apply(lambda op: next(     (plane for plane in operation_schedule       for runway in operation_schedule[plane]       if op in operation_schedule[plane][runway]), \"Unknown\"))  # Assign runway labels df[\"Runway\"] = df[\"Operation\"].apply(lambda op: next(     (runway for plane in operation_schedule       for runway in operation_schedule[plane]       if op in operation_schedule[plane][runway]), \"Unknown\"))  # Assign phase labels df[\"Phase\"] = df[\"Operation\"].apply(lambda op: next(     (operation_schedule[plane][runway][op][\"phase\"]       for plane in operation_schedule       for runway in operation_schedule[plane]       if op in operation_schedule[plane][runway]), \"Unknown\"))  print(df) <pre>    Operation  Start Time  Runway  Duration   Plane              Phase\n0           0           0       1         2  Plane1     Final approach\n1           1           2       1         1  Plane1            Landing\n2           2           3       1         3  Plane1    Taxiing to gate\n3           3           4       2         3  Plane2     Final approach\n4           4           7       2         1  Plane2            Landing\n5           5           8       2         2  Plane2    Taxiing to gate\n6           6           2       1         4  Plane3  Taxiing to runway\n7           7           6       1         1  Plane3            Takeoff\n8           8           7       1         2  Plane3          Departure\n9           9           2       1         2  Plane4     Final approach\n10         10           4       1         1  Plane4            Landing\n11         11           5       1         3  Plane4    Taxiing to gate\n12         12           3       3         4  Plane5     Final approach\n13         13           7       3         1  Plane5            Landing\n14         14           8       3         3  Plane5    Taxiing to gate\n15         15           0       2         5  Plane6  Taxiing to runway\n16         16           5       2         1  Plane6            Takeoff\n17         17           6       2         2  Plane6          Departure\n18         18           0       3         5  Plane7  Taxiing to runway\n19         19           5       3         1  Plane7            Takeoff\n20         20           6       3         2  Plane7          Departure\n21         21           3       2         6  Plane8  Taxiing to runway\n22         22           9       2         1  Plane8            Takeoff\n23         23          10       2         1  Plane8          Departure\n24         24           4       3         5  Plane9     Final approach\n25         25           9       3         1  Plane9            Landing\n26         26          10       3         3  Plane9    Taxiing to gate\n</pre> In\u00a0[15]: Copied! <pre># Find the earliest Landing or Takeoff start time per plane\ndf[\"Primary Start\"] = df.apply(lambda row: row[\"Start Time\"] \n                               if row[\"Phase\"] in [\"Landing\", \"Takeoff\"] else None, axis=1)\n\n# Fill missing values with the earliest available phase per plane\ndf[\"Primary Start\"] = df.groupby(\"Plane\")[\"Primary Start\"].transform(\"min\")\n\n# Sort by earliest Landing or Takeoff execution\ndf = df.sort_values(by=[\"Primary Start\", \"Start Time\"],ascending=False)\n\nprint(df)\n</pre> # Find the earliest Landing or Takeoff start time per plane df[\"Primary Start\"] = df.apply(lambda row: row[\"Start Time\"]                                 if row[\"Phase\"] in [\"Landing\", \"Takeoff\"] else None, axis=1)  # Fill missing values with the earliest available phase per plane df[\"Primary Start\"] = df.groupby(\"Plane\")[\"Primary Start\"].transform(\"min\")  # Sort by earliest Landing or Takeoff execution df = df.sort_values(by=[\"Primary Start\", \"Start Time\"],ascending=False)  print(df) <pre>    Operation  Start Time  Runway  Duration   Plane              Phase  \\\n23         23          10       2         1  Plane8          Departure   \n26         26          10       3         3  Plane9    Taxiing to gate   \n22         22           9       2         1  Plane8            Takeoff   \n25         25           9       3         1  Plane9            Landing   \n24         24           4       3         5  Plane9     Final approach   \n21         21           3       2         6  Plane8  Taxiing to runway   \n5           5           8       2         2  Plane2    Taxiing to gate   \n14         14           8       3         3  Plane5    Taxiing to gate   \n4           4           7       2         1  Plane2            Landing   \n13         13           7       3         1  Plane5            Landing   \n3           3           4       2         3  Plane2     Final approach   \n12         12           3       3         4  Plane5     Final approach   \n8           8           7       1         2  Plane3          Departure   \n7           7           6       1         1  Plane3            Takeoff   \n6           6           2       1         4  Plane3  Taxiing to runway   \n17         17           6       2         2  Plane6          Departure   \n20         20           6       3         2  Plane7          Departure   \n16         16           5       2         1  Plane6            Takeoff   \n19         19           5       3         1  Plane7            Takeoff   \n15         15           0       2         5  Plane6  Taxiing to runway   \n18         18           0       3         5  Plane7  Taxiing to runway   \n11         11           5       1         3  Plane4    Taxiing to gate   \n10         10           4       1         1  Plane4            Landing   \n9           9           2       1         2  Plane4     Final approach   \n2           2           3       1         3  Plane1    Taxiing to gate   \n1           1           2       1         1  Plane1            Landing   \n0           0           0       1         2  Plane1     Final approach   \n\n    Primary Start  \n23            9.0  \n26            9.0  \n22            9.0  \n25            9.0  \n24            9.0  \n21            9.0  \n5             7.0  \n14            7.0  \n4             7.0  \n13            7.0  \n3             7.0  \n12            7.0  \n8             6.0  \n7             6.0  \n6             6.0  \n17            5.0  \n20            5.0  \n16            5.0  \n19            5.0  \n15            5.0  \n18            5.0  \n11            4.0  \n10            4.0  \n9             4.0  \n2             2.0  \n1             2.0  \n0             2.0  \n</pre> In\u00a0[16]: Copied! <pre>import matplotlib.pyplot as plt\nimport pandas as pd\n\n# Colors\n# https://matplotlib.org/stable/users/explain/colors/colors.html#colors-def\n\n# Define phase colors\nphase_colors = {\n    \"Final approach\": \"#069AF3\",\n    \"Landing\": \"#0343DF\",\n    \"Taxiing to gate\": \"#000050\",\n    \"Taxiing to runway\": \"#FF796C\",\n    \"Takeoff\": \"#E50000\",\n    \"Departure\": \"purple\"\n}\n\n# Plot Gantt chart\nfig, axes = plt.subplots(3 , 1, figsize=(10, 8)) # len(uniqe runway)\n\n# Increase vertical spacing between subplots\nplt.subplots_adjust(hspace=0.5)  # Adjust spacing (increase value for more space)\n\n\nfor idx, runway in enumerate([1, 2, 3]):  # Assuming runways 1, 2, 3\n    ax = axes[idx]\n    \n    # Filter data for this runway\n    runway_data = df[df[\"Runway\"] == runway]\n\n    #print(runway_data)  # Debugging: Print runway data\n\n    for i, row in runway_data.iterrows():\n        ax.barh(row[\"Plane\"], row[\"Duration\"], left=row[\"Start Time\"], \n                color=phase_colors[row.Phase], edgecolor=\"black\", label=row.Phase if i == 0 else \"\")\n\n    ax.set_title(f\"Runway {runway}\")\n    ax.grid(axis='x', linestyle=\"--\")\n    ax.set_xlim(0, T+4) \n#plt.grid(True)\n\n# Add a legend for phase colors\nhandles = [plt.Rectangle((0,0),1,1, color=color) for color in phase_colors.values()]\nlabels = list(phase_colors.keys())\nplt.legend(handles, labels, title=\"Flight Phases\", bbox_to_anchor=(1.05, 1), loc='upper left')\n\nplt.xlabel(\"Time unit\")\n#plt.tight_layout()\nplt.show()\n</pre> import matplotlib.pyplot as plt import pandas as pd  # Colors # https://matplotlib.org/stable/users/explain/colors/colors.html#colors-def  # Define phase colors phase_colors = {     \"Final approach\": \"#069AF3\",     \"Landing\": \"#0343DF\",     \"Taxiing to gate\": \"#000050\",     \"Taxiing to runway\": \"#FF796C\",     \"Takeoff\": \"#E50000\",     \"Departure\": \"purple\" }  # Plot Gantt chart fig, axes = plt.subplots(3 , 1, figsize=(10, 8)) # len(uniqe runway)  # Increase vertical spacing between subplots plt.subplots_adjust(hspace=0.5)  # Adjust spacing (increase value for more space)   for idx, runway in enumerate([1, 2, 3]):  # Assuming runways 1, 2, 3     ax = axes[idx]          # Filter data for this runway     runway_data = df[df[\"Runway\"] == runway]      #print(runway_data)  # Debugging: Print runway data      for i, row in runway_data.iterrows():         ax.barh(row[\"Plane\"], row[\"Duration\"], left=row[\"Start Time\"],                  color=phase_colors[row.Phase], edgecolor=\"black\", label=row.Phase if i == 0 else \"\")      ax.set_title(f\"Runway {runway}\")     ax.grid(axis='x', linestyle=\"--\")     ax.set_xlim(0, T+4)  #plt.grid(True)  # Add a legend for phase colors handles = [plt.Rectangle((0,0),1,1, color=color) for color in phase_colors.values()] labels = list(phase_colors.keys()) plt.legend(handles, labels, title=\"Flight Phases\", bbox_to_anchor=(1.05, 1), loc='upper left')  plt.xlabel(\"Time unit\") #plt.tight_layout() plt.show()  <p>The optimized scheduling of aircraft operations across three runways ensures a smooth, conflict-free sequence of landings, taxiing, takeoffs, and departures. This structured plan keeps operations efficient and delay-free, following FAA wake separation constraints while maximizing runway utilization.</p> <p>Runway 1 Operations:</p> <ul> <li>Plane 1 begins its final approach, lands, and taxis to the gate.</li> <li>Plane 4 starts its approach simultaneously with Plane 3 taxiing to the runway. Since taxiing takes longer, Plane 4 is able to land, complete its rollout, and taxi to the gate before Plane 3 is ready for takeoff.</li> <li>Plane 3, after completing its taxi, takes off immediately after the required separation time from Plane 4\u2019s landing, ensuring continuous runway usage without interference.</li> </ul> <p>Runway 2 Operations:</p> <ul> <li>Plane 6 starts by taxiing to the runway, preparing for takeoff.</li> <li>While Plane 6 is taxiing, Plane 2 is already in its final approach phase, meaning that as soon as Plane 6 departs, the runway is cleared in time for Plane 2 to land after the required separation time.</li> <li>Meanwhile, Plane 8 begins taxiing to the runway even before Plane 2 enters its final approach, ensuring that as soon as Plane 2 lands and clears the runway, Plane 8 is already positioned for takeoff.</li> </ul> <p>Runway 3 Operations:</p> <ul> <li>Plane 7 begins with taxiing to the runway, followed by takeoff and departure. This ensures the runway is clear for incoming aircraft.</li> <li>Plane 5 starts its final approach while Plane 7 is departing, allowing for an efficient transition.</li> <li>Plane 9 follows next, entering its final approach after Plane 5 has safely landed. It then proceeds to land and taxi to the gate, ensuring continuous runway usage without delays.</li> </ul> <p>In sum, this jupyter demo maximizes runway throughput by allowing operations to start simultaneously without direct overlap, ensuring that each aircraft completes its phase without delay or interference. The integration of landing, taxiing, and takeoff sequences prevents runway idle time and minimizes unnecessary waiting.</p> <p>Here are some of the benefits of applying this methodology in the future can help reshape the aerospace industry. Every one of these are cirtical to everybody's safety and satisfaction. I am looking forward such implementation can benefit all human beings which makes our travel more safer and more efficient.</p> <ol> <li><p>Enhanced Air Traffic Control (ATC) Focus on Ground and Air Maneuvering \u2013 By automating runway scheduling, controllers can dedicate more attention to managing aircraft movement on the ground and in the air, reducing workload and improving response times.</p> </li> <li><p>Ensuring Runway Safety and Preventing Incursions \u2013 Optimized scheduling minimizes the risk of runway incursions by structuring takeoff and landing sequences, ensuring no two aircraft attempt to occupy the same runway simultaneously.</p> </li> <li><p>Improved Aircraft-Specific Attention \u2013 With a clear, optimized schedule, ATC can focus on individual aircraft operations, reducing errors and ensuring safer and more efficient sequencing.</p> </li> <li><p>Maximizing Aircraft Utilization \u2013 Efficient scheduling reduces aircraft idle time, leading to faster turnarounds, lower operational costs, and improved fleet efficiency.</p> </li> <li><p>Scalability for High-Density Air Traffic \u2013 Unlike classical algorithms, which struggle with the complexity of large-scale scheduling, quantum-based approaches can efficiently handle multiple runways, aircraft, and constraints simultaneously.</p> </li> <li><p>Fuel and Emissions Reduction \u2013 By minimizing holding patterns and excessive taxiing, optimized schedules lower fuel consumption, contributing to cost savings and environmental sustainability.</p> </li> <li><p>Improved Passenger Experience \u2013 More efficient scheduling reduces delays, prevents bottlenecks, and enhances airline reliability, leading to better overall airport operations and customer satisfaction.</p> </li> </ol> <p>Future Scalability and Enhancements As quantum computing power continues to advance and becomes more accessible, the potential for optimizing air traffic control (ATC) scheduling will significantly expand. With increased computational capacity, larger and more complex scheduling scenarios can be handled efficiently, making quantum algorithms even more impactful in real-world air traffic management.</p> <ol> <li><p>Scaling Up to Larger Air Traffic Scenarios Currently, quantum optimization is applied to a multi-runway airport with a limited number of aircraft. As quantum hardware improves, we can scale this model to handle large international airports with hundreds of flights arriving and departing simultaneously. This would allow for real-time scheduling adjustments and enhanced optimization for high-density airspaces.</p> </li> <li><p>Expanding Flight Phases for More Detailed Scheduling With greater computational power, we can expand beyond just runway operations and incorporate more detailed flight phases into the scheduling model. These may include:</p> <ul> <li>Baseleg and Downwind \u2013 Managing sequencing before final approach.</li> <li>Climb Phase \u2013 Optimizing the transition between takeoff and en-route flight.</li> <li>Approach/Departure (TRACON) \u2013 Controls aircraft arriving/departing within 30-50 miles of the airport.</li> </ul> </li> <li><p>Real-Time Adaptive Scheduling for Dynamic Environments As quantum computing becomes faster and more robust, the system can process real-time air traffic fluctuations, adjusting flight schedules dynamically in response to:</p> <ul> <li>Weather disruptions</li> <li>Emergency landings</li> <li>Last-minute aircraft rerouting</li> <li>Unexpected delays in takeoff or taxiing</li> </ul> </li> </ol> <p>In short, as quantum computing technology progresses, the ability to handle larger scheduling problems and more detailed flight phases will revolutionize ATC efficiency. The integration of pre-ATC flight phases (baseleg, downwind, climb) and real-time scheduling will push quantum-based ATC optimization toward fully scalable, dynamic air traffic management systems. This will enhance airport throughput, reduce airspace congestion, and improve global air travel efficiency in the near future.</p> In\u00a0[17]: Copied! <pre>import sys\nimport platform\nimport qiskit\nimport docplex\nimport qiskit_optimization\nimport qiskit_algorithms\n\nprint(\"=\"*10 + \" Version Information \" + \"=\"*10)\nprint(f\"Python              : {sys.version}\")\nprint(f\"Operating System    : {platform.system()} {platform.release()} ({platform.architecture()[0]})\")\nprint(\"=\"*41)\nprint(f\"Qiskit              : {qiskit.__version__}\")\nprint(f\"qiskit_optimization : {qiskit_optimization.__version__} \")\nprint(f\"qiskit_algorithms   : {qiskit_algorithms.__version__} \")\nprint(f\"Cplex               : {docplex.__version__}\")\nprint(\"=\"*41)\n</pre> import sys import platform import qiskit import docplex import qiskit_optimization import qiskit_algorithms  print(\"=\"*10 + \" Version Information \" + \"=\"*10) print(f\"Python              : {sys.version}\") print(f\"Operating System    : {platform.system()} {platform.release()} ({platform.architecture()[0]})\") print(\"=\"*41) print(f\"Qiskit              : {qiskit.__version__}\") print(f\"qiskit_optimization : {qiskit_optimization.__version__} \") print(f\"qiskit_algorithms   : {qiskit_algorithms.__version__} \") print(f\"Cplex               : {docplex.__version__}\") print(\"=\"*41)  <pre>========== Version Information ==========\nPython              : 3.11.11 (main, Dec 11 2024, 10:28:39) [Clang 14.0.6 ]\nOperating System    : Darwin 24.3.0 (64bit)\n=========================================\nQiskit              : 1.3.2\nqiskit_optimization : 0.6.1 \nqiskit_algorithms   : 0.3.1 \nCplex               : 2.29.241\n=========================================\n</pre>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#air-traffic-control-problem-optimal-runway-allocation-for-single-plane-assignments-in-a-multi-runway-airport","title":"Air Traffic Control Problem - Optimal Runway Allocation for Single-Plane Assignments in a Multi-Runway Airport\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#abstract","title":"Abstract\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#introduction","title":"Introduction\u00b6","text":"<p>Air Traffic Control (ATC) ensures the safe and efficient movement of aircraft in busy airspace. As traffic grows, optimizing runway assignments is crucial for reducing delays and maximizing efficiency. This study explores Optimal Runway Allocation for Single-Plane Assignments in a multi-runway airport, where ATC pre-assigns runways. The challenge is to schedule landings and takeoffs while maintaining safety and efficiency.</p>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#problem-overview","title":"Problem Overview\u00b6","text":"<p>The problem involves optimizing the scheduling of aircraft across multiple runways to ensure efficient sequencing of landings, taxiing, and takeoffs while adhering to safety constraints; as shown in the table, each runway is pre-assigned specific aircraft in ascending order, requiring a conflict-free and delay-minimized schedule to maximize runway utilization and maintain operational efficiency.</p>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#detailed-runway-and-aircraft-assignments","title":"Detailed Runway and Aircraft Assignments\u00b6","text":"Runway Plane Flight Phase Runway 1 Plane 1 Final Approach, Landing, Taxi to Gate Runway 1 Plane 3 Taxi to Runway, Takeoff, Departure Runway 1 Plane 4 Final Approach, Landing, Taxi to Gate Runway 2 Plane 2 Final Approach, Landing, Taxi to Gate Runway 2 Plane 6 Taxi to Runway, Takeoff, Departure Runway 2 Plane 8 Taxi to Runway, Takeoff, Departure Runway 3 Plane 5 Final Approach, Landing, Taxi to Gate Runway 3 Plane 7 Taxi to Runway, Takeoff, Departure Runway 3 Plane 9 Final Approach, Landing, Taxi to Gate"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#objectives","title":"Objectives\u00b6","text":"<ol> <li>Ensure conflict-free operations across runways.</li> <li>Maintain proper separation for safety.</li> <li>Minimize total timespan for all operations.</li> <li>Use optimization techniques (QUBO plus classical solvers) for efficient scheduling.</li> </ol>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#problem-definition","title":"Problem Definition\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#problem","title":"Problem\u00b6","text":"<p>In our ATC - Optimal Runway Allocation for Single-Plane Assignments in a Multi-Runway Airport porblem, which is essentially a variation of a Job Shop Scheduling problem, where:</p> <ol> <li><p>We have total of 9 planes $(N)$ waiting to land and takeoff.</p> </li> <li><p>We will write this as a set of $P = \\{\\text{plane1},\\text{plane2},\\cdots, \\text{plane9}\\}$ that must be scheduled on a set of runways $(r)$ where $r \\in R = \\{ \\text{runway1},\\text{runway2},\\text{runway3} \\}$ assigned by ATC.</p> </li> <li><p>Each plane must perform landing operations $O$ or takoff operations</p> <ul> <li>Landing: $\\{ \\text{Final Approach}\\rightarrow\\text{Landing}\\rightarrow\\text{Taxiing to gate}\\}$</li> <li>Takeoff: $\\{ \\text{Taxiing from gate}\\rightarrow\\text{takeoff}\\rightarrow\\text{Departure}\\}$</li> </ul> <p>$$ p_1 = \\{ O_{1}\\rightarrow \\cdots \\rightarrow O_{k_1} \\}\\\\ p_2 = \\{ O_{k_{1}+1} \\rightarrow \\cdots \\rightarrow O_{k_2} \\}\\\\ \\vdots\\\\ p_N = \\{ O_{k_{N-1}+1} \\rightarrow \\cdots \\rightarrow O_{k_N} \\}\\\\ $$</p> <p>given the running index overall opearations $i \\in \\{1, \\cdots, k_N \\}$, we let $q_i$ be the index of the plane $p_{q_i}$ responsible for executing operations $O_i$. We define $I_m$ to be the set of indices of all of the operations that have to be executed on plane $p_p$, i.e., $I_m = \\{i:q_{i} = m \\}$. The execution time of opearation $O_i$ is now simply denoted $p_i$.</p> </li> </ol> <p>Our binary decision variable $x$ and be defined as:</p> <p>$$ x_{i,t,r} =  \\begin{cases} 1, &amp; \\text{operation} \\ O_i \\ \\text{starts at time unit } t \\text{ on runway} \\ r, \\\\ 0, &amp; \\text{otherwise} \\end{cases} $$</p>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#constraints","title":"Constraints\u00b6","text":"<ol> <li>Runway Utilization $({h_1})$ \u2013 Only one aircraft can occupy a runway at any given time for takeoff or landing.</li> <li>Sequential Scheduling $({h_2})$ \u2013 An aircraft's next operation cannot begin until the previous one is completed.</li> <li>Continuous Flight Pattern $({h_3})$ - For any plane, no gap between each flight pattern.</li> <li>Runway Incursions &amp; Runway Separation $({h_4})$ \u2013 Aircraft must adhere to wake turbulence separation.</li> </ol>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#reference","title":"Reference\u00b6","text":"<p>[1]. D. Venturelli, D. Marchand, and G. Rojo, \"Quantum Annealing Implementation of Job-Shop Scheduling\", arXiv:1506.08479v2.</p> <p>[2]. dwave-examples/flow-shop-scheduling dwave-examples/flow-shop-scheduling.</p> <p>[3]. dwave-examples/job-shop-scheduling dwave-examples/job-shop-scheduling.</p>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#qubo-formulation","title":"QUBO Formulation\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#python-implementation","title":"Python Implementation\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#flight-operations-and-flight-information","title":"Flight Operations and flight information\u00b6","text":"<ul> <li><p>Landing Flight Patterns:</p> <ul> <li>Final Approach (<code>Final approach</code>)</li> <li>Landing (<code>Landing</code>)</li> <li>Taxi after Landing (<code>Taxiing to gate</code>)</li> </ul> </li> <li><p>Takeoff Operations:</p> <ul> <li>Taxi (<code>Taxiing to runway</code>)</li> <li>Takeoff (<code>Takeoff</code>)</li> <li>Departure (<code>Departure</code>)</li> </ul> </li> </ul> <p>Each operation is assigned a specific operation time $ p_i $.</p> <p>Additionally, we define our CPLEX model (<code>mdl</code>) and the time horizon (<code>T</code>) for optimization.</p>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#hamiltonian-qubo","title":"Hamiltonian QUBO\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#considerations","title":"Considerations:\u00b6","text":"<ul> <li>The penalty terms representviolations of constraints.</li> <li>These violations are penalized using Hamiltonian parameters.</li> <li>Higher violations result in higher energy states, which we aim to minimize.</li> </ul>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#qubo-hamiltonian-formulation","title":"QUBO Hamiltonian Formulation:\u00b6","text":"<p>$$ H_{T}(\\bar{x}) = \\alpha h_1({\\bar{x}})+ \\beta h_2({\\bar{x}}) + \\gamma h_3({\\bar{x}}) + \\delta h_4({\\bar{x}}) $$ where:</p> <ul> <li>$h_i(\\bar{x})$ represents different constraint violations.</li> <li>$\\alpha, \\beta, \\gamma, \\delta, \\epsilon, \\zeta$ are penalty parameters ensuring infeasible solutions have higher energy values.</li> </ul> <p>Our objective is to find the optimal solution that minimizes the total Hamiltonian energy, leading to the best scheduling of flights while satisfying all constraints.</p>"},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#constraint-1-runway-utilization-h_1-only-one-aircraft-can-occupy-a-runway-at-any-given-time-for-takeoff-or-landing","title":"Constraint 1: Runway Utilization $({h_1})$ \u2013 Only one aircraft can occupy a runway at any given time for takeoff or landing.\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#constraint-2-sequential-scheduling-h_2-an-aircrafts-next-operation-cannot-begin-until-the-previous-one-is-completed","title":"Constraint 2: Sequential Scheduling $({h_2})$ \u2013 An aircraft's next operation cannot begin until the previous one is completed.\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#constraint-3-continuous-flight-pattern-h_3-for-any-plane-no-gap-between-each-flight-pattern","title":"Constraint 3: Continuous Flight Pattern $({h_3})$ - For any plane, no gap between each flight pattern.\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#constaint-4-separation-requirements-h_4-aircraft-must-adhere-to-wake-turbulence-separation","title":"Constaint 4: Separation Requirements $({h_4})$ \u2013 Aircraft must adhere to wake turbulence separation.\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#python-explanation-what-is-python-for-r-in-r-for-plane-in-operation_schedule-for-r-in-operation_scheduleplane","title":"Python explanation - What is <code>python for r in {r for plane in operation_schedule for r in operation_schedule[plane]}</code>?\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#constructing-hamiltonian","title":"Constructing Hamiltonian\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#establish-hamiltonian-and-solve-it","title":"Establish Hamiltonian and solve it\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#genearte-a-gantt-chart","title":"Genearte a gantt chart\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#summary","title":"Summary\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#final-thought","title":"Final thought\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#importance-of-this-demo","title":"Importance of this demo\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#future-scalability-and-enhancements-of-quantum-world","title":"Future Scalability and Enhancements of Quantum world\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29Air_Traffic_Control_1_Runway/#version-information","title":"Version Information\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/","title":"Nurse Scheduling Problem Using Qiskit","text":"<p>Pic: freepik</p> <p>The Nurse Scheduling Problem (NSP) involves creating fair and efficient work schedules while meeting hospital demands, legal constraints, and nurse preferences. It balances staffing needs with employee well-being to ensure quality patient care. Solving NSP efficiently reduces burnout, improves job satisfaction, and enhances overall healthcare system performance and efficiency.</p> <p>In the Nurse Scheduling Problem (NSP), we define a binary variable $x_{n,d} \\in \\{0,1\\}$ for every possible nurse scheduling scenario, where:</p> <ul> <li>$n$ represents each nurse, where $n \\in \\{1, \\dots, N\\}$.</li> <li>$d$ represents the day a nurse is scheduled to be on duty, where $d \\in \\{1, \\dots, D\\}$.</li> </ul> <p>The problem can be formulated as the following optimization problem: $$ \\min \\sum_{n=1}^{N} \\sum_{d=1}^{D} x_{n,d} $$ However, this objective function is not in quadratic form. To ensure that the workload is evenly distributed among nurses, we introduce a penalty term $\\frac{D}{N}$ to encourage a balanced assignment. Thus, we redefine our objective function as: $$ \\min \\sum_{n=1}^{N} \\left( \\sum_{d=1}^{D} x_{n,d} - \\frac{D}{N} \\right)^{2} $$ This quadratic formulation ensures that each nurse has a workload close to $\\frac{D}{N}$, promoting fairness in day assignments.</p> <p>Then we have to impose constraints to ensure a feasible schedule.</p> <ol> <li>Nurse constraint (Hard constraint): Each day must have at least one nurse working. We can have $$ \\sum_{n}^{D} x_{n,d} \\geq 1, \\ n\\in \\{1,\\cdots,N\\}, \\ d\\in \\{1,\\cdots,D\\} $$</li> <li>Day constraint (Soft Constraint): No nurse should work two or more consecutive days $$ x_{n,d} + x_{n, d+1} \\leq 1, \\ n\\in \\{1,\\cdots,N\\}, \\ d\\in \\{1,\\cdots,D\\} $$</li> <li>Workload (Soft constraint): define average workload as $D/N$ and apply it as a penalty term to make our problem a quadratic problem.</li> </ol> <p>The final form of our Nurse Scheduling Problem (NSP) probelm can be represented as $$ \\begin{array}{ll} \\text{minimize} &amp; \\sum_{n=1}^{N}\\bigg( \\sum_{d=1}^{D} x_{n,d} - \\frac{D}{N} \\bigg)^{2}\\\\ \\text{subject to} &amp; \\sum_{n}^{D} x_{n,d} \\geq 1, \\forall \\ N, \\forall \\ D\\\\ &amp; x_{n,d} + x_{n, d+1} \\leq 1, \\forall \\ N, \\forall \\ D\\\\ \\end{array} $$</p> In\u00a0[1]: Copied! <pre>from docplex.mp.model import Model\nfrom qiskit_optimization import QuadraticProgram\nfrom qiskit_optimization.algorithms import MinimumEigenOptimizer\nfrom qiskit_optimization.translators import from_docplex_mp\nfrom qiskit.primitives import Sampler\nimport numpy as np\n</pre> from docplex.mp.model import Model from qiskit_optimization import QuadraticProgram from qiskit_optimization.algorithms import MinimumEigenOptimizer from qiskit_optimization.translators import from_docplex_mp from qiskit.primitives import Sampler import numpy as np In\u00a0[\u00a0]: Copied! <pre># Create model\nmdl = Model(\"nurse_scheduling\")\n\n# Define problem parameters\nnum_nurses = 2\nnum_days = 4\n</pre> # Create model mdl = Model(\"nurse_scheduling\")  # Define problem parameters num_nurses = 2 num_days = 4 In\u00a0[3]: Copied! <pre># Create binary variables for each nurse and day \nx = {(n,d): mdl.binary_var(name = f\"x_{n}_{d}\") for n in range(num_nurses) for d in range(num_days)}\n#print(x)\n</pre> # Create binary variables for each nurse and day  x = {(n,d): mdl.binary_var(name = f\"x_{n}_{d}\") for n in range(num_nurses) for d in range(num_days)} #print(x) In\u00a0[4]: Copied! <pre># Hard Constraint: Each day must have at least one nurse working\nfor d in range(num_days):\n    mdl.add_constraint(mdl.sum(x[n, d] for n in range(num_nurses)) &gt;= 1, f\"daily_coverage_{d}\")\n</pre> # Hard Constraint: Each day must have at least one nurse working for d in range(num_days):     mdl.add_constraint(mdl.sum(x[n, d] for n in range(num_nurses)) &gt;= 1, f\"daily_coverage_{d}\") In\u00a0[5]: Copied! <pre># Soft Constraint: No nurse should work two or more consecutive days\nfor n in range(num_nurses):\n    for d in range(num_days-1):\n        mdl.add_constraint(mdl.sum(x[n, d] + x[n, d+1]) &lt;= 1, f\"consecutive_days_{n}_{d}\")\n</pre> # Soft Constraint: No nurse should work two or more consecutive days for n in range(num_nurses):     for d in range(num_days-1):         mdl.add_constraint(mdl.sum(x[n, d] + x[n, d+1]) &lt;= 1, f\"consecutive_days_{n}_{d}\") In\u00a0[6]: Copied! <pre># Soft Constraint: Balance workload among nurses (minimize variance)\navg_workload = num_days / num_nurses\nworkload = {n: mdl.sum(x[n, d] for d in range(num_days)) for n in range(num_nurses)}\n</pre> # Soft Constraint: Balance workload among nurses (minimize variance) avg_workload = num_days / num_nurses workload = {n: mdl.sum(x[n, d] for d in range(num_days)) for n in range(num_nurses)} In\u00a0[7]: Copied! <pre># Define our objective function\nmdl.minimize(mdl.sum((workload[n] - avg_workload) ** 2 for n in range(num_nurses)))\n</pre> # Define our objective function mdl.minimize(mdl.sum((workload[n] - avg_workload) ** 2 for n in range(num_nurses))) In\u00a0[8]: Copied! <pre># Solve the model\nsolution = mdl.solve()\n\nschedule_list = []\n# Print results\nif solution:\n    print(\"Optimal Schedule:\")\n    for n in range(num_nurses):\n        assigned_days = [d for d in range(num_days) if x[n, d].solution_value &gt; 0.5]\n        print(f\"Nurse {n}: Works on days {assigned_days}\")\n        # Store the (nurse, assigned_day) pairs as tuples\n        for day in assigned_days:\n            schedule_list.append((n, day))\nelse:\n    print(\"No feasible solution found.\")\n</pre> # Solve the model solution = mdl.solve()  schedule_list = [] # Print results if solution:     print(\"Optimal Schedule:\")     for n in range(num_nurses):         assigned_days = [d for d in range(num_days) if x[n, d].solution_value &gt; 0.5]         print(f\"Nurse {n}: Works on days {assigned_days}\")         # Store the (nurse, assigned_day) pairs as tuples         for day in assigned_days:             schedule_list.append((n, day)) else:     print(\"No feasible solution found.\")  <pre>Optimal Schedule:\nNurse 0: Works on days [0, 2]\nNurse 1: Works on days [1, 3]\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Given list of tuples (nurse, day)\ndata = schedule_list #[(0, 0), (0, 2), (1, 1), (1, 3)]\n\n# Create a grid (default: 0 for no shift)\nschedule_grid = np.zeros((num_nurses, num_days))\n\n# Fill the grid (1 for assigned shifts)\nfor nurse, day in data:\n    schedule_grid[nurse, day] = 1  # Mark assigned shifts\n\n# Plot the grid\nfig, ax = plt.subplots(figsize=(4, 3))\nax.imshow(schedule_grid, cmap=\"Greys\", aspect=\"auto\")\n\n# Add labels\nax.set_xticks(np.arange(num_days))\nax.set_yticks(np.arange(num_nurses))\nax.set_xticklabels([f\"Day {i}\" for i in range(num_days)])\nax.set_yticklabels([f\"Nurse {i}\" for i in range(num_nurses)])\n\nplt.title(\"Nurse Scheduling (Cplex)\")\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Given list of tuples (nurse, day) data = schedule_list #[(0, 0), (0, 2), (1, 1), (1, 3)]  # Create a grid (default: 0 for no shift) schedule_grid = np.zeros((num_nurses, num_days))  # Fill the grid (1 for assigned shifts) for nurse, day in data:     schedule_grid[nurse, day] = 1  # Mark assigned shifts  # Plot the grid fig, ax = plt.subplots(figsize=(4, 3)) ax.imshow(schedule_grid, cmap=\"Greys\", aspect=\"auto\")  # Add labels ax.set_xticks(np.arange(num_days)) ax.set_yticks(np.arange(num_nurses)) ax.set_xticklabels([f\"Day {i}\" for i in range(num_days)]) ax.set_yticklabels([f\"Nurse {i}\" for i in range(num_nurses)])  plt.title(\"Nurse Scheduling (Cplex)\") plt.show()  In\u00a0[10]: Copied! <pre># Load qiskit modules\nfrom qiskit_optimization.converters import QuadraticProgramToQubo\nfrom qiskit_algorithms import QAOA, NumPyMinimumEigensolver\nfrom qiskit_algorithms.optimizers import COBYLA\nfrom qiskit_algorithms.utils import algorithm_globals\nalgorithm_globals.random_seed = 12345\n</pre> # Load qiskit modules from qiskit_optimization.converters import QuadraticProgramToQubo from qiskit_algorithms import QAOA, NumPyMinimumEigensolver from qiskit_algorithms.optimizers import COBYLA from qiskit_algorithms.utils import algorithm_globals algorithm_globals.random_seed = 12345 In\u00a0[11]: Copied! <pre># Load from a Docplex model we just defiend before.\nmod = from_docplex_mp(mdl)\nprint(type(mod))\nprint()\nprint(mod.prettyprint())\n</pre> # Load from a Docplex model we just defiend before. mod = from_docplex_mp(mdl) print(type(mod)) print() print(mod.prettyprint()) <pre>&lt;class 'qiskit_optimization.problems.quadratic_program.QuadraticProgram'&gt;\n\nProblem name: nurse_scheduling\n\nMinimize\n  x_0_0^2 + 2*x_0_0*x_0_1 + 2*x_0_0*x_0_2 + 2*x_0_0*x_0_3 + x_0_1^2\n  + 2*x_0_1*x_0_2 + 2*x_0_1*x_0_3 + x_0_2^2 + 2*x_0_2*x_0_3 + x_0_3^2 + x_1_0^2\n  + 2*x_1_0*x_1_1 + 2*x_1_0*x_1_2 + 2*x_1_0*x_1_3 + x_1_1^2 + 2*x_1_1*x_1_2\n  + 2*x_1_1*x_1_3 + x_1_2^2 + 2*x_1_2*x_1_3 + x_1_3^2 - 4*x_0_0 - 4*x_0_1\n  - 4*x_0_2 - 4*x_0_3 - 4*x_1_0 - 4*x_1_1 - 4*x_1_2 - 4*x_1_3 + 8\n\nSubject to\n  Linear constraints (10)\n    x_0_0 + x_1_0 &gt;= 1  'daily_coverage_0'\n    x_0_1 + x_1_1 &gt;= 1  'daily_coverage_1'\n    x_0_2 + x_1_2 &gt;= 1  'daily_coverage_2'\n    x_0_3 + x_1_3 &gt;= 1  'daily_coverage_3'\n    x_0_0 + x_0_1 &lt;= 1  'consecutive_days_0_0'\n    x_0_1 + x_0_2 &lt;= 1  'consecutive_days_0_1'\n    x_0_2 + x_0_3 &lt;= 1  'consecutive_days_0_2'\n    x_1_0 + x_1_1 &lt;= 1  'consecutive_days_1_0'\n    x_1_1 + x_1_2 &lt;= 1  'consecutive_days_1_1'\n    x_1_2 + x_1_3 &lt;= 1  'consecutive_days_1_2'\n\n  Binary variables (8)\n    x_0_0 x_0_1 x_0_2 x_0_3 x_1_0 x_1_1 x_1_2 x_1_3\n\n</pre> In\u00a0[12]: Copied! <pre># Convert mod into a QUBO problem\nqp2qubo = QuadraticProgramToQubo()\nqubo = qp2qubo.convert(mod)\nqubitOp, offset = qubo.to_ising()\nprint(\"Offset:\", offset)\nprint(\"Ising Hamiltonian:\")\nprint(str(qubitOp))\n</pre> # Convert mod into a QUBO problem qp2qubo = QuadraticProgramToQubo() qubo = qp2qubo.convert(mod) qubitOp, offset = qubo.to_ising() print(\"Offset:\", offset) print(\"Ising Hamiltonian:\") print(str(qubitOp)) <pre>Offset: 164.5\nIsing Hamiltonian:\nSparsePauliOp(['IIIIIIZI', 'IIIIIZII', 'IIZIIIII', 'IZIIIIII', 'IIIIIIZZ', 'IIIIIZIZ', 'IIIIZIIZ', 'IIIZIIIZ', 'IIIIIZZI', 'IIIIZIZI', 'IIZIIIZI', 'IIIIZZII', 'IZIIIZII', 'ZIIIZIII', 'IIZZIIII', 'IZIZIIII', 'ZIIZIIII', 'IZZIIIII', 'ZIZIIIII', 'ZZIIIIII'],\n              coeffs=[-16.25+0.j, -16.25+0.j, -16.25+0.j, -16.25+0.j,  16.75+0.j,   0.5 +0.j,\n   0.5 +0.j,  16.25+0.j,  16.75+0.j,   0.5 +0.j,  16.25+0.j,  16.75+0.j,\n  16.25+0.j,  16.25+0.j,  16.75+0.j,   0.5 +0.j,   0.5 +0.j,  16.75+0.j,\n   0.5 +0.j,  16.75+0.j])\n</pre> In\u00a0[13]: Copied! <pre># Solve the QUBO using the exact solver `NumPyMinimumEigensolver`\nexact_mes = NumPyMinimumEigensolver()\nexact_mes = MinimumEigenOptimizer(exact_mes)\nexact_result = exact_mes.solve(qubo)\nprint(exact_result.prettyprint())\n</pre> # Solve the QUBO using the exact solver `NumPyMinimumEigensolver` exact_mes = NumPyMinimumEigensolver() exact_mes = MinimumEigenOptimizer(exact_mes) exact_result = exact_mes.solve(qubo) print(exact_result.prettyprint()) <pre>objective function value: 0.0\nvariable values: x_0_0=0.0, x_0_1=1.0, x_0_2=0.0, x_0_3=1.0, x_1_0=1.0, x_1_1=0.0, x_1_2=1.0, x_1_3=0.0\nstatus: SUCCESS\n</pre> In\u00a0[14]: Copied! <pre># Print results\nbinary_values = exact_result.x\nvaraiable_names = exact_result.variable_names\n\nassigned_days = []\nif solution:\n    print(\"Optimal Schedule:\")\n    for value, var in zip(binary_values, varaiable_names):\n        if value == 1:\n            _, nurse, day = var.split(\"_\")\n            assigned_days.append((int(nurse), int(day)))\nelse:\n    print(\"No feasible solution found.\")\n\nschedule = {}\nfor nurse, day in assigned_days:\n    if nurse not in schedule:\n        schedule[nurse] = []\n    schedule[nurse].append(day)\n\nfor nurse, days in schedule.items():\n    print(f\"Nurse {nurse} works on Days {days}\")\n</pre> # Print results binary_values = exact_result.x varaiable_names = exact_result.variable_names  assigned_days = [] if solution:     print(\"Optimal Schedule:\")     for value, var in zip(binary_values, varaiable_names):         if value == 1:             _, nurse, day = var.split(\"_\")             assigned_days.append((int(nurse), int(day))) else:     print(\"No feasible solution found.\")  schedule = {} for nurse, day in assigned_days:     if nurse not in schedule:         schedule[nurse] = []     schedule[nurse].append(day)  for nurse, days in schedule.items():     print(f\"Nurse {nurse} works on Days {days}\")  <pre>Optimal Schedule:\nNurse 0 works on Days [1, 3]\nNurse 1 works on Days [0, 2]\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Given list of tuples (nurse, day)\ndata = assigned_days #[(0, 1), (0, 3), (1, 0), (1, 2)]\n\n# Create a grid (default: 0 for no shift)\nschedule_grid = np.zeros((num_nurses, num_days))\n\n# Fill the grid (1 for assigned shifts)\nfor nurse, day in data:\n    schedule_grid[nurse, day] = 1  # Mark assigned shifts\n\n# Plot the grid\nfig, ax = plt.subplots(figsize=(4, 3))\nax.imshow(schedule_grid, cmap=\"Greys\", aspect=\"auto\")\n\n# Add labels\nax.set_xticks(np.arange(num_days))\nax.set_yticks(np.arange(num_nurses))\nax.set_xticklabels([f\"Day {i}\" for i in range(num_days)])\nax.set_yticklabels([f\"Nurse {i}\" for i in range(num_nurses)])\n\nplt.title(\"Nurse Scheduling (NumPyMinimumEigensolver)\")\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Given list of tuples (nurse, day) data = assigned_days #[(0, 1), (0, 3), (1, 0), (1, 2)]  # Create a grid (default: 0 for no shift) schedule_grid = np.zeros((num_nurses, num_days))  # Fill the grid (1 for assigned shifts) for nurse, day in data:     schedule_grid[nurse, day] = 1  # Mark assigned shifts  # Plot the grid fig, ax = plt.subplots(figsize=(4, 3)) ax.imshow(schedule_grid, cmap=\"Greys\", aspect=\"auto\")  # Add labels ax.set_xticks(np.arange(num_days)) ax.set_yticks(np.arange(num_nurses)) ax.set_xticklabels([f\"Day {i}\" for i in range(num_days)]) ax.set_yticklabels([f\"Nurse {i}\" for i in range(num_nurses)])  plt.title(\"Nurse Scheduling (NumPyMinimumEigensolver)\") plt.show()  <ol> <li>A wrapper for minimum eigen solvers.: <code>MinimumEigenoptimizer</code>: link</li> <li>Return type: <code>MinimumEigenOptimizationResult</code> link</li> </ol> In\u00a0[16]: Copied! <pre># Solve the QUBO using the exact solver `QAOA`\nqaoa_mes = QAOA(sampler=Sampler(), optimizer=COBYLA())\nqaoa_mes = MinimumEigenOptimizer(qaoa_mes)\nqaoa_result = qaoa_mes.solve(qubo)\nprint(qaoa_result.prettyprint())\n</pre> # Solve the QUBO using the exact solver `QAOA` qaoa_mes = QAOA(sampler=Sampler(), optimizer=COBYLA()) qaoa_mes = MinimumEigenOptimizer(qaoa_mes) qaoa_result = qaoa_mes.solve(qubo) print(qaoa_result.prettyprint())  <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_92250/2972185069.py:2: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  qaoa_mes = QAOA(sampler=Sampler(), optimizer=COBYLA())\n</pre> <pre>objective function value: 0.0\nvariable values: x_0_0=0.0, x_0_1=1.0, x_0_2=0.0, x_0_3=1.0, x_1_0=1.0, x_1_1=0.0, x_1_2=1.0, x_1_3=0.0\nstatus: SUCCESS\n</pre> In\u00a0[17]: Copied! <pre># Print results\nbinary_values = qaoa_result.x\nvaraiable_names = qaoa_result.variable_names\n\nassigned_days = []\nif solution:\n    print(\"Optimal Schedule:\")\n    for value, var in zip(binary_values, varaiable_names):\n        if value == 1:\n            _, nurse, day = var.split(\"_\")\n            assigned_days.append((int(nurse), int(day)))\nelse:\n    print(\"No feasible solution found.\")\n\nschedule = {}\nfor nurse, day in assigned_days:\n    if nurse not in schedule:\n        schedule[nurse] = []\n    schedule[nurse].append(day)\n\nfor nurse, days in schedule.items():\n    print(f\"Nurse {nurse} works on Days {days}\")\n</pre> # Print results binary_values = qaoa_result.x varaiable_names = qaoa_result.variable_names  assigned_days = [] if solution:     print(\"Optimal Schedule:\")     for value, var in zip(binary_values, varaiable_names):         if value == 1:             _, nurse, day = var.split(\"_\")             assigned_days.append((int(nurse), int(day))) else:     print(\"No feasible solution found.\")  schedule = {} for nurse, day in assigned_days:     if nurse not in schedule:         schedule[nurse] = []     schedule[nurse].append(day)  for nurse, days in schedule.items():     print(f\"Nurse {nurse} works on Days {days}\")  <pre>Optimal Schedule:\nNurse 0 works on Days [1, 3]\nNurse 1 works on Days [0, 2]\n</pre> In\u00a0[\u00a0]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\n\n# Given list of tuples (nurse, day)\ndata = assigned_days #[(0, 1), (0, 3), (1, 0), (1, 2)]\n\n# Create a grid (default: 0 for no shift)\nschedule_grid = np.zeros((num_nurses, num_days))\n\n# Fill the grid (1 for assigned shifts)\nfor nurse, day in data:\n    schedule_grid[nurse, day] = 1  # Mark assigned shifts\n\n# Plot the grid\nfig, ax = plt.subplots(figsize=(4, 3))\nax.imshow(schedule_grid, cmap=\"Greys\", aspect=\"auto\")\n\n# Add labels\nax.set_xticks(np.arange(num_days))\nax.set_yticks(np.arange(num_nurses))\nax.set_xticklabels([f\"Day {i}\" for i in range(num_days)])\nax.set_yticklabels([f\"Nurse {i}\" for i in range(num_nurses)])\n\nplt.title(\"Nurse Scheduling (QAOA)\")\nplt.show()\n</pre> import matplotlib.pyplot as plt import numpy as np  # Given list of tuples (nurse, day) data = assigned_days #[(0, 1), (0, 3), (1, 0), (1, 2)]  # Create a grid (default: 0 for no shift) schedule_grid = np.zeros((num_nurses, num_days))  # Fill the grid (1 for assigned shifts) for nurse, day in data:     schedule_grid[nurse, day] = 1  # Mark assigned shifts  # Plot the grid fig, ax = plt.subplots(figsize=(4, 3)) ax.imshow(schedule_grid, cmap=\"Greys\", aspect=\"auto\")  # Add labels ax.set_xticks(np.arange(num_days)) ax.set_yticks(np.arange(num_nurses)) ax.set_xticklabels([f\"Day {i}\" for i in range(num_days)]) ax.set_yticklabels([f\"Nurse {i}\" for i in range(num_nurses)])  plt.title(\"Nurse Scheduling (QAOA)\") plt.show()  In\u00a0[19]: Copied! <pre>import sys\nimport platform\nimport qiskit\nimport docplex\nimport qiskit_optimization\nimport qiskit_algorithms\n\nprint(\"=\"*10 + \" Version Information \" + \"=\"*10)\nprint(f\"Python              : {sys.version}\")\nprint(f\"Operating System    : {platform.system()} {platform.release()} ({platform.architecture()[0]})\")\nprint(\"=\"*41)\nprint(f\"Qiskit              : {qiskit.__version__}\")\nprint(f\"qiskit_optimization : {qiskit_optimization.__version__} \")\nprint(f\"qiskit_algorithms   : {qiskit_algorithms.__version__} \")\nprint(f\"Cplex               : {docplex.__version__}\")\nprint(\"=\"*41)\n</pre> import sys import platform import qiskit import docplex import qiskit_optimization import qiskit_algorithms  print(\"=\"*10 + \" Version Information \" + \"=\"*10) print(f\"Python              : {sys.version}\") print(f\"Operating System    : {platform.system()} {platform.release()} ({platform.architecture()[0]})\") print(\"=\"*41) print(f\"Qiskit              : {qiskit.__version__}\") print(f\"qiskit_optimization : {qiskit_optimization.__version__} \") print(f\"qiskit_algorithms   : {qiskit_algorithms.__version__} \") print(f\"Cplex               : {docplex.__version__}\") print(\"=\"*41)  <pre>========== Version Information ==========\nPython              : 3.11.11 (main, Dec 11 2024, 10:28:39) [Clang 14.0.6 ]\nOperating System    : Darwin 24.3.0 (64bit)\n=========================================\nQiskit              : 1.3.2\nqiskit_optimization : 0.6.1 \nqiskit_algorithms   : 0.3.1 \nCplex               : 2.29.241\n=========================================\n</pre>"},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#nurse-scheduling-problem-using-qiskit","title":"Nurse Scheduling Problem Using Qiskit\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#introduction","title":"Introduction\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#method","title":"Method\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#objective-function","title":"Objective function\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#constraint","title":"Constraint\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#python-workflow","title":"Python Workflow\u00b6","text":"<p>Here's our workflow to solve the Nurse Scheduling Problem (NSP). To better demonstrate how to apply the quantum algorithm (QAOA) and compare it with the exact solver and classical solver in DOcplex, we will simplify our problem and only consider a 1-shift scenario, 2 nurses, and 4 days. The workflow of this notebook is as follows:</p> <ol> <li>Construct a Cplex model for the NSP.<ul> <li>Solve it using the Cplex solver.</li> </ul> </li> <li>Using Qiskit fto solve NSP.<ul> <li>Convert the Cplex model into a Qiskit quadratic problem using the <code>from_docplex_mp</code> class from <code>qiskit_optimization.translators</code>.</li> <li>Ensure the problem is in QUBO format using the <code>QuadraticProgramToQubo</code> class from <code>qiskit_optimization.converters</code>.</li> <li>Solve the QUBO using the exact solver <code>NumPyMinimumEigensolver</code> from <code>qiskit_algorithms</code>.</li> <li>Solve the QUBO using the quantum algorithm with <code>QAOA</code> from <code>qiskit_algorithms</code>.</li> </ul> </li> </ol>"},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#construct-a-cplex-model-for-the-nsp","title":"Construct a Cplex model for the NSP.\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#solve-it-using-the-cplex-solver","title":"Solve it using the Cplex solver.\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#using-qiskit-fto-solve-nsp","title":"Using Qiskit fto solve NSP.\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#convert-the-cplex-model-into-a-qiskit-quadratic-problem","title":"Convert the Cplex model into a Qiskit quadratic problem\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#ensure-the-problem-is-in-qubo-format","title":"Ensure the problem is in QUBO format\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#solve-the-qubo-using-the-exact-solver-numpyminimumeigensolver","title":"Solve the QUBO using the exact solver NumPyMinimumEigensolver\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#solve-the-qubo-using-the-quantum-algorithm-with-qaoa","title":"Solve the QUBO using the quantum algorithm with QAOA\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#version-infomation","title":"Version Infomation\u00b6","text":""},{"location":"Projs/jupyter_Opt/%28C%29nurse_scheduling_qiskit/#reference","title":"Reference\u00b6","text":"<p>[1]. D Wave examples - Nurse Scheduling</p> <p>[2]. A Brief Study of the Nurse Scheduling Problem (NSP)</p> <p>[3]. [PDF] SOLVING NURSE SCHEDULING PROBLEM USING CONSTRAINT PROGRAMMING TECHIQUE</p> <p>[4]. Nurse Scheduling Problem via PyQUBO</p>"},{"location":"QuantumOpt/MachineLearningRefresher/","title":"Machine Learning Refresher","text":""},{"location":"QuantumOpt/MachineLearningRefresher/#types-of-machine-learning","title":"Types of machine learning","text":"<p>There are three big categories in which most, if not all, machine learning techniques can fit:</p> <ol> <li>Supervised learning </li> <li>Unsupervised learning</li> <li>Reinforcement learning</li> </ol>"},{"location":"QuantumOpt/MachineLearningRefresher/#supervised-learning","title":"Supervised learning","text":""},{"location":"QuantumOpt/MachineLearningRefresher/#unsupervised-learning","title":"Unsupervised learning","text":""},{"location":"QuantumOpt/MachineLearningRefresher/#reinforcement-learning","title":"Reinforcement learning","text":""},{"location":"QuantumOpt/MachineLearningRefresher/#quantum-classical-models","title":"Quantum-classical models","text":""},{"location":"QuantumOpt/QML/QGANS/","title":"Quantum Generative Adversarial Networks","text":"<p>In the unsupervised learning, we will discuss quantum versions of the famous Generative Adversaial Networks (GANs) that are called Quantum Generative Adversarial Networks (QGANs).</p> <p>We will cover </p> <ul> <li>GANs and their quantum counterparts</li> <li>Quantum GANs in Qiskit</li> </ul>"},{"location":"QuantumOpt/QML/QGANS/#gans-and-their-quantum-counterparts","title":"GANs and their quantum counterparts","text":"<p>Quantum GANs are generative models that can be trained in a perfectly unsupervised manner. By the fact that they are generative models we mean that quantum GANs will be useful for generating data that can mimic a training dataset; for instance, if you had a large dataset with pictures of people, a good generative model would be able to generate new pictures of people that would be indiscernible from those coming from the original distribution.</p>"},{"location":"QuantumOpt/QML/QGANS/#what-actually-is-a-gan","title":"What actually is a GAN?","text":"<p>GANs were introduced in 2014 by Goodfellow et al. as a groundbreaking machine learning model designed to generate data that closely mimics a given dataset.</p> <p>A GAN consists of two key components:</p> <ul> <li> <p>Generator: A neural network that takes arbitrary seeds as input and produces outputs resembling the original dataset. Its primary objective is to generate realistic data.  </p> </li> <li> <p>Discriminator: A binary classifier that distinguishes between real data from the dataset and the generated data. Its role is to identify whether a given input is authentic or artificially created.</p> </li> </ul> <p>         A schematic representation of the agents involved in a generative adversarial network. Ref[1]     </p> <p>The GAN training process involves the following steps:</p> <ol> <li>Initialization: The generator and discriminator networks are initialized with random parameters.  </li> <li>Discriminator Training: The discriminator learns to differentiate real data from the generator\u2019s output. At this stage, distinguishing real from fake data is relatively easy.  </li> <li>Generator Training: The generator is trained to produce outputs that deceive the discriminator into classifying them as real. Once trained, it generates synthetic data.  </li> <li>Iterative Training: The discriminator is retrained on both real and newly generated data, followed by updating the generator to better fool the improved discriminator. This process repeats over multiple iterations.  </li> </ol> <p>Over time, the generator improves, making it increasingly difficult for the discriminator to distinguish real from generated data. Ideally, this process reaches an equilibrium where the generated data becomes nearly indistinguishable from the original dataset.</p> <p>         A schematic illustration of the training process of a GAN meant to generate pictures of cats. Ref[1]     </p> <p>It's important to note that this description is a simplified overview of GAN training. In practice, the discriminator and generator are not trained in a fully alternating manner but are optimized iteratively.  </p> <p>For instance, when using gradient descent with a given batch size, the training process typically follows these steps in each epoch:  </p> <ol> <li>Discriminator Update: For each batch, the discriminator's weights are adjusted in a single optimization step to improve its ability to differentiate real from generated data.  </li> <li>Generator Update: In the same epoch, the generator\u2019s weights are updated in a single optimizer step to improve its ability to generate data that fools the discriminator.  </li> </ol> <p>With this understanding of the training process, the term GAN becomes clearer.  </p> <ul> <li>Generative: These models focus on generating new data that resembles the original dataset.  </li> <li>Adversarial: The training process is framed as a competition between two networks\u2014the generator and the discriminator\u2014each trying to outsmart the other.  </li> <li>Networks: As expected, these models rely on neural networks as their fundamental building blocks.  </li> </ul> <p>So far, we have discussed how GANs utilize neural networks in both the generator and discriminator. However, the networks used in GANs are not always the standard dense neural networks we have covered.</p> <p>Dense networks consist of fully connected layers, where every neuron in one layer is connected to all neurons in the next. While these networks work well for many applications, they are not always the best choice\u2014especially for handling images.</p> <p>When working with images, whether for generation, classification, or manipulation, convolutional layers are often used instead. These layers are specifically designed to process spatial information efficiently, making them a key component in GANs designed for image generation.</p> <p>Note</p> <p>If you decide are interested in quantum versions of convolutional layers and networks, please see [2] and [3].</p> <p>A key detail in GAN training is that the generator is never directly exposed to the original data. Instead it learns soley through feedback from the discriminator. And this let GANs enable fully unsupervised training.</p>"},{"location":"QuantumOpt/QML/QGANS/#challenges","title":"Challenges","text":"<p>GANs, like other machine learning models, face challenges during training. One concern is ensuring that the generator creates truly new data rather than slightly altered copies of the original dataset. This issue, known as overfitting or memorization, can prevent the model from generalizing patterns effectively. Techniques such as adding noise, using regularization, applying dropout, or ensuring diversity in training samples help mitigate this risk and encourage the generator to produce novel yet realistic outputs. </p> <p>GAN training can fail if the generator produces only a limited set of variations from the dataset, a problem known as mode collapse. For example, a GAN trained on cat images might generate only a few similar-looking cats. To address this, various improvements have been proposed, such as Wasserstein GANs (WGANs) [4], which use the Wasserstein metric to refine the loss function and enhance training stability.</p>"},{"location":"QuantumOpt/QML/QGANS/#some-technicalities-about-gans","title":"Some technicalities about GANs","text":""},{"location":"QuantumOpt/QML/QGANS/#discriminator-loss-function","title":"Discriminator Loss Function","text":"<p>The discriminator in a GAN is trained as a binary classifier using binary cross-entropy loss. It assigns a label of 1 to real data samples from X and 0 to generated samples from S. Given a generator G and a discriminator D, the discriminator's loss function L_D is defined as: $$ L_{D} = -\\frac{1}{|X| + |S|}\\bigg( \\sum_{x\\in X}\\text{log}D(x)+ \\sum_{s\\in S}\\text{log}(1-D(G(s)))\\bigg), $$ where we are using |X| and |S| to denote the sie of the sets X and S, respectively. The job of the discriminator would be to minimize this loss.</p>"},{"location":"QuantumOpt/QML/QGANS/#generator-loss-function","title":"Generator Loss Function","text":"<p>Our goal when training the generator is to fool the discriminator trying to get it to classify our generated data as real data. Hence, the goal in the training of the generator is to maximize the loss function of the discriminator, that is, to minimize $$ -L_{D} = \\frac{1}{|X| + |S|}\\bigg( \\sum_{x\\in X}\\text{log}D(x)+ \\sum_{s\\in S}\\text{log}(1-D(G(s)))\\bigg), $$</p> <p>We can see that the first term in the sum is constant in the generator training since it does not depend on G(s). We may consider the goal of the generator training to be the minimization of the generator loss function $$ L_{G}^{'} = \\frac{1}{|S|}\\sum_{s\\in S}\\text{log}(1-D(G(s))). $$ However, in practice, it has been shown [5] that it is usually more stable to take the goal of the generator training to be the minimization of loss $$ L_{G} = -\\frac{1}{|S|}\\sum_{s\\in S}\\text{log}(D(G(s))) $$</p> <p>At the optimal equilibrium between the generator and discriminator, the discriminator assigns equal probabilities to real and generated data, meaning D(x) = D(G(s)) = \\frac{1}{2}. As a result, both the discriminator and generator losses converge to: $$ L_D = L_G = -\\log \\frac{1}{2} = \\log 2 \\approx 0.6931. $$ This means that at equilibrium, the discriminator is no longer able to differentiate real data from generated data, implying that the generator has successfully learned to produce realistic outputs. The loss value of approximately 0.6931 indicates that the model has reached a balanced state where the generator and discriminator are equally matched, preventing further improvement in distinguishing real from fake data. You can find the proof in the original GANs paper [5].</p>"},{"location":"QuantumOpt/QML/QGANS/#quantum-gans","title":"Quantum GANs","text":"<p>A quantum GAN (QGAN) is a GAN where either the generator, discriminator, or both are implemented using a quantum neural network. Despite its quantum components, it follows the same adversarial training process as a classical GAN.</p> <p>Broadly, QGANs can be categorized into three types:</p> <ol> <li> <p>Fully Quantum QGAN (Quantum Data + Quantum Generator &amp; Discriminator)    In this setup, both the generator and discriminator are quantum circuits, and the data consists of quantum states. This creates a purely quantum model where all components interact seamlessly without requiring feature maps or measurement operations.</p> </li> <li> <p>Hybrid QGAN (Quantum Data + Quantum Generator + Classical Discriminator)    Here, the generator is quantum, producing quantum states, but the discriminator remains classical. Since the discriminator processes classical data, measurement operations are required to convert both the generated quantum states and the original quantum data into classical form.</p> </li> <li> <p>Hybrid QGAN (Classical Data + Quantum Generator or Discriminator)    In this scenario, either the generator or discriminator (or both) is quantum while working with classical data. For a quantum discriminator, a feature map is used to encode classical data into quantum states. This setup closely resembles classical GANs but leverages quantum models to enhance performance or efficiency.</p> </li> </ol> <p>Because the availability of classical data is much bigger than that of quantum data, this is the type of architecture that has been studied more widely by the quantum computing community.</p>"},{"location":"QuantumOpt/QML/QGANS/#gans-in-qiskit","title":"GANs in Qiskit","text":""},{"location":"QuantumOpt/QML/QGANS/#reference","title":"Reference","text":"<ol> <li>Combarro, E. F., &amp; Gonz\u00e1lez-Castillo, S. (2023). A practical guide to quantum machine learning and quantum optimisation: Hands-on approach to modern quantum algorithms. Packt Publishing.</li> <li>I. Cong, S. Choi, and M. D. Lukin, \u201cQuantum convolutional neural networks,\u201d Nature Physics, vol. 15, pp. 1273\u20131278, 2019.</li> <li>M. Henderson, S. Shakya, S. Pradhan, and T. Cook, \u201cQuanvolutional neural networks: Powering image recognition with quantum circuits,\u201d Quantum Machine Intelligence, vol. 2, no. 1, pp. 1\u20139, 2020.</li> <li>M. Arjovsky, S. Chintala, and L. Bottou, \u201cWasserstein generative adversarial networks,\u201d in International conference on machine learning, PMLR, 2017, pp. 214\u2013223.</li> <li>I. Goodfellow, J. Pouget-Abadie, M. Mirza, et al., \u201cGenerative adversarial nets,\u201d Advances in neural information processing systems, vol. 27, 2014.</li> </ol>"},{"location":"QuantumOpt/QML/QHyb/","title":"Quantum Hybrid Architectures","text":"<p>In a hybrid quantum neural network (QNN), instead of manually reducing the number of features and potentially losing important information, we allow the classical neural network to learn which features are most relevant. This enables the classical network to extract meaningful representations, optimizing the input before passing it to the quantum neural network. The quantum component then focuses on classification or other complex tasks, leveraging its potential advantages in high-dimensional space processing and pattern recognition. This synergy between classical and quantum computing allows hybrid models to effectively balance efficiency and performance, making the most of both paradigms.</p> <p>When we talk about hybrid architectures or hybrid models, we refer to systems that integrate classical and quantum-based models into a single, unified framework for training.  </p> <p>In particular, we combine quantum neural networks (QNNs) with classical neural networks, as they naturally complement each other. Our approach embeds a QNN as a layer within a classical neural network, where the quantum layer processes inputs from the preceding layer or directly from the model\u2019s input. It then passes its output to the next layer, if one exists. The quantum layer produces a numerical array of length k, functioning like a classical layer with k neurons from the perspective of subsequent layers.  </p> <p>In essence, a hybrid QNN is a classical neural network in which one or more layers are replaced by quantum layers. These quantum layers operate within the network just like classical layers, receiving inputs from previous layers and passing outputs forward. If no subsequent layer exists, the quantum layer's output serves as the final output of the network.  </p>"},{"location":"QuantumOpt/QML/QHyb/#example-of-a-hybrid-qnn","title":"Example of a Hybrid QNN","text":"<p>Let\u2019s consider a simple example of a hybrid quantum neural network (QNN): </p> <ol> <li>Classical Input: The model starts by taking classical inputs. For example, an input of size 16.  </li> <li>Classical Layer: This input is fed into a standard classical layer with 8 neurons, using the sigmoid activation function.  </li> <li>Quantum Layer: Next, we introduce a quantum layer that accepts the 8 outputs from the classical layer. For instance, we could use a QNN with three qubits employing amplitude encoding. The output of this quantum layer might be the expectation values of the first and second qubits, both measured in the computational basis.  </li> <li>Final Classical Layer: A final classical layer with a single neuron and a sigmoid activation function takes the two outputs from the quantum layer as input.  </li> </ol>"},{"location":"QuantumOpt/QML/QHyb/#why-use-hybrid-qnns","title":"Why Use Hybrid QNNs?","text":"<p>You might wonder\u2014what's the advantage of hybrid models? What are they useful for?  </p> <p>In our exploration of QNNs (see QNN), we applied quantum neural networks to binary classification tasks. However, due to the limitations of current quantum hardware and simulators, we had to perform dimensionality reduction on our data before feeding it into the QNN.  </p> <p>This is where hybrid QNNs shine: instead of using a separate dimensionality reduction step, why not integrate it directly into the model? A hybrid QNN allows us to use a classical neural network for dimensionality reduction while leveraging a quantum neural network for classification\u2014combining the strengths of both classical and quantum computing within a single framework.  </p>"},{"location":"QuantumOpt/QML/QHyb/#the-role-of-hybrid-qnns","title":"The Role of Hybrid QNNs","text":"<p>By using a hybrid QNN, instead of first reducing the dimensionality of our data and then classifying it with a quantum neural network separately, we can design a model where:  </p> <ul> <li>Classical layers handle dimensionality reduction of the input data.  </li> <li>A quantum layer is responsible for classification.  </li> </ul> <p>Since the entire network is trained as a single unit, the separation between dimensionality reduction and classification isn\u2019t rigid. In practice, both the classical and quantum components will likely contribute to both tasks to some extent.  </p>"},{"location":"QuantumOpt/QML/QHyb/#important-considerations","title":"Important Considerations","text":"<p>While hybrid QNNs are an exciting approach, there are some key points to keep in mind:  </p> <ol> <li> <p>Quantum Layers Are Not a Guaranteed Performance Boost    Quantum layers aren\u2019t magic\u2014they don\u2019t automatically enhance the performance of a classical neural network. Simply swapping out a classical layer for a quantum one won\u2019t necessarily yield improvements. Instead, you should carefully consider the specific role the quantum layer will play in your model.  </p> </li> <li> <p>Pay Attention to the Classical-Quantum Connection    The way you integrate classical and quantum layers is crucial. The transition between these layers must be carefully designed to ensure smooth data flow and meaningful learning.  </p> </li> <li> <p>Neural Networks and Dimensionality Reduction    Classical neural networks can effectively reduce dimensionality, a technique often implemented using autoencoders. At the same time, quantum neural networks have been shown to perform well on classification tasks, especially when working with data that has already undergone dimensionality reduction.  </p> </li> </ol> <p>Given this, it\u2019s reasonable to assume that a well-structured hybrid QNN\u2014properly tuned\u2014can successfully achieve both dimensionality reduction and classification within a single model.  </p>"},{"location":"QuantumOpt/QML/QHyb/#questions-about-the-hybrid-architectures","title":"Questions about the hybrid architectures","text":"<p>Should You Perform Dimensionality Reduction Before Feeding Data into the Network?</p> <p>Yes, you can perform dimensionality reduction before feeding data into a classical neural network. Techniques like PCA (Principal Component Analysis), t-SNE, or autoencoders are often used for this purpose. This approach reduces the amount of data that the network has to process, making it more efficient.</p> <p>However, if you apply dimensionality reduction beforehand, you are manually deciding what information to keep and what to discard before the neural network even starts learning. This can be a limitation, as the model loses the opportunity to learn the best way to process the data on its own.</p> <p>What Happens If You Let the Classical Neural Network Handle Dimensionality Reduction?</p> <p>A neural network\u2014particularly one with layers designed for feature extraction\u2014can automatically learn how to reduce the dimensionality of the data as part of its training process. This is commonly seen in autoencoders, convolutional networks, and attention-based architectures.</p> <p>If you let the classical neural network learn the best way to reduce dimensionality, rather than applying a manual reduction step beforehand, the model remains more flexible and adaptable to the task at hand.</p> <p>Why Use Hybrid QNNs for Dimensionality Reduction and Classification Together?</p> <p>The motivation behind hybrid QNNs is to integrate classical and quantum models in a way that leverages the strengths of both:</p> <ul> <li>Classical neural networks are good at handling large amounts of data and extracting useful features.</li> <li>Quantum neural networks have the potential to detect patterns and relationships that classical networks struggle with, especially in high-dimensional data spaces.</li> </ul> <p>By using a hybrid model, we allow the network to:</p> <ol> <li>Learn how to reduce dimensionality automatically rather than applying a separate reduction step.</li> <li>Let the classical part extract relevant features, while the quantum part focuses on classification (or potentially other tasks).</li> </ol> <p>What\u2019s the Best Approach?</p> <p>It depends on the problem you're solving and available quantum resources:</p> <ol> <li>If quantum resources are very limited, pre-reducing dimensionality manually might help because it reduces the complexity of the quantum component.</li> <li>If you want a flexible, optimized model, letting the classical part of the hybrid QNN handle dimensionality reduction could be more effective.</li> <li>In some cases, a combination works best\u2014you might apply some initial dimensionality reduction (e.g., PCA to remove obvious redundancies) but still allow the classical neural network to fine-tune feature extraction before passing data to the quantum layer.</li> </ol> <p>So, it\u2019s not that you shouldn\u2019t do dimensionality reduction beforehand\u2014it\u2019s that you don\u2019t have to. If your dataset is large and high-dimensional, some preprocessing might help, but letting the classical network learn how to extract meaningful features before passing data to the quantum layer often leads to a more adaptive and powerful model.</p>"},{"location":"QuantumOpt/QML/QHyb/#reference","title":"Reference","text":"<p>[1]. Combarro, E. F., &amp; Gonz\u00e1lez-Castillo, S. (2023). A practical guide to quantum machine learning and quantum optimisation: Hands-on approach to modern quantum algorithms. Packt Publishing.</p>"},{"location":"QuantumOpt/QML/QNN/","title":"Quantum Neural Networks","text":"<p>There are the contents of this chapter:</p> <ol> <li>Building and training quantum neural networks</li> <li>Quantum neural networks in PennyLane</li> <li>Quantum neural networks in Qiskit</li> </ol>"},{"location":"QuantumOpt/QML/QNN/#building-and-training-a-quantum-neural-network","title":"Building and training a quantum neural network","text":""},{"location":"QuantumOpt/QML/QNN/#from-classical-neural-networks-to-quantum-neural-networks","title":"From classical neural networks to quantum neural networks","text":"Convolutional Neurak Networks Quantum Neurak Networks Data Pre-processing Data normalizing or scaling Encode classic data via feature map, normalize if needed Data processing Feeding the data via a sequence of layers Use variational form (ansatzs) to resembles the spirit of a classical neural network Data Output Retrun the output via a final layer The result of some measurement operation (whichever suits our problem best) <p>In fact, both feature map and variational form (ansatzs) are both examples of variational circuit: quantum circuits that are controlled by some classical parameters.</p> <ul> <li>Feature map: depend on the input data and are used to encode it.</li> <li>Variational form (ansatzs): depend on optimizable parameters and are used to transform a quantum input state.</li> </ul> <p>         Quantum neural networks flow. Where \\( F \\) us a feature map, variational form \\( V \\) depends on some optimizable parameters \\( \\overrightarrow{\\theta} \\). The output of the quantum neural network is the result of a measurement opeartion on the final state.     </p>"},{"location":"QuantumOpt/QML/QNN/#variational-forms","title":"Variational forms","text":"<p>In principle, variational forms for QNNs follow a \"layered structured,\" trying to mimic the spirit of classical neural networks.</p> <p>Let's first define a variational form with k layers, we could consider k vectors of independent parameters \\overrightarrow{\\theta_{1}}, \\cdots, \\overrightarrow{\\theta_{k}}. To define each layer j, we take variational circuit G_j depend on the parameters \\overrightarrow{\\theta_{j}}. A common approach is to prepare variational forms by stacking these variational circuits consecutively and separating them by some circuit U_{ent}^{t}, inpedendent of any parameters, meant to create entanglement between the qubits.</p> <p>         A variational form with \\(k\\) layers, each defined by a variational circuit \\( G_j \\) dependent on some parameters \\( \\overrightarrow{\\theta_{j}} \\). The circuits \\( U_{ent}^{t} \\) are used to create entanglement, and the state \\( | \\psi_{enc} \\rangle\\) denotes the output of the feature map     </p>"},{"location":"QuantumOpt/QML/QNN/#two-local","title":"Two-local","text":"<p>The two-local form with k repetitions on n qubits relies on n \\times (k+1) optimizable parameters, which we will denote as \\theta_{rj} with r = 0, \\cdots, k and j=1,\\cdots,n. The two-local circuit is constructed as</p> <pre><code>    # TWOLOCAL (n, k, theta)\n        for r in range(k):\n            # DO: add the r-th layer.\n            for j in range(1, n+1): # for all t = 1,...,n\n                # DO: Apply a Ry(theta_{rj}) gate on qubit j\n            # DO: create entanglement between layers\n            if r &lt; k:\n                for t in range(1, n): # for all t = 1,...,n-1\n                    # DO: Apply a CNOT gate with control on qubit t and target on qubit t+1\n</code></pre> <p>Below figure shows n = 4 and k=3 in the two-local method. The two-local variational form uses the same circuit as the angle encoding feature map for its layers, and then it relies on a cascade of contrlled-NOT operations in order to create entanglement (see CNOT gates after each R_{Y}(\\theta_{rj}) implementation). Also, the tow-local variational form with k repetitions has k+1 layers, not k. The two-local variational form is very versatile, and it can be used with any measurement operation.</p> <p>         Two-local variational form on four qubits and two repetitions.     </p> <p>For a two-local variational form, there are more options for the distribution of gates in entanglement circuit besides the \"linear\" model we have just covered. See the below figure for circular and full entangelment circuits diagram.</p> <p>         Different entanglement circuits     </p>"},{"location":"QuantumOpt/QML/QNN/#tree-tensor","title":"Tree tensor","text":"<p>The tree tensor variational form with k+1 layers can be applied on n = 2^{k} qubits. The variational form relies on 2^{k}+2^{k-1}+2^{k-2}+ \\cdots + 1 optimizable parameters of the form </p>  \\theta_{rs}, \\quad r = 0,\\cdots,k, \\quad s = 0,\\cdots,2^{k-r}-1.  <p>The tree tensor circuit is constructed as </p> <p><pre><code>    # TREETENSOR (k, theta)\n    # on each qubit j, apply a rotation Ry(theta_0j).\n    for r in range(1,k+1): # for all r = 1,..., k\n        for s in range(2^{k-r}): #for all s = 0,...,2^{k-r}-1 do\n            # DO: Apply a CNOT operation with target on qubit 1+s2^{r} and controlled by qubit 1 + s2^{r} + 2^{r-1}\n            # DO: Apply a rotation Ry(theta_{r,s}) on qubit 1+s2^{2}.\n</code></pre> The below image shows an output of the above algorithm for k=3.</p> <p>         Tree tensor variational form on \\( 8 = 2^{3}\\) qubits     </p> <p>The tree tensor variational form fits best in quantum neural networks designed to work as binary classifiers. The most natural measurement operation that can be used in conjuction with it is the obtention of the expected value of the first qubit, as measuremented in the computational basis.</p>"},{"location":"QuantumOpt/QML/QNN/#strongly-entangling-layers","title":"Strongly entangling layers","text":"<p>The strongly entangling layers variational form acts on n qubits anc can have any number k of layers. Each layer l is given a range r_l. The variational form uses 3nk parameters of the form</p>  \\theta_{ljx}, \\quad l = 1,\\cdots,k, \\quad j = 1,\\cdots,n, \\quad x = 1,2,3.  <p>The strongly entangling layer circuit is constructed as </p> <pre><code>    # STRONGLYENTANGLINGLAYERS(n,k,r,theta)\n    for l in range(1,l+1): # for all l = 1,..., l\n        for j in range(1,j+1): # for all j = 1,..., j\n            # DO: Apply a rotation RZ(theta_{l,j,1}) on qubit j.\n            # DO: Apply a rotation RY(theta_{l,j,2}) on qubit j.\n            # DO: Apply a rotation RZ(theta_{l,j,3}) on qubit j.\n        for j in range(1,j+1): # for all j = 1,..., j\n            # DO: Apply a CNOT operation controlled by qubit j and with target on qubit [(j+r_l - 1 mod N)] + 1.\n</code></pre> <p>Tge choice to use mostly Y rotations in the previouse examples of variational forms is somewhat arbitrary. We can also use X rotation. And we can also have used a different controlled operation. </p> <p>         Strongly entangling layers form on 4 qubits and 2 layers with respective range 1 and 2     </p>"},{"location":"QuantumOpt/QML/QNN/#measurements","title":"Measurements","text":"<p>From VQE, we know any physical observable can be represented by a Hermitian operator in such a way that all the possible outcomes of the measurement of the observable can be matched to the different eigenvalues of the operator.</p> <p>When we measure a single qubit in the computational basis, the coordinate matrix with respect to the computational basis of the associated Hermitian operator could well be either of </p>  M =  \\begin{pmatrix} 1 &amp; 0\\\\ 0 &amp; 0 \\end{pmatrix}, \\quad Z =  \\begin{pmatrix} 1 &amp; 0\\\\ 0 &amp; -1 \\end{pmatrix}.  <p>Both of these operators represent the measurement of a qubit, but they differ in the eigenvalues that they associate to the distinct outputs.</p> <ol> <li>The M operator associate with eigenvalues 1 and 0 to the qubit's value being 0 and 1 respectively.</li> <li>The Z operator associate with eigenvalues 1 and -1 to the qubit's value being 0 and 1 respectively.</li> </ol> <p>Practice</p> <p>Show that operatoin M and Z can be written as  $$ M = 1|0\\rangle \\langle 0 | + 0|1\\rangle\\langle1| = |1\\rangle\\langle1|, \\quad Z = |0\\rangle\\langle0|-|1\\rangle\\langle1| $$</p> Answer <p>As we know, PennyLane allow you to work with measurement operations defined by any Hermitian operator.</p> <p>In an n-qubit circuit, you will be able to instruct PennyLane to compute the expectation value of the obervable M \\otimes \\cdots \\otimes M, which has as its coordinate repersentation in the copmutational basis the matrix</p>  \\begin{pmatrix} 0 &amp; &amp; &amp; \\\\   &amp; \\ddots &amp; \\\\   &amp; 0 &amp; \\\\   &amp; &amp; 1  \\end{pmatrix}_{2^{n}\\times 2^{n}} .  <p>You can also consider the observable Z \\otimes \\cdots \\otimes Z. This observable will return +1 is an even number of qubits are measured as 0, and -1 otherwise. The Z \\otimes \\cdots \\otimes Z operation is also called as a partiy observable.</p>"},{"location":"QuantumOpt/QML/QNN/#gradient-computation-and-the-parameter-shift-rule","title":"Gradient computation and the parameter shift rule","text":"<p>After we have all the building blocks, let's see how we can train our QNN model! To do so, we have to bring back our old friend - optimization algorithm.</p> <p>The optimization algorithm that we shall use for quantum neural networks will be gradient descen algorithm, in particular, the Adam optimizer. The Adam optimizer in quantum optimization needs to obtain the gradient of the expected value of a loss function in terms of the optimizable parameters.</p>"},{"location":"QuantumOpt/QML/QNN/#numerical-approximation","title":"Numerical approximation","text":"<p>If we had a real-valued function taking n real inputs f: \\mathbb{R}^{n} \\rightarrow \\mathbb{R}, we approximate its partial dervatives as </p>  \\frac{\\partial f}{\\partial x_j} = \\frac{f(x_{1},\\cdots,x_{j}+h,\\cdots,x_{n}) - f(x_{1},\\cdots,x_{n})}{h}  <p>where h is a sufficiently small value.</p>"},{"location":"QuantumOpt/QML/QNN/#automatic-differentiation","title":"Automatic differentiation","text":"<p>Given the current state of real quantum hardware, odds are that most of the quantum neural networks that you will train will run on simulators.</p>"},{"location":"QuantumOpt/QML/QNN/#the-parameter-shift-rule","title":"The parameter shift rule","text":"<p>By using the parameter shift rule, you can compute gradients when executing quantum neural networks on real quantum hardware. This technique enables us to compute gradients by using the same circuit in the quantum neural network, yet shifting the values of the optimizable parameteres. This technique cannot always be applied, but it works on many common cases and can be used in conjuction with other techniquesm such as numerical approximation.</p> <p>For example, if you had a circuit consisting of a single rotation gate R_{X}(\\theta)  and the measurement of its expectation value E(\\theta), you would be able to compute its derivative with respect to \\theta as </p>  \\nabla_{\\theta}E(\\theta) = \\frac{1}{2}\\bigg(E\\bigg(\\theta+\\frac{\\pi}{2}\\bigg) -E \\bigg( \\theta - \\frac{\\pi}{2}\\bigg) \\bigg).  <p>This is a analogy to the trigonometric functions such as a derivative of the sine function in terms of shifted values of the same sine function.</p> <p>Note</p> <p>When quantum neural networks are run on simulators, gradients can be computed using automatic differentiation techniques analogous to those of classical machine learning. Alternatively, numerical approximation is always an effective way to compute gradients.</p> <p>Note</p> <p>Everything looks good and promising, but quantum neural networks also pose some challenges when it comes to training them. </p> <ol> <li>They are known to be vulnerable to barren plateaus: situations in which the training gradients vanish and, thus, the training can no longer progress (see the paper by McClean et. al for further explanation). [2]</li> <li>It is also known that the kind of measurement operation used and the depth of the QNN play a role in how likely these barren plateaus are to be found. (in a paper by Cerezo and collaborators) [3]</li> <li>In any case, you should be vigilant when training your QNNs, and follow the literature for possible solutions should barren plateaus threaten the learning of your models</li> </ol>"},{"location":"QuantumOpt/QML/QNN/#practical-usage-of-quantum-neural-networks","title":"Practical usage of quantum neural networks","text":"<p>Here are a collection of ideas that you should keep in mind when designing QNN models and training them.</p> <ul> <li> <p>Make a wise choice</p> <p>Choose your feature map, variational form, and measurement operation properly. Be intentional about these choices and consider the porblem and the data taht you are working with. Your decision can lead to barren plateaus. Try to build a case from a well-established cases in literature.</p> </li> <li> <p>Size matters</p> <p>When you use a well-designed variational form, such as two-local, tree tensor, or strongly entanging layers, the power of the resulting quantum neural network will be directly related to the number of optimizable parameters it has</p> </li> <li> <p>Optimize optmization</p> <p>For most problems, the Adam optimizer can be your go-to choice for training a quantum neural network</p> </li> <li> <p>Feed your QNN properly</p> <p>The data that is fed to a quantum neural network should be normalized according to the requirements of the feature map in use. Also, depends on the complexity of the problem, considering using dimensionality reduction techniques.</p> </li> </ul> <p>If you want to boost the power of your QNN, you amy consider using data reuploading technique [4].In QNN, you have a feature map F dependendt on some data \\overrightarrow{x}, which is then followed by a variational form V dependent on some optimizable parameters \\overrightarrow{\\theta_{x}} - any number of times you want - before performing the measurement opeartion of the QNN.</p> <p>         A data reuploading scheme of a QNN     </p> <p>This has been shown, both in practice and in theory [5], to offer some advantages over the simpler, standard approach at the cost of increasing the depth of the circuits that are used.</p>"},{"location":"QuantumOpt/QML/QNN/#reference","title":"Reference","text":"<ol> <li>Combarro, E. F., &amp; Gonz\u00e1lez-Castillo, S. (2023). A practical guide to quantum machine learning and quantum optimisation: Hands-on approach to modern quantum algorithms. Packt Publishing.</li> <li>M. Cerezo, A. Sone, T. Volkoff, L. Cincio, and P. J. Coles, \u201cCost function dependent barren plateaus in shallow parametrized quantum circuits,\u201d Nature communications, vol. 12, no. 1, pp. 1\u201312, 2021.</li> <li>M. C. Caro, H.-Y. Huang, M. Cerezo, et al., \u201cGeneralization in quantum machine learning from few training data,\u201d Nature Communications, vol. 13, no. 1, p. 4919, 2022.</li> <li>A. P\u00e9rez-Salinas, A. Cervera-Lierta, E. Gil-Fuster, and J. I. Latorre, \u201cData re-uploading for a universal quantum classifier,\u201d Quantum, vol. 4, p. 226, Feb. 2020.</li> <li>M. Schuld, R. Sweke, and J. J. Meyer, \u201cEffect of data encoding on the expressive power of variational quantum-machine-learning models,\u201d Phys. Rev. A, vol. 103, p. 032 430, 3 Mar. 2021.</li> </ol>"},{"location":"QuantumOpt/QML/QSVM/","title":"Quantum Support Vector Machine","text":"<p>This page focuses on the quantum implementation of the Support Vector Machine (SVM). Please see Support Vector Machine for classical SVM theory.</p>"},{"location":"QuantumOpt/QML/QSVM/#going-quantum","title":"Going quantum","text":"<p>A Quantum Support Vector machines is a special case of SVMs which rely on the kernel trick.</p>"},{"location":"QuantumOpt/QML/QSVM/#general-idea-behind-qsvm","title":"General idea behind QSVM","text":"<p>In quantum support vector machine, we only need to use our quantum algorithm for the kernel function. This function will have to rely on a quantum computer to do the following:</p> <ol> <li>Take as input two vectors in the original space of data.</li> <li>Map each of them to a quantum state through a feature map.</li> <li>Compute the inner product of the quantum states and return it.</li> </ol> <p>Let's say we have a feature map \\phi such that for each \\overrightarrow{x}, we will have a circuit \\Phi(\\overrightarrow{x}) such that the output of the feature map will be quantum state \\phi(\\overrightarrow{x}) = \\Phi{\\overrightarrow{x}}|0\\rangle. With a feature map ready, we can then take our kernel function to be</p>  k(\\overrightarrow{a},\\overrightarrow{b}) = |\\langle\\phi(a)|\\phi(b)\\rangle|^{2} = |\\langle 0|\\Phi^{\\dagger}(a)\\Phi(b)|0\\rangle|^{2}.  <p>This is nothing then the probability of measuring all zeros after preparing the state \\Phi^{\\dagger}(a)\\Phi(b). This follows from the fact that the computational basis is orthonormal.</p> <p>Since quantum circuits are always represented by unitary operations, \\Phi^{\\dagger} is just a inverse of \\Phi. But \\Phi will be given by a series of quantum gates. So all you need to do is apply the gates in the circuit from right to left and invert each of them.</p> <p>Let's review how to implement a quantum kernel function.</p> <ol> <li>Take a feature map that will return a circuit \\Phi(\\overrightarrow{x}) for any input \\overrightarrow{x}.</li> <li>You prepare the state \\Phi^{\\dagger}(a)\\Phi(b) for the pair of vectors on which you want to compute the kernel.</li> <li>Return the probability of measuring zero on all the qubits.</li> </ol> <p>Excercise</p> <p>One of the conditions for a function k to be a kernel is that it be symmetric. Prove that, for any quantum kernel, is symmetric. (k(\\overrightarrow{a},\\overrightarrow{b}) = k(\\overrightarrow{b},\\overrightarrow{a}) for any inputs.)</p>"},{"location":"QuantumOpt/QML/QSVM/#feature-maps","title":"Feature maps","text":"<p>A feature map is a parameterized circuit \\Phi(\\overrightarrow{x}) that depends on the original data and thus can be used to prepare a state depends on it.</p>"},{"location":"QuantumOpt/QML/QSVM/#angle-encoding","title":"Angle encoding","text":"<p>The Angle encoding consists in the application of rotation gate on each qubit j parameterized by the value x_{j}. In angle encoding, we are using the x_{j} values as angles in the rotations hence the name of the encoding.</p> <p>We are free to use any rotation gate of our choice. However, if we use R_{Z} gates and take |0\\rangle to be our initial state. The action of our feature map will have no effects, as a result, we have to apply Hadamard gates on each qubit.</p> <p>         Figure. Angle encoding of an input \\( (x_{1}, \\cdots, x_{n}) \\) using different rotation gates.     </p> <p>These parameters should be properly normaliezd within a certian interval before feeding into angle encoding. For example, if they are normalized between 0 and 4\\pi, then the data will be mapped to a wider region of the feature space then if they were normalized with in 0 to 1 interval.</p>"},{"location":"QuantumOpt/QML/QSVM/#amplitude-encoding","title":"Amplitude encoding","text":"<p>Alghouth the Angle encoding can take n inputs on n qubits, the Amplitude encoding can take 2^{n} inputs when implemnted on an n-qubit circuit. If the amplitude encoding feature map is given an input x_{0}, \\cdots, x_{2^{n}-1}, it simply prepares the state</p>  | \\phi(\\overrightarrow{a}\\rangle) = \\frac{1}{\\sqrt{\\sum_{k}x_{k}^{2}}}\\sum_{k=0}^{2^{n}-1}x_{k} |k\\rangle.  <p>As we were told in the basic quantum state, all quantum states need to be normalized vectors. And that's what we have done for this equation to make sure the output is, obviously, a quantum state. Also, we can tell from the formula, the amplititude encoding works for any inputs except for the zero vector since nothing can be divided by 0.</p> <p>Normally, we don't use all the 2^{n} parameters that amplititude encoding provides. Instead, we use some of them and fill the rest with zeros. If you want to use all 2^{n} inputs for n-qubits, you have to make sure that n is big enough to avoid loss information in 2^{n}-1 degree of freedom.</p>"},{"location":"QuantumOpt/QML/QSVM/#zz-feature-map","title":"ZZ feature map","text":"<p>ZZ feature map can take n inputs a_{1}, \\cdots, a_{n} on n qubits, just like angle embedding. Its parameterized circuit is constructed following these steps:</p> <ol> <li>Apply a Hadamard gate on each qubit.</li> <li>Apply a rotation R_{Z} on each qubit j.</li> <li>For each pair of elements \\{j,k\\}\\subseteq\\{1,\\cdots,n\\} with j &lt; k, do<ul> <li>Apply a CNOT gate targeting qubit k and controlled by qubit j. </li> <li>Apply a rotation R_{Z} (2(\\pi - x_{j})(\\pi - x_{k})) on each qubit.</li> <li>Apply a CNOT gate targeting qubit k and controlled by qubit j. </li> </ul> </li> </ol> <p>         Figure. \\( ZZ \\) feature map of three qubits with inputs \\(x_{1}, x_{2}, x_{3} \\).     </p> <p>To guarantee a healthy balance between separating the extrema of the dataset and using as big a region a possible in the feature space, the variables could be normalized to [0,1].</p>"},{"location":"QuantumOpt/QML/QSVM/#quantum-support-vector-machines-in-pennylane","title":"Quantum support vector machines in PennyLane","text":""},{"location":"QuantumOpt/QML/QSVM/#quantum-support-vector-machines-in-qiskit","title":"Quantum support vector machines in Qiskit","text":""},{"location":"QuantumOpt/QML/QSVM/#references","title":"References","text":"<p>[1]. Combarro, E. F., &amp; Gonz\u00e1lez-Castillo, S. (2023). A practical guide to quantum machine learning and quantum optimisation: Hands-on approach to modern quantum algorithms. Packt Publishing.</p> <p>[2]. What are support vector machines (SVMs)? https://www.ibm.com/think/topics/support-vector-machine.</p> <p>[3]. Support vector machineBy Larhmam - Own work, CC BY-SA 4.0, Link</p>"},{"location":"QuantumOpt/QOpt/AQQA/","title":"Adiabatic Quantum Computing &amp; Quantum Annealing (AQQA)","text":"<p>Quantum annealers is a special type of quantum computer which is designed to find the approcimate solutions to combinatorial optimization problems.</p>"},{"location":"QuantumOpt/QOpt/AQQA/#key-takeaways","title":"Key Takeaways","text":"<ol> <li> <p>Adiabatic Quantum Computing:</p> <ul> <li>Adiabatic quantum computing uses the time-dependent Schr\u00f6dinger equation \\hat{H}(t) \\lvert\\psi(t)\\rangle = i \\hbar \\frac{\\partial \\lvert\\psi(t)\\rangle}{\\partial t}.</li> <li>The total time should be inversely proportional to the square of the spectral gap (wiki).</li> <li>Adiabatic quantum computing (AQC) is equivalent to the quantum circuit model but uses a time-dependent Hamiltonian for continuous evolution instead of discrete quantum gates.</li> <li>The adiabatic theorem ensures that, with slow enough evolution, the ground state can be measured at the end.</li> <li>The time-dependent Hamiltonian for the quantum annealing can be described as H(t) = A(t)H_{0} + B(t)H_{1}.</li> <li>The ground state of H_0 is a simple, well-understood configuration (e.g., a uniform superposition of all states) that is easy to prepare and serves as the starting point for quantum annealing.</li> <li>The ground state of H_1 represents the solution to the optimization or computational problem.</li> </ul> </li> <li> <p>Quantum Annealing:</p> <ul> <li>In practice, quantum annealing is used over AQC because adiabatic evolution can be too slow for practical applications.</li> <li>The Hamiltonian of the quantum annealing can be written as H(t) = -A(t)\\sum_{j=0}^{n-1}X_{j}-B(t)\\sum_{j,k}J_{jk}Z_{j}Z_{k}-B(t)\\sum_{j}h_{j}Z_{j}.</li> </ul> </li> </ol>"},{"location":"QuantumOpt/QOpt/AQQA/#example","title":"Example","text":"<p>Please see followings for D-Wave implementation:</p> <ol> <li>Working AQQA with D-wave</li> </ol>"},{"location":"QuantumOpt/QOpt/AQQA/#adiabatic-quantum-computing","title":"Adiabatic Quantum Computing","text":"<p>When using quantum circuits, we apply operations through discrete, sequential steps. However, adiabatic quantum computing relies on the use of continuous transformations.</p> <p>That's is, we will use a H(t) that will vary with time and that will be the driving force to change the state of our qubits according to time-dependent Schr\u00f6dinger equation:</p>  \\hat{H}(t) \\lvert\\psi(t)\\rangle = i \\hbar \\frac{\\partial \\lvert\\psi(t)\\rangle}{\\partial t}  <p>where:</p> <ol> <li>\\hbar is the reduced Planck's constant,</li> <li>\\lvert\\psi(t)\\rangle = \\psi(x,t) is the wave function,</li> <li>\\hat{H}(t) is the Hamiltonian operator, time-dependent.</li> <li>i is the imaginary unit.</li> </ol> <p>This means that the energy can varies with time.</p> <p>In addition to using time-dependent Hamiltonians, adiabatic evolution, the other important ingredient in our new quantum algorithm model. </p> <p>Note</p> <p>The adiabatic process is one in which the energy configuration of the system changes very gently.</p> <p>The key observation is that we will be considering problem whose optimal solutions will correspond to minimum-energy or ground states of some Hamiltonian of an Ising model. If we make our model so that the final Hamiltonian of the system is the one whose ground state will yield the solution to our problem, then we only need to measure the system to get the solution we are looking for.</p> <p>Note</p> <p>The idea behind adiabatic quantum computing is to start with a simple Hamiltonian, one for which we can easily obtain \u2014 and prepare! \u2014 the ground state, and evolve it \u201ccarefully.\u201d</p> <p>Of course, the crucial thing here is how to perform the evolution to ensure that it is, indeed, adiabatic. But don\u2019t worry, the adiabatic theorem from Max Born and Vladimir Fock, two of the fathers of quantum mechanics, says that for your process to be adiabatic, it should be slow enough.</p> <p>The tips is that the total time should be inversely proportional to the square of the spectral gap (wiki), which is the minimum difference in energy between the ground state and the first excited state of the Hamiltonian during the whole evolution. That is:</p> <ol> <li>If the difference is big, you\u2019d better be faster!</li> <li>If the difference is small, you\u2019d better be careful! -&gt; slower</li> </ol> <p>In a more formal way, suppose that you have a problem for which H_1 is the Hamiltonian whose ground state encodes the result that you want to find. For instance, H_1 could be an Ising Hamiltonian that you obtained from transforming a QUBO problem. Now, imagine that your system is in the ground state of some initial Hamiltonian H_0. We will soon discuss how to choose H_0, but for now just think that you can prepare its ground state easily enough so that it is a natural choice for you. Suppose that we run the process for total time T. The time-dependent Hamiltonian that we consider will be of the form </p>  H(t) = A(t)H_{0} + B(t)H_{1}  <p>where A and B are real-valued functions that accept inputs over the interval [0, T] such that A(0) = B(T) = 1 and A(T) = B(0) = 0. Notice that it holds that H(0) = H_{0} and H(T) = H_{1}, exactly as we desired. However, a more common choose is to set A(t) = 1-t/T and B(t) = t/T. </p> <p>Hamiltonian</p> <p>H_0 (Initial Hamiltonian):   The ground state of H_0 is a simple, well-understood configuration (e.g., a uniform superposition of all states) that is easy to prepare and serves as the starting point for quantum annealing. It does not encode the solution to the problem but ensures a practical and reliable initialization for the system.</p> <p>H_1 (Problem Hamiltonian):   The ground state of H_1 represents the solution to the optimization or computational problem. The goal of quantum annealing is to evolve the system from the ground state of H_0 to the ground state of H_1, where the true minimum of the problem is found.</p>"},{"location":"QuantumOpt/QOpt/AQQA/#quantum-annealing","title":"Quantum annealing","text":"<p>Quantum annealing relies on the same core idea as adiabatic quantum computing: it takes an initial Hamiltonian H_0, a final Hamiltonian H_1 whose ground state encodes the solution to the problem of interest, and it gradually changes the acting Hamiltonian from the initial to the final one by using some functions A and A (as described in the previous section) to decrease the action of H_0 and to increase the action of H_1. However, there are two difference between the quantum annealing and adiabatic quantum computing.</p>"},{"location":"QuantumOpt/QOpt/AQQA/#1-difference-in-hamiltonian","title":"1. Difference in Hamiltonian","text":"<p>The final Hamiltonian H_1 that can be realized, in the practial implementations of quantum annealing, must be selected from a certain way. </p> <p>The initial Hamiltonian in the quantum annealing setup is also usually fixed to be H_{0} = -\\sum_{j=0}^{n-1} X_{j}, where n is the number of qubits, and X_{j} stands for the tensor product in which the X matrix is acting on qubit j with the rest of positions occupied by I. The Ground state of H_{0} is easily seen to be \\bigotimes_{i=0}^{n-1} \\lvert+\\rangle, the tensor product of n copies of the plus state, which is relatively easy to prepare because it is completely unentangled. </p> <p>Thus, the Hamiltonian used in quantum annealing is given by:</p>  H(t) = -A(t)\\sum_{j=0}^{n-1}X_{j}-B(t)\\sum_{j,k}J_{jk}Z_{j}Z_{k}-B(t)\\sum_{j}h_{j}Z_{j},  <p>where J_{j,k} and h_{j} are some adjustable coefficicents, and A and B are functions such that A(0) = B(T) = 1 and A(T) = B(0) = 0, with T being the total annealing time, A and B are called the annealing schedule.</p>"},{"location":"QuantumOpt/QOpt/AQQA/#2-difference-in-spectral-gap","title":"2. Difference in spectral gap","text":"<p>In the Quantum annealing, evolution is no longer guaranteed to be adiabatic. Here are the two main reasons:</p> <ol> <li>The spectral gap (wiki) gap is the minimum of the difference between the ground sate and the first state of H(t) for t\\in[0,T], which can be very difficult to compute, sometimes, it can be more difficult to compute than find the ground state that we are looking for. Cubitt et al. [38].</li> <li>The time we need to compute the adiabatic process (evolution) could be too large.</li> </ol> <p>Thus, we only run the evolution for a certain amount of time that need not satisfy the conditions for adiabaticity, and hope to still be able to find good approximations of the optimal solution to our problem. In fact, remaining in the ground state of H(t)  is not always needed. Since, at the end, we are going to measure the state, it would be enough if the amplitude of an optimal or sufficiently good solution in our final state were big enough. That\u2019s because, then, the probability of obtaining a useful result will still be high. And, of course, we can always repeat the process several times and keep the best of all measurements!</p>"},{"location":"QuantumOpt/QOpt/AQQA/#working-with-d-wave","title":"Working with D-wave","text":"<p>D-Wave, the first company commercialize a quantum device that implemented quantum annealing as we have just covered. We need to keep in mind that, with these quantum computers, the evolution process will not be adiabatic in general, so there is no guarantee that the exact solution will be found in all cases.</p> <p>Using D-wave is easier than you think. You need to install Ocean, which is D-Wave's quantum annealing Python library, and to create a free account on D-Wave Laep, a cloud service where you can get one minute per month of free computing time on D-Wave's quantum annealers. </p> <p>Once you have everything set up, you can access quantum annealers to find an approximation of a solution to any combinatiorial optimiazation problem that you may have written as either an instance of finding the groud state of an Ising model or as a QUBO problem. Let's try with the MaxCut problem from QUBO first! </p> <p>         A very simple Max-Cut model     </p> <p>ok let's do some review first, for the Ising model from QUBO, we have</p>  \\begin{array}{ll} \\text{Minimize} &amp; -\\sum_{(j,k)\\in E} J_{jk}\\langle \\psi \\lvert Z_{j}Z_{k}\\lvert \\psi \\rangle -\\sum_{j} h_{j}\\langle \\psi \\lvert Z_{j}\\lvert \\psi \\rangle \\\\ \\text{where} &amp; \\lvert \\psi \\rangle \\text{is taken from the set of quantum states on n qubis} \\end{array}  <p>and we can reduce to a 3 vertices problem to the following:</p>  \\begin{array}{ll} \\text{Minimize} &amp; \\langle \\psi\\lvert(Z_{0}Z_{1}+Z_{0}Z_{2})\\lvert \\psi\\rangle = \\langle \\psi \\lvert Z_{0}Z_{1}\\lvert \\psi \\rangle + \\langle \\psi \\lvert Z_{0}Z_{2}\\lvert \\psi \\rangle,\\\\ \\text{where} &amp; \\lvert \\psi \\rangle \\text{is taken from the set of quantum states on 3 qubis} \\end{array}  <p>we can write the ground state as,</p>  Z_{0}Z_{1} + Z_{0}Z_{2}  <p>which is, of course, an Ising Hamiltonian in which J_{01} = J_{02} = 1 and the rest of the coefficients are 0.</p> <p>Next, all we need is to tell the quantum annealer is that those are the coefficients we want to use, and then we can perfrom the annealing multiple times to obtain some resutls that will hopefully wolve our problem. To specift the problem, we can use the <code>dimod</code> package inclided in the Ocean library.</p> <p>Next, let's move to our Jupyter file to work on this!</p>"},{"location":"QuantumOpt/QOpt/GAS/","title":"GAS: Grover Adpative Search","text":"<p>Grover's algorithm is a quantum search algorithm used to find elements satisfying a specific condition. Given a collection indexed by n-bit strings and a Boolean function f(x), the function returns 1 if the condition is satisfied and 0 otherwise. For example, with 8 elements, f(x) = 1 for x = 010 or x = 100, and f(x) = 0 otherwise.</p> <p>We treat f as a black box, meaning we can only call it with inputs and observe outputs, without knowing its inner workings. Since we lack information about which indices satisfy the condition, no position can be favored over another. In classical algorithms, searching among N elements with one satisfying the condition requires about N/2 calls to f on average, and up to N-1 in the worst case. </p> <p>Grover's algorithm, however, can locate the desired element with high probability using only about \\sqrt{N} calls. For instance, solving a problem with 1,000,000 elements requires just 1,000 calls instead of 500,000 in the classical case. To understand this, we need to explore quantum oracles and their applications.</p>"},{"location":"QuantumOpt/QOpt/GAS/#takeaways","title":"Takeaways","text":"<ol> <li>Quantum orcale is a unitary and reversible quantum operator. See Quantum oracles.</li> <li>Construction of a quantum orcale can be accomplished by using NOT gates and multi-CNOT gate. See Quantum oracles.</li> </ol>"},{"location":"QuantumOpt/QOpt/GAS/#quantum-oracles","title":"Quantum oracles","text":"<p>In the classical case, we have n inputs and a single output. In the quantum world, this setup doesn't work because quantum operations must be unitary and therefore reversible. As a result, every quantum gate must have the same number of inputs and outputs!</p> <p>The Quantum oracles, O_{f}, is an quantum gate (operation) of f that take any input of \\lvert x\\rangle \\lvert y \\rangle, where x is an n-bit string and y is a single bit, and the output of the O_{f} gate will be </p>  O_{f} = \\lvert x \\rangle \\lvert y \\oplus f(x) \\rangle  <p>where \\oplus denotes addition modulo 2. </p> <p>It might seem intuitive to think of the output as \\lvert x \\rangle \\lvert f(x) \\rangle. However, this could make the operation irreversible because different inputs \\lvert x \\rangle that satisfy f(x) = 1 would produce the same output \\lvert x \\rangle \\lvert 1 \\rangle. Instead, we use a reversible operation O_f, which ensures reversibility by applying the transformation \\lvert x \\rangle \\lvert y \\rangle \\mapsto \\lvert x \\rangle \\lvert y \\oplus f(x) \\rangle. </p> <p>If O_f is applied twice, the result is:</p>  \\lvert x \\rangle \\lvert y \\oplus f(x) \\oplus f(x) \\rangle = \\lvert x \\rangle \\lvert y \\rangle,  <p>since f(x) \\oplus f(x) = 0 (modulo 2 addition). This ensures the operation remains reversible.</p> <p>The operation O_f is commonly referred to as a quantum oracle for f, as it allows us to evaluate f(x) for any input x without needing to understand its internal implementation.</p> <p>For any Boolean function f, O_f can always be constructed using only NOT gates and multi-controlled NOT gates. For instance, consider a Boolean function f defined on 3-bit strings where f(x) = 1 only for x = 101 and x = 011. In this case, we can design a quantum circuit using multi-controlled NOT gates that target these specific inputs, flipping an ancillary qubit to encode f(x). This circuit effectively implements the transformation \\lvert x \\rangle \\lvert y \\rangle \\mapsto \\lvert x \\rangle \\lvert y \\oplus f(x) \\rangle.</p> <p>         Figure. Oracle for the Boolean function \\(f\\) that takes value 1 on 101 and 011, and value 0 on the rest of the 3-bit strings     </p> <p>In this example, we only used NOT gates before and after the multi-controlled gates to select those qubits that should be 0 in the input and to restore them to their original values.</p> <p>Excercise</p> <p>Construct a circuit for O_f where f is a 4-bit Boolean function that takes value 1 on 0111, 1110, and 0101, and value 0 on any other input.</p>"},{"location":"QuantumOpt/QOpt/GAS/#grovers-circuits","title":"Grover's circuits","text":"<p>Now, let's say that we want to apply Grover's algorithm to a Boolean function f which receives binary strings of leangth n. Besides the quantum oracle O_f we mentioned above, we still need two more elements to complete our circuit.</p> <p>        Figure. Circuit for Grover\u2019s algorithm in the case in which \\(f\\) receives strings of length 3 as input. The oracle \\(O_f\\) and Grover\u2019s diffusion operator are repeated, in that order, a number of times before the final measurements     </p>"},{"location":"QuantumOpt/QOpt/GAS/#phase-kickback","title":"Phase kickback:","text":"<p>The first block is composed of one-qubit gates that are applied to the initial state \\lvert0 \\cdots 0\\rangle \\lvert 0 \\rangle, where the first integer is of length n and the second one if of length 1. Thus the state before applying the oracle is </p>  \\begin{array}{lll} H^{\\otimes n+1} \\lvert 0 \\rangle ^{\\otimes n}\\lvert 1 \\rangle 1 &amp; = &amp; \\lvert + \\rangle^{\\otimes n} \\lvert - \\rangle \\\\ &amp; = &amp; \\frac{1}{\\sqrt{2^{n}}} \\ ((\\lvert 0 \\rangle + \\lvert 1 \\rangle) \\cdots (\\lvert 0 \\rangle + \\lvert 1 \\rangle)) \\ \\lvert + \\rangle \\\\ &amp; = &amp; \\frac{1}{\\sqrt{2^{n}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle \\lvert - \\rangle \\end{array}  <p>because we apply the first X gate to \\lvert 0 \\rangle to obtain \\lvert 1 \\rangle.</p> <p>The first register of this state is a superposition of all basis state \\lvert x \\rangle. This is exacatly what we will to evaluate f \"in superposition\" with our application of the O_{f} oracle.</p> <p>To apply the quantum oracle, we have</p>  \\begin{array}{lll} O_f \\bigg(\\frac{1}{\\sqrt{2^{n}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle \\color{red}{\\lvert - \\rangle} \\bigg) &amp; = &amp; O_f \\bigg(\\frac{1}{\\sqrt{2^{n+\\color{red}{1}}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle \\color{red}{(\\lvert 0 \\rangle - \\lvert 1 \\rangle)}\\bigg) \\\\  &amp; = &amp; O_f \\frac{1}{\\sqrt{2^{n+1}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle (\\lvert 0 \\rangle - \\lvert 1 \\rangle) \\\\ &amp; = &amp; \\frac{1}{\\sqrt{2^{n+1}}}\\sum_{x=0}^{2^{n}-1}O_{f}\\lvert x \\rangle (\\lvert 0 \\rangle - \\lvert 1 \\rangle) \\\\ &amp; = &amp; \\frac{1}{\\sqrt{2^{n+1}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle (\\lvert 0 \\oplus f(x) \\rangle - \\lvert 1 \\oplus f(x) \\rangle)  \\end{array}  <p>Let's focus on \\lvert 0 \\oplus f(x) \\rangle - \\lvert 1 \\oplus f(x) \\rangle. We can interpret it as a XOR operator such that:</p>  \\begin{array}{llll} \\lvert 0 \\oplus f(x) \\rangle - \\lvert 1 \\oplus f(x) \\rangle &amp; = &amp; \\lvert 0 \\rangle - \\lvert 1 \\rangle, &amp; \\text{if} \\ f(x) = 0 \\\\ \\lvert 0 \\oplus f(x) \\rangle - \\lvert 1 \\oplus f(x) \\rangle &amp; = &amp; -(\\lvert 0 \\rangle - \\lvert 1 \\rangle), &amp; \\text{if} \\ f(x) = 1 \\end{array}  <p>Thus, we can write it in a generalized form,</p>  \\lvert 0 \\oplus f(x) \\rangle - \\lvert 1 \\oplus f(x) \\rangle = (-1)^{f(x)}(\\lvert 0 \\rangle - \\lvert 1 \\rangle)  <p>As you may observe, there is information about the value f(x) coded in the amplitude of the state now. Now let's put everything together!</p>  \\begin{array}{lll} O_f \\bigg(\\frac{1}{\\sqrt{2^{n}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle \\lvert - \\rangle \\bigg) &amp; = &amp; \\frac{1}{\\sqrt{2^{n+1}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle (-1)^{f(x)}(\\lvert 0 \\rangle - \\lvert 1 \\rangle) \\\\     &amp; = &amp; \\frac{1}{\\sqrt{2^{n}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle (-1)^{f(x)}\\color{red}{\\frac{1}{\\sqrt{2}}(\\lvert 0 \\rangle - \\lvert 1 \\rangle)} \\\\     &amp; = &amp; \\frac{1}{\\sqrt{2^{n}}}\\sum_{x=0}^{2^{n}-1}\\lvert x \\rangle \\color{blue}{(-1)^{f(x)}}\\color{red}{\\lvert - \\rangle} \\end{array}  <p>The application of O_f introduces a relative phase (\\color{blue}{(-1)^{f(x)}}) to some of the states \\lvert x \\rangle in the superposition. This process is known as phase kickback, where the ancillary qubit in the \\lvert - \\rangle state creates the phase, but it ends up influencing the entire quantum state. </p> <p>The phase associated with each basis state \\lvert x \\rangle depends solely on f(x): it is 1 if f(x) = 0 and -1 if f(x) = 1. In this way, we say that the elements satisfying f(x) = 1 are marked. This phase shift doesn't change the probability of measuring any particular \\lvert x \\rangle state (since probabilities depend on the magnitude, not the phase).</p> <p>However, while this marks the desired elements, it doesn't directly help us find one of them. The probabilities of measuring each state remain unchanged before and after applying O_f. To identify the marked elements, we need a second step to amplify their probability, bringing them closer to detection.</p>"},{"location":"QuantumOpt/QOpt/GAS/#grovers-diffusion-operator","title":"Grover's diffusion operator","text":"<p>The Grover diffusion operator is used to increase the probability of measuring the marked states by performing an operation called inversion about the mean. Here\u2019s how it works:</p> <ol> <li>The average amplitude m of all the quantum states is calculated.</li> <li>Each amplitude a is then replaced with 2m - a. </li> </ol> <p>This transformation reduces positive amplitudes slightly while increasing negative ones, a process also known as amplitude amplification. As a result, the amplitudes of the marked states (those we are interested in) become slightly larger.</p> <p>However, a single application of this process is not enough to ensure a high probability of measuring a marked state. To achieve this, the quantum oracle O_f and the Grover diffusion operator are applied repeatedly. This iterative process amplifies the amplitudes of the marked states with each step, until their probability of being measured is high (close to 1). At that point, a measurement can be performed to successfully identify one of the marked states.</p> <p>Question</p> <p>You may ask, so how many times should we apply O_{f} with Grover's diffusiont operator?</p>"},{"location":"QuantumOpt/QOpt/GAS/#probability-of-finding-a-marked-element","title":"Probability of finding a marked element","text":"<p>There's one very important obervation about the O_{f} and the Grover's diffusion is that the combination of these two acts just like a rotation in a two-dimensional space. Let\u2019s assume we have n-bit strings and only one marked element, x_1. It can be shown that after m iterations of applying O_f and the Grover diffusion operator, the quantum state becomes:</p>  \\cos(2m+1)\\theta \\lvert x_{0} \\rangle + \\sin(2m+1)\\theta \\lvert x_{1} \\rangle,  <p>where </p>  \\lvert x_{0} \\rangle = \\sum_{x \\in \\{ 0, 1 \\}^{n}, \\ x \\neq x_{1}}\\sqrt{\\frac{1}{2^{n}-1}}\\lvert x \\rangle  <p>is the superposition of all unmarked states and \\theta \\in (0, \\pi/2) is such that </p>  \\begin{array}{ll} \\cos \\theta =  \\sqrt{\\frac{2^{n}-1}{2^{n}}}, &amp; \\sin \\theta = \\sqrt{\\frac{1}{2^{n}}}. \\end{array}  <p>Notice that \\lvert x_{0} \\rangle is just the uniform superposition of the state \\lvert x \\rangle such that f(x) = 0. Therefore, as you know, we want to obtain the state where \\sin (2m +1) \\theta is close to 1. That is,</p>  (2m + 1) \\theta \\approx \\frac{\\pi}{2}  <p>Solving for m</p>  m \\approx \\frac{\\pi}{4\\theta} - \\frac{1}{2}.  <p>More, by plugging in \\sin \\theta = \\sqrt{1/2^{n}} and we asigning a big enough of n, we then have </p>  \\theta \\approx \\sqrt{\\frac{1}{2^{n}}}  <p>After plugging it into m, </p>  m = \\frac{\\pi}{4}\\sqrt{2^{n}}.  <p>that is, the biggest integer that is less than or equal to (\\pi/4)\\sqrt{2^{n}}</p> <p>In this scenario, there are 2^n elements, but only one satisfies the condition we are searching for. A classical algorithm would require about 2^n / 2 calls to f, on average, to find the solution. In contrast, Grover's algorithm significantly reduces this to approximately \\sqrt{2^n} calls.</p> <p>However, there's an important distinction: while classical algorithms steadily increase the probability of finding the solution as f is used more, Grover's algorithm requires careful selection of the number of iterations m. If m is not chosen wisely, the algorithm can overshoot and reduce the probability of finding the solution. </p> <p>The probability of measuring the correct result x_1 is given by (\\sin((2m+1)\\theta))^2, a periodic function. After reaching values close to 1, the probability decreases back to 0, meaning the success rate oscillates.</p> <p>If there are k marked elements instead of just one, the same reasoning applies. A good choice for m in this case is:</p>  m = \\frac{\\pi}{4} \\sqrt{\\frac{2^n}{k}},  <p>where k is small compared to 2^n. This ensures the probability of measuring one of the marked elements is maximized.</p> <p>Let's see the following example:</p> <p>         Figure: Probability of finding one marked element among 16 when using Grover\u2019s algorithm with a number of iterations that varies from 0 to 20     </p> <p>In this example, we consider the case where n = 4 and analyze how the probability of finding exactly one marked element varies with the number of Grover iterations m, ranging from 0 to 20. </p> <p>In this scenario, \\lfloor (\\pi/4) \\sqrt{2^n} \\rfloor is 3. As shown, the success probability when m = 3 is close to 1. However, with m = 5, the probability drops significantly, and by m = 6, it is nearly 0.</p>"},{"location":"QuantumOpt/QOpt/GAS/#finding-minima-with-grovers-algorithm","title":"Finding Minima with Grover's Algorithm","text":"<p>Finding a minimum involves identifying a value that satisfies a specific property. Suppose we want to find the minimum of a function g defined over binary strings of length n. Here\u2019s how we can use Grover's algorithm for this task:</p> <ol> <li> <p>Initialization: Select an initial binary string x_0 at random and compute g(x_0).</p> </li> <li> <p>Oracle Setup: Construct an oracle that, on input x, returns 1 if g(x) &lt; g(x_0) and 0 otherwise.</p> </li> <li> <p>Grover's Search: Apply Grover's algorithm using the constructed oracle to search for an x_1 such that g(x_1) &lt; g(x_0).</p> </li> <li> <p>Update: </p> <ul> <li>If g(x_1) &lt; g(x_0), replace x_0 with x_1 and update the oracle to check the condition g(x) &lt; g(x_1).</li> <li>If g(x_1) \\geq g(x_0), keep x_0 as it is and continue.</li> </ul> </li> <li> <p>Iteration: Repeat this process multiple times, progressively narrowing down the search, until the minimum value is found.</p> </li> </ol>"},{"location":"QuantumOpt/QOpt/GAS/#quantum-oracles-for-combinatorial-optimization","title":"Quantum oracles for combinatorial optimization","text":"<p>To further explore the D\u00fcrr-H\u00f8yer algorithm and its application in finding minima, the next step involves constructing a quantum oracle capable of comparing two inputs x and y to determine whether g(x) &lt; g(y). This oracle serves as a fundamental component for implementing the algorithm to identify the minimum of a given function g.</p> <p>We will initiate this investigation by addressing specific cases, namely QUBO (Quadratic Unconstrained Binary Optimization) and HOBO (Higher-order Binary Optimization), where the coefficients of the polynomials are integer-valued. Building on this foundation, we will extend the discussion to more general cases, accommodating scenarios where the coefficients are real numbers.</p> <p>Before advancing to these topics, it is imperative to examine one of the most critical subroutines in quantum computing: the quantum Fourier transform (QFT). A thorough understanding of the QFT is essential for constructing and leveraging the quantum oracle effectively. Let us begin by exploring this fundamental tool.</p>"},{"location":"QuantumOpt/QOpt/GAS/#the-quantum-fourier-transform","title":"The quantum Fourier transform","text":"<p>The quantum Fourier transform (QFT) is a fundamental and highly versatile tool in quantum computing. It plays a critical role in various quantum algorithms, such as Shor's algorithm for integer factorization and the HHL algorithm for solving linear systems of equations.</p> <p>In our context, the QFT will be utilized to facilitate the arithmetic operations required to compute the values of polynomial functions in QUBO (Quadratic Unconstrained Binary Optimization) and HOBO (Higher-order Binary Optimization) problems.</p> <p>The QFT on m-qubits is defined as a unitary transformation that maps the computational basis state \\lvert j \\rangle to:</p>  \\frac{1}{\\sqrt{2^m}} \\sum_{k=0}^{2^m-1} e^{\\frac{2\\pi i j k}{2^m}} \\lvert k \\rangle,  <p>where i represents the imaginary unit. This transformation uses the principles of quantum superposition and interference, making it a powerful component for efficiently implementing arithmetic and optimization processes in quantum algorithms.</p> <p>The QFT can be implemented with a number of one- and two- qubit gates that is quadratic in m.</p> <p>For instance, the circuit for the QFT on three qubits is shown below. As you can see, the rightmost gate, which acts on the top and bottom qibits, is the SWAP gate. Moreover, this QFT circuit uses the phase gate, denote by P(\\theta). This is a parameterized gate that depends on an angle \\theta and whose coordinate matrix is </p>  \\begin{pmatrix} 1 &amp; 0\\\\ 0 &amp; e^{i\\theta} \\end{pmatrix}  <p>         Figure: A circuit example for the quantum Fourier transform on 3 qubits.     </p> <p>Note</p> <p>The phase gate is closely related to the R_Z gate introduced earlier. Specifically, when applied to a single qubit, the phase gate P(\\theta) is equivalent to R_Z(\\theta), differing only by an insignificant global phase. However, in the context of the QFT circuit, a controlled version of the phase gate is used. In this case, the global phase becomes a relative phase, which is highly significant and cannot be ignored.</p> <p>The QFT acts by introducing phases of the form e^{2\\pi ijk/2^{m}} when it is applied on basis state \\lvert j \\rangle and we are insterested in recovering the values j from those phases. Therefore, as you can imagine, we need to perform the inverse quantum Fourier transform (\\text{QFT}^\\dagger) </p>  \\frac{1}{\\sqrt{2^{m}}}\\sum_{k=0}^{2^{m}-1} e^{\\frac{2\\pi ijk}{2^m}}\\lvert k \\rangle  <p>to tha basis state \\lvert j \\rangle.</p> <p>The circuit for the inverse QFT can be obtained from that of the QFT by reading the circuit backwards and using the inverse of each gate we find. </p> <ol> <li>The inverse of P(\\theta) is P(-\\theta)</li> <li>The inverse of H and SWAP are its own.</li> </ol> <p>         Figure. Circuit for the inverse quantum Fourier transform on 3 qubits.     </p> <p>When designing a quantum oracle to minimize a function g, our goal will be to perform the computation in such a way that the g(x) values appear as exponents in the amplitudes of our states so that we can later recover them by means of the inverse QFT.</p>"},{"location":"QuantumOpt/QOpt/GAS/#takeaways_1","title":"Takeaways","text":"<ol> <li> <p>Steps for Using QFT in QUBO/HOBO Optimization:     The calculation between the QFT and the inverse QFT typically involves manipulating the phases encoded by the QFT to perform operations like comparisons, arithmetic, or optimizations. Here's the breakdown:</p> <ul> <li> <p>Basis \\lvert j \\rangle to \\lvert k \\rangle via QFT:</p> <ul> <li>QFT maps \\lvert j \\rangle to a superposition of \\lvert k \\rangle states with phases e^{2\\pi i jk / 2^m}.</li> <li>The phases encode the computational input j.</li> </ul> </li> <li> <p>Calculation (Phase Manipulation):</p> <ul> <li>Perform operations on the encoded phases to solve the problem:<ul> <li>Arithmetic: For QUBO/HOBO, encode polynomial g(x) values into the phases e^{i g(x)}.</li> <li>Comparison: Use controlled operations to compare values (e.g., g(x) &lt; g(y)).</li> <li>Optimization: Apply Grover's algorithm or similar methods to amplify desirable states (e.g., states with lower g(x)).</li> </ul> </li> </ul> </li> <li> <p>Inverse QFT (Recover Results):</p> <ul> <li>After the calculation, the inverse QFT decodes the manipulated phases back into the original basis \\lvert j \\rangle, revealing the result of the computation.</li> </ul> </li> </ul> </li> <li> <p>Advangates:</p> <ul> <li> <p>Efficient Encoding and Representation: QFT maps polynomial function values into quantum phases, enabling compact and efficient representation of large and complex optimization problems.</p> </li> <li> <p>Parallelism via Superposition: Allows simultaneous evaluation of g(x) for multiple inputs, drastically reducing computation time compared to classical methods.</p> </li> <li> <p>Facilitates Grover\u2019s Algorithm: Seamlessly integrates with Grover\u2019s search to amplify the probability of finding optimal solutions, leveraging quantum speedup for minimization tasks.</p> </li> <li> <p>Precision for Complex Problems: Ensures high accuracy in encoding and manipulating polynomial coefficients, critical for handling intricate interactions in HOBO and QUBO.</p> </li> <li> <p>Scalability: Efficient gate usage (O(m^2)) makes QFT scalable to larger problem sizes, making it practical for real-world applications.           </p> </li> </ul> </li> </ol>"},{"location":"QuantumOpt/QOpt/GAS/#encoding-and-adding-integer-numbers","title":"Encoding and adding integer numbers","text":"<p>When working with integer numbers, the two's complement representation is the most convenient method. Using m-bit strings, this representation encodes numbers in the range -2^{m-1} to 2^{m-1} - 1. </p> <ul> <li>Positive numbers are represented as standard binary numbers.</li> <li>Negative numbers x are represented as 2^m - |x|. For example, with m = 4:<ul> <li>3 is represented as 0011,</li> <li>-5 is represented as 1011 (since 2^4 - 5 = 11, and the binary representation of 11 is 1011).</li> </ul> </li> </ul> <p>This system ensures that positive numbers always start with 0, and negative numbers start with 1.</p> <p>Two's complement simplifies addition involving both positive and negative numbers by allowing standard binary addition, followed by discarding the final carry-out. Examples:</p> <ol> <li> <p>Adding 0011 (3) and 1101 (-5):</p>  0011 + 1101 = 11110 \\quad \\text{(5 bits, discard the carry-out to get $1110$)}.  <p>Result: 1110, which is -2 in two's complement.</p> </li> <li> <p>Adding 0110 (6) and 1100 (-4):</p>  0110 + 1100 = 10010 \\quad \\text{(5 bits, retain the lower 4 bits: $0010$)}.  <p>Result: 0010, which is 2.</p> </li> </ol> <p>Exercise</p> <p>Using two\u2019s complement with 5 qubits, represent 10 and \u22127 and perform their addition.</p> Answer <ol> <li>First we write 10: 01010 and -7: 11001 (2^5 - 7 = 25).</li> <li>then we perform the addition 01010 + 11001 = 100011 \\quad \\text{(6 bits)}.</li> <li>Then we keep the lower 5 bits: 00011. The final result is 00011 = 3.</li> </ol> <p>When computing g(x) with an oracle, we are intersted in obtaining the state</p>  \\frac{1}{\\sqrt{2^{m}}} \\sum_{k=0}^{2^{m}-1} e^{\\frac{2\\pi i g(x) k}{2^{m}}} \\vert k \\rangle,  <p>so that we can apply the inverse QFT to get \\lvert g(x) \\rangle. Notice that g(x) is always a sum of products of integer values. </p> <p>The phase encoding of j represents the transformation of a state into a quantum superposition with specific phase factors.</p>  \\frac{1}{\\sqrt{2^{m}}}\\sum_{k=0}^{2^{m}-1} e^{\\frac{2 \\pi i j k}{2^{m}}} \\lvert k \\rangle  <p>Let's start with phase encoding of \\color\\red{0}. To achieve this, we just apply the Hadamard gate to each and every qubit that we are using to represent the integer values. In this way, we will obtain the state</p>  \\frac{1}{\\sqrt{2^{m}}}\\sum_{k=0}^{2^{m}-1}\\lvert k \\rangle = \\frac{1}{\\sqrt{2^{m}}}\\sum_{k=0}^{2^{m}-1} e^{\\frac{2 \\pi i \\color\\red{0} k}{2^{m}}} \\lvert k \\rangle  <p>which is the phase encoding of \\color\\red{0}.</p> <p>Suppose that we have a state that phase-encodes j and we want to add l to it. We first assume that l is non-negative and deal with negative numbers later. To add l in phase encoding, we just need to apply the gates shown below</p> <p>         Figure. Circuit for adding \\(l\\) to a state in phase encoding when we have \\(m\\) qubits.     </p> <p>When we apply those gates to a basis state k, we obtain e^{\\frac{2 \\pi i l k}{2^{m}}} \\lvert k \\rangle. Thus, by linearity, when we apply the circuit to the phase encoding of j, we get</p>  \\frac{1}{\\sqrt{2^{m}}}\\sum_{k=0}^{2^{m}-1} e^{\\frac{2 \\pi i j k}{2^{m}}}e^{\\frac{2 \\pi i l k}{2^{m}}} \\lvert k \\rangle = \\frac{1}{\\sqrt{2^{m}}}\\sum_{k=0}^{2^{m}-1} e^{\\frac{2 \\pi i (j+l) k}{2^{m}}} \\lvert k \\rangle  <p>which is the phase encoding of j+l. </p> <p>For negative numbers, we can still apply figure above without additional adjustment. The key observation is that, for any integer 0\\leq h \\leq m-1, it holds that </p>  e^{\\frac{\\pi i(2^{m}+l)}{2^h}} = e^{\\frac{\\pi il}{2^h}}e^{\\frac{\\pi i2^{m}}{2^h}} = e^{\\frac{\\pi il}{2^h}}e^{\\pi i 2^{m-h}} = e^{\\frac{\\pi il}{2^h}}  <p>since m-h &gt; 0, making 2^{m-h} even and implying e^{\\pi i 2^{m-h}} = 1. This means that if we plug in l or 2^{m}+l in the gates of figure above, we obtain exactly the same circuit. Thus, we can work with the two's complement representation of l.</p> <p>         Figure presents a circuit that prepares the phase representation of 0, adds 3 to it and then subtracts 5. Of course, we can simplified the circuit such as \\(P(-5\\frac{\\pi}{2})P(3\\frac{\\pi}{2}) = P(\\pi)\\) and \\(P(3\\pi) = P(\\pi)\\). Since the phase \\(\\phi\\) is a modulo \\(2\\pi\\) quantity becasue \\(e^{i(\\pi +2\\pi)}\\). That is, adding \\(2\\pi\\) to the phase does not change the effect of the gate.     </p>  3 \\pi \\ \\text{mod} \\ 2\\pi = \\pi."},{"location":"QuantumOpt/QOpt/GAS/#computing-the-whole-polynomial","title":"Computing the whole polynomial","text":"<p>Here is an example of a quantum circuit that computes the polynomial 3x_0x_1 - 2x_1x_2 + 1:</p> <ol> <li>First Column: The first column of gates prepares the phase encoding of 0, creating a uniform superposition state as the initial step.</li> <li>Second Column: The next set of gates adds the constant term +1 to the phase encoding.</li> <li>Third Column: This column adds +3, but only if x_0 = x_1 = 1. To achieve this, all gates in this column are controlled by the qubits \\lvert x_0 \\rangle and \\lvert x_1 \\rangle. The operation ensures that the term 3x_0x_1 contributes only when x_0 and x_1 are both 1.</li> <li>Fourth Column: The final column subtracts 2, but only when x_1 = x_2 = 1. This is implemented using controlled gates activated by \\lvert x_1 \\rangle and \\lvert x_2 \\rangle.</li> </ol> <p>         Figure. Circuit for computing \\(3x_{0}x_{1} - 2x_{1}x_{2} + 1\\) in phase encoding.      </p> <p>Note</p> <p>Controlled gates execute their quantum operation (e.g., adding or subtracting a phase) only when the control qubits are in a specific state, typically \\lvert 1 \\rangle. For example:</p> <ul> <li>3x_0x_1 contributes only when x_0 = x_1 = 1, as enforced by the controlled gates.</li> <li>-2x_1x_2 contributes only when x_1 = x_2 = 1.</li> </ul> <p>These conditions ensure that each term in the polynomial is included in the computation only when logically valid. Controlled gates enforce these conditions, activating their operations only when the control qubits satisfy the required state.</p> <p>From the figure, we have adopted the usual convention of setting all the one-qubit gates that are controlled by the same qubits in a single column. This technique is also called as a single multi-qubit gate. Also, you may notice that these gates are multi-controlled, but you can always decompose them into a combination of one and two-qubit gates with Toffoli gates.</p> <p>There are two methods that we can use to deal with the real numbers in phase encoding.</p> <ol> <li> <p>Approximation Using Fractions:</p> <ul> <li>Represent real coefficients as fractions (e.g., 0.25 = 25/100, -1.17 = -117/100).</li> <li>Multiply the polynomial by the denominator (100) to convert coefficients to integers while preserving structure.</li> <li>Example: 0.25x_0 - 1.17x_1 \\to 25x_0 - 117x_1.</li> </ul> </li> <li> <p>Direct Encoding:</p> <ul> <li>Encode real coefficients directly by creating a superposition of approximations with the largest amplitude for the best approximation.</li> <li>Example: Coefficient 0.73 encoded as a superposition of 0.7, 0.73, 0.75.</li> </ul> </li> </ol>"},{"location":"QuantumOpt/QOpt/GAS/#constructing-the-oracle","title":"Constructing the oracle","text":"<p>This diagram represents an oracle to determine whether g(x) &lt; g(y), utilizing quantum operations. Here\u2019s a breakdown of its components and functionality:</p> <p>         Figure of a oracle to determine \\(g(x) &lt; g(y)\\).     </p> <p>If g(x) &lt; g(y), then g(x) - g(y) &lt; 0, and the most significant bit (MSB) of g(x) - g(y) will be 1. Using a CNOT gate, we set the bottom qubit (z) to \\lvert 1 \\rangle if g(x) &lt; g(y) and \\lvert 0 \\rangle otherwise.</p> <p>However, after obtaining z, we must reset the m auxiliary qubits to \\lvert 0 \\rangle for correct subsequent operations, such as Grover's algorithm, and to disentangle them from the circuit. If left entangled, these qubits could disrupt the computation.</p> <p>This reset process is called uncomputation. It involves reversing the operations used to compute g(x) - g(y). By applying the inverse QFT, the subtraction is undone, and the qubits return to their initial phase encoding of 0. Applying Hadamard gates then ensures the auxiliary qubits are reset to \\lvert 0 \\rangle, preserving the circuit's integrity for further computations.</p>"},{"location":"QuantumOpt/QOpt/GAS/#how-to-read-the-circuit","title":"How to Read the Circuit","text":"<ol> <li> <p>Input Qubits:</p> <ul> <li>\\lvert x \\rangle and \\lvert y \\rangle: Represent binary strings for x and y.</li> <li>\\lvert 0^m \\rangle: Auxiliary qubits initialized to \\lvert 0 \\rangle.</li> <li>\\lvert 0 \\rangle: A single qubit to store the result (z).</li> </ul> </li> <li> <p>Steps:</p> <ul> <li>Hadamard Gates: Prepare the auxiliary qubits in a superposition.</li> <li>Compute g(x) - g(y): Apply arithmetic gates to encode g(x) - g(y) in the auxiliary qubits.</li> <li>Apply Inverse QFT (\\text{QFT}^\\dagger): Decode the phase encoding into a computational basis state for comparison.</li> <li>CNOT Gate: Compare g(x) - g(y). If g(x) &lt; g(y), the MSB is 1, flipping the \\lvert z \\rangle qubit.</li> <li>Uncompute:<ul> <li>Apply the QFT and reverse g(x) - g(y) (now g(y) - g(x)).</li> <li>Reset auxiliary qubits to \\lvert 0 \\rangle using Hadamard gates.</li> </ul> </li> </ul> </li> </ol>"},{"location":"QuantumOpt/QOpt/GAS/#why-inverse-qft-comes-first","title":"Why Inverse QFT Comes First","text":"<p>The Inverse QFT (\\text{QFT}^\\dagger) is applied after computing g(x) - g(y) because it converts the phase-encoded result into a basis state, allowing the MSB to be read and compared using the CNOT gate. Without the inverse QFT, the phase-encoded information could not be directly accessed or interpreted.</p> <p>More, we can also create oracles to check whether polynomial constraints are met or not, like 3x_{0} - 2x_{0}x_{1} &lt; 3. This allows constraints to be incorporated into the optimization process without transforming the problem entirely into a QUBO form. This approach can sometimes be more convenient than using penalty terms for constraints.</p>"},{"location":"QuantumOpt/QOpt/GAS/#using-gas-with-qiskit","title":"Using GAS with Qiskit","text":"<p>Please see GAS Qiskit Molecule</p>"},{"location":"QuantumOpt/QOpt/QAOA/","title":"Quantum Approximate Optimization Algorithm","text":"<p>The Quantum Approximate Optimization Algorithm (QAOA) is a gate-based algorithm that can be considered the counterpart to quantum annealing in the quantum circuit model. QAOA utilizes quantum circuits\u2014with their qubits, quantum gates, and measurements\u2014to solve combinatorial optimization problems formulated in the QUBO framework.</p> <p>After reading this chapter, </p> <ol> <li>You will understand how QAOA works.</li> <li>You will know how to design the circuits used in the algorithm.</li> <li>You will be able to solve your own combinatorial optimization problems using QAOA in Qiskit and PennyLane.</li> </ol>"},{"location":"QuantumOpt/QOpt/QAOA/#from-adiabatic-computing-to-qaoa","title":"From adiabatic computing to QAOA","text":""},{"location":"QuantumOpt/QOpt/QAOA/#discretizing-adiabatic-quantum-computing","title":"Discretizing adiabatic quantum computing","text":"<p>In the Adiabatic Quantum Computing &amp; Quantum Annealing (AQQA), we've learn how to use adiabatic quantum computing and the quantum annearling to calculate combinatorial optimization problems. Both methods relied on the adiabatic theorem, which we used a time-dependent Hamiltonian that induced a continuous transformation of the state of a quantum system. You may wonder is there any sort of analog to this way of solving optimization problems for circuit-based quantum computers.</p> <p>QAOA was initially proposed as a discretization of adiabatic quantum computing with the goal of approximating the optimal solution to combinatorial optimization problems. Recall that the Hamiltonian used in adiabatic quantum computing and quantum annealing is of the form:</p>  H(t) = A(t)H_{0} + B(t)H_{1},  <p>with H_{0} and H_{1} two fixed Hamiltonians and A(t) and B(t) functions satifying A(0) = B(T) = 1 and A(T) = B(0) = 0, where T is the total time of the process. It turns out that the evolution of the quantum system is governed by the famous time-depent Schr\u00f6dinger equation.  </p> <p>In QAOA, all we need to know is that, applying discretization, we can express the solution as a production of operators of the form</p>  e^{i\\Delta t(A(t_{c})H_{0} + B (t_{c})H_{1})}  <p>applied to the initial state. Where,</p> <ol> <li>i is the imaginary unit.</li> <li>t_{c} is a fixed time point in [0,T]</li> <li>\\Delta t is a small amount of time.</li> </ol> <p>It's worth to notice that:</p> <ol> <li>In the inteval [t_{c}, t_{c} + \\Delta] we assume that the Hamiltonian is constant and equal to H(t_{c}) = A(t_c)H_{0} + B(t_{c})H_{1}. </li> <li>The smaller \\Delta t is, the better this approximation will be. </li> <li>It is also critical to know that e^{i\\Delta t(A(t_{c})H_{0} + B (t_{c})H_{1})} is a unitary transformation. </li> <li>Some of the quantum gates such as R_X, R_Y, and R_Z are also exponentials of some matirces. </li> </ol> <p>Thus, by using the descretiation technique, if \\lvert \\psi \\rangle is the initial state, then the final state can be approximated by</p>  \\bigg( \\prod_{m = 0}^{p}e^{i\\Delta t(A(t_{m})H_{0} + B (t_{m})H_{1})} \\bigg) \\lvert \\psi_{0} \\rangle  <p>where t_{m} = m\\frac{\\Delta t}{T}, and p = \\frac{T}{\\Delta t} (discretized by p steps).</p> <p>To compute this state with a quantum circuit, we just need an additional approximation. You know that e^{a+b} = e^{a}e^{b} for any real numbers. However, this identity doesn't hold for a matrices, unless the matrices commute. However, if \\Delta t is small, then </p>  e^{i\\Delta t(A(t_{m})H_{0} + B (t_{m})H_{1})}  \\approx e^{i\\Delta tA(t_{c})H_{0}}\\ e^{i\\Delta t B (t_{c})H_{1}},  <p>which is known as the Lie-Trotter formula.</p> <p>Putting theLie-Trotter formula with the discretization we mentioned above, we can obtain,</p>  \\bigg( \\prod_{m = 0}^{p}e^{i\\Delta t(A(t_{m})H_{0} + B (t_{m})H_{1})} \\bigg) \\lvert \\psi_{0} \\rangle =  \\prod_{m = 0}^{p} e^{i\\Delta tA(t_{c})H_{0}}\\ e^{i\\Delta t B (t_{c})H_{1}} \\lvert \\psi_{0} \\rangle,  <p>which is the inspiration for QAOA.</p>"},{"location":"QuantumOpt/QOpt/QAOA/#qaoa-algorithm","title":"QAOA Algorithm","text":"<p>Let's start with a combinatorial optimization problem that we want to solve, and we encode it into an Ising Hamiltonian H_{1}. To find its ground state and solve our problem, we seek to apply a quantum state evolution similar to that of quantum annealing, but using a quantum circuit instead of a quantum annealer.</p> <p>To simulate with a quantum circuit the evolution of a state under a time-dependent Hamiltonian, you only need to take an initial state \\lvert \\psi \\rangle and the alternate for p times the application of the operators e^{i\\gamma H_{1}} and e^{i\\beta H_{0}} for some values of \\gamma and \\beta. We will see that the unitary transformations e^{i\\gamma H_{1}} and e^{i\\beta H_{0}} can be implemented with just one-qubit and two-qubit quantum gates.</p> <p>What we are doing is using a quantum circuit to prepare a state of the form</p>  e^{i\\beta_{p}H_{0}}e^{i\\gamma_{p}H_{1}} \\dots e^{i\\beta_{2}H_{0}}e^{i\\gamma_{2}H_{1}} e^{i\\beta_{1}H_{0}}e^{i\\gamma_{1}H_{1}}  \\lvert \\psi_{0} \\rangle,  <p>where p \\geq 1. Usually, we collect all the coefficients in the exponents in two tuples \\beta = (\\beta_{1}, \\cdots, \\beta_{p}) and \\gamma = (\\gamma_{1}, \\cdots, \\gamma_{p}) and we denote the whole state by \\lvert \\beta , \\gamma \\rangle.</p> <p>In QAOA, we choose a fixed value of p and we have some values for \\beta and \\gamma. We'll just consider these values to be plain real numbers. </p> <p>So how to choose the best possible values? Remember that we are just trying to find the ground state of H_{1}, the lower the value of the energy \\langle \\beta, \\gamma \\lvert H_{1} \\lvert \\beta, \\gamma \\rangle, the better. In this way, we have transformed our optimization problem into finding the values \\beta and \\gamma that minimize </p>  E(\\beta, \\gamma) = \\langle \\beta, \\gamma \\lvert H_{1} \\lvert \\beta, \\gamma \\rangle.  <p>Since \\beta, \\gamma, and energy E(\\beta, \\gamma) are real numbers, we are just having a problem of finding a minimum for a real-valued function with real inputs. Therefore, we can just apply some optimization algorith such as the gradient descent algorithm. However, as we know, the number of amplitudes needed to describe a state like \\lvert \\beta , \\gamma \\rangle is exponential in the number of qubits that we are using. Thus, computing E(\\beta, \\gamma) may be difficult with just a classical computer.</p> <p>Luckly, estimating value of E(\\beta, \\gamma) is something that we can do very efficiently with a quantum computer - when the number of terms in H_1 is polynomial in the number of qubits.</p> <p>Thus, we can use the classical optimization algorithm for function minimization and use a quantum computer to estimate E value. Then we give that value back to the classical algorithm until it needs another of value E. This is what we call a hybrid algorithm.</p> <p>Once we obtained the optimal values \\beta^{*} and \\gamma^{*} for \\beta and \\gamma, we can use the quantum computer once more in order to prepare the state \\lvert \\beta^{*}, \\gamma^{*}\\rangle. This state should have a sizeable overlap with the ground state of H_{1}, so when we measure it in the computational basis, we will have a good chance of obtaining a string of zeros and ones that is a good solution to our original problem.</p>"},{"location":"QuantumOpt/QOpt/QAOA/#takeaways","title":"Takeaways","text":"<ol> <li>The input to QAOA is an Ising Hamiltonian H_{1}, the ground state of which we wich to approximate becasuse it encodes the solution to a certain combinatorial optimization problem. </li> <li>We consider the energy function E(\\beta, \\gamma) as defined before and we proceed to minimize it.</li> <li>Pick p \\geq 1 and some initial values \\beta_{0} and \\gamma_{0} for some optimization algorithm.</li> <li>Run the optimization in a classic computer, use quantum computer E to prepare the state \\lvert \\beta, \\gamma \\rangle and to estimate energy, retrun the value back to the optmization algorithm in a classic computer.</li> <li>Continue this porcess until the classical optmization algorithm finds the optimal values of \\beta^{*} and \\gamma^{*}.</li> <li>Using qunautm copmuter to prepare \\lvert \\beta^{*}, \\gamma^{*}\\rangle. </li> </ol> <p>Here is the pseudocode in the following algorithm:</p> <p>Algorithm 5.1 (QAOA).</p> <ol> <li>Choose a value for <code>p</code>.</li> <li>Choose a starting set of values:<ul> <li><code>\u03b2 = (\u03b2\u2081, ..., \u03b2\u209a)</code></li> <li><code>\u03b3 = (\u03b3\u2081, ..., \u03b3\u209a)</code></li> </ul> </li> <li>While the stopping criteria are not met, do the following:<ul> <li>Prepare state <code>|\u03b2, \u03b3\u27e9</code>. This is done on the quantum computer!</li> <li>From measurements of <code>|\u03b2, \u03b3\u27e9</code>, estimate <code>E(\u03b2, \u03b3)</code>.</li> <li>Update <code>\u03b2</code> and <code>\u03b3</code> according to the minimization algorithm.</li> </ul> </li> <li>Obtain the optimal values:<ul> <li><code>\u03b2*</code> and <code>\u03b3*</code> returned by the minimization algorithm.</li> </ul> </li> <li>Prepare state <code>|\u03b2*, \u03b3*\u27e9</code>. This is done on the quantum computer!</li> <li>Measure the state to obtain an approximate solution.</li> </ol>"},{"location":"QuantumOpt/QOpt/QAOA/#circuits-of-qaoa","title":"Circuits of QAOA","text":"<p>For QAOA, it always involves with preparing state of the form </p>  \\lvert \\beta, \\gamma \\rangle = e^{i\\beta_{p}H_{0}}e^{i\\gamma_{p}H_{1}} \\dots e^{i\\beta_{2}H_{0}}e^{i\\gamma_{2}H_{1}} e^{i\\beta_{1}H_{0}}e^{i\\gamma_{1}H_{1}}  \\lvert \\psi_{0} \\rangle,  <p>where \\lvert \\psi_{0} \\rangle is the ground state of H_{0}. As we know, H_{0} is usually taken to be -\\sum_{j=0}^{n-1} X_{j}, while H_{1} is an Ising Hamiltonian of the form </p>  -\\sum_{j,k} J_{jk}Z_{j}Z_{k} - \\sum_{j} h_{j}Z_{j}  <p>where the coefficients J_{jk} and h_{j} are real numbers. The ground state of H_{0} is \\bigotimes_{i=1}^{n-1} \\lvert + \\rangle. This state can be esaily prepared, you just need to use Hadamard gate on each qubit of the circuit starting from \\lvert 0 \\rangle.</p> <p>Let's focus on the operations of the form e^{i \\beta_{k}H_{0}}, with \\beta_{k} a real number. We also know that H_{0} = -\\sum_{j=0}^{n-1} X_{j} and that all X_{j} matrices commute with each other. Thus, we can say</p>  e^{i \\beta_{k}H_{0}} = e^{-i \\beta_{k} \\sum_{j=0}^{n-1}X_{j}} = \\prod_{j=0}^{n-1} e^{-i \\beta_{k}X_{j}}  <p>Since e^{i \\beta X_{j}} is the expression for the rotation gate R_{X}(2\\beta), we just need to apply this gate to each of the qubits in our circuit.</p> <p>Next, we will take care of the e^{i \\gamma_{l}H_{1}} for any real coefficient \\gamma_{l}. We know that H_{1} is a sum of terms of the form J_{jk}Z_{j}Z_{k} and h_{j}Z_{j}. Since these matrices commute with each other, we get</p>  e^{i \\gamma_{l}H_{1}} = e^{i\\gamma_{l}(\\sum_{j,k} J_{jk}Z_{j}Z_{k} + \\sum_{j}h_{j}Z_{j})} = \\prod_{j,k}e^{-i\\gamma_{l}J_{jk}Z_{j}Z_{k}} \\prod_{j}e^{-i \\gamma_{l} h_{j} Z_{j}}  <p>Same, the operations of the form e^{-i\\gamma_{l}h_{j}Z_{j}} can be carried out with rotation gate R_{Z}. Thus, we only need to figure out how to represent e^{-i \\gamma_{l} h_{j} Z_{j}} using quantum gates. </p> <ol> <li>First, let's denote the real number \\gamma_{l}J_{jk} by a. </li> <li>Notice that e^{iaZ_{j}Z_{k}} is the exponential of a diagonal matrix, since Z_{j}Z_{k} is the tensor product of diagonal matrices.</li> <li>If \\lvert x \\rangle is a computational basis, we have the following properties</li> </ol>      \\begin{array}{ll}         e^{-iaZ_{j}Z_{k}}\\lvert x \\rangle = e^{-ia}\\lvert x \\rangle &amp; \\text{if qubit j and k have the same values} \\\\         e^{-iaZ_{j}Z_{k}}\\lvert x \\rangle = e^{ia}\\lvert x \\rangle &amp; \\text{if qubit j and k have the different values}     \\end{array}  <p>This unitary action is implemented by the circuit below, where we have only depicted qubits j and k.</p> <p>         Figure. Circuit Implementation of \\(e^{-iaZ_{j}Z_{k}}\\)     </p> <p>Imagine that the Ising Hamiltonian of your problem is 3Z_{0}Z_{2} - Z_{1}Z_{2} + 2Z_{0} Then, the circuit used by QAOA to prepare \\beta, \\gamma</p> <p>         Figure. QAOA circuit with \\(p=1\\)     </p> <p>Don't worry, let's go through this together!</p> <ol> <li>First, we prepare the ground state of H_0 with a column of Hadamard gates.</li> <li>Remember that we set a = \\gamma_{l}J_{jk} and e^{-iaZ_{j}Z_{k}}\\lvert x \\rangle = e^{ia}\\lvert x \\rangle if qubit j and k have the different values. Since J = 3, we implemented R_{Z}(2a = 2 \\times 3\\gamma_{l} = 6 \\gamma_{1}) with CNOT gate between qubit 0 and 2. </li> <li>Next, we perform the same operation between qubit 1 and 2 with R_{Z}(2a = 2 \\times -1\\gamma_{l} = -2 \\gamma_{1}) and CNOT gates.</li> <li>Then we use an R_Z gate on qubit 0 to implement e^{-i2\\gamma_{1}Z_{0}}.</li> <li>Finally, a column of R_X(2\\beta_1) gates implements e^{-i\\beta_{1}\\sum_{j}X_{j}}</li> </ol> <p>If we increase the number of layers p, the circuit would grow by repeating for another p-1 times the very same circuit structure shown above except for the inintal Hadamard gates. More, we have to replace \\beta and \\gamma with corresponding p.</p>"},{"location":"QuantumOpt/QOpt/QAOA/#estimating-the-energy","title":"Estimating the energy","text":"<p>After knowing how to construct a quantum circuit, let's see how to estimate the energy for the state \\lvert \\beta, \\gamma \\rangle.</p> <p>Here, we are more interested in the energy of the \\lvert \\beta, \\gamma \\rangle since this is the quantity that we want to minimize. That's beeing say, we need to evaluate \\langle \\beta, \\gamma \\lvert H_{1} \\lvert \\beta, \\gamma \\rangle. Of course, we don't have to access to the state vector since we are preparing the state with a quantum computer.</p> <p>Since we already know how to evaluate efficiently \\langle x\\lvert H_{1} \\lvert x \\rangle for any basis state \\lvert x \\rangle. In fact, \\langle x\\lvert H_{1} \\lvert x \\rangle is the value of x in the cost function of our combinatorial optimization problem, because we derived H_{1} from it. We only need to notice that \\langle x\\lvert Z_{j} \\lvert x \\rangle = 1 if the j-th bit of x is 0 and that \\langle x\\lvert Z_{j} \\lvert x \\rangle = -1 otherwise. In the same fashion, \\langle x\\lvert Z_{j}Z_{k} \\lvert x \\rangle = 1 if j-th and k-th bits of x are equal and \\langle x\\lvert Z_{j}Z_{k} \\lvert x \\rangle = -1 if they are different.</p> <p>Let's look into this problem, for instance, try to evaluate \\langle x \\lvert H_{1} \\lvert x \\rangle if H_{1} = 3Z_{0}Z_{2}-Z_{1}Z_{2}+2Z_{0}, </p>  \\langle 101 \\lvert H_{1} \\lvert 101\\rangle = 3\\langle 101 \\lvert Z_{0}Z_{2} \\lvert 101\\rangle - \\langle 101 \\lvert Z_{1}Z_{2} \\lvert 101\\rangle + 2\\langle 101 \\lvert Z_{0} \\lvert 101\\rangle = 3 + 1 - 2 = 4  <p>Since state 101 gives that j=0,2-th bits. Therefore, Z_{j}Z_{k} = 1 if Z_{0}Z_{2} = -1 otherwise. In the same fashion, 1-th bits is 0, therefore, only \\langle 101|Z_{1}|101\\rangle =1.</p> <p>Practice</p> <p>Try to evaluate \\langle 100 \\lvert H_{1} \\lvert 100\\rangle with H_{1} = 3Z_{0}Z_{2}-Z_{1}Z_{2}+2Z_{0} = ?</p> Answer <p>H_{1} = 3Z_{0}Z_{2}-Z_{1}Z_{2}+2Z_{0} = 3 \\times (-1) - 1 + 2 \\times (-1) = -6.</p> <p>We also know that the can always write \\lvert \\beta, \\gamma \\rangle as a linear combination of basis state,</p>  \\lvert \\beta, \\gamma \\rangle = \\sum_{x} a_{x} \\lvert x \\rangle  <p>for certain amplitudes a_{x} such that \\sum_{x}|a_{x}|^{2} = 1. Therefore, we can have,</p>  \\langle \\beta, \\gamma \\lvert H_{1} \\lvert \\beta, \\gamma \\rangle = \\bigg( \\sum_{y} a_{y}^{*} \\langle y \\lvert \\bigg) H_{1} \\bigg( \\sum_{y} a_{x}^{*} \\lvert x \\rangle \\bigg) = \\sum_{y}\\sum_{x} a_{y}^{*} a_{x} \\langle y \\lvert H_{1} \\lvert x \\rangle = \\sum_{x} \\lvert a_{x} \\lvert ^{2} \\langle x \\lvert H_{1} \\lvert x \\rangle.  <p>because H_{1} \\lvert c \\rangle is always a multiple of \\lvert x \\rangle (H_{1} is a diagonal matrix since it is a sum of diagonal matrices), because \\langle y | x \\rangle = 0 when y\\neq x, and because a_{y}^{*} a_{x} = | a_{x} |^{2}.</p> <p>From this, we obtain</p>  \\langle \\beta, \\gamma \\lvert H_{1} \\lvert \\beta, \\gamma \\rangle \\approx \\sum_{x} \\frac{m_{x}}{M} \\langle x | H_{1} | x \\rangle,  <p>where m_{x} is the number of times that x was measured. The higher the value of M, the better this approximation will be.</p>"},{"location":"QuantumOpt/QOpt/QAOA/#qubo-and-hobo","title":"QUBO and HOBO","text":"<p>The Higher Order Binary Optimization (HOBO) or Polynomial Unconstrained Binary Optimization (PUBO), are the optimization problems that deals with minimizing a binary polynomial - of any degree - with no additional restrictions.</p>"},{"location":"QuantumOpt/QOpt/QAOA/#solving-hobo-by-tansforming-it-to-qubo-problems","title":"Solving HOBO by tansforming it to QUBO problems","text":"<p>One way to solve HOBO problems is by transforming them into QUBO problems. For an example, you can substitute prodcuts xy by a new binary variables z as long as you introduce a penalty term xy - 2xz - 2yz +3z, which is 0 if and only if xy = z. This kind of transformations can be access in D-Wave via <code>BinaryPolynomial</code> objects that you can reduce polynomials of degree 2 with the <code>make_quadratic</code> function.</p>"},{"location":"QuantumOpt/QOpt/QAOA/#solving-qubo-via-qaoa","title":"Solving QUBO via QAOA","text":"<p>We can consider a binary polynomial of any degree and transform it using the techniques we have covered in QUBO section. We will end up having a Hamiltonian that is a sum of tensor products of Z_{j} matrices. Luckly, we can now deal with more than just one or two Z_{j} matrices.</p> <p>In the same fashion, if \\lvert x \\rangle is a basis state, we have </p>  e^{-iaZ_{j1}Z_{j2}\\cdots Z_{jm}} \\lvert x \\rangle = e^{-ia} \\lvert x \\rangle  <p>if the sum of the bits of x in positions j_{1}, j_{2}, \\cdots, j_{m} is even, and </p> <p>$$ e^{-iaZ_{j1}Z_{j2}\\cdots Z_{jm}} \\lvert x \\rangle = e^{ia} \\lvert x \\rangle $$ if the sum is odd.</p> <p>This unitary action can be implemented by using consecutive CNOT gates with control qubits in j_{1}, j_{1}, \\cdots, j_{m-1} and targets in j_{m} then a R_Z gate with parameter 2a on qubit j_{m} and again, consecutive CNOT gates with control qubits j_{m-1}, j_{m-2}, \\cdots, j_{1} and targets in j_{m}. You can see the implementation in the image down below for case e^{-iaZ_{0}Z_{1}Z_{3}}.</p> <p>         Figure. Implementation of \\( e^{-iaZ_{0}Z_{1}Z_{3}}\\).     </p> <p>We can also expand the same concept to help us evaluate the Hamiltonian H_{1} that includes tensor products of Z matrices. We have </p>  \\langle x | Z_{j_1}Z_{j_2} \\cdots Z_{m} | x \\rangle = 1  <p>if the sum of the bits of x positions j_{1}, j_{1}, \\cdots, j_{m} is even. And</p>  \\langle x | Z_{j_1}Z_{j_2} \\cdots Z_{m} | x \\rangle = -1  <p>if the sum of the bits of x positions j_{1}, j_{1}, \\cdots, j_{m} is odd.</p> <p>Example</p> <p>Please evaluate \\langle 100| H_{1} |100 \\rangle with H_{1} = Z_{0}Z_{1}Z_{2} + 3Z_{0}Z_{2} - Z_{1}Z_{2} + 2Z_{0} </p> Answer <p>Notice that the convention for labelling qubits in a state vector like |x\\rangle = |x_{n}x_{n-1}\\cdots x_{0}\\rangle follows the big-endian convention, where:</p> <ul> <li>The leftmost bit corresponds to the most significant qubit (x_{n}), which has the highest index.</li> <li>The rightmost bit corresponds to the most significant qubit (x_{0}), which has the lowest index.</li> </ul> <p>This convention is used by IBM Qiskit and Google Cirq.</p> <p>(a)  Z_0 Z_1 Z_2 </p> <ul> <li>Positions involved:  j_0 = 0, j_1 = 1, j_2 = 2 </li> <li>Sum of bits:  x_0 + x_1 + x_2 = 0 + 0 + 1 = 1  (odd)</li> <li>Result:  \\langle 100 | Z_0 Z_1 Z_2 | 100 \\rangle = -1 </li> </ul> <p>(b)  3 Z_0 Z_2 </p> <ul> <li>Positions involved:  j_0 = 0, j_2 = 2 </li> <li>Sum of bits:  x_0 + x_2 = 0 + 1 = 1  (odd)</li> <li>Result:  \\langle 100 | Z_0 Z_2 | 100 \\rangle = -1 </li> <li>Coefficient:  3 </li> <li>Contribution:  3 \\times (-1) = -3 </li> </ul> <p>(c)  - Z_1 Z_2 </p> <ul> <li>Positions involved:  j_1 = 1, j_2 = 2 </li> <li>Sum of bits:  x_1 + x_2 = 0 + 1 = 1  (odd)</li> <li>Result:  \\langle 100 | Z_1 Z_2 | 100 \\rangle = -1 </li> <li>Coefficient:  -1 </li> <li>Contribution:  -1 \\times (-1) = 1 </li> </ul> <p>(d)  2 Z_0 </p> <ul> <li>Position involved:  j_0 = 0 </li> <li>Sum of bits:  x_0 = 0  (even)</li> <li>Result:  \\langle 100 | Z_0 | 100 \\rangle = 1 </li> <li>Coefficient:  2 </li> <li>Contribution:  2 \\times 1 = 2 </li> </ul> <p>Now, sum up the results from all terms \\langle 100 | H_1 | 100 \\rangle = (-1)+ (-3) + 1 + 2 = -1</p>"},{"location":"QuantumOpt/QOpt/QAOA/#using-qaoa-with-qiskit","title":"Using QAOA with Qiskit","text":"<p>See Solving QUBO problems with QAOA in Qiskit</p>"},{"location":"QuantumOpt/QOpt/QAOA/#using-qaoa-with-pennylane","title":"Using QAOA with PennyLane","text":"<p>See Using QAOA with PennyLane</p>"},{"location":"QuantumOpt/QOpt/QAOA/#summary","title":"Summary","text":"<p>In this chapter, you've learn the most popular quantum algorithms used to solve optimization problmes with gate-based quantum computers. You also learned that QAOA is a \"discretization version\" of a quantum annealing and it is implemented in hybrid way such that we run the classical optimization tool to update parameters such as \\beta and \\gamma and then use the powerful qunatum computer to prepare its energy state. And you surely know how to use these circuits to estimate expectation values in an efficient way.</p>"},{"location":"QuantumOpt/QOpt/QUBO/","title":"Quadratic unconstrained Binary Optimization Problems","text":""},{"location":"QuantumOpt/QOpt/QUBO/#key-takeaways","title":"Key Takeaways","text":"<ol> <li> <p>A expectation value is defined as \\langle \\psi| (\\sum_{(j,k)\\in E}Z_{j}Z_{k})|\\psi \\rangle = \\sum_{(j,k)\\in E}\\langle \\psi|Z_{j}Z_{k}|\\psi\\rangle, formed by an orthonormal basis by real eigenvalues with their eigenvectors. The minimum state of one of these eigenvector are called ground state, this is also known as a variational principle.</p> </li> <li> <p>Finding a minimum state in a combinatorial optimization problem is try to find the ground state its Hamiltonian of the system.</p> </li> <li> <p>A general rule of the numbers of slack variables: given a constraint Ax\\leq b, we solve x_{j} for 2^{j}-1\\leq b.</p> </li> </ol>"},{"location":"QuantumOpt/QOpt/QUBO/#examples","title":"Examples","text":"<p>Please see followings for Qiskit implementations:</p> <ol> <li>Start QUBO with Qiskit</li> <li>Knapsack problem with Qiskit</li> <li>Max-Cut and Traveler Saleman Problem with Qiskit</li> </ol>"},{"location":"QuantumOpt/QOpt/QUBO/#the-max-cut-problem-and-the-ising-model","title":"The Max-Cut problem and the Ising model","text":"<p>When you are given a graph, you are essentially given some elements, which we will refer to as vertices, and some connections between pairs of these vertices, which we will call edges.</p> <p>         Example of a Max-Cut     </p> <p>That is, it is a partition of the graph's vertices into two complementary sets S and T, such that the number of edges between S and T is as large as possible. Finding such a cut is known as the max-cut problem.</p> <p> </p>"},{"location":"QuantumOpt/QOpt/QUBO/#problem-formulation","title":"Problem formulation","text":"<p>We can formulate the Max-Cut problem as combinatorial optimization problem with no reference whatsoever to graphy, edges, or vertices. To do that, we assign vairable z_i to each vertix i=0, \\cdots, n-1 of the graph. Variables z_i will take value 1 or -1. Each assignment of values to the variables determines a cut: vertices whose variable take value 1 will be in one set and vertices whose variables take value -1 will be in the other one. </p> <p>The key observation to formulate Max-Cut as a combinatorial optimization problem is that edge is cut if and only if z_{j}z_{k}=1 This is because if two vertices are in the same set, then either z_{j} = z_{k} = 1 or z_{j} = z_{k} = 1 and, consequently, z_{j}z_{k}=1.</p> <p>Thus, we can formulate our problem into</p>  \\begin{array}{ll}     \\text{Minimize} &amp;\\sum_{(j,k)\\in E} z_{j}z_{k}\\\\     \\text{subject to} &amp; z_{j} \\in \\{-1,1\\}, \\ j = 0, \\cdots,n-1. \\end{array}  <p>From the figure we showed above, we can write</p>  \\begin{array}{ll}     \\text{Minimize} &amp;\\sum_{(j,k)\\in E} z_{0}z_{1}+z_{0}z_{2}+z_{1}z_{2}+z_{1}z_{3}+z_{2}z_{4}+z_{3}z_{4}\\\\     \\text{subject to} &amp; z_{j} \\in \\{-1,1\\}, \\ j = 0, \\cdots,4. \\end{array}  <p>The cut z_{1}=z_{4}=-1, z_{0}=z_{2}=z_{3}=1, which achieves a optimal value of -4. The cut z_{0}=z_{3}=-1, z_{1}=z_{2}=z_{4}=1, on the other hand, has a value of -2, which we already know that its not optimal value.</p> <p>         Another Max-Cut example     </p> <p>We can formulate the above graph as the follwoing:</p>  \\begin{array}{ll}     \\text{Minimize} &amp; z_{0}z_{1}+z_{0}z_{2}+z_{1}z_{0}+z_{1}z_{2}+z_{1}z_{4}+z_{2}z_{0}+z_{2}z_{1}+z_{2}z_{3}\\\\      &amp; +z_{3}z_{4}+z_{3}z_{5}+z_{4}z_{5}\\\\     \\text{subject to} &amp; z_{j} \\in \\{-1,1\\}, \\ j = 0, \\cdots,4. \\end{array}"},{"location":"QuantumOpt/QOpt/QUBO/#the-ising-model","title":"The Ising model","text":"<p>         Example of an Ising model     </p> <p>The total energy of the system is given by a quantity called the Hamiltonian function defined by</p>  -\\sum_{j,k}{J_{jk}}z_{j}z_{k}-\\sum_{j}h_{j}z_{j}  <p>where the coefficients J_{jk} represent the interaction between particles j and k and the coefficicents h_j represent the influence of an external magnetic field on particle j.</p> <p>Finding the state of minimum energy of the system consists in obtaining a spin configuration for which the Hamiltonian function attains its minimum value. As you can easily check that if J_{jk} coefficients are -1 and all the h_j coefficients are 0, the problem is exactly the same as the max-cut problem.</p> <p>That is, we can formulate the Ising showed above like as</p>  \\begin{array}{ll}     \\text{Recall} &amp; \\color{red}{-\\sum_{j,k}{J_{jk}}z_{j}z_{k}}\\color{blue}{-\\sum_{j}h_{j}z_{j}}\\\\     \\text{Minimize} &amp; \\color{red}{z_{0}z_{1}-2z_{1}z_{2}+z_{2}z_{3}-3z_{0}z_{4}+z_{4}z_{5}+z_{1}z_{5}}\\\\                     &amp; \\color{red}{-2z_{5}z_{6}+z_{2}z_{6}+z_{6}z_{7}-3z_{3}z_{7}-3z_{4}z_{8}+z_{8}z_{9}}\\\\                     &amp; \\color{red}{z_{5}z_{9}-2z_{9}z_{10}+z_{6}z_{10}+z_{10}z_{11}-7z_{3}z_{11}}\\\\                     &amp; \\color{blue}{-z_{0}-z_{1}-z_{2}-z_{3}-z_{4}-z_{5}-z_{6}-z_{7}-z_{8}}\\\\                     &amp; \\color{blue}{-z_{9}-z_{10}-z_{11}}\\\\     \\text{subject to} &amp; z_{j} \\in \\{-1,1\\}, \\ j = 0, \\cdots,11. \\end{array}"},{"location":"QuantumOpt/QOpt/QUBO/#formulating-optimization-problems-the-quantum-way","title":"Formulating optimization problems the quantum way","text":"<p>         A very simple Max-Cut model     </p> <p>Taking above very simple Max-Cut problem as an example. To transform a Max-Cut problem in to a quantum one, we have to use Z matrix. Since we know that</p>  \\begin{array}{ll} \\langle0|Z|0\\rangle =     \\begin{pmatrix}1 &amp; 0 \\end{pmatrix}     \\begin{pmatrix}1 &amp; 0\\\\ 0 &amp; -1 \\end{pmatrix}     \\begin{pmatrix}1 \\\\ 0 \\end{pmatrix}=1, &amp; \\langle1|Z|1\\rangle =     \\begin{pmatrix}0 &amp; 1 \\end{pmatrix}     \\begin{pmatrix}1 &amp; 0\\\\ 0 &amp; -1 \\end{pmatrix}     \\begin{pmatrix}0 \\\\ 1 \\end{pmatrix}=-1  \\end{array}   <p>Now, consider the tensor product Z\\otimes Z\\otimes I and basis state |010\\rangle. </p>  \\begin{array}{ll} \\langle 010 |Z\\otimes Z\\otimes I|010\\rangle &amp; = \\langle 010|(Z|0\\rangle \\otimes Z|1\\rangle\\otimes I|0\\rangle)\\\\    &amp; = \\langle0|Z|0\\rangle \\langle1|Z|1\\rangle \\langle0|I|0\\rangle \\\\    &amp; = 1 \\cdot (-1) \\cdot 1 = -1 \\end{array}  <ul> <li>|010\\rangle represents a cut where vertices 0 and 2 are grouped together and vertex is assigned to the other.</li> <li>The product \\langle 010 |Z\\otimes Z\\otimes I|010\\rangle evaluates to -1 means that edge (0,1) has extremes in dfferent sets of the cut since we have used Z\\otimes Z\\otimes I, having Z operators acting on qubits 0 and 1.</li> <li> <p>We usually denote Z\\otimes Z\\otimes I as Z_{0}Z_{1} and, following this convention, we could have, for instance</p>  \\langle 010|Z_{0}Z_{2}|010\\rangle = \\langle0|Z|0\\rangle\\langle1|I|1\\rangle\\langle0|Z|0\\rangle = 1 \\cdot 1 \\cdot 1 = 1  <p>since the edge (0,2) is not cut with this particular case. -   Also, we can expand this to </p>  \\langle x|(Z_{0}Z_{1}+Z_{0}Z_{2})|x\\rangle = \\langle x|Z_{0}Z_{1}|x\\rangle+\\langle x|Z_{0}Z_{2}|x\\rangle  <p>due to linearity.</p> </li> </ul> <p>This is also applies to all basis state |x\\rangle with x \\in \\{000,001,\\cdots,111\\}, so \\langle x|Z_{j}Z_{k}|x\\rangle will be -1 if the edga (j,k) is cut under an assignment x.</p> <p>Note</p> <p>For any basis state |x\\rangle, it holds that either Z_{j}Z_{k}|x\\rangle = |x\\rangle or Z_{j}Z_{k}|x\\rangle = -|x\\rangle. This indicates that |x\\rangle is an eigenvector of Z_{j}Z_{k} with eigenvalue either 1 or -1. Thus, for x\\neq y we have  $$ \\langle y | Z_{j}Z_{k} |x\\rangle = \\pm \\langle y|x\\rangle = 0. $$</p> <p>Consequently, since we can write |\\psi \\rangle as \\psi \\rangle = \\sum_{x}a_{x}|x\\rangle, from linearity, we have</p>  \\begin{array}{ll} \\langle \\psi|Z_{j}Z_{k}|\\psi\\rangle &amp; = \\bigg( \\sum_{y}a_{y}^{*}\\langle y| \\bigg) Z_{j}Z_{k} \\bigg( \\sum_{x}a_{x}\\langle x| \\bigg)\\\\     &amp; = \\sum_{y}\\sum_{x}a_{y}^{*}a_{x}\\langle y|Z_{j}Z_{k}|x\\rangle\\\\     &amp; = \\sum_{x}|a_{x}|^{2}\\langle x|Z_{j}Z_{k}|x\\rangle, \\end{array}  <p>where a_{x}^{*}a_{x} = |a_{x}|^{2}.</p> <p>Hence, we transform \\langle x|(Z_{0}Z_{1}+Z_{0}Z_{2})|x\\rangle to</p>  \\begin{array}{ll} \\langle x|(Z_{0}Z_{1}+Z_{0}Z_{2})|x\\rangle &amp; = \\langle\\psi|Z_{0}Z_{1}|\\psi\\rangle\\langle\\psi|Z_{0}Z_{2}|\\psi\\rangle\\\\     &amp; = \\sum_{x}|a_{x}|^{2}\\langle x|Z_{0}Z_{1}|x\\rangle + \\sum_{x}|a_{x}|^{2}\\langle x|Z_{0}Z_{2}|x\\rangle \\\\     &amp; = \\sum_{x}|a_{x}|^{2}\\langle x|Z_{0}Z_{1}+Z_{0}Z_{2}|x\\rangle. \\end{array}  <p>Since we know \\sum_{x}|a_{x}|^{2} = 1 (Total probability sum is 1) and the every |a_{x}|^{2} is non-negative, </p>  \\begin{array}{ll} \\sum_{x}|a_{x}|^{2}\\langle x|Z_{0}Z_{1}+Z_{0}Z_{2}|x\\rangle &amp; \\leq \\sum_{x}|a_{x}|^{2}\\langle x_{\\text{min}}|Z_{0}Z_{1}+Z_{0}Z_{2}|x_{\\text{min}}\\rangle\\\\     &amp; = \\langle x_{\\text{min}}|Z_{0}Z_{1}+Z_{0}Z_{2}|x_{\\text{min}}\\rangle \\sum_{x}|a_{x}|^{2}\\\\     &amp; = \\langle x_{\\text{min}}|Z_{0}Z_{1}+Z_{0}Z_{2}|x_{\\text{min}}\\rangle \\end{array}  <p>where |x_{\\text{min}}\\rangle is a basis state x \\in \\{000,001,\\cdots,111\\} for which x_{\\text{min}}|Z_{0}Z_{1}+Z_{0}Z_{2}|x_{\\text{min}} is minimum and x_{\\text{min}} represents a maximum cut.</p> <p>Therefore, we rewite our problem in to a quantum form as </p>  \\begin{array}{l} \\text{minimize} \\ \\ \\ \\ \\langle x_{\\text{min}}|Z_{0}Z_{1}+Z_{0}Z_{2}|x_{\\text{min}}\\rangle = \\sum_{x}|a_{x}|^{2}\\langle x|Z_{0}Z_{1}+Z_{0}Z_{2}|x\\rangle\\\\ \\text{where} |\\psi\\rangle \\text{is taken from the set of quantum state on 3 qubits.} \\end{array}  <p>This, in constrast to the previous example, we are minimizing overall possible quantum states.</p> <p>For any number of qubits and any sum of tensor products Z_{j}Z_{k}, if we have a graphy with set of vertices V, of size n, and set of edge E, we can rewrite the Max-Cut problem for the graph as:</p>  \\begin{array}{l} \\text{minimize} \\ \\ \\ \\ \\sum_{(j,k)\\in E}\\langle \\psi|Z_{j}Z_{k}|\\psi\\rangle\\\\ \\text{where} |\\psi\\rangle \\text{is taken from the set of quantum state on 3 qubits.} \\end{array}  <p>We said that the matrix</p>  \\sum_{(j,k)\\in E}Z_{j}Z_{k}  <p>are Hamiltonian, as the matrix equals to its conjugate tranpose. Hamiltonian has real eigenvalues and being able to form an orthonomal basis withe their eigenvector. The equantity </p>  \\langle \\psi| \\bigg( \\sum_{(j,k)\\in E}Z_{j}Z_{k} \\bigg)|\\psi \\rangle = \\sum_{(j,k)\\in E}\\langle \\psi|Z_{j}Z_{k}|\\psi\\rangle,  <p>which we usually refer to the expectation value of \\sum_{(j,k)\\in E}Z_{j}Z_{k}, attains its minimum value on one of those eigenvectors, aclled the ground state. </p> <p>In the same fashion, we appy this method to the Ising model</p>  \\begin{array}{l} \\text{minimize} \\ \\ \\ \\ -\\sum_{(j,k)\\in E}J_{jk}\\langle \\psi|Z_{j}Z_{k}|\\psi\\rangle - \\sum_{j}h_{j}\\langle\\psi|Z_{j}|\\psi\\rangle,\\\\ \\text{where} |\\psi\\rangle \\text{is taken from the set of quantum state on 3 qubits.} \\end{array}"},{"location":"QuantumOpt/QOpt/QUBO/#moving-from-ising-to-qubo-and-back","title":"Moving from Ising to QUBO and back","text":""},{"location":"QuantumOpt/QOpt/QUBO/#subset-sum","title":"Subset Sum","text":"<p>Let's say that you are given a set of integers S and T, and you are asked whether there is any subset of S whose sum is T. For example, if S = \\{1,3,4,7,-4\\} and T = 6, then the answer is positive because 3+7-4 = 6. If S = \\{2,-2,4,8,-12 \\} and T=1, the answer is negative because all the numbers in the set are even and they cannot add up to an odd number.</p> <p>This problem is so called the Subset Sum problem and known for a N-complete. It turns out that we can reduce the Subset Sum problem to finding a spin configuration of minimal energy for any Ising model.</p> <p>Let's consider a binery values instead of 1 and -1 in this case. If we are given a case S = {a_{0},\\cdots,a_{m}} and an integer T, we can define binary variable x_j, j=0,\\cdots,m and consider</p>  c(x_{0},x_{1},\\cdots,x_{m}) = (a_{0}x_{0}+a_{1}x_{1}+ \\cdots +a_{m}x_{m} - T)^{2}  <p>and we can find the positive answer if and only if we can find the binary values x_j, j=0,\\cdots, m such that c(x_{0},x_{1}, \\cdots, x_{m}) = 0.</p> <p>For example, if we are given a set of S = \\{1,4,-2 \\} and T=2, we can formulate the question as:</p>  \\begin{array}{ll} \\text{minimize} &amp; (x_{0}+4x_{1}-2x_{2}-2)^{2}\\\\ \\text{subject to} &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, \\cdots,m \\end{array}  <p>and we have to expand (x_{0}+4x_{1}-2x_{2}-2)^{2} to obtain the epxression to be optimized. For this case, we need x_{0}, x_{1} = x_{2} = 1 to find a optimal solution. It turns out that, if the minimum is 0, the Subset Sum has a positive solution; otherwise, it doesn\u2019t.</p> <p>Notice that, in all of these cases, the function c(x_{0},x_{1},\\cdots,x_{m}) that we need to minimize is a polynomial of degree 2 on the binary variables x_j. We thus generalize this setting and define Quadratic Unconstrained Binary Optimization (QUBO) problems.</p>  \\begin{array}{ll} \\text{minimize} &amp; q(x_{0},\\cdots,x_{m})\\\\ \\text{subject to} &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, \\cdots,m \\end{array}  <p>where q(x_{0},\\cdots,x_{m}) is a quadratic polynomial on the x_j variables.</p> <p>Note</p> <p>We are calling this QUBO since we are minimizing quadratic expressions over binary variables with no restrictions (every combinations of ones and zeros are acceptable).</p> <p>For an Ising problem, if you want to minimize:</p>  -\\sum_{j,k}J_{j,k}z_{j}z_{k} - \\sum_{j} h_{j}z_{j}  <p>with some variables z_{j}, j = 0,\\cdots,m, taking values 1 or -1, you can define new variables x_{j} = (1-z_{j})/2. x_{j} will be 0 when z_{j} is 1, and 1 when z_{j} is -1.</p> <p>On the other hand, you can define a new variable called z_{j} = 1-2x_{j}, which leads you to a quadratic polynomial in the binary variable x_j that takes exactly the same values as the energy function of the original Ising model. If you minimize the polynomical for the variables x_{j}, you can then recover the spin value z_{j} that achieve the minimal energy. As you may wonder, you can also use z_{j} = 2x_{j}-1 to transform Ising problem into QUBO.</p> <p>For example, if the Ising energy is given by \\frac{1}{2}z_{0}z_{1}+z_{2}, then, under the transformation z_{j} = 1-2x_{j}, the corresponding QUBO problem will be (by substitute z_{0} = 1-2x_{0}, z_{1} = 1-2x_{1}, and z_{2} = 1-2x_{2} in to Ising energy \\frac{1}{2}z_{0}z_{1}+z_{2}.):</p>  \\begin{array}{ll} \\text{minimize} &amp; -2x_{0}x_{1}+x_{0}+x_{1}-2x_{2}+\\frac{1}{2}\\\\ \\text{subject to} &amp; x_{j}\\in \\{0,1\\}, \\ j =0, 1, 2. \\end{array}"},{"location":"QuantumOpt/QOpt/QUBO/#combinatorial-optimization-problems-with-the-qubo-model","title":"Combinatorial optimization problems with the QUBO model","text":""},{"location":"QuantumOpt/QOpt/QUBO/#binary-linear-programming","title":"Binary linear programming","text":"<p>Binary linear programming problems involve optimizaing a linear function on binary variables subject to linear constraints. </p>  \\begin{array}{ll} \\text{minimize} &amp; c_{0}x_{0}+c_{1}x_{1}+\\cdots+c_{m}x_{m}\\\\ \\text{subject to} &amp; Ax \\leq b, \\\\ &amp; x_{j}\\in \\{0,1\\}, \\ j = 0,\\cdots,m, \\end{array}  <p>where c_{j} are integer coefficients, A is an integer matrix, x is the transpose of (x_{0},\\cdots,x_{m}), and b is an integer column vector.</p> <p>For an example:</p>  \\begin{array}{ll} \\text{minimize} &amp; -5x_{0}+3x_{1}-2x_{2} \\\\ \\text{subject to} &amp; x_{0}+x_{2} \\leq 1, \\\\                 &amp; 3x_{0} - x_{1}+3x_{2} \\leq 4,\\\\                 &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2, \\end{array}  <p>Note</p> <p>Binary linear programming (zero-one programming) is NP-hard.</p> <p>To write a binary linear program in QUBO, we need to perfrom some transformations. The first one is to convert the inequality constraints into equality constraints by adding slack variables. In the previous example, we have inquality constraints x_{0}+x_{2} \\leq 1 and 3x_{0} - x_{1}+3x_{2} \\leq 4. We know that the minimum value for the left hand side of the first equation is 0 and -1 for the left hand side of the second equation. The goal here is to add slack variable(s) to make the equation equals when left hand side of the original inequality has its minimum. To add non-negative slack variable(s), we can modify the first inequality into</p>  x_0 + x_2 + y_0 = 1  <p>and since the minimum of the second inequality is when x_0 = x_2 =0 and x_1 = 1, 3x_{0} - x_{1}+3x_{2} = -1. We need to add at least 3 different slack variables with a proper coefficient to make 3x_{0} - x_{1}+3x_{2} = 5. Therefore,</p>  3x_0-x_1+3x_2+y_1+2y_2+2y_3 = 4  <p>can be  satisfied if and only if 3x_{0} - x_{1}+3x_{2} \\leq 4 can be satified. Now, we rewrite the original problem as,</p>  \\begin{array}{ll} \\text{minimize} &amp; -5x_{0}+3x_{1}-2x_{2} \\\\ \\text{subject to} &amp; x_0 + x_2 + y_0 = 1, \\\\                 &amp; 3x_0-x_1+3x_2+y_1+2y_2+2y_3 = 4,\\\\                 &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2,\\\\                 &amp; y_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2, 3 \\end{array}  <p>Next, we introduce penalty terms in the expression to our QUBO instance of the binary programming. For that, we use an integer B (for which we will select a concrete value later on) and consider the problem,</p>  \\begin{array}{ll} \\text{minimize} &amp; -5x_{0}+3x_{1}-2x_{2} + B(x_0 + x_2 + y_0-1)^2\\\\                 &amp; + B(3x_0-x_1+3x_2+y_1+2y_2+2y_3-4)^2 \\\\ \\text{subject to} &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2,\\\\                   &amp; y_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2, 3, \\end{array}  <p>which is already in QUBO form.</p> <p>Let's us breakdown why and how to choose the B. </p> <ol> <li>First, B(x_0 + x_2 + y_0-1)^2 term will penalizes solutions where the sum of the x_0, x_2, and y_0 does not equal 1. (\\rightarrow violates the first constraint.)</li> <li>Second, B(3x_0-x_1+3x_2+y_1+2y_2+2y_3-4)^2 term will pernalizes solutions where this sum does not equal to 4. (\\rightarrow violates the second constraint.)</li> </ol> <p>We then choose B=11 based on the range of the solution, which, in this case is [-7,3]. We choose 11 &gt; 10 (range of the solution). Re-write our QUBO,</p>  \\begin{array}{ll} \\text{minimize} &amp; -5x_{0}+3x_{1}-2x_{2} + 11(x_0 + x_2 + y_0-1)^2\\\\                 &amp; + 11(3x_0-x_1+3x_2+y_1+2y_2+2y_3-4)^2 \\\\ \\text{subject to} &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2,\\\\                   &amp; y_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2, 3, \\end{array}"},{"location":"QuantumOpt/QOpt/QUBO/#integer-linear-programming","title":"Integer linear programming","text":"<p>Integer linear programming is a generalization of binary linear programming where nonnegative variables are used instead of 0 and 1. For example, we have a constraint</p>  2a_0 + 3a_1 \\leq 10  <p>where, we can replace a_0 with x_0 + 2x_1 + 4x_2 (a_{0} \\leq 5) and a_1 with x_3 + 2x_4 (a_{1} \\leq 3) where x_{j} \\in \\{0,1\\}. By doing this, we successfully transform the integer linear programming to a QUBO problem. There is a general rule that tells you how many x_{j} you need. For the fist constraint, a_{0} \\leq 5, we need j of x_{j} such that 2^{j} - 1 \\geq 5. By solving this, we can get j=3, in the same fashion, we can get j=2 to satisfy 2^{2}-1 \\geq 3.</p>"},{"location":"QuantumOpt/QOpt/QUBO/#the-knapsack-problem","title":"The Knapsack problem","text":"<p>It is straightforward to write the Knapsack problem as a binary linear problem. The Knapsack problem is a NP-hard problem. We need to define binary variables x_j, j=0,\\cdots,m that indicate whether we choose object j (x_j = 1) or not (x_j = 0).</p>  \\begin{array}{ll} \\text{minimize} &amp; -(c_{0}x_{0} + c_{1}x_{1} + \\cdots + c_{m}x_{m})\\\\ \\text{subject to} &amp; w_{0}x_{0} + w_{1}x_{1}+ \\cdots + w_{m}x_{m} \\leq W,\\\\                 &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, \\cdots, m, \\end{array}  <p>where c_j are the object values, w_j are their weights, and W is the maximum weight of the knapsack. Since we are asking the maximum, so we are now minimizing the negative value. Let's write a Knapsack problem as a binary linear program.</p>  \\begin{array}{ll} \\text{minimize} &amp; -(3x_{0} + 1x_{1} + 7x_{2} + 7x_{3})\\\\ \\text{subject to} &amp; 2x_{0} + x_{1}+ 5x_{2} + 4x_{3} \\leq 8,\\\\                 &amp; x_{j}\\in \\{0,1\\}, \\ j = 0, 1, 2,3,  \\end{array}  <p>which has values of 3,1,7,7 and weight 2,1,5,4 with the maximum weight of 8.</p>"},{"location":"QuantumOpt/QOpt/QUBO/#graph-coloring","title":"Graph coloring","text":"<p>In its simplest form, it is a way of coloring the vertices of a graph such that no two adjacent vertices are of the same color.</p> <p>In the graph coloring problem, we are given a graph and we are asked to assign a color to each vertex in such a way that vertices that are connected by and edge (also called adjacent) receive different colors. We also are asked to do this using the minimum possible numebr of colors or using no mroe than a given number of different colors. If we can color a graph with k colors, we say that it is k-colorable. The minimum number of colors needed to color a graph is called its chromatic number.</p> <p>         Example of a GraphColoring     </p> <p>Let's get start to formulate the graph coloring problem to a QUBO framework!</p> <p>First, we have to define some binary variables, let's say we have m vertices from j=0,\\cdots,m, and k-1 of different colors with lth on each vertices. To ensure each vertice j only recieve one color l, we can have the following condition:</p>  \\sum_{l=0}^{k-1}x_{jl} = 1.  <p>For an example, this ensure that every j-th vertice only receive one l-th color. We also have to consider for every vertice j, there must exist l such that x_{jl}=1 and such that x_{jh}=0 for any h\\neq l. </p> <p>Now, we can impose a constraint that adjacent vertice are not assigned the same color. We know that if two vertices j and h receive the same color l, then we would have x_{jl}x_{hl}=1. Therefore, the sum of any j and h must be 0, that is,</p>  \\sum_{l=0}^{k-1}x_{jl}x_{hl} = 0.  <p>Then we can write this graph coloring problem into a QUBO framework as,</p>  \\begin{array}{ll} \\text{minimize} &amp; \\sum_{j=0}^{m}\\bigg(\\sum_{l=0}^{k-1}x_{jl}-1\\bigg)^{2} + \\sum_{(j,h)\\in E}\\sum_{l=0}^{k-1}x_{jl}x_{hl}\\\\ \\text{subject to} &amp; x_{jl}\\in \\{0,1\\}, \\ j = 0,\\cdots,m, \\ l = 0,\\cdots,k-1, \\end{array}  <p>where E is the set of edges of the graph. We added -1 term to ensure when the result deviates from 1, our framework impose a penalty on it. And we don't need to square the second term since they are always non-negative.</p>"},{"location":"QuantumOpt/QOpt/QUBO/#the-traveling-salesperson-problem","title":"The Traveling Salesperson Problem","text":"<p>The Traveling salesperon problem is one of the most famous problems in combinatorial optimization. The problem is wasy to state: you need to find a route that goes through each of the cities in a given set once and only once while minimizing some global quantity (distance traveled, time spent, total cost...). </p> <p>         A TSP example     </p> <p>Figure. An example of the Traveling Salesperson Problem (TSP)</p> <p>First, let's deal with visiting each vertex  j once and route l once. Let's says we have j vertices and l th different route. If vertex j is the l th in our travel route, the x_{ij} will be 1 and x_{jh} will be 0 for h \\neq l. Thus, for every vertex j, we must impose a constraint,</p>  \\sum_{l=0}^{m}x_{jl}=1  <p>because every vertex needs to be visited exactly once. Next, since we can only visit one city at a time for each l travel route</p>  \\sum_{j=0}^{m}x_{jl} = 1.  <p>If these two constraints are met, we will have a path that visit every vertex once and only once. However, that's not enough. Remember that we may want to minimize some global quantity (distance traveled, time spent, total cost...)? We need an expression that gives us that global quantity in terms of the x_{jl} varialbles. Notice that an edge (j,k) is used if and only if the vertices j and k are consecutive in the path. That is, if and only if there exists an l such that j is visited in position l and k is visited in position l+1. In that case, the cost of using the edge will be given by w_{jk}x_{jl}x_{kl+1}, because x_{jl}x_{kl+1} =1. and if j and k are not consecutive in the path, then x_{jl}x_{kl+1} = 0 for every l.</p> <p>This ensure that we only visit kl+1 after vertiex kl, thus we calculate the cost(or any global quantity). As a resutl, the cost of our tour is given by,</p>  \\sum_{l=0}^{m-1}\\sum_{j=0}^{m}\\sum_{k=0}^{m} w_{jk}x_{jl}x_{kl+1},  <p>then we conbine our constraints and get:</p>  \\begin{array}{ll} \\text{minimize} &amp; \\sum_{l=0}^{m-1}\\sum_{j=0}^{m}\\sum_{k=0}^{m} w_{jk}x_{jl}x_{kl+1} + B_{1}(\\sum_{l=0}^{m}x_{ij}-1)^{2}+B_{2}(\\sum_{j=0}^{m}x_{jl}-1)^{2}\\\\ \\text{subject to} &amp; x_{jl}\\in \\{0,1\\}, \\ j = 0,\\cdots,m, \\ l = 0,\\cdots,k-1. \\end{array}  <p>where penalty constants B_1 and B_2 is choosen so that any deviated results will generate large outcome in our cost function.</p>"},{"location":"QuantumOpt/QOpt/QUBO/#reference","title":"Reference","text":"<p>[1]. Combarro, E. F., &amp; Gonz\u00e1lez-Castillo, S. (2023). A practical guide to quantum machine learning and quantum optimisation: Hands-on approach to modern quantum algorithms. Packt Publishing. [2]. By Miym - Own work, CC BY-SA 3.0, https://commons.wikimedia.org/w/index.php?curid=6002348</p>"},{"location":"QuantumOpt/QOpt/VQEIntro/","title":"Variational Quantum Eigensolver (VQE)","text":"<p>The Variational Quantum Eigensolver (VQE) is a hybrid quantum-classical algorithm for solving optimization problems and finding ground-state energies in quantum systems, with applications in chemistry and physics. </p> <p>VQE uses a parameterized quantum circuit to prepare states and a classical optimizer to minimize the expectation value of a Hamiltonian, iteratively refining the solution. It generalizes the Quantum Approximate Optimization Algorithm (QAOA), with QAOA being a specific instance of the VQE framework, making VQE a versatile tool for quantum computations.</p>"},{"location":"QuantumOpt/QOpt/VQEIntro/#hamiltonians-observables-and-their-expectation-values","title":"Hamiltonians, observables, and their expectation values","text":""},{"location":"QuantumOpt/QOpt/VQEIntro/#hamiltonians","title":"Hamiltonians","text":"<p>From QUBO (Quadratic Unconstrained Binary Optimization), we know that we start with a cost function f that maps binary strings of length n to real numbers, aiming to find the binary string x that minimizes f(x). To approach this problem quantum mechanically, we define a Hamiltonian H_f such that:</p>  \\langle x | H_f | x \\rangle = f(x)  <p>for every binary string x of length n. Solving the optimization problem then translates to finding the ground state of H_f\u2014a quantum state \\lvert \\psi \\rangle that minimizes the expectation value \\langle \\psi | H_f | \\psi \\rangle.</p> <p>Additionally, H_f satisfies a key property: for every computational basis state \\lvert x \\rangle, the Hamiltonian acts as:</p>  H_f \\lvert x \\rangle = f(x) \\lvert x \\rangle.  <p>This implies that \\lvert x \\rangle are eigenstates of H_f, with eigenvalues corresponding to the cost function f(x) because:</p> <ol> <li>We use Hamiltonians that are sums of tensor products of Z matrices themselves.</li> <li>The sum of diagonal matrices are still diagonal</li> <li>Since these Hamiltonians are diagaonial, the computational basis states are their eignevalues.</li> </ol> <p>This property enables a direct connection between the classical optimization problem and the quantum framework.</p> <p>From the linear algebra, if we have a state \\lvert \\psi \\rangle, we can always write it as a linear combination of the computational basis states such that </p>  \\lvert \\psi \\rangle = \\sum_{x} a_{x} \\lvert x \\rangle  <p>where the sum is over all the computational basis states \\lvert x \\rangle and a_{x} = \\langle x | \\psi \\rangle, since </p>  \\langle x | \\psi \\rangle = \\langle \\sum_{y} a_{y} \\lvert y \\rangle = \\sum_{y} a_{y} \\langle y | \\psi \\rangle = \\sum_{y} a_{y} \\langle x | y \\rangle = a_{x}.  <p>\\sum_{y} a_{y} \\langle x | y \\rangle = a_{x} is because the fact that \\langle x | y \\rangle = 1  if x = y and 0 otherwise. (The computational basis is an orthonormal basis).</p> <p>Thus, the expectation value of H_{f} in the state \\lvert \\psi \\rangle can be computed as </p>  \\begin{array}{lll} \\langle x | H_{f} | x \\rangle &amp; = &amp; \\sum_{y} a^{*}_{y} \\langle y | H_{f} \\sum_{x} a_{x} | x \\rangle\\\\  &amp; = &amp; \\sum_{x,y} a^{*}_{y} a_{x} \\langle y | H_{f} | x \\rangle\\\\  &amp; = &amp; \\sum_{x,y} a^{*}_{y} a_{x} f(x) \\langle y | x \\rangle \\\\  &amp; = &amp; \\sum_{x} a_{x}^{*} a_{x} f(x) = \\sum_{x} |a_x|^{2} f(x). \\end{array}  <p>We also know that |a_x|^{2} = |\\langle x | \\psi \\rangle|^{2} is the probability of obtaining |x\\rangle when measuring \\lvert \\psi \\rangle in the computational basis. That is, The expectation value matches the statistical expected value of the measurement.</p>"},{"location":"QuantumOpt/QOpt/VQEIntro/#observables-in-quantum-mechanics","title":"Observables in Quantum Mechanics","text":"<p>In quantum mechanics, any measurable physical quantity, known as an observable, is represented by a Hermitian operator. A Hermitian operator A satisfies the property A^\\dagger = A, where A^\\dagger is its conjugate transpose.</p> <p>A key property of Hermitian operators is that they always have an orthonormal basis of eigenvectors with real eigenvalues. This means there exist real numbers \\lambda_j (j = 1, \\cdots, l) and corresponding states \\lvert \\lambda_j^k \\rangle (j = 1, \\cdots, l and k = 1, \\cdots, r_j), such that the eigenstates \\{\\lvert \\lambda_j^k \\rangle \\}_{j,k} form an orthonormal basis and satisfy the eigenvalue equation:</p>  A \\lvert \\lambda_j^k \\rangle = \\lambda_j \\lvert \\lambda_j^k \\rangle,  <p>for each j = 1, \\cdots, l and k = 1, \\cdots, r_j.</p> <p>Here: </p> <ol> <li> <p>Degeneracy of Eigenvalues: Multiple eigenvectors \\lvert \\lambda_j^k \\rangle can correspond to the same eigenvalue \\lambda_j. The number of such eigenvectors is denoted by r_j, representing the degeneracy of \\lambda_j.</p> <ul> <li>If all eigenvalues are distinct, r_j = 1 for all j, and the k-index can be dropped. k as k-th eignestate.</li> </ul> </li> <li> <p>Measurement Outcomes: </p> <ul> <li>Any Hermitian operator A, representing an observable, has eigenvalues \\lambda_j, which correspond to the possible outcomes of a measurement.</li> <li>For a quantum state \\lvert \\psi \\rangle, the probability of measuring a specific eigenvalue \\lambda_j is given by:</li> </ul> </li> </ol>  P(\\lambda_j) = \\sum_k \\big|\\langle \\lambda_j^k \\lvert \\psi \\rangle\\big|^2.  <p>This ensures that any physical observable can be represented by a Hermitian operator, and the eigenvalue equation governs both the measurement outcomes and their probabilities.</p> <p>Note</p> <p>Remember, in quantum mehcanics, if the measurement returns the result associated to an eigenvalue \\lambda_{j}, the state of the system will then become the normalized projection of |\\psi \\rangle onto the space of eigenvectors with eigenvalue \\lambda_{j}.</p> <p>That is, if we measure a state in a superposition such as </p>  \\sum_{j,k} a_{j}^{k} \\lvert \\lambda_{j}^{k} \\rangle  <p>and we obtain \\lambda_{j} as the result, then the new state will be</p>  \\frac{\\sum_{j,k} a_{j}^{k} \\lvert \\lambda_{j}^{k} \\rangle}{\\sqrt{\\sum_{j,k} |a_{j}^{k}|^{2}}}.  <p>This is the collapse of the original state! For instance, whenever we measure in the computational basis, we are indeed measuring some physical observable, and this physical observable can be represented by a Hermitian operator.</p> <p>The coordinated matrix of this measurement operator with respect to the computational basis could be the diagonal matrix </p>  \\begin{pmatrix} 0 &amp; &amp; &amp; \\\\ &amp; 1 &amp; &amp; \\\\ &amp; &amp; \\ddots &amp; \\\\ &amp; &amp; &amp; 2^n - 1 \\end{pmatrix}  <p>when we measure a single qubit in the computational basis, the coordinate matrix with respect to the computational basis of the associated hermitian operator could be either of</p>  \\begin{array}{cc}     N =      \\begin{pmatrix}     0 &amp; 0 \\\\     0 &amp; 1     \\end{pmatrix}     ,&amp;     Z =      \\begin{pmatrix}     1 &amp; 0 \\\\     0 &amp; -1     \\end{pmatrix}     . \\end{array}  <p>Both of these operators represent the same observable: they only differ in the eigenvalues that they associate to the distinct possible outcomes. </p> <ol> <li>N operator: eigenvalues 0 and 1 to the qubit's value being 0 and 1 respectively.</li> <li>Z operator: eigenvalues 1 and -1 to these outcomes.</li> </ol>"},{"location":"QuantumOpt/QOpt/VQEIntro/#key-takeaways","title":"Key takeaways","text":"<ol> <li> <p>An observable is the mathematical representation of a physical property of a quantum system represented by a Hermitian operator.</p> <ul> <li>An observable corresponds to a physical property that can be measured, such as energy or position.</li> <li>In the quantum framework, an observable is represented by a Hermitian operator A. For example, the energy of a system is associated with the Hamiltonian H, which is a Hermitian operator.</li> <li>When you measure an observable, the possible outcomes correspond to the eigenvalues of the operator.</li> <li>An observable is not the action of measuring\u2014it\u2019s the property being measured. The action of measurement is distinct and involves interacting with the system.</li> </ul> </li> <li> <p>Measurements in quantum mechanics are represented by Hermitian operators, which we refer to as observable. One possible operator corresponding to measuring a qubit in the computational basis can be the Pauli Z matrix.</p> </li> </ol>"},{"location":"QuantumOpt/QOpt/VQEIntro/#expectation-values","title":"Expectation values","text":"<p>Let's see what expectation value is and how it can be computed. First, we know that the probability of measuring a specific eigenvalue \\lambda_j is given by</p>  P(\\lambda_j) = \\sum_k \\big|\\langle \\lambda_j^k \\lvert \\psi \\rangle\\big|^2.  <p>The expectation value of any observable under a state \\lvert \\psi \\rangle can be defined as </p>  \\langle A \\rangle_{\\psi} = \\sum_{j,k} |\\langle \\lambda_{j}^{k}|\\psi \\rangle|^{2} \\lambda_{j},   <p>which is a natural definition that agrees with the statistical expected value of the results obtained when we measure \\lvert \\psi \\rangle according to A. Therefore, we can further simplify it as follows:</p>  \\begin{array}{lllll} \\langle A \\rangle_{\\psi} &amp; = &amp; \\sum_{j,k}|\\langle \\lambda_{j}^{k} | \\psi \\rangle |^{2} \\lambda_{j} &amp; = &amp; \\sum_{j,k} \\langle \\psi | \\lambda_ {j}^{k} \\rangle \\langle \\lambda_ {j}^{k} | \\psi \\rangle \\lambda_{j}\\\\  &amp; = &amp; \\sum_{j,k} \\langle \\lambda_ {j}^{k} | \\psi  \\rangle \\langle \\psi | \\lambda_ {j}^{k} \\rangle \\lambda_{j} &amp; = &amp;\\sum_{j,k} \\langle \\lambda_ {j}^{k} | \\psi \\rangle \\langle \\psi | A | \\lambda_ {j}^{k} \\rangle\\\\  &amp; = &amp; \\langle \\psi | A \\sum_{j,k} \\rangle \\lambda_{j}^{k} | \\psi \\rangle | \\lambda_{j}^{k} \\rangle &amp; = &amp; \\langle \\psi | A | \\psi \\rangle \\end{array}  <p>Let's look into these steps by steps! Let's start with the first row.</p> <ol> <li> <p>For the first term</p>  \\langle A \\rangle_{\\psi} = \\sum_{j,k} \\left| \\langle \\lambda_{j}^{k} | \\psi \\rangle \\right|^2 \\lambda_{j}.  <ul> <li>\\langle \\lambda_{j}^{k} | \\psi \\rangle: Projection (Inner product!) of the state |\\psi\\rangle onto the eigenstate |\\lambda_{j}^{k}\\rangle.</li> <li>\\sum \\left| \\langle \\lambda_{j}^{k} | \\psi \\rangle \\right|^2: Probability of obtaining the eigenvalue \\lambda_{j} upon measurement.</li> <li>\\lambda_{j}: Measurable value (eigenvalue) associated with the eigenstate.</li> </ul> <p>This form means the expectation value as a sum over the probabilities of each measurement outcome multiplied by the corresponding eigenvalue \\lambda_{j}.</p> </li> <li> <p>The second term</p>  \\langle A \\rangle_{\\psi} = \\sum_{j,k} \\langle \\psi | \\lambda_{j}^{k} \\rangle \\langle \\lambda_{j}^{k} | \\psi \\rangle \\lambda_{}.  <ul> <li> <p>The probabilities are expressed in terms of the inner products \\langle \\psi | \\lambda_{j}^{k} \\rangle and \\langle \\lambda_{j}^{k} | \\psi \\rangle, showing explicitly how the state |\\psi\\rangle interacts with the eigenbasis |\\lambda_{j}^{k}\\rangle.</p> </li> <li> <p>The eigenstates |\\lambda_{j}^{k}\\rangle form an orthonormal basis, so the squared magnitude \\left| \\langle \\lambda_{j}^{k} | \\psi \\rangle \\right|^2 is equivalent to the product \\langle \\psi | \\lambda_{j}^{k} \\rangle \\langle \\lambda_{j}^{k} | \\psi \\rangle.</p> </li> </ul> </li> </ol> <p>The equation shows how the expectation value of a Hermitian operator (observable) is calculated by summing over all possible eigenvalues \\lambda_{j}, weighted by the probability of measuring \\lambda_{j} when the system is in state |\\psi\\rangle. The expectation value \\langle A \\rangle_{\\psi} is the weighted average of the possible outcomes \\lambda_{j}, with the probabilities \\left| \\langle \\lambda_{j}^{k} | \\psi \\rangle \\right|^2 serving as weights.</p> <ol> <li> <p>Then, the next equations show how the expectation value of a Hermitian operator A in a quantum state |\\psi\\rangle is derived, step by step. Let\u2019s break it down:</p> </li> <li> <p>First Step:</p>  \\sum_{j,k} \\langle \\psi | \\lambda_j^k \\rangle \\langle \\lambda_j^k | \\psi \\rangle \\lambda_j = \\sum_{j,k} \\langle \\lambda_j^k | \\psi \\rangle \\langle \\psi | \\lambda_j^k \\rangle \\lambda_j  <ul> <li>This step shows that the ordering of inner products doesn't matter due to the properties of complex conjugation.</li> </ul> </li> <li> <p>Second Step:</p>  \\sum_{j,k} \\langle \\lambda_j^k | \\psi \\rangle \\langle \\psi | A | \\lambda_j^k \\rangle = \\langle \\psi | A \\sum_{j,k} | \\lambda_j^k \\rangle \\langle \\lambda_j^k | \\psi \\rangle  <ul> <li>Here, \\lambda_j | \\lambda_j^k \\rangle = A | \\lambda_j^k \\rangle, because | \\lambda_j^k \\rangle is an eigenstate of A with eigenvalue \\lambda_j.</li> <li>The summation \\sum_{j,k} | \\lambda_j^k \\rangle \\langle \\lambda_j^k | represents the resolution of identity (I), which means that any state can be expressed in this eigenbasis.</li> </ul> </li> <li> <p>Final Step:</p>  \\langle \\psi | A | \\psi \\rangle  <ul> <li>This simplifies the expectation value entirely into the form \\langle \\psi | A | \\psi \\rangle, which is the standard expression for the expectation value of a Hermitian operator A in the state |\\psi\\rangle.</li> </ul> </li> <li> <p>Physical Interpretation:</p> <ul> <li>The derivation connects the abstract summation over eigenvalues and eigenstates to the compact, widely-used notation \\langle \\psi | A | \\psi \\rangle.</li> <li>The expectation value \\langle \\psi | A | \\psi \\rangle represents the average value of many measurements of the observable A when the system is in state |\\psi\\rangle.</li> </ul> </li> </ol> <p>Notice that we have used the fact that A|\\lambda_{j}^{k}\\rangle = \\lambda_{j}|\\lambda_{j}^{k} \\rangle and that |\\psi \\rangle = \\sum_{j,k} | \\lambda_{j}^{k} | \\psi \\rangle | \\lambda_{j}^{k} \\rangle.</p> <p>Note</p> <p>The expectation value of any Hermitian operator (observable) A is given by</p>  \\langle A \\rangle_{\\psi} = \\sum_{j,k}|\\langle \\lambda_{j}^{k} | \\psi \\rangle |^{2} \\lambda_{j} = \\langle \\psi | A | \\psi \\rangle.  <p>The variational principle states that the smallest expectation value of an observable A is always achieved at an eigenvector of A. Suppose \\lambda_0 is the smallest eigenvalue of A. For any quantum state \\lvert \\psi \\rangle, the expectation value of A is given by:</p>  \\langle A \\rangle_\\psi = \\sum_{j,k} \\big| \\langle \\lambda_j^k \\lvert \\psi \\rangle \\big|^2 \\lambda_j.  <p>Since \\lambda_0 is the minimal eigenvalue, it follows that:</p>  \\langle A \\rangle_\\psi \\geq \\sum_{j,k} \\big| \\langle \\lambda_j^k \\lvert \\psi \\rangle \\big|^2 \\lambda_0 = \\lambda_0,  <p>where the last equality arises because the probabilities of all possible outcomes add up to 1, i.e., \\sum_{j,k} \\big| \\langle \\lambda_j^k \\lvert \\psi \\rangle \\big|^2 = 1.</p> <p>Now, consider an eigenvector \\lvert \\lambda_0^k \\rangle associated with \\lambda_0. The expectation value of A for this eigenvector is:</p>  \\langle \\lambda_0^k \\lvert A \\lvert \\lambda_0^k \\rangle = \\lambda_0 \\langle \\lambda_0^k \\lvert \\lambda_0^k \\rangle = \\lambda_0,  <p>since eigenvectors are normalized. This states that the minimum expectation value of A is achieved at an eigenvector corresponding to \\lambda_0.</p>"},{"location":"QuantumOpt/QOpt/VQEIntro/#key-takeaways_1","title":"Key Takeaways","text":"<ol> <li> <p>Definition:  </p> <p>The expectation value of an observable A in a quantum state \\lvert \\psi \\rangle is given by: $$ \\langle A \\rangle_\\psi = \\langle \\psi \\lvert A \\rvert \\psi \\rangle. $$ It represents the average value of measurements of A if the system is repeatedly prepared in the state \\lvert \\psi \\rangle.</p> </li> <li> <p>Relation to Eigenvalues:  </p> <p>The expectation value of A is a weighted sum of its eigenvalues: $$ \\langle A \\rangle_\\psi = \\sum_{j,k} \\big| \\langle \\lambda_j^k \\lvert \\psi \\rangle \\big|^2 \\lambda_j, $$ where \\big| \\langle \\lambda_j^k \\lvert \\psi \\rangle \\big|^2 is the probability of measuring the eigenvalue \\lambda_j.</p> </li> <li> <p>Variational Principle:  </p> <ul> <li>The smallest expectation value of A is achieved at an eigenvector corresponding to the smallest eigenvalue \\lambda_0. </li> <li>For any state \\lvert \\psi \\rangle, \\langle A \\rangle_\\psi \\geq \\lambda_0, proving the principle.</li> </ul> </li> <li> <p>Physical Meaning:  </p> <ul> <li>In practice, the expectation value corresponds to measurable quantities like the average energy, position, or momentum in repeated experiments.</li> <li>It connects the mathematical framework of quantum mechanics to observable physical properties.</li> </ul> </li> <li> <p>Implication of Hermitian Operators: </p> <p>Since observables are represented by Hermitian operators, their eigenvalues (and hence the expectation values) are always real, ensuring physical observability.</p> </li> </ol>"},{"location":"QuantumOpt/QOpt/VQEIntro/#estimaing-the-expectation-values-of-observables","title":"Estimaing the expectation values of observables","text":"<p>For a given state |\\psi\\rangle, the expectation value of an observable A can be calculated as:</p>  \\langle A \\rangle_\\psi = \\sum_{j,k} \\big| \\langle \\lambda_j^k \\lvert \\psi \\rangle \\big|^2 \\lambda_j.  <p>This means that if we know the eigenvalues \\lambda_j and the eigenvectors \\{ |\\lambda_j^k\\rangle \\}_{j,k} of A, we can compute \\sum_{j,k} \\big| \\langle \\lambda_j^k \\lvert \\psi \\rangle \\big|^2 and, consequently, determine the expectation value of A.</p> <p>However, finding the eigenvalues and eigenvectors of A is generally a challenging task, particularly for large and complex systems. This is where the Variational Quantum Eigensolver (VQE) becomes useful. The purpose of VQE is to approximate specific eigenvalues and eigenvectors of a Hamiltonian H, enabling the computation of expectation values and solving quantum systems efficiently.</p> <p>To find these eigenvalues and eigenvectors, we will use the fact that we can always express an observable A on n qubits as a linear combination of tensor products of Pauli matrices. </p> <p>Note</p> <p>A will be given to us in such form, in most cases, in the same way that the Hamiltonians of our combinatorial optimization problems were always expressed as sums of tensor products of Z matrices.</p> <p>Let's consider an observable </p>  A = \\frac{1}{2}Z\\otimes I\\otimes X -3I\\otimes Y \\otimes Y + 2Z\\otimes X \\otimes Z.  <p>From the linearity,</p>  \\begin{array}{lll} \\langle \\psi |A|\\psi\\rangle &amp; = &amp; \\langle\\psi|\\big( \\frac{1}{2}Z\\otimes I\\otimes X -3I\\otimes Y \\otimes Y + 2Z\\otimes X \\otimes Z \\big)|\\psi\\rangle\\\\ &amp; = &amp; \\frac{1}{2}\\langle\\psi|(Z\\otimes I\\otimes X)|\\psi\\rangle -3\\langle \\psi|I\\otimes Y \\otimes Y|\\psi\\rangle + 2\\langle \\psi|(Z\\otimes X \\otimes Z)\\psi\\rangle. \\end{array}  <p>To compute the expectation value of A, we can compute the expectation values of Z\\otimes I\\otimes X, I\\otimes Y \\otimes Y, and 2Z\\otimes X \\otimes Z as combine their results.</p> <p>Exercise 1</p> <p>Suppoer that |\\lambda_{j}\\rangle is an eigenvector of A_{j} with associated eigenvalue \\lambda_{j} for j = 1, \\cdots,n. Prove that |\\lambda_{1}\\rangle\\otimes\\cdots\\otimes|\\lambda_{n}\\rangle is an eigenvector of A_{1}\\otimes\\cdots\\otimes A_{n} with associated eigenvalue \\lambda_{1} \\cdot \\lambda_{n}.</p> Answer exercise 1 <p>Let |\\psi\\rangle = |\\lambda_1\\rangle \\otimes |\\lambda_2\\rangle \\otimes \\cdots \\otimes |\\lambda_n\\rangle. Applying A_1 \\otimes A_2 \\otimes \\cdots \\otimes A_n to |\\psi\\rangle: $$ (A_1 \\otimes A_2 \\otimes \\cdots \\otimes A_n)(|\\lambda_1\\rangle \\otimes |\\lambda_2\\rangle \\otimes \\cdots \\otimes |\\lambda_n\\rangle) = (A_1 |\\lambda_1\\rangle) \\otimes (A_2 |\\lambda_2\\rangle) \\otimes \\cdots \\otimes (A_n |\\lambda_n\\rangle). $$ Since A_j |\\lambda_j\\rangle = \\lambda_j |\\lambda_j\\rangle, this becomes: $$ (\\lambda_1 |\\lambda_1\\rangle) \\otimes (\\lambda_2 |\\lambda_2\\rangle) \\otimes \\cdots \\otimes (\\lambda_n |\\lambda_n\\rangle). $$ Factor out the eigenvalues: $$ = (\\lambda_1 \\cdot \\lambda_2 \\cdot \\cdots \\cdot \\lambda_n)(|\\lambda_1\\rangle \\otimes |\\lambda_2\\rangle \\otimes \\cdots \\otimes |\\lambda_n\\rangle). $$ Thus, |\\psi\\rangle is an eigenvector with eigenvalue \\lambda_1 \\cdot \\lambda_2 \\cdot \\cdots \\cdot \\lambda_n.</p> <p>Exercise 2</p> <p>Prove that:</p> <ol> <li>The eigenvectors of Z are |0\\rangle (with assocaiated eignevalue 1) and |1\\rangle (with assocaiated eignevalue -1). </li> <li>The eigenvectors of X are |+\\rangle (with assocaiated eignevalue 1) and |-\\rangle (with assocaiated eignevalue -1). </li> <li>The eigenvectors of Y are \\frac{1}{2}(|0\\rangle+i|1\\rangle) (with assocaiated eignevalue 1) and \\frac{1}{2}(|0\\rangle-i|1\\rangle) (with assocaiated eignevalue -1).</li> <li>Any non-null state is an eigenvector of I with associated eigenvalue 1.</li> </ol> Answer exercise 2 <ol> <li> <p>Eigenvectors of Z:</p> <ul> <li>Z|0\\rangle = |0\\rangle, eigenvalue = 1.</li> <li>Z|1\\rangle = -|1\\rangle, eigenvalue = -1.</li> </ul> </li> <li> <p>Eigenvectors of X:</p> <ul> <li>X|+\\rangle = |+\\rangle, eigenvalue = 1.</li> <li>X|-\\rangle = -|-\\rangle, eigenvalue = -1.</li> </ul> <p>Using |+\\rangle = \\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}} and |-\\rangle = \\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}}, verify: -   X|+\\rangle = |0\\rangle + |1\\rangle = |+\\rangle. -   X|-\\rangle = |0\\rangle - |1\\rangle = -|-\\rangle.</p> </li> <li> <p>Eigenvectors of Y:</p> <ul> <li>Y\\left(\\frac{|0\\rangle + i|1\\rangle}{\\sqrt{2}}\\right) = i|1\\rangle - i^2|0\\rangle = \\frac{|0\\rangle + i|1\\rangle}{\\sqrt{2}}, eigenvalue = 1.</li> <li>Y\\left(\\frac{|0\\rangle - i|1\\rangle}{\\sqrt{2}}\\right) = i|1\\rangle - |0\\rangle = -\\frac{|0\\rangle - i|1\\rangle}{\\sqrt{2}}, eigenvalue = -1.</li> </ul> </li> <li> <p>Eigenvectors of I:</p> <ul> <li>I|\\psi\\rangle = |\\psi\\rangle, eigenvalue = 1 for any |\\psi\\rangle.</li> </ul> </li> </ol> <p>Using the results from theses exercises, we can find that </p> <ol> <li>|0\\rangle|+\\rangle|0\\rangle, |0\\rangle|-\\rangle|1\\rangle, |1\\rangle|+\\rangle|1\\rangle, and |1\\rangle|-\\rangle|0\\rangle are eigenvectors of Z\\otimes X\\otimes Z with eigenvalue of 1.</li> <li>|0\\rangle|+\\rangle|1\\rangle, |0\\rangle|-\\rangle|0\\rangle, |1\\rangle|+\\rangle|0\\rangle, and |1\\rangle|-\\rangle|1\\rangle are eigenvectors of Z\\otimes X\\otimes Z with eigenvalue of -1.</li> </ol> <p>For an example, eigenvector |1\\rangle|-\\rangle|0\\rangle of Z\\otimes X\\otimes Z = (-1) \\times(-1) \\times 1 = 1. We multiply the eigenvalues because tensor product operators act independently on each part of the state, and the overall eigenvalue is the product of the eigenvalues of the individual operators acting on their respective qubits. All these states together form an orthonormal basis of eigenvectors of Z\\otimes X\\otimes Z.</p> <p>Exercise 3</p> <p>Find orthonormal bases of eigenvectors for Z\\otimes I \\otimes X and I\\otimes Y \\otimes Y. Compute their associated eigenvalues.</p> Answer exercise 3 <p>Answer 3</p> <p>For a given Hermitian matrix A, the expectation value \\langle \\psi|A|\\psi\\rangle can be computed as:</p>  \\sum_{j,k} |\\langle \\lambda_j^k|\\psi\\rangle|^2 \\lambda_j,  <p>where \\lambda_j are the eigenvalues of A (in this case, only 1 and -1), and \\{|\\lambda_j^k\\rangle\\}_{j,k} are the associated eigenvectors.</p> <p>To compute |\\langle \\lambda_j^k|\\psi\\rangle|^2, consider an observable like Z \\otimes X \\otimes Z. Using the techniques practiced, we can determine the eigenvalues and eigenvectors for any tensor product of Pauli matrices. Now, we focus on one of them: |0\\rangle|+\\rangle|0\\rangle. If we want to compute |(\\langle 0 |\\langle+|\\langle0|)|\\psi\\rangle|^{2}, where |\\psi\\rangle is a 3-qubit state</p>  |0\\rangle|+\\rangle|0\\rangle = (I\\otimes H\\otimes I)|0\\rangle|0\\rangle|0\\rangle  <p>and hence</p>  \\begin{array}{lll} \\color{green}{\\langle 0 |\\langle+|\\langle0|} &amp; = &amp; (|0\\rangle|+\\rangle|0\\rangle)^{\\dagger}\\\\ &amp; = &amp; ((I\\otimes H\\otimes I)|0\\rangle|+\\rangle|0\\rangle)^{\\dagger}\\\\ &amp; = &amp; \\color{blue}{\\langle 0 |\\langle+|\\langle0|(I\\otimes H\\otimes I)^{\\dagger}}\\\\ &amp; = &amp; \\langle 0 |\\langle+|\\langle0|(I\\otimes H\\otimes I) \\end{array}  <p>as we already know that I^{\\dagger} = I and H^{\\dagger} = H. Therefore,</p>  |\\color{green}{(\\langle 0 |\\langle+|\\langle0|)}|\\psi\\rangle|^{2} = |\\color{blue}{\\langle 0 |\\langle+|\\langle0|(I\\otimes H\\otimes I)^{\\dagger}}|\\psi\\rangle|^{2}.  <ul> <li>The equation {(\\langle 0 |\\langle+|\\langle0|)}|\\psi\\rangle|^{2} represents the probability of obtaining the state |0\\rangle|0\\rangle|0\\rangle (all qubits in the \"0\" state) when measuring the state |\\psi\\rangle in the computational basis.</li> <li>Quantum mechanics is probabilistic, so each measurement provides one outcome, which may not immediately reflect the actual probability. Repeating the process many times and recording how often |0\\rangle|0\\rangle|0\\rangle is observed allows you to calculate its relative frequency, which approximates the probability {(\\langle 0 |\\langle+|\\langle0|)}|\\psi\\rangle|^{2}.</li> </ul> <p>In fact, this is not only eigenvector for which this works. It turns out that for each and every eigenvector |\\lambda_{A}\\rangle of Z\\otimes X\\otimes Z, there is a unique state in the computational basis |\\lambda_{C}\\rangle such that </p>  |\\lambda_{A}\\rangle = (I\\otimes H \\otimes I)|\\lambda_{C}\\rangle.  <p>Actually, for every state in the computational basis \\color{red}{|\\lambda_{C}\\rangle}, there is also a unique eigenvector \\color{blue}{|\\lambda_{A}\\rangle} of Z\\otimes X\\otimes Z such that \\color{red}{|\\lambda_{C}\\rangle} = (I\\otimes H\\otimes I)^{\\dagger}\\color{blue}{|\\lambda_{A}\\rangle}, sinec U^{\\dagger} = U^{-1}. We call this operator, (I\\otimes H\\otimes I), a Change of basis operator. For example,</p>  \\color{blue}{|1\\rangle|-\\rangle|1\\rangle} = (I\\otimes H\\otimes I)\\color{red}{|1\\rangle|1\\rangle|1\\rangle}, \\ \\color{red}{|1\\rangle|1\\rangle|1\\rangle} = (I\\otimes H\\otimes I)^{\\dagger}\\color{blue}{|1\\rangle|-\\rangle|1\\rangle}.  <p>That is, if we want to estimate the probabilities |\\langle\\lambda_{j}^{k}|\\psi\\rangle|^{2} where |\\lambda_{j}^{k}\\rangle are the eigenvectors of Z\\otimes X\\otimes Z, </p> <ol> <li>We just need to prepare (I\\otimes H\\otimes I)^{\\dagger}|\\psi\\rangle and measure it in the computational basis.</li> <li> <p>Then, given any eigenvector |\\lambda_{A}\\rangle of Z\\otimes X\\otimes Z, the probability |\\langle\\lambda_{A}|\\psi\\rangle|^{2} can be estimated by the relative frequency of the measurement outcome associated to the eigenstate |\\lambda_{C}\\rangle = (I\\otimes H\\otimes I)^{\\dagger}|\\lambda_{A}\\rangle in the computational basis. Since</p>  \\langle \\lambda_{C}|((I\\otimes H\\otimes I)^{\\dagger}|\\psi\\rangle) = \\langle\\lambda_{A}|(I\\otimes H\\otimes I)(I\\otimes H\\otimes I)^{\\dagger}|\\psi\\rangle = \\langle \\lambda_{A}|\\psi\\rangle,  </li> </ol> <p>where for any operator L and any states |\\alpha\\rangle and |\\beta\\rangle, if \\beta\\rangle = L|\\alpha\\rangle, then \\langle \\beta| = \\langle \\alpha|L^{\\dagger\\dagger}, and L^{\\dagger\\dagger} = L.</p> <p>Measurement in the computational basis</p> <p>If we measure |\\psi\\rangle in the computational basis, we have probability |\\color{red}{\\langle x|}\\psi\\rangle|^{2} of obtaining the outcome associated to \\color{blue}{|x\\rangle}. That is, we are measure an observable that had all the |\\lambda_{j}^{k}\\rangle as eigenvectors with a distinct eigenvalue for each of tehm, we would have probability |\\color{red}{\\langle\\lambda_{j}^{k}|}\\psi\\rangle|^{2} of getting the outcome associated to \\color{blue}{|\\lambda_{j}^{k}\\rangle}.</p> <p>This is why we say the process of changing basis and, then, measuring in computational basis, as performing a measurement in the eigenvector basis \\{\\lambda_{j}^{k}\\} of A. Therefore, we don't have to run executions for each of the possibilities individually if we want to compute the probabilities |\\langle\\lambda_{A}|\\psi\\rangle|^{2}. We can just measure (I\\otimes H\\otimes I)^{\\dagger}|\\psi\\rangle in the computational basis several times and then retrieve the relative frequency of every outcome. </p> <p>Since, as we mentioned before, (I\\otimes H\\otimes I)^{\\dagger} transfers all the eigenvectors of A into the state of the computational basis. The probability |\\langle\\lambda_{A}|\\psi\\rangle|^{2} will be the relative frequency of the outcome in the computational basis associated to (I\\otimes H\\otimes I)^{\\dagger}|\\lambda_{A}\\rangle.</p> <p>Exercise 4</p> <p>Since the computational basis is an eigenvector basis of Z, a change of basis opeartor of Z can be the identity I. Check that you can use H for X in order to change from the computational basis to the basis of eigenvactors; and SH for Y.</p> Answer exercise 4 <p>Answer 4</p> <p>Exercise 5</p> <p>Prove that if U_{1} and U_{2} are the respective change of basis operations from the computational basis to the eigenvector basis of two observables A_1 and A_2, the U_{1}\\otimes U_{2} is the change of basis operator from the computational basis to the eigenvector basis of A_{1}\\otimes A_{2}.</p> Answer exercise 5 <p>Answer 5</p> <p>From the original question, </p>  \\begin{array}{lll} A &amp; = &amp; \\frac{1}{2}Z\\otimes I\\otimes X -3I\\otimes Y \\otimes Y + 2Z\\otimes X \\otimes Z. \\\\ &amp; = &amp; \\frac{1}{2}\\langle\\psi|(Z\\otimes I\\otimes X)|\\psi\\rangle -3\\langle \\psi|I\\otimes Y \\otimes Y|\\psi\\rangle + 2\\langle \\psi|(Z\\otimes X \\otimes Z)\\psi\\rangle. \\end{array}  <p>we can use certain tensor product of Pauli matrices for each case:</p> <ol> <li>I\\otimes H\\otimes H takes the eigenvectors of Z\\otimes I\\otimes X to the computational basis.</li> <li>I\\otimes (SH)^{\\dagger}\\otimes (SH)^{\\dagger} takes the eigenvectors of I\\otimes Y\\otimes Y to the computational basis.</li> <li>I\\otimes H\\otimes I takes the eigenvectors of Z\\otimes X\\otimes Z to the computational basis.</li> </ol> <p>Remember, to estimate \\langle\\psi|(I\\otimes Y\\otimes Y)|\\psi\\rangle, we first prepare |\\psi\\rangle then apply I\\otimes (SH)^{\\dagger}\\otimes (SH)^{\\dagger} = I\\otimes HS^{\\dagger}\\otimes HS^{\\dagger}, and finally, measure in the computational basis.</p> <p>Note</p> <p>For any Hermitian operator A, there's always a unitary transformation that takes any basis of eigenvectors of A to the computational basis.</p>"},{"location":"QuantumOpt/QOpt/VQEIntro/#takeaways","title":"Takeaways","text":"<ol> <li>The purpose of VQE is to approximate specific eigenvalues and eigenvectors of a Hamiltonian H, enabling the computation of expectation values and solving quantum systems efficiently.</li> <li>We say the process of changing basis and, then, measuring in computational basis, as performing a measurement in the eigenvector basis \\{\\lambda_{j}^{k}\\} of A. </li> <li>For any Hermitian operator A, there's always a unitary transformation that takes any basis of eigenvectors of A to the computational basis.</li> </ol>"},{"location":"QuantumOpt/QOpt/VQEIntro/#intoducing-variational-quantum-eigensolver-vqe","title":"Intoducing Variational Quantum Eigensolver (VQE)","text":"<p>The goal of the Variational Quantum Eigensolver (VQE) is to find the ground state of a given Hamiltonian H_1, which typically represents the energy of a physical or chemical system. Specifically, the objective is to identify a state |\\psi\\rangle that minimizes the expectation value \\langle \\psi|H_1|\\psi \\rangle.</p> <p>In this context, H_1 is used to denote the Hamiltonian, and the focus is on leveraging quantum-classical hybrid algorithms to iteratively improve the state |\\psi\\rangle toward the optimal solution. The general structure of VQE closely resembles that of the Quantum Approximate Optimization Algorithm (QAOA).</p> <pre><code>flowchart TD\n    A[Parepare a parameterized quantum state. Done by quantum computer] --&gt; B[Measurement. Done by quantum computer];\n    B --&gt; C[Energy estimation. Handle by classical computer];\n    C --&gt; F[Minimization. Handle by classical computer];\n    F --&gt; E{Minimum energy state reached?}\n    E --&gt; |No| D[Change parameters];\n    D --&gt; A;\n    E --&gt; |Yes| G[Minimum energy state found!]</code></pre> <p>The parameterized quantum circuit, known as the ansatz, is typically designed based on insights from the problem domain. It aims to parameterize typical solutions to the class of problems under consideration. The ansatz is chosen beforehand and is usually straightforward to implement as a quantum circuit.</p> <p>In many applications, the creation of the parameterized state involves two components:</p> <ol> <li> <p>Preparation of an Initial State:     The initial state |\\psi_0\\rangle is independent of any parameters and is often represented as |\\psi_0\\rangle = U|0\\rangle, where U is a unitary transformation implemented by quantum gates.</p> </li> <li> <p>Variational Form:     The variational form V(\\theta), which depends on a set of tunable parameters \\theta, generates a family of states based on the initial state.</p> </li> </ol> <p>The ansatz thus prepares the state V(\\theta)U|0\\rangle, where V(\\theta)U is referred to as the ansatz. For simplicity, we generally assume the initial state is |0\\rangle and denote the entire parameterized transformation as the ansatz V(\\theta)U.</p>"},{"location":"QuantumOpt/QOpt/VQEIntro/#algorithm-vqe","title":"Algorithm VQE","text":"<p>Require: H_1: given as a linear combination of tensor products of Pauli matrices  </p> <ul> <li>Choose a ansatz (variational form) V(\\theta) </li> <li>Choose a starting set of values for \\theta (initial values)</li> </ul> <p>While the stopping criteria are not met do:</p> <ul> <li>Prepare the state |\\psi(\\theta)\\rangle = V(\\theta)|0\\rangle This is done on the quantum computer!</li> <li>From the measurements of |\\psi(\\theta)\\rangle in different bases, estimate \\langle\\psi(\\theta)|H_{1}|\\psi(\\theta)\\rangle</li> <li>Update \\theta according to the minimization algorithm</li> </ul> <p>End While</p> <ul> <li>Parepare the sate |\\psi(\\theta)\\rangle = V(\\theta)|0\\rangle This is done on the quantum computer!</li> <li>From the measurement of |\\psi(\\theta)\\rangle in different bases, estimate \\langle\\psi(\\theta)|H_{1}|\\psi(\\theta)\\rangle</li> </ul> <p>Notice that:</p> <ol> <li>We require that H_{1} be given as a linear combination of tensor products of Pauli matrices since we can use change of basis operator that we introduced before to estimate \\langle \\psi|H_{1}|\\psi \\rangle. </li> <li>The more terms we have in the linear combination, the bigger the number of bases in which we need to perform measurements. However, we can group serval measurements together. For instance, if we have I \\otimes X \\otimes I \\otimes X, I \\otimes I \\otimes X \\otimes X, and I \\otimes X \\otimes I \\otimes X, we can use I \\otimes H \\otimes H \\otimes H as our change of basis matrix (H is Hadamard matrix) because it works for the three terms at the same time - that any orthonormal basis is an eigenvector basis of I, not just \\{|0\\rangle, |1\\rangle \\}.</li> <li>More frequent we measure |\\psi \\rangle in each basis can lead to a more accurate estimation but increase time needed to estimate \\langle \\psi |H_{1}|\\psi \\rangle</li> <li>We usually estimiate \\langle\\psi(\\theta)|H_{1}|\\psi(\\theta)\\rangle for the last state |\\psi(\\theta)\\rangle found by the optimization algorithm.</li> <li>At the end of the VQE execution, you also know the \\theta_{0} parameters that were used to build the ground state, and you could use them to reconstruct |\\psi(\\theta_{0})\\rangle = V(\\theta_{0})|0\\rangle. This state can be used to send to another quantum algorithm.</li> </ol>"},{"location":"QuantumOpt/QOpt/VQEIntro/#takeaways_1","title":"Takeaways","text":"<ol> <li>The parameterized circuit is called ansatz, is usually chosen taking into account information from the problem domain. </li> </ol>"},{"location":"QuantumOpt/QOpt/VQEIntro/#vqe","title":"VQE","text":"<p>VQE is used to search for a ground state of a given Hamiltonian H. However, with a small modification, we can also use it to find excited states: eigenstates with higher energies.</p> <p>Suppose that you have been given a Hamiltonian H and you have used VQE to find a ground state |\\psi_{0}\\rangle = V(\\theta_{0})|0\\rangle with energy \\lambda_{0}. We may consider the modified Hamiltonian</p>  H' = H + C|\\psi_{0}\\rangle\\langle\\psi_{0}|,  <p>where C is a positive real number.</p> <ul> <li> <p>|\\psi_{0}\\rangle\\langle\\psi_{0}|: This is a product of a column vector (|\\psi_{0}\\rangle) and a row vector (\\langle\\psi_{0}|) of the same length. This is also a Hermitian matrix, since </p>  (|\\psi_{0}\\rangle\\langle\\psi_{0}|)^{\\dagger} = \\langle\\psi_{0}|^{\\dagger} |\\psi_{0}\\rangle^{\\dagger} = |\\psi_{0}\\rangle\\langle\\psi_{0}|.  </li> <li> <p>H' is a Hermitian since it's the sum of two Hermitian matrics.</p> </li> </ul> <p>If we have a generic quantum state |\\psi\\rangle, then</p>  \\langle\\psi|H'|\\psi\\rangle = \\langle\\psi|H|\\psi\\rangle + C\\langle\\psi|\\psi_{0}\\rangle\\langle\\psi_{0}|\\psi\\rangle = \\langle\\psi|H|\\psi\\rangle+|\\langle\\psi_{0}|\\psi\\rangle|^{2}.  <p>This means that the expectation value of H' in a state |\\psi\\rangle is the expectation value of H plus a non-negative value that quantifies the overlap of |\\psi\\rangle and |\\psi_{0}\\rangle. Hence we will have two extreme cases.</p> <ol> <li>|\\langle\\psi_{0}|\\psi\\rangle| = C if |\\psi\\rangle = |\\psi_{0}\\rangle</li> <li>|\\langle\\psi_{0}|\\psi\\rangle| = 0 if |\\psi\\rangle and |\\psi_{0}\\rangle are orthogonal.</li> </ol> <p>Thus, if we make C big enough, |\\psi_{0}\\rangle, a ground state by hypothesis, will no longer be a ground state of H'. Once you obtain |\\lambda_{1}\\rangle (the first excited state), you can consider H'' = H' + C|\\psi_{1}\\rangle\\langle\\psi_{1}| and use VQE to search for |\\lambda_{2}, and so on and so forth. In this process, we need to pick the constants C,C',\\cdots wisely so that none of the eigenstates that we already know becomes a ground state again.</p> <p>We have discussed how to estimate the expectation value of a Hamiltonian under the assumption that it was given as a sum of tensor products of Pauli matrices. However, |\\psi_{0}\\rangle\\langle\\psi_{0}| term is not of that form. In fact, we know |\\psi_{0}\\rangle only as the result of applying VQE. so we will not know |\\psi_{0}\\rangle explicitly. Instead, we will have nothing more than some parameters \\theta_{0} such that V(\\theta_{0})|0\\rangle = |\\psi_{0}\\rangle. This is enough to compute the expectation values that we need.</p> <p>At a given moment in the application of VQE, we have some parameters \\theta and we want to estimate the expectation value of |\\psi_{0}\\rangle\\langle\\psi_{0}| with respect to |\\psi(\\theta)\\rangle = V(\\theta)|0\\rangle. This quantuty is </p>  \\langle\\psi(\\theta)|\\psi_{0}\\rangle\\langle\\psi_{0}|\\psi(\\theta)\\rangle = |\\langle \\psi_{0}|\\psi(\\theta)\\rangle|^{2} = |\\langle0|V(\\theta_{0})^{\\dagger}V(\\theta)|0\\rangle|^{2}.  <p>This is the probability of obtaining |0\\rangle as the outcome of measuring V(\\theta_{0})^{\\dagger}V(\\theta)|0\\rangle in the computational basis! This is something that we can easily estimate because we can prepare V(\\theta_{0})^{\\dagger}V(\\theta)|0\\rangle by first applying our ansatz V, using \\theta as the parameters, to |0\\rangle, and then applying the inverse of our ansatz, with parameter \\theta_{0}, to the resulting state. We will repeat this process several times, always measuring the resulting state V(\\theta_{0})^{\\dagger}V(\\theta)|0\\rangle in the computational basis and computing the relative frequency of the outcome |0\\rangle.</p> <p>         Figure. Circuit to copmute \\(\\langle0|V(\\theta_{0})^{\\dagger}V(\\theta)|0\\rangle\\).     </p> <p>Then we have to deal with preparing the circuit for V(\\theta_{0})^{\\dagger}. All you need to remember that every unitary gate is reversible. Thus, you can take the circuit for V(\\theta) and read the gates from right to left, reversing each one of them. For example, if \\theta_{0} = (a,b) and V(\\theta_{0}) = XR_{Z}(a)R_{X}(b)S, then V(\\theta_{0})^{\\dagger} = S^{\\dagger}R_{x}(-b)R_{z}(-a)X^{\\dagger} = S^{\\dagger}R_{x}(-b)R_{z}(-a)X.</p>"},{"location":"QuantumOpt/QOpt/VQEIntro/#using-vqe-with-qiskit","title":"Using VQE with Qiskit","text":""},{"location":"QuantumOpt/QOpt/VQEIntro/#using-vqe-with-pennylane","title":"USing VQE with PennyLane","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/","title":"Quantum Support Vector Machine in PennyLane","text":"<p>Photo by Maksym Kaharlytskyi on Unsplash</p> <p>In this Notebook, we will give a introduction of how to use Quantum Support Vector Mechine in PennyLane. For demonstrate purpose, we will work on 2 categories of <code>load_wine</code>.</p> <p>First, let's import Sklean package <code>load_wine</code> to explore our data. The wine recofnition dataset a labeled dataset with information about wines. There are 13 numerical variables that describe the color intensitym alcohol concentration, and other things.</p> <ul> <li><p>Learn more about tutorial for <code>load_wine</code>: https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html</p> </li> <li><p>Find out raw data of the <code>load_wine</code>: https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data</p> </li> </ul> In\u00a0[1]: Copied! <pre># import `load_wine` dataset\nfrom sklearn.datasets import load_wine\nimport numpy as np\n\n# Set seed for reproducibility\nnp.random.seed(seed=5678)\n\nx,y = load_wine(return_X_y=True)\n</pre> # import `load_wine` dataset from sklearn.datasets import load_wine import numpy as np  # Set seed for reproducibility np.random.seed(seed=5678)  x,y = load_wine(return_X_y=True) <p>In <code>load_wine</code>, the first 59 elements must belong to the first category (label 0) while the 71 sybsequent belongs to the second one (label 1). We can run the following code to obtain a labeled dataset with two categories.</p> In\u00a0[2]: Copied! <pre># Let's print out our dataset\nx = x[:59+71]\ny = y[:59+71]\n\n# print out x and y to explore our data\nprint(\"=\"*10)\nprint(f\" x data\\n {x}\")\nprint(\"=\"*10)\nprint(f\" The first row from the raw data: \\n {x[0]}\")\nprint(f\" Number of x variables : {len(x[0])}\")\nprint(\"=\"*10)\nprint(f\" y data\\n {y}\")\n</pre> # Let's print out our dataset x = x[:59+71] y = y[:59+71]  # print out x and y to explore our data print(\"=\"*10) print(f\" x data\\n {x}\") print(\"=\"*10) print(f\" The first row from the raw data: \\n {x[0]}\") print(f\" Number of x variables : {len(x[0])}\") print(\"=\"*10) print(f\" y data\\n {y}\") <pre>==========\n x data\n [[1.423e+01 1.710e+00 2.430e+00 ... 1.040e+00 3.920e+00 1.065e+03]\n [1.320e+01 1.780e+00 2.140e+00 ... 1.050e+00 3.400e+00 1.050e+03]\n [1.316e+01 2.360e+00 2.670e+00 ... 1.030e+00 3.170e+00 1.185e+03]\n ...\n [1.179e+01 2.130e+00 2.780e+00 ... 9.700e-01 2.440e+00 4.660e+02]\n [1.237e+01 1.630e+00 2.300e+00 ... 8.900e-01 2.780e+00 3.420e+02]\n [1.204e+01 4.300e+00 2.380e+00 ... 7.900e-01 2.570e+00 5.800e+02]]\n==========\n The first row from the raw data: \n [1.423e+01 1.710e+00 2.430e+00 1.560e+01 1.270e+02 2.800e+00 3.060e+00\n 2.800e-01 2.290e+00 5.640e+00 1.040e+00 3.920e+00 1.065e+03]\n Number of x variables : 13\n==========\n y data\n [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n</pre> <p>Here,</p> <ul> <li><code>x</code> is the data set includes the 13 variables and <code>y</code> is the corresponding of the <code>x</code>.</li> <li><code>0</code> represents the category 0 and <code>1</code> represents the category 1.</li> </ul> <p>Let's call <code>train_test_split</code> from <code>sklearn.model_selection</code> to help us split our training and test dataset. We set the <code>training_size = 0.9</code> as we take 90% of the raw data from x and y as a training set and the remaining 10% as the test set.</p> In\u00a0[3]: Copied! <pre>from sklearn.model_selection import train_test_split\n\n# Split the data into training and test sets with training size of 0.9.\nx_tr, x_test, y_tr, y_test = train_test_split(x,y, train_size=0.9)\n</pre> from sklearn.model_selection import train_test_split  # Split the data into training and test sets with training size of 0.9. x_tr, x_test, y_tr, y_test = train_test_split(x,y, train_size=0.9) <p>Before we do any quantum operations, we should normalized our dataset. We will use the easiest way of normalization ways: scaling each of the variables linearly in such way that the maximum absolute value taken by each variable be 1.</p> <p>Please run <code>MaxAbsScaler()</code> object from <code>sklearn.preprocessing</code> to normalize our training set.</p> In\u00a0[4]: Copied! <pre>from sklearn.preprocessing import MaxAbsScaler\n\n# Normalize our training data into a range of {0,1}\nscaler = MaxAbsScaler()\nx_tr = scaler.fit_transform(x_tr)\n</pre> from sklearn.preprocessing import MaxAbsScaler  # Normalize our training data into a range of {0,1} scaler = MaxAbsScaler() x_tr = scaler.fit_transform(x_tr) <p>Now, all of our data are positive number between 0 and 1. It is worth to notice that we don't normalize the test simultaneously since we will includes the information from the training set. Instead, we normalize the test set independently from the training set. Please run the following code to normalize the testing set.</p> In\u00a0[5]: Copied! <pre># Normalize our test set independently from the training set to avoid includes training set data leaks into test set.\nx_test = scaler.transform(x_test)\nx_test = np.clip(x_test,0,1)\n</pre> # Normalize our test set independently from the training set to avoid includes training set data leaks into test set. x_test = scaler.transform(x_test) x_test = np.clip(x_test,0,1) <p>Since out dataset has 13 variables, using angle encoding or the ZZ feature map need 13 qubtis. This maight not be feasible if we want our kernal to be simulated on some powerful computer. Therefore, we will work on amplitude encoding using 4 qubots, which can encode up to 16 qubits, and we will refill the remaining qubits with zeros.</p> <p>Here's the installation instruction for <code>lightning.qubit</code>:</p> <p>https://docs.pennylane.ai/projects/lightning/en/stable/lightning_qubit/installation.html</p> In\u00a0[6]: Copied! <pre>import pennylane as qml\n\n# initialize our quantum device\nnqubits = 4\ndev = qml.device(name = 'default.qubit', wires = nqubits)\n\n# define our kernel circuit\n@qml.qnode(dev)\ndef kernel_circ(a, b):\n    # encode a into amplitude vector of n qubits\n    qml.AmplitudeEmbedding(\n        a, wires=range(nqubits), pad_with=0, normalize=True\n    )\n    # Conpute the inverse(adjoint) of the amplitude encoding of b\n    qml.adjoint(qml.AmplitudeEmbedding(\n        b, wires=range(nqubits), pad_with=0, normalize=True\n    ))\n    return qml.probs(wires=range(nqubits))\n</pre> import pennylane as qml  # initialize our quantum device nqubits = 4 dev = qml.device(name = 'default.qubit', wires = nqubits)  # define our kernel circuit @qml.qnode(dev) def kernel_circ(a, b):     # encode a into amplitude vector of n qubits     qml.AmplitudeEmbedding(         a, wires=range(nqubits), pad_with=0, normalize=True     )     # Conpute the inverse(adjoint) of the amplitude encoding of b     qml.adjoint(qml.AmplitudeEmbedding(         b, wires=range(nqubits), pad_with=0, normalize=True     ))     return qml.probs(wires=range(nqubits)) <p>Here,</p> <ol> <li>We use <code>AmplitudeEmbedding()</code> to returns an operation equivalent to the amplitude encoding of its first arguemnt. In our case, we used <code>a</code> and <code>b</code> for this first argument. And <code>AmplitudeEmbedding</code> encodes $2^n$ features into the amplitude vector of $n$ qubits.</li> <li>There are the classical data that our kernel function takes as input. More, we also asked <code>AmplitudeEmbedding()</code> to noramlize each input vector for us, just as amplitude encoding needs us to do (as we were told in basic quantum state).</li> <li>We use <code>pad_with = 0</code> to fill the remaining qubits with zeros since we are only consider <code>nqubits = 4</code> case out of total of 13 cases.</li> <li>We implemented <code>qml.adjoint()</code> to compute the adjoint (inverse) of the amplitude encoding <code>b</code>.</li> <li>Lastly, we retrive the probabilities of measuring each possible state in the computational basis by using <code>qml.probs(wires=range(nqubits))</code>. The first element of this array will be the output of our kernel.</li> </ol> <p>Recall that if the amplitude encoding feature map is given an inputs $x_{0},\\cdots,x_{2^{n}-1}$, it simply prepares the state</p> <p>$$ | \\phi(\\overrightarrow{a}\\rangle) = \\frac{1}{\\sqrt{\\sum_{k}x_{k}^{2}}} \\sum_{k=0}^{2^{n}-1}x_{k}|k\\rangle. $$</p> <p>You can run the below to check if the circuit works as expected. The first entry should return 1, which corresponds to the output of the kernel.</p> In\u00a0[7]: Copied! <pre>kernel_circ(x_tr[0],x_tr[0])\n</pre> kernel_circ(x_tr[0],x_tr[0]) Out[7]: <pre>tensor([1.00000000e+00, 9.90011286e-35, 1.49909334e-32, 2.57335126e-33,\n        1.47137684e-32, 8.95091217e-34, 4.65150803e-33, 9.97555849e-35,\n        4.93038066e-32, 1.26313737e-34, 7.40552773e-33, 4.06038555e-33,\n        1.37899948e-32, 6.66163615e-34, 1.50394221e-33, 2.17790719e-36], requires_grad=True)</pre> <p>Now, let's run the following code to train our model. In order to use a custom kernel, you are required to provide a <code>kernel</code> function accepting two arrays, <code>A</code> and <code>B</code>, and returning a matrix with entries <code>(j,k)</code> containing the kernel applied to <code>A[j]</code> and <code>B[k]</code>.</p> In\u00a0[8]: Copied! <pre>from sklearn.svm import SVC\n\ndef qkernal(A, B):\n    # [0] for return the first entry: the measured value.\n    return np.array([[kernel_circ(a,b)[0] for b in B] for a in A] )\n\n# Fit the model\nsvm = SVC(kernel=qkernal).fit(x_tr, y_tr) \n</pre> from sklearn.svm import SVC  def qkernal(A, B):     # [0] for return the first entry: the measured value.     return np.array([[kernel_circ(a,b)[0] for b in B] for a in A] )  # Fit the model svm = SVC(kernel=qkernal).fit(x_tr, y_tr)  <p>The training can take up to a few mintues depends on the performance of your computer. Once it's over, you can check the accuracy of your trained model with the following instructions:</p> In\u00a0[12]: Copied! <pre>from sklearn.metrics import accuracy_score\n\nscore_test_amp = accuracy_score(svm.predict(x_test), y_test)\nprint(f\"Amplitude encoding test score: {score_test_amp}\")\n</pre> from sklearn.metrics import accuracy_score  score_test_amp = accuracy_score(svm.predict(x_test), y_test) print(f\"Amplitude encoding test score: {score_test_amp}\") <pre>Amplitude encoding test score: 0.9230769230769231\n</pre> <p>In our casem this gives an accuracy of 0.92, meaning that the SVM is capable of classifying most of the elements in the test dataset correctly.</p> <p>We've seen how to use amplitude encoding to take full advantage of the 13 variables of our dataset while only using 4 qubits. Now, let's see how can we reduce the number of variables in the dataset - while trying to minimize the loss of information - and thus be able to use other feature maps that could perhaps yield better results.</p> <p>Here, we will try to reduce the number of variables in our dataset into 8 and we train our QVSM with the new angle encoding.</p> <p>The method we are going to use in this section is called principal component analysis.</p> <p>The <code>PCA</code> class uses <code>fit</code> method that analyzes the data and figures out the best way to reduce its dimensionality using principal component analysis. Follow by transform, which can then transform any data in the way it learned to do when <code>fit</code> was invoked.</p> In\u00a0[14]: Copied! <pre>from sklearn.decomposition import PCA\n\n# Apply PCA method with targeted dimension of 8\npca = PCA(n_components=8)\n\nxs_tr = pca.fit_transform(x_tr)\nxs_test = pca.fit_transform(x_test)\n</pre> from sklearn.decomposition import PCA  # Apply PCA method with targeted dimension of 8 pca = PCA(n_components=8)  xs_tr = pca.fit_transform(x_tr) xs_test = pca.fit_transform(x_test) <p>             Figure. Angle encoding of an input using different rotation angle.          </p> In\u00a0[15]: Copied! <pre>nqubits = 8\ndev = qml.device(name = 'default.qubit', wires = nqubits) \n\n# Apply Angle encoding\n@qml.qnode(dev)\ndef kernel_circ(a,b):\n    qml.AngleEmbedding(a, wires = range(nqubits))\n    qml.adjoint(qml.AngleEmbedding(b, wires=range(nqubits)))\n    return qml.probs(wires=range(nqubits))\n</pre> nqubits = 8 dev = qml.device(name = 'default.qubit', wires = nqubits)   # Apply Angle encoding @qml.qnode(dev) def kernel_circ(a,b):     qml.AngleEmbedding(a, wires = range(nqubits))     qml.adjoint(qml.AngleEmbedding(b, wires=range(nqubits)))     return qml.probs(wires=range(nqubits)) In\u00a0[16]: Copied! <pre># Fit the model\nsvm = SVC(kernel=qkernal).fit(xs_tr, y_tr) \n\nscore_test_angle = accuracy_score(svm.predict(xs_test), y_test)\nprint(f\"Angle encoding test score: {score_test_angle}\")\n</pre> # Fit the model svm = SVC(kernel=qkernal).fit(xs_tr, y_tr)   score_test_angle = accuracy_score(svm.predict(xs_test), y_test) print(f\"Angle encoding test score: {score_test_angle}\") <pre>Angle encoding test score: 0.9230769230769231\n</pre> <p>You should get the result of around 92.3% of accuracy and should have less time then the amplitude encoding with all 13 varaibels.</p> <p>             Figure. ZZ feature map of three qubits with inputs x          </p> <p>In this section, we will train a QSVM on the reduced dataset using our own implementation of the ZZ feature map.</p> In\u00a0[17]: Copied! <pre>from itertools import combinations\n\n# creating a ZZFeatureMap\ndef ZZFeatureMap(nqubits, data):\n    # Number of variables that we will load:\n    # Could be smaller thatn the number of qubits\n    nload = min(len(data), nqubits)\n    \n    # apply Hadamard and Rz rotation for each qubit,\n    for i in range(nload):\n        qml.Hadamard(i)\n        qml.RZ(2.0 * data[i], wires=i)\n        \n    for pair in list(combinations(range(nload),2)):\n        q0 = pair[0]\n        q1 = pair[1]\n\n        qml.CZ(wires=[q0, q1])\n        qml.RZ(2.0 * (np.pi - data[q0]) * (np.pi - data[q1]), wires = q1)\n        qml.CZ(wires=[q0, q1])\n</pre> from itertools import combinations  # creating a ZZFeatureMap def ZZFeatureMap(nqubits, data):     # Number of variables that we will load:     # Could be smaller thatn the number of qubits     nload = min(len(data), nqubits)          # apply Hadamard and Rz rotation for each qubit,     for i in range(nload):         qml.Hadamard(i)         qml.RZ(2.0 * data[i], wires=i)              for pair in list(combinations(range(nload),2)):         q0 = pair[0]         q1 = pair[1]          qml.CZ(wires=[q0, q1])         qml.RZ(2.0 * (np.pi - data[q0]) * (np.pi - data[q1]), wires = q1)         qml.CZ(wires=[q0, q1]) <p>We have used the <code>combinations</code> function from the <code>itertools</code> module. This function take 2 arguments: an array <code>arr</code> and an integer <code>l</code>. And it returns an array with all the sorted tuples of length <code>l</code> with elements from the array <code>arr</code>.</p> <p>Let's use it as our kernel function and train our model!</p> In\u00a0[18]: Copied! <pre>nqubits = 4\ndev = qml.device(name = 'default.qubit', wires = nqubits) \n\n@qml.qnode(dev)\ndef kernel_circ(a,b):\n    ZZFeatureMap(nqubits, a)\n    qml.adjoint(ZZFeatureMap)(nqubits, b) ## qml.adjoint(fn: Operator)(nqubits, b)\n    return qml.probs(wires=range(nqubits))\n</pre> nqubits = 4 dev = qml.device(name = 'default.qubit', wires = nqubits)   @qml.qnode(dev) def kernel_circ(a,b):     ZZFeatureMap(nqubits, a)     qml.adjoint(ZZFeatureMap)(nqubits, b) ## qml.adjoint(fn: Operator)(nqubits, b)     return qml.probs(wires=range(nqubits)) In\u00a0[19]: Copied! <pre># Fit the model\nsvm = SVC(kernel=qkernal).fit(xs_tr, y_tr) \nscore_test_ZZ = accuracy_score(svm.predict(xs_test), y_test)\nprint(f\"ZZ feature map encoding test score: {score_test_ZZ}\")\n</pre> # Fit the model svm = SVC(kernel=qkernal).fit(xs_tr, y_tr)  score_test_ZZ = accuracy_score(svm.predict(xs_test), y_test) print(f\"ZZ feature map encoding test score: {score_test_ZZ}\") <pre>ZZ feature map encoding test score: 0.8461538461538461\n</pre> <p>It is a fact that <code>qml.adjoint</code> is acting on the <code>ZZFeatureMap</code> function itself, not on its qubit.</p> In\u00a0[32]: Copied! <pre>print(f\"------------------------------------------\")\nprint(f\"Feature map                 | Test Score |\")\nprint(f\"------------------------------------------\")\nprint(f\"Amplitude encoding          | {score_test_amp:10.3f} | \")\nprint(f\"Angle encoding              | {score_test_angle:10.3f} |\")\nprint(f\"ZZ feature map              | {score_test_ZZ:10.3f} | \")\nprint(f\"------------------------------------------\")\n</pre> print(f\"------------------------------------------\") print(f\"Feature map                 | Test Score |\") print(f\"------------------------------------------\") print(f\"Amplitude encoding          | {score_test_amp:10.3f} | \") print(f\"Angle encoding              | {score_test_angle:10.3f} |\") print(f\"ZZ feature map              | {score_test_ZZ:10.3f} | \") print(f\"------------------------------------------\")  <pre>------------------------------------------\nFeature map                 | Test Score |\n------------------------------------------\nAmplitude encoding          |      0.923 | \nAngle encoding              |      0.923 |\nZZ feature map              |      0.846 | \n------------------------------------------\n</pre> In\u00a0[20]: Copied! <pre>import sys\nimport platform\nimport pennylane\nimport pennylane_lightning\n\n\nprint(\"=\"*10 + \" Version Information \" + \"=\"*10)\nprint(f\"Python              : {sys.version}\")\nprint(f\"Operating System    : {platform.system()} {platform.release()} ({platform.architecture()[0]})\")\nprint(\"=\"*41)\nprint(f\"Pennylane           : {pennylane.__version__}\")\nprint(f\"pennylane_lightning : {pennylane_lightning.__version__} \")\nprint(\"=\"*41)\n</pre> import sys import platform import pennylane import pennylane_lightning   print(\"=\"*10 + \" Version Information \" + \"=\"*10) print(f\"Python              : {sys.version}\") print(f\"Operating System    : {platform.system()} {platform.release()} ({platform.architecture()[0]})\") print(\"=\"*41) print(f\"Pennylane           : {pennylane.__version__}\") print(f\"pennylane_lightning : {pennylane_lightning.__version__} \") print(\"=\"*41) <pre>========== Version Information ==========\nPython              : 3.11.11 (main, Dec 11 2024, 10:28:39) [Clang 14.0.6 ]\nOperating System    : Darwin 24.3.0 (64bit)\n=========================================\nPennylane           : 0.26.0\npennylane_lightning : 0.28.0 \n=========================================\n</pre>"},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#quantum-support-vector-machine-in-pennylane","title":"Quantum Support Vector Machine in PennyLane\u00b6","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#python-workflow","title":"Python Workflow\u00b6","text":"<ol> <li>Preparing data set from load_wine</li> <li>PennyLane and scikit-learn</li> <li>Dataset dimension reduction</li> <li>Custom feature maps</li> </ol>"},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#preparing-data-set-from-load_wine","title":"Preparing data set from load_wine\u00b6","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#pennylane-and-scikit-learn","title":"PennyLane and scikit-learn\u00b6","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#amplitude-encoding","title":"Amplitude Encoding\u00b6","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#dataset-dimension-reduction","title":"Dataset dimension reduction\u00b6","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#principle-directions","title":"Principle directions\u00b6","text":"<p>When you have a dataset with $n$ variables, you are basically have a set of points in $R^{n}$.</p> <ol> <li>The first principle direction is the direction of the line that best fits the data as measured by the mean squared error.</li> <li>The second principle direction is the direction of the line that best fits the data while being orthogonal to the first principle direction.</li> </ol> <p>This goes on in such way that the $k$-th principal direction is that of the line that best fits the data while being orthogonal to the first, second, and all the way up to $(k-1)$-th principle direction.</p> <p>Let's consider an orthonormal basis $\\{v_{1},\\cdots,v_{n}\\}$ of $R^{n}$ in which $v_{j}$ points in the direction of the $j$-th principal component. The vectors in this orthonormal basis will be of the form $v_{j} = (v_{j}^{1},\\cdots,v_{j}^{n}) \\in R^{n}$.</p> <p>When using principal component analysis, we compute the vector of the aforementioned basis. Then we define variables</p> <p>$$ \\overrightarrow{x}_{j} = v_{j}^{1}x_{1} + \\cdots +v_{j}^{n}x_{n}. $$</p>"},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#angle-encoding","title":"Angle Encoding\u00b6","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#custom-feature-maps","title":"Custom feature maps\u00b6","text":""},{"location":"QuantumOpt/jupyter_QML/%28C%29load_wine_QSVM_PennyLane/#references","title":"References\u00b6","text":"<p>[1]. Combarro, E. F., &amp; Gonz\u00e1lez-Castillo, S. (2023). A practical guide to quantum machine learning and quantum optimisation: Hands-on approach to modern quantum algorithms. Packt Publishing.</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/","title":"Working AQQA with D-wave","text":"<p>D-Wave, the first company commercialize a quantum device that implemented quantum annealing as we have just covered. We need to keep in mind that, with these quantum computers, the evolution process will not be adiabatic in general, so there is no guarantee that the exact solution will be found in all cases.</p> <p>Using D-wave is easier than you think. You need to install Ocean, which is D-Wave's quantum annealing Python library, and to create a free account on D-Wave Laep, a cloud service where you can get one minute per month of free computing time on D-Wave's quantum annealers.</p> <p>Once you have everything set up, you can access quantum annealers to find an approximation of a solution to any combinatiorial optimiazation problem that you may have written as either an instance of finding the groud state of an Ising model or as a QUBO problem. Let's try with the MaxCut problem from QUBO first!</p> <p>ok let's do some review first, for the Ising model from QUBO, we have</p> <p>$$ \\begin{array}{ll} \\text{Minimize} &amp; -\\sum_{(j,k)\\in E} J_{jk}\\langle \\psi \\lvert Z_{j}Z_{k}\\lvert \\psi \\rangle -\\sum_{j} h_{j}\\langle \\psi \\lvert Z_{j}\\lvert \\psi \\rangle \\\\ \\text{where} &amp; \\lvert \\psi \\rangle \\text{is taken from the set of quantum states on} \\ n \\ \\text{qubis} \\end{array} $$</p> <p>and we can reduce to a 3 vertices problem to the following:</p> <p>$$ \\begin{array}{ll} \\text{Minimize} &amp; \\langle \\psi\\lvert(Z_{0}Z_{1}+Z_{0}Z_{2})\\lvert \\psi\\rangle = \\langle \\psi \\lvert Z_{0}Z_{1}\\lvert \\psi \\rangle + \\langle \\psi \\lvert Z_{0}Z_{2}\\lvert \\psi \\rangle,\\\\ \\text{where} &amp; \\lvert \\psi \\rangle \\text{is taken from the set of quantum states on 3 qubis} \\end{array} $$</p> <p>we can write the ground state as,</p> <p>$$ Z_{0}Z_{1} + Z_{0}Z_{2} = Z \\otimes Z \\otimes I + Z \\otimes I \\otimes Z $$</p> <p>which is, of course, an Ising Hamiltonian in which $J_{01} = J_{02} = 1$ and the rest of the coefficients are $0$.</p> <p>Next, all we need is to tell the quantum annealer is that those are the coefficients we want to use, and then we can perfrom the annealing multiple times to obtain some resutls that will hopefully wolve our problem. To specift the problem, we can use the <code>dimod</code> package inclided in the Ocean library.</p> In\u00a0[3]: Copied! <pre>import dimod\n\nJ = {(0,1):1, (0,2):1}\nh = {}\n\nproblem = dimod.BinaryQuadraticModel(h,J,0.0,dimod.SPIN)\n\nprint(\"The problem we are going to solve is:\")\nprint(problem)\n</pre> import dimod  J = {(0,1):1, (0,2):1} h = {}  problem = dimod.BinaryQuadraticModel(h,J,0.0,dimod.SPIN)  print(\"The problem we are going to solve is:\") print(problem) <pre>The problem we are going to solve is:\nBinaryQuadraticModel({0: 0.0, 1: 0.0, 2: 0.0}, {(1, 0): 1.0, (2, 0): 1.0}, 0.0, 'SPIN')\n</pre> <p>You should get the following result:</p> <p><code>The problem we are going to solve is: BinaryQuadraticModel({0: 0.0, 1: 0.0, 2: 0.0}, {(1, 0): 1.0, (2, 0): 1.0}, 0.0, 'SPIN')</code></p> <ol> <li><p>We used $J$ for the coefficients of the degree $2$ terms (quadratic) - <code>(0,1):1</code> sets the $J_{01}$ coefficient to 1 and <code>(0,2):1</code> sets $J_{02} = 1$ - and <code>h</code> for the linear ones.</p> </li> <li><p>These parameters will be set to $0$ by <code>BinaryQuadraticModel()</code> if we don't specify.</p> </li> <li><p>Notice that the result shows <code>(1,0)</code> and <code>(2,0)</code> that are identical to $Z_{0}Z_{1}$ and $Z_{0}Z_{2}$ since $Z_{0}Z_{1} = Z_{1}Z_{0}$ and, thus, the situation is symmetrical.</p> </li> <li><p>We set offset to $0.0$, which is a constant term that can be added to the Hamiltonian.</p> </li> <li><p>We used <code>dimod.SPIN</code> since we are working with an Ising Hamiltonian and, thus, the values of our variables are $1$ and $-1$.</p> </li> </ol> In\u00a0[6]: Copied! <pre>from dwave.system import DWaveSampler\nfrom dwave.system import EmbeddingComposite\n\nsampler = EmbeddingComposite(DWaveSampler())\nresult = sampler.sample(problem, num_reads = 10)\n\nprint(\"The solutions that we have obtained are\")\nprint(result)\n</pre> from dwave.system import DWaveSampler from dwave.system import EmbeddingComposite  sampler = EmbeddingComposite(DWaveSampler()) result = sampler.sample(problem, num_reads = 10)  print(\"The solutions that we have obtained are\") print(result) <pre>The solutions that we have obtained are\n   0  1  2 energy num_oc. chain_.\n0 -1 +1 +1   -2.0       1     0.0\n1 +1 -1 -1   -2.0       9     0.0\n['SPIN', 2 rows, 10 samples, 3 variables]\n</pre> <p>This means that we obtained two different solutions: $z_{0} = -1$, $z_{1} = 1$, and $z_{2} = 1$, and $z_{0} = 1$, $z_{1} = -1$, and $z_{2} = -1$, both with energy $-2$; the first one was measured in $1$ of the executions and the second one was measured in $9$ of the executions. The <code>chain_</code> column shows information about the chain break in quantum annealing or related solvers. A value of 0.0 means there were no chain breaks (ideal solution). But, as you can check, these two solutions are maximum cuts in our graph.</p> <p>For the first result:</p> <p>$$ Z_{0}\\cdot Z_{1}\\cdot I + Z_{0}\\cdot I\\cdot Z_{2} = -1\\cdot 1\\cdot 1 + 1\\cdot 1 \\cdot -1 = -2 $$</p> <ol> <li>$Z_{0}$ = -1 is in one partition.</li> <li>$Z_{1}$ = 1 and $Z_{2}$ = 1 are in another partition.</li> <li>The edges between $Z_{0}$ and $Z_{1}$, and between $Z_{0}$ and $Z_{2}$, are cut since their spins differ.</li> </ol> <p>For the QUBO problems, we have to specify the linear coefficients of the quadratic terms (2 degree terms). Also, don't forget we are using binary (0,1) variables, so expression like $x_{3}^{2}$ can be simplified to $x_3$ $(1^2 = 1)$. Also we have to specify the independent coefficient. The only change is that we will use <code>dimod.BINARY</code> parameter when creating our problem with the <code>BinaryQuadraticModel</code> class.</p> <p>You are given a problem like this:</p> <p>$$ \\begin{array}{ll} \\text{Minimize} &amp; -5x_{0} + 3x_{1} - 2x_{2} \\\\ \\text{subject to} &amp; x_{0} + x_{2} \\leq 1,\\\\                   &amp; 3x_{0} - x_{1} + 3x_{2} \\leq 4\\\\                   &amp; x_{j} \\in \\{ 0,1 \\}, \\ \\ \\ j=0,1,2 \\end{array} $$</p> <p>This is an obvious binary linear programming problem which we have introduced before that can be transformed into a QUBO or Icing problems by using proper slack variables and penalty terms.</p> <p>For the binary linear programming problem, we don't need to transform our problem into QUBO coefficients and then use them to define <code>BinaryQuadraticModel</code> manually. All we have to do is to use <code>ConstrainedQuadraticModel</code>class provided by <code>dimod</code>. To construct our binary linear programm as a <code>ConstrainedQuadraticModel</code> model, we need to do the followlings:</p> <ol> <li><code>x0 = dimod.Binary(\"x0\")</code></li> <li><code>x1 = dimod.Binary(\"x1\")</code></li> <li><code>x2 = dimod.Binary(\"x2\")</code></li> </ol> <p>These three instructions created three binary variables and we have labeled them so that we can use them in math expression directly!</p> <p>Note that if you don't define constraint before execute the code, dimod will assign an alphanumeric string to each constraint, you need to use <code>relabel_constraints</code> if you want to change label after.</p> In\u00a0[11]: Copied! <pre># Define binary \nx0 = dimod.Binary(\"x0\")\nx1 = dimod.Binary(\"x1\")\nx2 = dimod.Binary(\"x2\")\n\n# Use these binary in to the math expression directly!\nblp = dimod.ConstrainedQuadraticModel()\nblp.set_objective(-5*x0 + 3*x1 - 2*x2)\nblp.add_constraint(x0 + x2 &lt;= 1, \"First constraint\")\nblp.add_constraint(3*x0 - x1 + 3*x2 &lt;= 4, \"Second constraint\")\n\n# Inspect our model\nprint(\"Our variables:\", blp.variables)\nprint(\"Our objective:\", blp.objective)\nprint(\"Our constraints:\", blp.constraints)\n</pre> # Define binary  x0 = dimod.Binary(\"x0\") x1 = dimod.Binary(\"x1\") x2 = dimod.Binary(\"x2\")  # Use these binary in to the math expression directly! blp = dimod.ConstrainedQuadraticModel() blp.set_objective(-5*x0 + 3*x1 - 2*x2) blp.add_constraint(x0 + x2 &lt;= 1, \"First constraint\") blp.add_constraint(3*x0 - x1 + 3*x2 &lt;= 4, \"Second constraint\")  # Inspect our model print(\"Our variables:\", blp.variables) print(\"Our objective:\", blp.objective) print(\"Our constraints:\", blp.constraints)  <pre>Our variables: Variables(['x0', 'x1', 'x2'])\nOur objective: ObjectiveView({'x0': -5.0, 'x1': 3.0, 'x2': -2.0}, {}, 0.0, {'x0': 'BINARY', 'x1': 'BINARY', 'x2': 'BINARY'})\nOur constraints: {'First constraint': Le(ConstraintView({'x0': 1.0, 'x2': 1.0}, {}, 0.0, {'x0': 'BINARY', 'x2': 'BINARY'}), np.float64(1.0)), 'Second constraint': Le(ConstraintView({'x0': 3.0, 'x1': -1.0, 'x2': 3.0}, {}, 0.0, {'x0': 'BINARY', 'x1': 'BINARY', 'x2': 'BINARY'}), np.float64(4.0))}\n</pre> <p>You should expect the result as following:</p> <p><code>Our variables: Variables(['x0', 'x1', 'x2']) Our objective: ObjectiveView({'x0': -5.0, 'x1': 3.0, 'x2': -2.0}, {}, 0.0, {'x0': 'BINARY', 'x1': 'BINARY', 'x2': 'BINARY'}) Our constraints: {'First constraint': Le(ConstraintView({'x0': 1.0, 'x2': 1.0}, {}, 0.0, {'x0': 'BINARY', 'x2': 'BINARY'}), np.float64(1.0)), 'Second constraint': Le(ConstraintView({'x0': 3.0, 'x1': -1.0, 'x2': 3.0}, {}, 0.0, {'x0': 'BINARY', 'x1': 'BINARY', 'x2': 'BINARY'}), np.float64(4.0))}</code></p> <ol> <li><code>Le</code> stands for less than or equal to.</li> <li>You can also create quality constraints, which will belong to the <code>dimod.sym.Eq</code> class.</li> <li>The inequality constraint $\\geq$ belongs to <code>dimod.sym.Ge</code> objects.</li> </ol> <p>Here we are aiming to solve the problem we just formulated by using <code>dimod</code>. To do this, we can define an assignment of values to the variables, check if it is feasible, and compute its cost for the problem defined in the previous subsection by using the following code:</p> In\u00a0[12]: Copied! <pre># Check if sample1 is a feasible solution\nsample1 = {\"x0\":1, \"x1\":1, \"x2\":1}\nprint(\"The assignment is\", sample1)\nprint (\"It's cost is:\", blp.objective.energy(sample1))\nprint (\"Is it feasible:\", blp.check_feasible(sample1))\nprint(\"The violations of the constraints are:\", blp.violations(sample1))\n</pre> # Check if sample1 is a feasible solution sample1 = {\"x0\":1, \"x1\":1, \"x2\":1} print(\"The assignment is\", sample1) print (\"It's cost is:\", blp.objective.energy(sample1)) print (\"Is it feasible:\", blp.check_feasible(sample1)) print(\"The violations of the constraints are:\", blp.violations(sample1))  <pre>The assignment is {'x0': 1, 'x1': 1, 'x2': 1}\nIt's cost is: -4.0\nIs it feasible: False\nThe violations of the constraints are: {'First constraint': np.float64(1.0), 'Second constraint': np.float64(1.0)}\n</pre> <p>This tells us that the assignment is not feasible. The $1$s represent that left-hand side of each inequality is bigger than the right-hand side.</p> <p>Let's try <code>sample2</code></p> In\u00a0[13]: Copied! <pre># Check if sample2 is a feasible solution\nsample2 = {\"x0\":0, \"x1\":0, \"x2\":1}\nprint(\"The assignment is\", sample2)\nprint (\"It's cost is:\", blp.objective.energy(sample2))\nprint (\"Is it feasible:\", blp.check_feasible(sample2))\nprint(\"The violations of the constraints are:\", blp.violations(sample2))\n</pre> # Check if sample2 is a feasible solution sample2 = {\"x0\":0, \"x1\":0, \"x2\":1} print(\"The assignment is\", sample2) print (\"It's cost is:\", blp.objective.energy(sample2)) print (\"Is it feasible:\", blp.check_feasible(sample2)) print(\"The violations of the constraints are:\", blp.violations(sample2)) <pre>The assignment is {'x0': 0, 'x1': 0, 'x2': 1}\nIt's cost is: -2.0\nIs it feasible: True\nThe violations of the constraints are: {'First constraint': np.float64(0.0), 'Second constraint': np.float64(-1.0)}\n</pre> <p>The result should show that <code>sample2</code> is a feasible solution and no positive term in <code>violation</code>.</p> <p>The <code>dimod</code> package also provide a brute-force solver that tries all possible assignments and sort them according to their cost, from lowest to highest. Please run the below code:</p> In\u00a0[15]: Copied! <pre>solver = dimod.ExactCQMSolver()\nsolution = solver.sample_cqm(blp)\nprint(\"The list of assignments is:\")\nprint(solution)\n</pre> solver = dimod.ExactCQMSolver() solution = solver.sample_cqm(blp) print(\"The list of assignments is:\") print(solution) <pre>The list of assignments is:\n  x0 x1 x2 energy num_oc. is_sat. is_fea.\n6  1  0  1   -7.0       1 arra... np.F...\n2  1  0  0   -5.0       1 arra... np.T...\n7  1  1  1   -4.0       1 arra... np.F...\n3  1  1  0   -2.0       1 arra... np.T...\n4  0  0  1   -2.0       1 arra... np.T...\n0  0  0  0    0.0       1 arra... np.T...\n5  0  1  1    1.0       1 arra... np.T...\n1  0  1  0    3.0       1 arra... np.T...\n['INTEGER', 8 rows, 8 samples, 3 variables]\n</pre> <p>The first number is just an identifier of the assignment. The result also shows that if the assignemnt is feasible or not. In fact, if we execute <code>solution.first</code>, we will get:</p> In\u00a0[17]: Copied! <pre>print(solution.first)\n</pre> print(solution.first) <pre>Sample(sample={'x0': np.int64(1), 'x1': np.int64(0), 'x2': np.int64(1)}, energy=np.float64(-7.0), num_occurrences=np.int64(1), is_satisfied=array([False, False]), is_feasible=np.False_)\n</pre> <p>This shows the first solution, which is obviously infeasible in our case.</p> <p>You may wonder what if I want the optimal solution? We can try <code>filter</code> method like below:</p> In\u00a0[19]: Copied! <pre>feasible_sols = solution.filter(lambda s: s.is_feasible)\nprint(feasible_sols.first)\n</pre> feasible_sols = solution.filter(lambda s: s.is_feasible) print(feasible_sols.first) <pre>Sample(sample={'x0': np.int64(1), 'x1': np.int64(0), 'x2': np.int64(0)}, energy=np.float64(-5.0), num_occurrences=np.int64(1), is_satisfied=array([ True,  True]), is_feasible=np.True_)\n</pre> <p>You should get the solution of $x_{0} = 1$, $x_{1} = 0$, $x_{2} = 0$ with an energy of $-5.0$ and it's a feasible assignment.</p> <p>To define problem on class <code>ConstrainedQuadraticModel</code> and run it on the quantum annealers, we first need to eliminate the constraints and created a <code>BinaryQuadraticModel</code> object that we can later execute on actual quantum hardware. This process can be achieved thanks to the Ocean library. Let's define a simple constrained problem with the following code:</p> In\u00a0[22]: Copied! <pre># Construct a smple constrained problem\ny0, y1 = dimod.Binaries([\"y0\",\"y1\"])\ncqm = dimod.ConstrainedQuadraticModel()\ncqm.set_objective(-2*y0 - 3*y1)\ncqm.add_constraint(y0 + 2*y1 &lt;= 2)\n\n# Make the above problem into a unconstrained problem.\nqubo, invert = dimod.cqm_to_bqm(cqm, lagrange_multiplier=5)\nprint(qubo)\n</pre> # Construct a smple constrained problem y0, y1 = dimod.Binaries([\"y0\",\"y1\"]) cqm = dimod.ConstrainedQuadraticModel() cqm.set_objective(-2*y0 - 3*y1) cqm.add_constraint(y0 + 2*y1 &lt;= 2)  # Make the above problem into a unconstrained problem. qubo, invert = dimod.cqm_to_bqm(cqm, lagrange_multiplier=5) print(qubo)  <pre>BinaryQuadraticModel({'y0': -17.0, 'y1': -23.0, 'slack_v8466ba63c65c435890f38d4ac99e843e_0': -15.0, 'slack_v8466ba63c65c435890f38d4ac99e843e_1': -15.0}, {('y1', 'y0'): 20.0, ('slack_v8466ba63c65c435890f38d4ac99e843e_0', 'y0'): 10.0, ('slack_v8466ba63c65c435890f38d4ac99e843e_0', 'y1'): 20.0, ('slack_v8466ba63c65c435890f38d4ac99e843e_1', 'y0'): 10.0, ('slack_v8466ba63c65c435890f38d4ac99e843e_1', 'y1'): 20.0, ('slack_v8466ba63c65c435890f38d4ac99e843e_1', 'slack_v8466ba63c65c435890f38d4ac99e843e_0'): 10.0}, 20.0, 'BINARY')\n</pre> <p>The result may seems overwhelming at the begining, but let's break it down!</p> <ol> <li>First, we have the linear part, which starts with <code>y0 : -17.0</code>. It tells us that in the objective function, $y_0$ has coefficient of $-17$, $y_1$ has coefficient $-23$, and the two other variables ahve coefficient of $-15$.</li> <li>Then we look into the quadratic term. $y_{0}y_{1}$ has a coefficient of 20 and with coefficients $10$ and $20$ for the other products of two variables.</li> <li>Lastly, 20 is the independent term or offset.</li> <li>We know that all the variables are binary.</li> </ol> <p>What <code>dimod</code> does is to apply transformation in section 3.4.1 : Binary linear programmig. First two slack variables are introduced to transform the inequality constraint into an equality one. Then the equality constraint is incorporated into the cose function as a penalty term with a penalty coefficient (<code>lagrange_multiplier</code> parameter).</p> <p>After all of these transformation, we can finally use a quantum annealer to run the problem defined in the <code>qubo</code> object!</p> In\u00a0[23]: Copied! <pre># Run the quantum annealer\nsampler = EmbeddingComposite(DWaveSampler())\nresult = sampler.sample(qubo, num_reads = 10)\nprint(\"The solutions that we have obtained are\")\nprint(result)\n</pre> # Run the quantum annealer sampler = EmbeddingComposite(DWaveSampler()) result = sampler.sample(qubo, num_reads = 10) print(\"The solutions that we have obtained are\") print(result)  <pre>The solutions that we have obtained are\n  slack_v8466ba63c65c435890f38d4ac99e843e_0 ... y1 energy num_oc. chain_.\n0                                         0 ...  1   -3.0       5     0.0\n1                                         1 ...  0   -2.0       1     0.0\n2                                         0 ...  0   -2.0       2     0.0\n3                                         0 ...  1    0.0       1     0.0\n4                                         1 ...  0    0.0       1     0.0\n['BINARY', 5 rows, 10 samples, 4 variables]\n</pre> <p>To make the result more informative. I mean we don't really care about the slack variables that we used to transform our problem. Therefore, we can use <code>invert</code> object to retrieve the solution to the original problem.</p> In\u00a0[27]: Copied! <pre># Use invert object to retrieve the original solution from `result`\nsamples = []\noccurrences =[]\nfor s in result.data():\n    samples.append(invert(s.sample))\n    occurrences.append(s.num_occurrences)\nsampleset = dimod.SampleSet.from_samples_cqm(samples, cqm, num_occurrences = occurrences)\n\nprint(\"The solutions to the original problem are\")\nprint(sampleset)\n</pre> # Use invert object to retrieve the original solution from `result` samples = [] occurrences =[] for s in result.data():     samples.append(invert(s.sample))     occurrences.append(s.num_occurrences) sampleset = dimod.SampleSet.from_samples_cqm(samples, cqm, num_occurrences = occurrences)  print(\"The solutions to the original problem are\") print(sampleset) <pre>The solutions to the original problem are\n  y0 y1 energy num_oc. is_sat. is_fea.\n3  1  1   -5.0       1 arra... np.F...\n0  0  1   -3.0       5 arra... np.T...\n1  1  0   -2.0       1 arra... np.T...\n2  1  0   -2.0       2 arra... np.T...\n4  0  0    0.0       1 arra... np.T...\n['INTEGER', 5 rows, 10 samples, 2 variables]\n</pre> <p>Here, we created <code>SampleSet</code> object from the samples obtained with the trainsformed probelm. we also elimiate slack variables by using the <code>invert</code> method. Finally, we pass the <code>cqm</code> problem to the <code>from_samples_cqm</code> method, the energy without the penalties computed, as well as the feasibility status of each assignment.</p> <p>Againm lets use <code>filter</code> to get the feasible results.</p> In\u00a0[28]: Copied! <pre>final_sols = sampleset.filter(lambda s: s.is_feasible)\nfinal_sols = final_sols.aggregate()\nprint(\"The final solutions are\")\nprint(final_sols)\n</pre> final_sols = sampleset.filter(lambda s: s.is_feasible) final_sols = final_sols.aggregate() print(\"The final solutions are\") print(final_sols) <pre>The final solutions are\n  y0 y1 energy num_oc. is_sat. is_fea.\n0  0  1   -3.0       5 arra... np.T...\n1  1  0   -2.0       3 arra... np.T...\n2  0  0    0.0       1 arra... np.T...\n['INTEGER', 3 rows, 9 samples, 2 variables]\n</pre> <p>In this section, we will learn how to have more control over what the quantum annealer is doing in order to fine the ground state of our Hamiltonians. Also, we will discuss the different types of annealers that we can access via D-Wave Leap. And also, what does <code>EmbeddingComposite</code> do.</p> In\u00a0[\u00a0]: Copied! <pre># A list of solver we can access via D-Wave\nfrom dwave.cloud import Client\nfor solver in Client.from_config().get_solvers():\n    print(solver)\n</pre> # A list of solver we can access via D-Wave from dwave.cloud import Client for solver in Client.from_config().get_solvers():     print(solver) <pre>BQMSolver(id='hybrid_binary_quadratic_model_version2')\nDQMSolver(id='hybrid_discrete_quadratic_model_version1')\nStructuredSolver(id='Advantage_system4.1')\nCQMSolver(id='hybrid_constrained_quadratic_model_version1')\nNLSolver(id='hybrid_nonlinear_program_version1')\nStructuredSolver(id='Advantage2_prototype2.6')\nStructuredSolver(id='Advantage_system6.4')\n</pre> <p>Let's grab one of the solver and see some of the basic sampler properties.</p> In\u00a0[48]: Copied! <pre>from dwave.system import DWaveSampler\nsampler = DWaveSampler(solver = 'Advantage_system4.1')\nprint(\"Name:\", sampler.properties[\"chip_id\"])\nprint(\"Number of qubits:\", sampler.properties[\"num_qubits\"])\nprint(\"Category:\", sampler.properties[\"category\"])\nprint(\"Support problems:\", sampler.properties[\"supported_problem_types\"])\nprint(\"Topology:\", sampler.properties[\"topology\"])\nprint(\"Range of reads:\", sampler.properties[\"num_reads_range\"])\n</pre> from dwave.system import DWaveSampler sampler = DWaveSampler(solver = 'Advantage_system4.1') print(\"Name:\", sampler.properties[\"chip_id\"]) print(\"Number of qubits:\", sampler.properties[\"num_qubits\"]) print(\"Category:\", sampler.properties[\"category\"]) print(\"Support problems:\", sampler.properties[\"supported_problem_types\"]) print(\"Topology:\", sampler.properties[\"topology\"]) print(\"Range of reads:\", sampler.properties[\"num_reads_range\"])  <pre>Name: Advantage_system4.1\nNumber of qubits: 5760\nCategory: qpu\nSupport problems: ['ising', 'qubo']\nTopology: {'type': 'pegasus', 'shape': [16]}\nRange of reads: [1, 10000]\n</pre> <p>It's worth to notice that all of them accept problems in the QUBO or Ising formats but not constrained problems and that's why we need to transform them befoe running them in the previous section. The toloplogy refers to the way in which the qubits are connected to each other in the machine, and determines which couplings - or connections bewteen variables - can be used to define our problem.</p> <p>In current quantum computers, technological difficulties prevent qubits from being connected in an all-to-all way. In fact, each qubit is usually connected exclusively to some of its neighbours and we can only apply two-qubit gates or use couplings (that is, use non-zero coefficients in the Ising model) between those qubits that are actually linked.</p> <p>That is, the particular way in which the qubits are connected in a certain quantum chip is called its topology nad sometimes it is important to be aware of it when we design our algorithm or when we anneal our problems. You can find more on Ocean websute $\\rightarrow$ QPU Topology.</p> <p>Here are the high level overview for the topology used in D-Wave systems:</p> <ol> <li>Chimera topology for D-Wave 2000Q systems.</li> </ol> <ul> <li>In the topology Chimera, it has 6 qubits organized into two groups of 4 qubits each in column configuration. All the qubits in one group are connected to all the qubits in the other group, but there are no connections inside each group.</li> </ul> <ol> <li>Pegasus topology for Advantage systems.</li> </ol> <ul> <li>Every qubits connected to up to 15 qubits, compared to the maximum of 6 in Chimera.</li> <li>This topology also contains group of 4 qubits that are all connected to each other, making it mush easier to embed problems into it.</li> </ul> <ol> <li>Zephyr topology for next-generation quantum computers currently under development.</li> </ol> <p>To obtain a list enumerating all the connections by using the <code>properties[\"couplers\"]</code> attribute as follows:</p> In\u00a0[1]: Copied! <pre># Using the properties[\"couplers\"]\nsampler = DWaveSampler(solver = 'Advantage_system4.1')\n#print(\"Couplings:\", sampler.properties[\"couplers\"])\n</pre> # Using the properties[\"couplers\"] sampler = DWaveSampler(solver = 'Advantage_system4.1') #print(\"Couplings:\", sampler.properties[\"couplers\"]) <pre>\n---------------------------------------------------------------------------\nNameError                                 Traceback (most recent call last)\nCell In[1], line 2\n      1 # Using the properties[\"couplers\"]\n----&gt; 2 sampler = DWaveSampler(solver = 'Advantage_system4.1')\n      3 #print(\"Couplings:\", sampler.properties[\"couplers\"])\n\nNameError: name 'DWaveSampler' is not defined</pre> <p>One more important thing to note about the Chimera topology is that it does not contain triangles. There are no three vertices all connected to each other. Thus if our Ising Hamiltonian is somethin like $Z_{0}Z_{1}+Z_{0}Z_{2}+Z_{1}Z_{2}$, we cannot directly map it to qubits in the Chimera annealer. Therefore, we need to introduce <code>embedding</code> in to our solver.</p> <p>An <code>embedding</code> is a way of mapping the qubits in our problem Hamiltonian to the phsical qubits in the annealer. We can use several physical qubits (what we call a chain) to represent a single qubit from our problem. In that case, we want all the qubits in the same chain to have the same value when we measure them.</p> <p>For instance, if qubits 12 and 20 are part of the same chain, the coefficient for (12,20) could be, for instance, -15. Then, the term -15$Z_{12}Z_{20}$ will be part of the spin Hamiltonian that we want to minimize and it will make it very likely for $Z_{12}$ and $Z_{20}$ to be equal to each other, because that will make the total energy significantly slower.</p> <p>You may think it's complicated to ensure every embedding is correct and each every physical qubits are used to ensure they repsent our problem properly and correctly. However, Ocean can compute embeddings automatically for us.</p> In\u00a0[51]: Copied! <pre># Define problem \nJ = {(0,1):1, (0,2):1, (1,2):1 }\nh = {}\ntriangle = dimod.BinaryQuadraticModel(h, J, 0.0, dimod.SPIN)\n\n# Embed it and solve it on the \nsampler = EmbeddingComposite(DWaveSampler(solver = 'Advantage_system4.1'))\nresult = sampler.sample(triangle, num_reads= 10, return_embedding=True)\n\nprint(\"The sampels obtained are:\")\nprint(result)\nprint(\"The embedding used was:\")\nprint(result.info[\"embedding_context\"])\n                                        \n</pre> # Define problem  J = {(0,1):1, (0,2):1, (1,2):1 } h = {} triangle = dimod.BinaryQuadraticModel(h, J, 0.0, dimod.SPIN)  # Embed it and solve it on the  sampler = EmbeddingComposite(DWaveSampler(solver = 'Advantage_system4.1')) result = sampler.sample(triangle, num_reads= 10, return_embedding=True)  print(\"The sampels obtained are:\") print(result) print(\"The embedding used was:\") print(result.info[\"embedding_context\"])                                          <pre>The sampels obtained are:\n   0  1  2 energy num_oc. chain_.\n0 +1 +1 -1   -1.0       1     0.0\n1 +1 -1 -1   -1.0       3     0.0\n2 -1 +1 -1   -1.0       2     0.0\n3 -1 +1 +1   -1.0       1     0.0\n4 +1 -1 +1   -1.0       3     0.0\n['SPIN', 5 rows, 10 samples, 3 variables]\nThe embedding used was:\n{'embedding': {1: (5519,), 0: (2684,), 2: (5504,)}, 'chain_break_method': 'majority_vote', 'embedding_parameters': {}, 'chain_strength': 1.9996979771955565}\n</pre> <p>As you can see, <code>EmbeddingComposite</code> performs the embdeeing in a way that is completely transparent for the user and, in fact, the samples returned only refer to the variables in the original pronlem. However, variable <code>0</code> has been mapped to qubit 2684, variable <code>2</code> has been mapped to 5504, and <code>1</code> is represented by 5519.</p> <p>In addition to <code>EmbeddingComposite</code>, there are other classes in Ocean that allow you to find embeddings for your problems.</p> <ol> <li>For instance <code>AutoEmbeddingComposite</code> first tries to run the problem on the annealer directly without using embedding, and use it only if it is needed, which can save some computation time.</li> <li>The <code>FixEmbeddingComposite</code> class doesn't compute an embedding, but uses whichever one is passed as a parameter.</li> <li>The <code>LazyEmbeddingComposite</code> only computes the embedding for a problem on the first call to the <code>sample</code> method, storing it for future calls;<code>EmbeddingComposite</code>, on the other hand, recomputes the embedding with each call <code>sample</code>.</li> </ol> In\u00a0[54]: Copied! <pre># Define problem\nsampler = DWaveSampler(solver  = \"Advantage_system4.1\")\n\n# Show default and possible annealing time\nprint(\"The default annealing time is\", sampler.properties[\"default_annealing_time\"], \"microseconds\")\nprint(\"The possible values for the annealing time (in microseconds) lie in the range\", sampler.properties[\"annealing_time_range\"])\n</pre> # Define problem sampler = DWaveSampler(solver  = \"Advantage_system4.1\")  # Show default and possible annealing time print(\"The default annealing time is\", sampler.properties[\"default_annealing_time\"], \"microseconds\") print(\"The possible values for the annealing time (in microseconds) lie in the range\", sampler.properties[\"annealing_time_range\"]) <pre>The default annealing time is 20.0 microseconds\nThe possible values for the annealing time (in microseconds) lie in the range [0.5, 2000.0]\n</pre> <p>You should see the follwoing result</p> <p><code>The default annealing time is 20.0 microseconds The possible values for the annealing time (in microseconds) lie in the range [0.5, 2000.0]</code></p> <p>We can jsut modify the annealing in <code>sample</code> function.</p> In\u00a0[55]: Copied! <pre>J = {(0,1):1, (0,2):1, (1,2):1}\nh = {}\ntriangle = dimod.BinaryQuadraticModel(h,J,0.0, dimod.SPIN)\nsampler = EmbeddingComposite(DWaveSampler(solver = \"Advantage_system4.1\"))\nresult = sampler.sample(triangle, num_reads = 10, annealing_time = 100)\nprint(\"The samples obtained are\", result)\n</pre> J = {(0,1):1, (0,2):1, (1,2):1} h = {} triangle = dimod.BinaryQuadraticModel(h,J,0.0, dimod.SPIN) sampler = EmbeddingComposite(DWaveSampler(solver = \"Advantage_system4.1\")) result = sampler.sample(triangle, num_reads = 10, annealing_time = 100) print(\"The samples obtained are\", result) <pre>The samples obtained are    0  1  2 energy num_oc. chain_.\n0 +1 -1 -1   -1.0       3     0.0\n1 -1 -1 +1   -1.0       3     0.0\n2 +1 -1 +1   -1.0       2     0.0\n3 +1 +1 -1   -1.0       2     0.0\n['SPIN', 4 rows, 10 samples, 3 variables]\n</pre> <p>To obtain better and better solutions, you may be tempted to increase the annealing time to its maximum possible value. However, the longer you run the annealing process, the higher possibility that external interactions will affect the system state and ruin your computation: you might get worse resuls instead of better one. On the other handm by increasing the annealing time, you will obvisously spend more time!</p> <p>Not only you can adjust the annealing time, but you can also adjust the annealing sequence. Let's refer the follwoing equation:</p> <p>$$ H(t) = -A(t)\\sum_{j=0}^{n-1} X_{j} - B(t)\\sum_{j,k}Z_{j}Z_{k} - B(t)\\sum_{j}h_{j}Z_{j}, $$</p> <p>which defines the Hamiltonian that we use in the annealing process.</p> <p>Also, you know that we only required $A$ and $B$ to satisfy that $A(0) = B(T) = 1$ and $A(t) = B(0) = 0$, where T is the total annealing time, but we did not restrict in any way how $A$ and $B$ should behave except fo these boundary conditions.</p> <p>While D-Wave has its own annealing schedule (annealing section), we can still modify those default schdeules by assigning the values that we want the funcitons to take at some intermediate times.</p> <p>Let's see what can we change:</p> <ol> <li>Anneal fraction (s):</li> </ol> <ul> <li>The first number of each pair needs to be a time value given in microseconds and the second number has to be a number between $0$ and $1$.</li> <li>The higher the value of $s$ is, the higher the value of $B$ and the lower the value of $A$ will be. As a consequence, when $s=1$, we can interpret that $B$ is $1$ and $A$ is $0$; when $s=0$, we can interpret that $A$ is $1$ and $B$ is $0$.</li> </ul> <ol> <li>Forward Annealing:</li> </ol> <ul> <li>Starts at $(0,0)$ and ends at $(T,1)$, where $T$ is the total annealing time.</li> <li>$s$ values increase monotonically overtime.</li> <li>Represents the standard annealing process.</li> <li>Example: <code>forward_schedule = [[0.0, 1.0], [5.0, 0.25], [25, 0.75], [30, 1.0]]</code>.<ul> <li><code>forward_schedule = [[0.0, 1.0], [5.0, 0.25], [25, 0.75], [30, 1.0]]</code></li> <li><code>sampler = EmbeddingComposite(DWaveSampler())</code></li> <li><code>result = sampler.sample(triangle, num_reads = 10, anneal_schedule = forward_schedule)</code></li> </ul> </li> </ul> <ol> <li>Reverse Annealing:</li> </ol> <ul> <li>Starts with $s=1$, decreases, and then increases back to $s=1$.</li> <li>Requires an initial state since the ground state of the Hamiltonian is unknown.</li> <li>Commonly sued to refine approximate solutions to find lower-energy configuration, which means we already found solution and are trying to find a better one.</li> <li>For example, <code>reverse_schedule = [[0.0, 1.0], [10.0, 0.5], [20, 1.0]]</code>.</li> <li>Two approaches:<ul> <li>Reinitialize State: Repeats the annealing process on the same initial state by setting: <code>reinitialize_state = True</code>.</li> <li>Final State Progression: Uses the final state of one run as the initial state for the next by setting <code>reinitialize_state = True</code>.</li> </ul> </li> </ul> <p>Controlling the annealing schedule can be useful for certain problems, for instance, you know that at some points the groud state and the first excited state are closer, you may slow down the annealing process.</p> In\u00a0[56]: Copied! <pre># Reverse schedule\nreverse_schedule = [[0.0, 1.0], [10.0, 0.5], [20, 1.0]]\ninitial_state = {0:1, 1:1, 2:1}\nsample = EmbeddingComposite(DWaveSampler())\nresult = sampler.sample(triangle, num_reads = 10,\n                        anneal_schedule = reverse_schedule,\n                        reinitialize_state = False, initial_state = initial_state)\nprint(\"The samples obtained are\")\nprint(result)\n</pre> # Reverse schedule reverse_schedule = [[0.0, 1.0], [10.0, 0.5], [20, 1.0]] initial_state = {0:1, 1:1, 2:1} sample = EmbeddingComposite(DWaveSampler()) result = sampler.sample(triangle, num_reads = 10,                         anneal_schedule = reverse_schedule,                         reinitialize_state = False, initial_state = initial_state) print(\"The samples obtained are\") print(result) <pre>The samples obtained are\n   0  1  2 energy num_oc. chain_.\n0 -1 +1 +1   -1.0       1     0.0\n1 -1 +1 +1   -1.0       1     0.0\n2 -1 -1 +1   -1.0       1     0.0\n3 -1 +1 -1   -1.0       1     0.0\n4 -1 +1 +1   -1.0       1     0.0\n5 -1 -1 +1   -1.0       1     0.0\n6 -1 +1 -1   -1.0       1     0.0\n7 -1 -1 +1   -1.0       1     0.0\n8 +1 -1 -1   -1.0       1     0.0\n9 +1 -1 +1   -1.0       1     0.0\n['SPIN', 10 rows, 10 samples, 3 variables]\n</pre> <p>Congrats! you know how to control both the annealing time and the schedule! Let's look into why it's important to set the coupling strengths and the penalty terms wisely!</p> <p>You know that there are a couple of situations wherer we have to select values for some arbitrary constants that are used to set coupling strengths in the annealer:</p> <ol> <li><p>Penalty Terms in Objective Functions: Constants are used as penalty terms in the objective function, like the <code>lagrange_multiploer</code> parameter in the <code>cqm_to_bqm</code> method of the <code>dimod package.</code></p> </li> <li><p>Coupling Strengths in Embedding: Selevting coupling strengths for chains in a quantum embedding, often handled automatically by classes like <code>EmbeddindComposite</code>.</p> </li> </ol> <p>You also know that we want these parameters as big as possible since all of us are not interested in solutions that do not satisfy the problem constraints and you don't want your chains to be broken.</p> <p>Before select a good number, we need to know that D-Wave does not allow us to selet arbitrarily large numbers. In fact, the <code>h_range</code> will be [-4.0, 4.0] as you can verify it by running the following code:</p> In\u00a0[57]: Copied! <pre>sampler = DWaveSampler(\"Advantage_system4.1\")\nprint(\"The coupling strength range is\", sampler.properties[\"h_range\"])\n</pre> sampler = DWaveSampler(\"Advantage_system4.1\") print(\"The coupling strength range is\", sampler.properties[\"h_range\"]) <pre>The coupling strength range is [-4.0, 4.0]\n</pre> <p>This means that if you set coupling strengths (that is, $J$ coefficicent) that in absolute value are bigger than $4$, the largest one will be scaled down to $4$, and the rest of the coefficients in your model will be scaled down accordingly. This can cause some of the values to be very close together, even closer than the resolution of the device, affecting the results of the annealing process, as we can see in the follwoing example:</p> In\u00a0[59]: Copied! <pre># Choose a sampler\nsampler = EmbeddingComposite(DWaveSampler(\"Advantage_system4.1\"))\n\n# Define the problem\nx0 = dimod.Binary(\"x0\")\nx1 = dimod.Binary(\"x1\")\nx2 = dimod.Binary(\"x2\")\nblp = dimod.ConstrainedQuadraticModel()\nblp.set_objective(-5*x0 + 3*x1 - 2*x2)\nblp.add_constraint(x0 + x2 &lt;= 1, \"First constraint\")\nblp.add_constraint(3*x0 - x1 + 3*x2 &lt;= 4, \"Second constraint\")\n\n# Convert the problem and run it\nqubo, invert = dimod.cqm_to_bqm(blp, lagrange_multiplier=10)\nresult = sampler.sample(qubo, num_reads = 100)\n\n# Aggregate and show the results\nsamples = []\noccurrences = []\nfor s in result.data():\n    samples.append(invert(s.sample))\n    occurrences.append(s.num_occurrences)\nsampleset = dimod.SampleSet.from_samples_cqm(samples, blp, num_occurrences = occurrences)\nprint(\"The solutions to the original problem are\")\nprint(sampleset.filter(lambda s: s.is_feasible).aggregate())\n</pre> # Choose a sampler sampler = EmbeddingComposite(DWaveSampler(\"Advantage_system4.1\"))  # Define the problem x0 = dimod.Binary(\"x0\") x1 = dimod.Binary(\"x1\") x2 = dimod.Binary(\"x2\") blp = dimod.ConstrainedQuadraticModel() blp.set_objective(-5*x0 + 3*x1 - 2*x2) blp.add_constraint(x0 + x2 &lt;= 1, \"First constraint\") blp.add_constraint(3*x0 - x1 + 3*x2 &lt;= 4, \"Second constraint\")  # Convert the problem and run it qubo, invert = dimod.cqm_to_bqm(blp, lagrange_multiplier=10) result = sampler.sample(qubo, num_reads = 100)  # Aggregate and show the results samples = [] occurrences = [] for s in result.data():     samples.append(invert(s.sample))     occurrences.append(s.num_occurrences) sampleset = dimod.SampleSet.from_samples_cqm(samples, blp, num_occurrences = occurrences) print(\"The solutions to the original problem are\") print(sampleset.filter(lambda s: s.is_feasible).aggregate())  <pre>The solutions to the original problem are\n  x0 x1 x2 energy num_oc. is_sat. is_fea.\n0  1  0  0   -5.0      16 arra... np.T...\n1  1  1  0   -2.0      26 arra... np.T...\n2  0  0  1   -2.0      17 arra... np.T...\n3  0  0  0    0.0      11 arra... np.T...\n4  0  1  1    1.0      20 arra... np.T...\n5  0  1  0    3.0       6 arra... np.T...\n['INTEGER', 6 rows, 96 samples, 3 variables]\n</pre> <p>The result may very but we can tell that the result is not very obvious since the <code>Lagrange_multiplier</code> parameter is too big compared to the range of energies of the objective function. In fact, if you use <code>Exactsolver</code> on the transformed problem, you can easily check that all the assignment that are unfeasible on the the original problem get energy $16$ or higher on the transformed one, while the feasible solutions always get energy $3$ or lower. THAT IS A HUGE GAP!</p> <p>Let's try set <code>Lagrange_multiplier</code> to $4$ and rerun the problem!</p> In\u00a0[\u00a0]: Copied! <pre>## Case: lagrange_multiplier = 4\n\n# Convert the problem and run it\nqubo, invert = dimod.cqm_to_bqm(blp, lagrange_multiplier=4)\nresult = sampler.sample(qubo, num_reads = 100)\n\n# Aggregate and show the results\nsamples = []\noccurrences = []\nfor s in result.data():\n    samples.append(invert(s.sample))\n    occurrences.append(s.num_occurrences)\nsampleset = dimod.SampleSet.from_samples_cqm(samples, blp, num_occurrences = occurrences)\nprint(\"The solutions to the original problem are\")\nprint(sampleset.filter(lambda s: s.is_feasible).aggregate())\n</pre> ## Case: lagrange_multiplier = 4  # Convert the problem and run it qubo, invert = dimod.cqm_to_bqm(blp, lagrange_multiplier=4) result = sampler.sample(qubo, num_reads = 100)  # Aggregate and show the results samples = [] occurrences = [] for s in result.data():     samples.append(invert(s.sample))     occurrences.append(s.num_occurrences) sampleset = dimod.SampleSet.from_samples_cqm(samples, blp, num_occurrences = occurrences) print(\"The solutions to the original problem are\") print(sampleset.filter(lambda s: s.is_feasible).aggregate()) <pre>The solutions to the original problem are\n  x0 x1 x2 energy num_oc. is_sat. is_fea.\n0  1  0  0   -5.0      42 arra... np.T...\n1  1  1  0   -2.0      21 arra... np.T...\n2  0  0  1   -2.0      13 arra... np.T...\n3  0  0  0    0.0       8 arra... np.T...\n4  0  1  1    1.0      10 arra... np.T...\n5  0  1  0    3.0       5 arra... np.T...\n['INTEGER', 6 rows, 99 samples, 3 variables]\n</pre> <p>You can see that the lowest energy state of value $-5.0$ has the most number. By setting the <code>lagrange_multiplier = 4</code>, all the infeasible solutions will, therefore, have a relative low energy state. by checking with the <code>Exactsolver</code>, the energy gap is much smaller now and we got 99 feasible solution over 99 samples.</p> <p>How about we change the <code>lagrange_multiplier = 1</code>?</p> In\u00a0[65]: Copied! <pre>## Case: lagrange_multiplier = 1\n\n# Convert the problem and run it\nqubo, invert = dimod.cqm_to_bqm(blp, lagrange_multiplier=1)\nresult = sampler.sample(qubo, num_reads = 100)\n\n# Aggregate and show the results\nsamples = []\noccurrences = []\nfor s in result.data():\n    samples.append(invert(s.sample))\n    occurrences.append(s.num_occurrences)\nsampleset = dimod.SampleSet.from_samples_cqm(samples, blp, num_occurrences = occurrences)\nprint(\"The solutions to the original problem are\")\nprint(sampleset.filter(lambda s: s.is_feasible).aggregate())\n</pre> ## Case: lagrange_multiplier = 1  # Convert the problem and run it qubo, invert = dimod.cqm_to_bqm(blp, lagrange_multiplier=1) result = sampler.sample(qubo, num_reads = 100)  # Aggregate and show the results samples = [] occurrences = [] for s in result.data():     samples.append(invert(s.sample))     occurrences.append(s.num_occurrences) sampleset = dimod.SampleSet.from_samples_cqm(samples, blp, num_occurrences = occurrences) print(\"The solutions to the original problem are\") print(sampleset.filter(lambda s: s.is_feasible).aggregate()) <pre>The solutions to the original problem are\n  x0 x1 x2 energy num_oc. is_sat. is_fea.\n0  1  0  0   -5.0      79 arra... np.T...\n1  1  1  0   -2.0       9 arra... np.T...\n2  0  0  1   -2.0       8 arra... np.T...\n3  0  0  0    0.0       1 arra... np.T...\n['INTEGER', 4 rows, 97 samples, 3 variables]\n</pre> <p>The frequency of the optimal result has dramatically improved! However, we \"lost\" 3 samples because they corresponded ot unfeasible solutions.</p> <p>Setting a gooe penalty constant can be difficult since it involves having some information about the energy distribution of the solutions to the problem. The example here just showed that you should not just use any value for <code>lagrange_multiplier</code>, since it can mess up your result.</p> <p>Note: Something similar may happen when the value of the coupling strength for chains in an embedding is too big. Fortunately, <code>EmbeddingComposite</code> and its relatives takes this into account and will try to keep the value as low as possible without breaking many chains. Don't take the choice of the coupling strenglth lightly.</p> <p>Before that, please run <code>pip install dwave-greedy</code> to install tabu package.</p> In\u00a0[77]: Copied! <pre>! pip install dwave-greedy\n</pre> ! pip install dwave-greedy <pre>Requirement already satisfied: dwave-greedy in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (0.3.0)\nRequirement already satisfied: dwave-samplers&gt;=1.0.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-greedy) (1.4.0)\nRequirement already satisfied: numpy&lt;3.0.0,&gt;=1.19.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&gt;=1.0.0-&gt;dwave-greedy) (2.0.2)\nRequirement already satisfied: dimod&lt;0.13.0,&gt;=0.12.13 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&gt;=1.0.0-&gt;dwave-greedy) (0.12.18)\nRequirement already satisfied: networkx&gt;=3.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&gt;=1.0.0-&gt;dwave-greedy) (3.4.2)\n</pre> In\u00a0[71]: Copied! <pre>import greedy\nimport dimod\n\n# Create a BinaryQuadraticModel\nJ = {(0,1):1, (1,2):1, (2,3):1, (3,0):1}\nh = {}\nproblem = dimod.BinaryQuadraticModel(h, J, 0.0, dimod.SPIN)\n\n# Using SteepestDescentSolver\nsolver = greedy.SteepestDescentSolver()\nsolution = solver.sample(problem, num_reads = 10)\nprint(solution.aggregate())\n</pre> import greedy import dimod  # Create a BinaryQuadraticModel J = {(0,1):1, (1,2):1, (2,3):1, (3,0):1} h = {} problem = dimod.BinaryQuadraticModel(h, J, 0.0, dimod.SPIN)  # Using SteepestDescentSolver solver = greedy.SteepestDescentSolver() solution = solver.sample(problem, num_reads = 10) print(solution.aggregate()) <pre>   0  1  2  3 energy num_oc. num_st.\n0 -1 +1 -1 +1   -4.0       5       1\n1 +1 -1 +1 -1   -4.0       2       1\n2 +1 +1 -1 -1    0.0       3       0\n['SPIN', 3 rows, 10 samples, 4 variables]\n</pre> <p>As you can see, this is exactly the format we already know from using quantum solvers.</p> <p>Next, we will talk about the <code>TabuSolver</code>.</p> <p>Before that, please run <code>pip install dwave-tabu</code> to install tabu package.</p> In\u00a0[74]: Copied! <pre>! pip install dwave-tabu\n</pre> ! pip install dwave-tabu <pre>Requirement already satisfied: dwave-tabu in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (0.5.0)\nRequirement already satisfied: dwave-samplers&gt;=1.0.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-tabu) (1.4.0)\nRequirement already satisfied: numpy&lt;3.0.0,&gt;=1.19.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&gt;=1.0.0-&gt;dwave-tabu) (2.0.2)\nRequirement already satisfied: dimod&lt;0.13.0,&gt;=0.12.13 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&gt;=1.0.0-&gt;dwave-tabu) (0.12.18)\nRequirement already satisfied: networkx&gt;=3.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&gt;=1.0.0-&gt;dwave-tabu) (3.4.2)\n</pre> In\u00a0[76]: Copied! <pre>import tabu\n\n# Build a sample\nsolver = tabu.TabuSampler()\nsolution = solver.sample(problem, num_reads = 10)\nprint(solution.aggregate())\n</pre> import tabu  # Build a sample solver = tabu.TabuSampler() solution = solver.sample(problem, num_reads = 10) print(solution.aggregate())  <pre>   0  1  2  3 energy num_oc. num_re.\n0 +1 -1 +1 -1   -4.0       7       1\n1 -1 +1 -1 +1   -4.0       3       0\n['SPIN', 2 rows, 10 samples, 4 variables]\n</pre> <p>SimulatedAnnealingSampler accepts using of <code>initial_states</code> and <code>seed</code> commands.</p> In\u00a0[78]: Copied! <pre>! pip install dwave-neal\n</pre> ! pip install dwave-neal <pre>Collecting dwave-neal\n  Downloading dwave_neal-0.6.0-py3-none-any.whl.metadata (3.0 kB)\nRequirement already satisfied: dwave-samplers&lt;2.0.0,&gt;=1.0.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-neal) (1.4.0)\nRequirement already satisfied: numpy&lt;3.0.0,&gt;=1.19.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&lt;2.0.0,&gt;=1.0.0-&gt;dwave-neal) (2.0.2)\nRequirement already satisfied: dimod&lt;0.13.0,&gt;=0.12.13 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&lt;2.0.0,&gt;=1.0.0-&gt;dwave-neal) (0.12.18)\nRequirement already satisfied: networkx&gt;=3.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from dwave-samplers&lt;2.0.0,&gt;=1.0.0-&gt;dwave-neal) (3.4.2)\nDownloading dwave_neal-0.6.0-py3-none-any.whl (8.7 kB)\nInstalling collected packages: dwave-neal\nSuccessfully installed dwave-neal-0.6.0\n</pre> In\u00a0[80]: Copied! <pre>import neal\n\nsolver = neal.SimulatedAnnealingSampler()\nsolution = solver.sample(problem, num_reads = 10)\nprint(solution.aggregate())\n</pre> import neal  solver = neal.SimulatedAnnealingSampler() solution = solver.sample(problem, num_reads = 10) print(solution.aggregate())  <pre>   0  1  2  3 energy num_oc.\n3 +1 -1 +1 -1   -4.0       2\n0 +1 +1 +1 -1    0.0       2\n1 -1 -1 +1 +1    0.0       3\n2 +1 +1 -1 -1    0.0       2\n4 -1 -1 -1 +1    0.0       1\n['SPIN', 5 rows, 10 samples, 4 variables]\n</pre> In\u00a0[81]: Copied! <pre>import dwave.system\n\nsampler = dwave.system.LeapHybridSampler()\nsolution = solver.sample(problem, num_reads= 10)\nprint(solution.aggregate())\n</pre> import dwave.system  sampler = dwave.system.LeapHybridSampler() solution = solver.sample(problem, num_reads= 10) print(solution.aggregate()) <pre>   0  1  2  3 energy num_oc.\n0 +1 -1 +1 -1   -4.0       5\n3 -1 +1 -1 +1   -4.0       1\n1 +1 +1 +1 -1    0.0       1\n2 -1 -1 +1 +1    0.0       1\n4 +1 +1 -1 -1    0.0       1\n5 +1 -1 -1 -1    0.0       1\n['SPIN', 6 rows, 10 samples, 4 variables]\n</pre> <p>It's also worth to notice that these hybrid samplers has a property called <code>qouta_conversion_rate</code>. This can be check by running <code>sampler.properties[\"quota_conversion_rate\"]</code>. The <code>qouta_conversion_rate</code> for the <code>LeapHybridSampler</code> is 20. This means that for each 20 microseconds that you use this hybrid sampler, you will get charge of 1 microsecond of quantum processor access.</p> <p>The other hybrid solver Dwave provides is <code>LeapHybridCQMsampler</code>, which is used similarly to <code>LeapHybridSampler</code>, but with constrained problems. Finally, there is also <code>LeapHybridDQMSampler</code>, which works with discrete quadratic problems defined as objects of the <code>DiscreteQuadraticModel</code> class.</p> In\u00a0[82]: Copied! <pre>sampler.properties[\"quota_conversion_rate\"]\n</pre> sampler.properties[\"quota_conversion_rate\"] Out[82]: <pre>20</pre>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#working-aqqa-with-d-wave","title":"Working AQQA with D-wave\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#build-a-maxcut-model-with-dimod","title":"Build a MaxCut model with dimod\u00b6","text":"<p>First, we use the function <code>BinaryQuadraticModel(linear, quadratic, offset, vartype)</code> in <code>dimod</code> object.</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#run-the-annealing-process-on-one-of-the-quantum-annealers","title":"Run the annealing process on one of the quantum annealers:\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#modeling","title":"Modeling\u00b6","text":"<p>Let's break down what are going to do:</p> <ol> <li>We use <code>EmbeddingComposite()</code>, which allow us to map or embed our problem into the actual qubits of the annealer. (An automatically way of selecting a few qubits in the computer that will be used to represent our variables.)</li> <li>After mapping, we will create an object <code>sampler</code> that we then use to obtain 10 samples or possible solutions to our problem This is where the actual execution on the actual quantum annealer happens.</li> <li>Print our result, which will vary from execution to execution, since we are using an actual quantum computer!</li> </ol>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#results","title":"Results\u00b6","text":"<p>You should get the result similar to this form.</p> <p><code>The solutions that we have obtained are    0  1  2 energy num_oc. chain_. 0 -1 +1 +1   -2.0       1     0.0 1 +1 -1 -1   -2.0       9     0.0 ['SPIN', 2 rows, 10 samples, 3 variables]</code></p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#additional-info","title":"Additional info\u00b6","text":"<p>In addition, we can access the best solution through <code>result.first</code> and the total time what we used the quantum annealer for, with <code>result.info['timing][qpu_access_time]</code>, which is the actual time you use for your monthly credit. The time is in microseconds.</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#build-a-qubo-problem","title":"Build a QUBO problem\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#using-ocean-to-formulate-and-transform-optimization-problems","title":"Using Ocean to formulate and transform optimization problems\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#solving-constructed-quadratic-models-with-dimod","title":"Solving constructed quadratic models with dimod\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#running-constrained-problems-on-quantum-annealers","title":"Running constrained problems on quantum annealers\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#solving-optimization-problems-on-quantum-annealer-with-leap","title":"Solving optimization problems on quantum annealer with Leap\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#the-leap-annealers","title":"The Leap annealers\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#embeddings-and-annealer-topologies","title":"Embeddings and annealer topologies\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#controlling-annealing-parameters","title":"Controlling annealing parameters\u00b6","text":"<p>You may remember that we have mentioned handle the adiabatic process, a system which remains in a state of minimal energy, slow enough. However, we also know that it's hard to achieve in practice os we jsut use the quantum annealing. In order to control the annealing process with D-Wave's quantum annealer, we need to do something to improve our results for our combinatorial optimization problems.</p> <ol> <li>Changing the duration of the annealing process.</li> </ol>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#the-importance-of-coupling-strengths","title":"The importance of coupling strengths\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#classical-and-hybrid-samplers","title":"Classical and hybrid samplers\u00b6","text":"<p>Besides the quantum annealing, D-Wave also provide other ways of solving optimization problem beyond \"pure\" quantum annealing. We will talk about Classiscal solvers and Hybrid solvers in this section.</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#classical-solvers","title":"Classical solvers\u00b6","text":"<p>In D-Wave, <code>SimulatedAnnealing</code> and <code>SteepestDescentSolver</code> are two solvers other than the <code>ExactSolver</code> that do not use quantum resources whatsoever. This seciont helps you not just know how to use classical solver to solve your problem but also provide so called hybrid solver to work with the power of quantum annealer!</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#steepestdescentsolver","title":"SteepestDescentSolver\u00b6","text":"<p>The first classical solver we are going to talk about is the <code>SteepestDescentSolver</code>. This is included in the <code>greedy</code> package and it is a discrete version of the gradient descent algorith, for continuous optimization. It selects one direction where the decrease in energy is bigger. Let's see how to use it in D-Wave by the following code:</p> <p>SteepestDescentSolver accepts using of <code>initial_states</code> and <code>seed</code> commands.</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#tabusolver","title":"TabuSolver\u00b6","text":"<p>Tabu solver is a type of local search algorithm, which means it improves its search by exploring neighbors. The tabu solver avoids falling into local minima by sometimes accepting solutions with higher energy than the current one, and it also \"remembers\" solutions it has already explored. Let's look into how to use <code>TabuSolver</code> in D-Wave.</p> <p>TabuSolver accepts using of <code>initial_states</code> and <code>seed</code> commands.</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#simulatedannealingsampler","title":"SimulatedAnnealingSampler\u00b6","text":"<p>The last calssical solver we are going to talk about is the <code>SimulatedAnnealingSampler</code>. As you may assume, this solver simulates annealing behavior. It's just another algorithm that explores the neighbourhood of the candidate solution that it is considering at a given moment. It tries to move to solutions with lower energy.</p> <p>Just like the <code>TabuSolver</code>, it sometime explore higher energy state to avoid stucking at the local minimum, which is accomplished by controlling the global \"temperature\" parameter that decreases with time, eventually to 0. In fact, the Hamiltonian $H_0$ in our quantum annealing process can be understood as analogous to the temperature in simulated annealing: it allows the solutions to move or \"tunnel\" to some neightboring ones and it decreases over time. The <code>SimulatedAnnealingSampler</code> can be used in D-Wave Ocean as:</p>"},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#hybrid-solvers","title":"Hybrid solvers\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/AQQA_D-WAVE/#leaphybridsampler","title":"LeapHybridSampler\u00b6","text":"<p>Let's start with the <code>LeapHybridSampler()</code>. This sampler accepts QUBO and Ising problems and can scale up to a high number of variables because it deivdes the problem, assigns different parts to classical solvers and quantum annealers, and then reconstructs a global solution from the local ones.</p>"},{"location":"QuantumOpt/jupyter_QOpt/GAS_Qiskit_molecule/","title":"Using GAS with Qiskit","text":"<p>Let's start with a QUBO problem we have covered in QAOA section.</p> <p>To solve this using GAS, we need to define a <code>GroverOptimizer</code> object as follows:</p> <ol> <li>GroverOptimizer: Qiskit doc.</li> </ol> In\u00a0[1]: Copied! <pre>from qiskit_optimization.algorithms import GroverOptimizer\nfrom qiskit_optimization.problems import QuadraticProgram\nfrom qiskit_algorithms.utils import algorithm_globals\nfrom qiskit_ibm_runtime import QiskitRuntimeService # Sampler from qiskit_ibm_runtime can flag error\nfrom qiskit_optimization.translators import from_docplex_mp\nfrom qiskit.primitives import Sampler\nfrom docplex.mp.model import Model\n</pre> from qiskit_optimization.algorithms import GroverOptimizer from qiskit_optimization.problems import QuadraticProgram from qiskit_algorithms.utils import algorithm_globals from qiskit_ibm_runtime import QiskitRuntimeService # Sampler from qiskit_ibm_runtime can flag error from qiskit_optimization.translators import from_docplex_mp from qiskit.primitives import Sampler from docplex.mp.model import Model In\u00a0[6]: Copied! <pre># Get the real machine\nservice = QiskitRuntimeService(instance=\"ibm-q/open/main\")\nbackend_name = service.least_busy(operational=True, simulator=False)\nprint(backend_name)\n#backend = service.backend(backend_name, instance=\"ibm-q/open/main\")\n</pre> # Get the real machine service = QiskitRuntimeService(instance=\"ibm-q/open/main\") backend_name = service.least_busy(operational=True, simulator=False) print(backend_name) #backend = service.backend(backend_name, instance=\"ibm-q/open/main\") <pre>&lt;IBMBackend('ibm_sherbrooke')&gt;\n</pre> In\u00a0[7]: Copied! <pre>qp = QuadraticProgram()\n</pre> qp = QuadraticProgram() In\u00a0[8]: Copied! <pre>model = Model()\nx0 = model.binary_var(name=\"x0\")\nx1 = model.binary_var(name=\"x1\")\nmodel.minimize( 2 * x0 + 2 * x1 - 3 * x0 * x1)\nqp = from_docplex_mp(model)\nprint(qp.prettyprint())\n</pre> model = Model() x0 = model.binary_var(name=\"x0\") x1 = model.binary_var(name=\"x1\") model.minimize( 2 * x0 + 2 * x1 - 3 * x0 * x1) qp = from_docplex_mp(model) print(qp.prettyprint()) <pre>Problem name: docplex_model1\n\nMinimize\n  -3*x0*x1 + 2*x0 + 2*x1\n\nSubject to\n  No constraints\n\n  Binary variables (2)\n    x0 x1\n\n</pre> In\u00a0[9]: Copied! <pre># grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler(mode = backend)) \n# This can flag 'The instruction h on qubits (0,) is not supported by the target system. Circuits that do not match the target hardware definition are no longer supported after March 4, 2024. See the transpilation documentation (https://docs.quantum.ibm.com/guides/transpile) for instructions to transform circuits and the primitive examples (https://docs.quantum.ibm.com/guides/primitives-examples) to see this coupled with operator transformations.'\n\ngrover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler())\nresults = grover_optimizer.solve(qp)\nprint(results.prettyprint())\n</pre> # grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler(mode = backend))  # This can flag 'The instruction h on qubits (0,) is not supported by the target system. Circuits that do not match the target hardware definition are no longer supported after March 4, 2024. See the transpilation documentation (https://docs.quantum.ibm.com/guides/transpile) for instructions to transform circuits and the primitive examples (https://docs.quantum.ibm.com/guides/primitives-examples) to see this coupled with operator transformations.'  grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler()) results = grover_optimizer.solve(qp) print(results.prettyprint()) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_13619/2281955874.py:4: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler())\n</pre> <pre>objective function value: 0.0\nvariable values: x0=0.0, x1=0.0\nstatus: SUCCESS\n</pre> <p>Let's try $3x + 2y - 3z + 3xy$.</p> In\u00a0[10]: Copied! <pre># Example 2 \n# Define one more variable\nx2 = model.binary_var(name=\"x2\")\n</pre> # Example 2  # Define one more variable x2 = model.binary_var(name=\"x2\") In\u00a0[11]: Copied! <pre># Establish the model\nmodel.minimize( 3 * x0 + 2 * x1 - 3 * x2 + 3 * x0 * x1)\nqp = from_docplex_mp(model)\nprint(qp.prettyprint())\n\n# Find the minima\ngrover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler())\nresults = grover_optimizer.solve(qp)\nprint(results.prettyprint())\n</pre> # Establish the model model.minimize( 3 * x0 + 2 * x1 - 3 * x2 + 3 * x0 * x1) qp = from_docplex_mp(model) print(qp.prettyprint())  # Find the minima grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler()) results = grover_optimizer.solve(qp) print(results.prettyprint()) <pre>Problem name: docplex_model1\n\nMinimize\n  3*x0*x1 + 3*x0 + 2*x1 - 3*x2\n\nSubject to\n  No constraints\n\n  Binary variables (3)\n    x0 x1 x2\n\n</pre> <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_13619/4279303789.py:7: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler())\n</pre> <pre>objective function value: -3.0\nvariable values: x0=0.0, x1=0.0, x2=1.0\nstatus: SUCCESS\n</pre> In\u00a0[12]: Copied! <pre># Example 3\nmodel.minimize(-x0 + 2 * x1 - 3 * x2 - 2 * x0 * x2 - 1 * x1 * x2)\nqp = from_docplex_mp(model)\nprint(qp.prettyprint())\n\n# Find the minima\ngrover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler())\nresults = grover_optimizer.solve(qp)\nprint(results.prettyprint())\n</pre> # Example 3 model.minimize(-x0 + 2 * x1 - 3 * x2 - 2 * x0 * x2 - 1 * x1 * x2) qp = from_docplex_mp(model) print(qp.prettyprint())  # Find the minima grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler()) results = grover_optimizer.solve(qp) print(results.prettyprint()) <pre>Problem name: docplex_model1\n\nMinimize\n  -2*x0*x2 - x1*x2 - x0 + 2*x1 - 3*x2\n\nSubject to\n  No constraints\n\n  Binary variables (3)\n    x0 x1 x2\n\n</pre> <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_13619/1049609804.py:7: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  grover_optimizer = GroverOptimizer(6, num_iterations=10, sampler=Sampler())\n</pre> <pre>objective function value: -6.0\nvariable values: x0=1.0, x1=0.0, x2=1.0\nstatus: SUCCESS\n</pre> <p>Constrained QUBO</p> In\u00a0[13]: Copied! <pre>qp = QuadraticProgram()\nqp.binary_var('x')\nqp.binary_var('y')\nqp.binary_var('z')\nqp.minimize(linear= {'x':2}, quadratic= {('x', 'z'):1, ('z', 'y'):-2})\nqp.linear_constraint(linear= {'x':2, 'y': -1, 'z':1}, sense= \"&lt;=\", rhs = 2)\n\nprint(qp.export_as_lp_string())\n#print(qp.prettyprint())\n</pre> qp = QuadraticProgram() qp.binary_var('x') qp.binary_var('y') qp.binary_var('z') qp.minimize(linear= {'x':2}, quadratic= {('x', 'z'):1, ('z', 'y'):-2}) qp.linear_constraint(linear= {'x':2, 'y': -1, 'z':1}, sense= \"&lt;=\", rhs = 2)  print(qp.export_as_lp_string()) #print(qp.prettyprint()) <pre>\\ This file has been generated by DOcplex\n\\ ENCODING=ISO-8859-1\n\\Problem name: CPLEX\n\nMinimize\n obj: 2 x + [ 2 x*z - 4 y*z ]/2\nSubject To\n c0: 2 x - y + z &lt;= 2\n\nBounds\n 0 &lt;= x &lt;= 1\n 0 &lt;= y &lt;= 1\n 0 &lt;= z &lt;= 1\n\nBinaries\n x y z\nEnd\n\n</pre> In\u00a0[14]: Copied! <pre>from qiskit_optimization.converters import QuadraticProgramToQubo\n\nqp_to_qubo = QuadraticProgramToQubo()\nqubo = qp_to_qubo.convert(qp)\nprint(qubo.export_as_lp_string())\n</pre> from qiskit_optimization.converters import QuadraticProgramToQubo  qp_to_qubo = QuadraticProgramToQubo() qubo = qp_to_qubo.convert(qp) print(qubo.export_as_lp_string()) <pre>\\ This file has been generated by DOcplex\n\\ ENCODING=ISO-8859-1\n\\Problem name: CPLEX\n\nMinimize\n obj: - 46 x + 24 y - 24 z - 24 c0@int_slack@0 - 48 c0@int_slack@1 + [ 48 x^2\n      - 48 x*y + 50 x*z + 48 x*c0@int_slack@0 + 96 x*c0@int_slack@1 + 12 y^2\n      - 28 y*z - 24 y*c0@int_slack@0 - 48 y*c0@int_slack@1 + 12 z^2\n      + 24 z*c0@int_slack@0 + 48 z*c0@int_slack@1 + 12 c0@int_slack@0^2\n      + 48 c0@int_slack@0*c0@int_slack@1 + 48 c0@int_slack@1^2 ]/2 + 24\nSubject To\n\nBounds\n 0 &lt;= x &lt;= 1\n 0 &lt;= y &lt;= 1\n 0 &lt;= z &lt;= 1\n 0 &lt;= c0@int_slack@0 &lt;= 1\n 0 &lt;= c0@int_slack@1 &lt;= 1\n\nBinaries\n x y z c0@int_slack@0 c0@int_slack@1\nEnd\n\n</pre> <p>Solving QUBO</p> In\u00a0[15]: Copied! <pre># Solving QUBO\ngrover_optimizer = GroverOptimizer(10, num_iterations=4, sampler=Sampler())\nresults = grover_optimizer.solve(qubo)\nprint(results.prettyprint())\n</pre> # Solving QUBO grover_optimizer = GroverOptimizer(10, num_iterations=4, sampler=Sampler()) results = grover_optimizer.solve(qubo) print(results.prettyprint()) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_13619/521563221.py:1: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  grover_optimizer = GroverOptimizer(10, num_iterations=4, sampler=Sampler())\n</pre> <pre>objective function value: -2.0\nvariable values: x=0.0, y=1.0, z=1.0, c0@int_slack@0=0.0, c0@int_slack@1=1.0\nstatus: SUCCESS\n</pre> <p>Solving qp</p> In\u00a0[\u00a0]: Copied! <pre>grover_optimizer = GroverOptimizer(10, num_iterations=4, sampler=Sampler())\nresults = grover_optimizer.solve(qp)\nprint(results.prettyprint())\n</pre> grover_optimizer = GroverOptimizer(10, num_iterations=4, sampler=Sampler()) results = grover_optimizer.solve(qp) print(results.prettyprint()) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_13619/2588980930.py:1: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  grover_optimizer = GroverOptimizer(10, num_iterations=4, sampler=Sampler())\n</pre> <pre>objective function value: -2.0\nvariable values: x=0.0, y=1.0, z=1.0\nstatus: SUCCESS\n</pre> <p>You should get the exact result like the qubo but without slack variables.</p>"},{"location":"QuantumOpt/jupyter_QOpt/GAS_Qiskit_molecule/#using-gas-with-qiskit","title":"Using GAS with Qiskit\u00b6","text":"<p>In thie Jupyter notebook, we will learn how to use Grover Adaptive Search in Qiskit Oprimization module.</p>"},{"location":"QuantumOpt/jupyter_QOpt/QAOA_D-Wave.ipynb/","title":"Solving QUBO problems with QAOA in Qiskit","text":"<p>In this jupyter notebook, we are going use Qiskit to help us solve the QAOA problem.</p> <p>First, we import Pauli matrix from <code>qiskit.quantum_info</code> and QAOA from</p> In\u00a0[1]: Copied! <pre>from qiskit.primitives import Sampler\nfrom qiskit.quantum_info import Pauli\nfrom qiskit_algorithms import QAOA\nfrom qiskit_algorithms.optimizers import COBYLA\n\nsampler = Sampler()\nH1 = Pauli('Z')^Pauli('Z')\ncircuit  = QAOA(sampler = sampler, optimizer=COBYLA())\n#circuit.draw(output = 'mpl')\n</pre> from qiskit.primitives import Sampler from qiskit.quantum_info import Pauli from qiskit_algorithms import QAOA from qiskit_algorithms.optimizers import COBYLA  sampler = Sampler() H1 = Pauli('Z')^Pauli('Z') circuit  = QAOA(sampler = sampler, optimizer=COBYLA()) #circuit.draw(output = 'mpl')   <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_95126/2134802490.py:6: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  sampler = Sampler()\n</pre> <p>Here is the guide through the latest qiskit optimization package: https://qiskit-community.github.io/qiskit-optimization/getting_started.html</p> <p>First, let's install the required qiskit optimization package by running the following code.</p> In\u00a0[2]: Copied! <pre>#!pip install qiskit-optimization\n</pre> #!pip install qiskit-optimization <pre>Requirement already satisfied: qiskit-optimization in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (0.6.1)\nRequirement already satisfied: qiskit&gt;=0.44 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit-optimization) (1.3.1)\nRequirement already satisfied: qiskit-algorithms&gt;=0.2.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit-optimization) (0.3.1)\nRequirement already satisfied: scipy&gt;=1.9.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit-optimization) (1.14.1)\nRequirement already satisfied: numpy&gt;=1.17 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit-optimization) (2.0.2)\nRequirement already satisfied: docplex!=2.24.231,&gt;=2.21.207 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit-optimization) (2.29.241)\nRequirement already satisfied: setuptools&gt;=40.1.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit-optimization) (75.6.0)\nRequirement already satisfied: networkx&gt;=2.6.3 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit-optimization) (3.4.2)\nRequirement already satisfied: six in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from docplex!=2.24.231,&gt;=2.21.207-&gt;qiskit-optimization) (1.17.0)\nRequirement already satisfied: rustworkx&gt;=0.15.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit&gt;=0.44-&gt;qiskit-optimization) (0.15.1)\nRequirement already satisfied: sympy&gt;=1.3 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit&gt;=0.44-&gt;qiskit-optimization) (1.12.1)\nRequirement already satisfied: dill&gt;=0.3 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit&gt;=0.44-&gt;qiskit-optimization) (0.3.9)\nRequirement already satisfied: python-dateutil&gt;=2.8.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit&gt;=0.44-&gt;qiskit-optimization) (2.9.0.post0)\nRequirement already satisfied: stevedore&gt;=3.0.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit&gt;=0.44-&gt;qiskit-optimization) (5.4.0)\nRequirement already satisfied: typing-extensions in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit&gt;=0.44-&gt;qiskit-optimization) (4.12.2)\nRequirement already satisfied: symengine&lt;0.14,&gt;=0.11 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from qiskit&gt;=0.44-&gt;qiskit-optimization) (0.13.0)\nRequirement already satisfied: pbr&gt;=2.0.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from stevedore&gt;=3.0.0-&gt;qiskit&gt;=0.44-&gt;qiskit-optimization) (6.1.0)\nRequirement already satisfied: mpmath&lt;1.4.0,&gt;=1.1.0 in /opt/anaconda3/envs/pcchouCR97/lib/python3.13/site-packages (from sympy&gt;=1.3-&gt;qiskit&gt;=0.44-&gt;qiskit-optimization) (1.3.0)\n</pre> <p>Let's define a quadratic problem with three binary variables. Our quadratic problem has a linear part <code>linear= {'y':-1}</code> and quadratic part <code>quadratic = {('x','y'):2, ('z', 'y'): -4}</code> and linear constraint <code>qp.linear_constraint(linear = {'x':1, 'y':2, 'z':3}, sense= \"&lt;=\", rhs = 5)</code>.</p> In\u00a0[3]: Copied! <pre>from qiskit_optimization import QuadraticProgram\n\n# Define variables\nqp = QuadraticProgram()\nqp.binary_var('x')\nqp.binary_var('y')\nqp.binary_var('z')\n\nqp.minimize(linear= {'y':-1}, quadratic = {('x','y'):2, ('z', 'y'): -4}) # Apply objective function.\nqp.linear_constraint(linear = {'x':1, 'y':2, 'z':3}, sense= \"&lt;=\", rhs = 5) # Apply linear constraint.\n\n# Print problem\nprint(qp.export_as_lp_string())\n</pre> from qiskit_optimization import QuadraticProgram  # Define variables qp = QuadraticProgram() qp.binary_var('x') qp.binary_var('y') qp.binary_var('z')  qp.minimize(linear= {'y':-1}, quadratic = {('x','y'):2, ('z', 'y'): -4}) # Apply objective function. qp.linear_constraint(linear = {'x':1, 'y':2, 'z':3}, sense= \"&lt;=\", rhs = 5) # Apply linear constraint.  # Print problem print(qp.export_as_lp_string()) <pre>\\ This file has been generated by DOcplex\n\\ ENCODING=ISO-8859-1\n\\Problem name: CPLEX\n\nMinimize\n obj: - y + [ 4 x*y - 8 y*z ]/2\nSubject To\n c0: x + 2 y + 3 z &lt;= 5\n\nBounds\n 0 &lt;= x &lt;= 1\n 0 &lt;= y &lt;= 1\n 0 &lt;= z &lt;= 1\n\nBinaries\n x y z\nEnd\n\n</pre> <p>As you can observe from the result, a package from IBM called CPLEX was used to implemented to help with solving optimization problems with classic methods.</p> <p>Once we have a <code>QuadraticProgram</code> object, we can use the solver provided by Qiskit. Let's import <code>MinimumEigenOptimizer</code> and <code>NumPyMinimumEigensolver</code> from <code>qiskit_optimization.algorithms</code> and <code>qiskit_algorithms</code>, respectively.</p> In\u00a0[4]: Copied! <pre>from qiskit_optimization.algorithms import MinimumEigenOptimizer\nfrom qiskit_algorithms import NumPyMinimumEigensolver\n\nnp_solver = NumPyMinimumEigensolver()\nnp_optimizer = MinimumEigenOptimizer(np_solver)\n\nresult = np_optimizer.solve(qp)\nprint(result)\n</pre> from qiskit_optimization.algorithms import MinimumEigenOptimizer from qiskit_algorithms import NumPyMinimumEigensolver  np_solver = NumPyMinimumEigensolver() np_optimizer = MinimumEigenOptimizer(np_solver)  result = np_optimizer.solve(qp) print(result) <pre>fval=-5.0, x=0.0, y=1.0, z=1.0, status=SUCCESS\n</pre> <p>Here, you will see result <code>fval=-5.0, x=0.0, y=1.0, z=1.0, status=SUCCESS</code>. As you can see, we obtain the optimal value of the function as well as its x, y, and z values.</p> <p>In the same fashion, we can use QAOA to solve the problem with following instructions.</p> <p>You may face the following issue:</p> <p>The <code>qiskit.utils.QuantumInstance</code> is a utility class that allows the joint configuration of the circuit transpilation and execution steps, and provides functions at a higher level of abstraction for a more convenient integration with algorithms. These include measurement error mitigation, splitting and combining execution to conform to job limits, and ensuring reliable circuit execution with additional job management tools.</p> <p>Below are the alternatives:</p> <ol> <li><code>class qiskit.primitives.Estimator(*, options=None)</code></li> <li><code>class qiskit.primitives.Sampler(*, options=None)</code> (Deprecated since version 1.2)</li> </ol> In\u00a0[5]: Copied! <pre>from qiskit_algorithms import QAOA\nfrom qiskit_algorithms.optimizers import COBYLA\nfrom qiskit_aer.primitives import Estimator, Sampler\nfrom qiskit_algorithms.utils import algorithm_globals\n\nsampler = Sampler()\nalgorithm_globals.random_seed = 10598\n\nqaoa = QAOA(optimizer=COBYLA(), sampler = sampler, reps = 1)\nqaoa_optimizer = MinimumEigenOptimizer(qaoa)\nresult1 = qaoa_optimizer.solve(qp)\nprint('result1:',result1)\n\nprint('Variable order', [var.name for var in result1.variables])\nfor s in result1.samples:\n    print(s)\n</pre> from qiskit_algorithms import QAOA from qiskit_algorithms.optimizers import COBYLA from qiskit_aer.primitives import Estimator, Sampler from qiskit_algorithms.utils import algorithm_globals  sampler = Sampler() algorithm_globals.random_seed = 10598  qaoa = QAOA(optimizer=COBYLA(), sampler = sampler, reps = 1) qaoa_optimizer = MinimumEigenOptimizer(qaoa) result1 = qaoa_optimizer.solve(qp) print('result1:',result1)  print('Variable order', [var.name for var in result1.variables]) for s in result1.samples:     print(s)  <pre>result1: fval=-5.0, x=0.0, y=1.0, z=1.0, status=SUCCESS\nVariable order ['x', 'y', 'z']\nSolutionSample(x=array([0., 1., 1.]), fval=np.float64(-5.0), probability=0.1025390625, status=&lt;OptimizationResultStatus.SUCCESS: 0&gt;)\nSolutionSample(x=array([0., 1., 0.]), fval=np.float64(-1.0), probability=0.1171875, status=&lt;OptimizationResultStatus.SUCCESS: 0&gt;)\nSolutionSample(x=array([0., 0., 0.]), fval=np.float64(0.0), probability=0.1376953125, status=&lt;OptimizationResultStatus.SUCCESS: 0&gt;)\nSolutionSample(x=array([0., 0., 1.]), fval=np.float64(0.0), probability=0.140625, status=&lt;OptimizationResultStatus.SUCCESS: 0&gt;)\nSolutionSample(x=array([1., 0., 0.]), fval=np.float64(0.0), probability=0.1611328125, status=&lt;OptimizationResultStatus.SUCCESS: 0&gt;)\nSolutionSample(x=array([1., 0., 1.]), fval=np.float64(0.0), probability=0.1982421875, status=&lt;OptimizationResultStatus.SUCCESS: 0&gt;)\nSolutionSample(x=array([1., 1., 0.]), fval=np.float64(1.0), probability=0.0703125, status=&lt;OptimizationResultStatus.SUCCESS: 0&gt;)\nSolutionSample(x=array([1., 1., 1.]), fval=np.float64(-3.0), probability=0.072265625, status=&lt;OptimizationResultStatus.INFEASIBLE: 2&gt;)\n</pre> <p>We print out a listing of different solutions that are part of the final, optimal state found by QAOA. Each item of the list includes the assignment the energy or function value, the probability of obtaining the corrsponding basis state when measuring the QAOA state, and whether the solution is feasible or not.</p> <p>We can also access the full infomation about the QAOA execution by using the following:</p> In\u00a0[6]: Copied! <pre>print(result1.min_eigen_solver_result)\n</pre> print(result1.min_eigen_solver_result) <pre>{   'aux_operators_evaluated': None,\n    'best_measurement': {   'bitstring': '000110',\n                            'probability': 0.0380859375,\n                            'state': 6,\n                            'value': np.complex128(-52+0j)},\n    'cost_function_evals': 30,\n    'eigenstate': {56: 0.0009765625, 26: 0.0029296875, 19: 0.0048828125, 4: 0.001953125, 54: 0.001953125, 6: 0.009765625, 24: 0.0048828125, 2: 0.0029296875, 27: 0.005859375, 9: 0.0146484375, 11: 0.005859375, 44: 0.0478515625, 39: 0.005859375, 30: 0.0205078125, 36: 0.001953125, 5: 0.03515625, 49: 0.001953125, 29: 0.005859375, 0: 0.005859375, 60: 0.0009765625, 8: 0.021484375, 34: 0.0205078125, 62: 0.013671875, 32: 0.0283203125, 48: 0.044921875, 46: 0.01171875, 53: 0.0009765625, 15: 0.017578125, 28: 0.0322265625, 12: 0.05078125, 40: 0.005859375, 10: 0.0146484375, 18: 0.0185546875, 59: 0.0068359375, 1: 0.0078125, 37: 0.0595703125, 43: 0.0107421875, 50: 0.0419921875, 22: 0.0087890625, 23: 0.01171875, 13: 0.0068359375, 57: 0.033203125, 45: 0.00390625, 51: 0.009765625, 42: 0.015625, 7: 0.033203125, 20: 0.0048828125, 38: 0.0146484375, 16: 0.025390625, 55: 0.00390625, 25: 0.048828125, 61: 0.0205078125, 21: 0.0654296875, 35: 0.0068359375, 3: 0.01953125, 41: 0.0546875, 14: 0.021484375},\n    'eigenvalue': np.float64(-18.9921875),\n    'optimal_circuit': &lt;qiskit.circuit.quantumcircuit.QuantumCircuit object at 0x120e0f6b0&gt;,\n    'optimal_parameters': {   ParameterVectorElement(\u03b2[0]): np.float64(-0.3399070054274298),\n                              ParameterVectorElement(\u03b3[0]): np.float64(-4.1087983813741635)},\n    'optimal_point': array([-0.33990701, -4.10879838]),\n    'optimal_value': np.float64(-18.9921875),\n    'optimizer_evals': None,\n    'optimizer_result': &lt;qiskit_algorithms.optimizers.optimizer.OptimizerResult object at 0x120ee5fd0&gt;,\n    'optimizer_time': 1.0629889965057373}\n</pre> <p>We can see that these assignments include slack variables used in transform from constrained to unconstrained problem. Let's obtain the corrsponding QUBO problem with the following code:</p> In\u00a0[7]: Copied! <pre>from qiskit_optimization.converters import QuadraticProgramToQubo\nqp_to_qubo = QuadraticProgramToQubo()\nqubo = qp_to_qubo.convert(qp)\n\nprint(qubo.export_as_lp_string())\n</pre> from qiskit_optimization.converters import QuadraticProgramToQubo qp_to_qubo = QuadraticProgramToQubo() qubo = qp_to_qubo.convert(qp)  print(qubo.export_as_lp_string()) <pre>\\ This file has been generated by DOcplex\n\\ ENCODING=ISO-8859-1\n\\Problem name: CPLEX\n\nMinimize\n obj: - 80 x - 161 y - 240 z - 80 c0@int_slack@0 - 160 c0@int_slack@1\n      - 160 c0@int_slack@2 + [ 16 x^2 + 68 x*y + 96 x*z + 32 x*c0@int_slack@0\n      + 64 x*c0@int_slack@1 + 64 x*c0@int_slack@2 + 64 y^2 + 184 y*z\n      + 64 y*c0@int_slack@0 + 128 y*c0@int_slack@1 + 128 y*c0@int_slack@2\n      + 144 z^2 + 96 z*c0@int_slack@0 + 192 z*c0@int_slack@1\n      + 192 z*c0@int_slack@2 + 16 c0@int_slack@0^2\n      + 64 c0@int_slack@0*c0@int_slack@1 + 64 c0@int_slack@0*c0@int_slack@2\n      + 64 c0@int_slack@1^2 + 128 c0@int_slack@1*c0@int_slack@2\n      + 64 c0@int_slack@2^2 ]/2 + 200\nSubject To\n\nBounds\n 0 &lt;= x &lt;= 1\n 0 &lt;= y &lt;= 1\n 0 &lt;= z &lt;= 1\n 0 &lt;= c0@int_slack@0 &lt;= 1\n 0 &lt;= c0@int_slack@1 &lt;= 1\n 0 &lt;= c0@int_slack@2 &lt;= 1\n\nBinaries\n x y z c0@int_slack@0 c0@int_slack@1 c0@int_slack@2\nEnd\n\n</pre> <p>Congrats! We successfully convert our problem into a QUBO problem where slack variables and penalty terms have been introduced.</p> <p>It is also worth to notice that <code>qiskit_optimization.converters</code> module in Qiskit also provide <code>InequalityToEquality</code>, <code>IntegerToBinary</code>, and <code>LinearEqualityToPenalty</code> functions. <code>QuadraticProgramToQubo</code> calls them to convert quadratic programs with constraints into QUBO instance, by first introducing slack variables to transform inequalities into equalities, then transforming the integer slack variables into binary once, and finally, replacing the equality constraints with penalty terms.</p> In\u00a0[8]: Copied! <pre>H1, offset = qubo.to_ising()\n\nprint(\"The Hamiltonian is\", H1)\nprint(\"The constant term is\",offset)\n</pre> H1, offset = qubo.to_ising()  print(\"The Hamiltonian is\", H1) print(\"The constant term is\",offset) <pre>The Hamiltonian is SparsePauliOp(['IIIIZI', 'IIIIIZ', 'IIIZII', 'IIZIII', 'IZIIII', 'ZIIIII', 'IIIIZZ', 'IIIZIZ', 'IIZIIZ', 'IZIIIZ', 'ZIIIIZ', 'IIIZZI', 'IIZIZI', 'IZIIZI', 'ZIIIZI', 'IIZZII', 'IZIZII', 'ZIIZII', 'IZZIII', 'ZIZIII', 'ZZIIII'],\n              coeffs=[ -7. +0.j,  -4.5+0.j, -11. +0.j,  -4. +0.j,  -8. +0.j,  -8. +0.j,\n   8.5+0.j,  12. +0.j,   4. +0.j,   8. +0.j,   8. +0.j,  23. +0.j,\n   8. +0.j,  16. +0.j,  16. +0.j,  12. +0.j,  24. +0.j,  24. +0.j,\n   8. +0.j,   8. +0.j,  16. +0.j])\nThe constant term is 47.0\n</pre> <p>Ok, it seems like we can use <code>H1</code> to solve the problem with QAOA runtime program and even recover the energy by adding the <code>offset</code> term. It seems like a lot of work! Luckly, Qislit provide a simpler way.</p> <p>Qiskit Optimization 0.6.1</p> <p>The classes <code>VQEClient</code>, <code>QAOAClient</code>, and <code>VQERuntimeResult</code> are removed. Instead, users should migrate their code to use the <code>Qiskit Runtime Primitives</code> with session.</p> In\u00a0[50]: Copied! <pre>from qiskit_ibm_runtime import QiskitRuntimeService, Session\nfrom qiskit.primitives import Sampler\nfrom qiskit_algorithms import QAOA\n</pre> from qiskit_ibm_runtime import QiskitRuntimeService, Session from qiskit.primitives import Sampler from qiskit_algorithms import QAOA In\u00a0[52]: Copied! <pre>service = QiskitRuntimeService(channel=\"ibm_quantum\", #ibm_cloud #https://quantum.ibm.com/\n                               token = '***your own token***')\n</pre> service = QiskitRuntimeService(channel=\"ibm_quantum\", #ibm_cloud #https://quantum.ibm.com/                                token = '***your own token***') In\u00a0[51]: Copied! <pre>backend = service.least_busy(operational=True, simulator=False)\n</pre> backend = service.least_busy(operational=True, simulator=False) In\u00a0[53]: Copied! <pre>#algorithm_globals.random_seed = 10598\n\nsession = Session(backend = backend)\n#print(session)\n\nsampler = Sampler()\n\nqaoa = QAOA(optimizer=COBYLA(), sampler = sampler, reps = 1)\nqaoa_opt = MinimumEigenOptimizer(qaoa)\nresult2 = qaoa_opt.solve(qp)\nprint('result2:',result2)\n</pre> #algorithm_globals.random_seed = 10598  session = Session(backend = backend) #print(session)  sampler = Sampler()  qaoa = QAOA(optimizer=COBYLA(), sampler = sampler, reps = 1) qaoa_opt = MinimumEigenOptimizer(qaoa) result2 = qaoa_opt.solve(qp) print('result2:',result2) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_95126/3017666165.py:6: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  sampler = Sampler()\n</pre> <pre>result2: fval=-5.0, x=0.0, y=1.0, z=1.0, status=SUCCESS\n</pre>"},{"location":"QuantumOpt/jupyter_QOpt/QAOA_D-Wave.ipynb/#solving-qubo-problems-with-qaoa-in-qiskit","title":"Solving QUBO problems with QAOA in Qiskit\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QAOA_D-Wave.ipynb/#using-qaoa-with-hamiltonians","title":"Using QAOA with Hamiltonians\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QAOA_D-Wave.ipynb/#qaoa","title":"QAOA\u00b6","text":"<p>QAOA</p> <p><code>class QAOA(sampler, optimizer, *, reps=1, initial_state=None, mixer=None, initial_point=None, aggregation=None, callback=None)[source]</code></p> <p>Tutorial: https://qiskit-community.github.io/qiskit-algorithms/tutorials/05_qaoa.html</p>"},{"location":"QuantumOpt/jupyter_QOpt/QAOA_D-Wave.ipynb/#run-qaoa-on-the-real-quantum-machine","title":"Run QAOA on the real quantum machine\u00b6","text":"<p>Let's run our problem on the real quantum machine! But, before that, to avoid delay when access quantum device queue many time, we need to get the Hamiltonian first. After having the Hamiltonian, we can use it directly in a QAOA program to submit our request to the real quantum machine just once. Let's see the following code to obtain out Hamiltonian directly!</p>"},{"location":"QuantumOpt/jupyter_QOpt/QAOA_PennyLane/","title":"Using QAOA with PennyLane","text":"<p>In this Jupyter Note Book, we will go through how to run a QAOA problem via PennyLane step by step. PennyLane provides a couple of handy ways to define a QAOA problem that can save our time, let's explore PennyLane's potential together!</p> <p>First, we are going to learn how to set up a Hamiltonian via PennyLane. You should already know that we can use <code>@</code> as a tensor product in PennyLane to help us represent the circuit more easiler. Please run the following code to construct a Hamiltonian:</p> In\u00a0[6]: Copied! <pre>import pennylane as qml\nfrom pennylane import PauliZ\n\n# setting Hamiltonian's coefficients &amp; PauliZ\ncoefficients = [2, -1, 3.5]\nPaulis = [PauliZ(0)@PauliZ(1), PauliZ(0)@PauliZ(2), PauliZ(2)@PauliZ(1)]\n\nH = qml.Hamiltonian(coefficients, Paulis)\n\n# Print out our problem\nprint(H)\n\n# Print out matrix form of our Hamiltonian\nprint(qml.matrix(H))\n</pre> import pennylane as qml from pennylane import PauliZ  # setting Hamiltonian's coefficients &amp; PauliZ coefficients = [2, -1, 3.5] Paulis = [PauliZ(0)@PauliZ(1), PauliZ(0)@PauliZ(2), PauliZ(2)@PauliZ(1)]  H = qml.Hamiltonian(coefficients, Paulis)  # Print out our problem print(H)  # Print out matrix form of our Hamiltonian print(qml.matrix(H)) <pre>2 * (Z(0) @ Z(1)) + -1 * (Z(0) @ Z(2)) + 3.5 * (Z(2) @ Z(1))\n[[ 4.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n [ 0. +0.j -0.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n [ 0. +0.j  0. +0.j -6.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n [ 0. +0.j  0. +0.j  0. +0.j  2.5+0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j]\n [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  2.5+0.j  0. +0.j  0. +0.j  0. +0.j]\n [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j -6.5+0.j  0. +0.j  0. +0.j]\n [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j -0.5+0.j  0. +0.j]\n [ 0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  0. +0.j  4.5+0.j]]\n</pre> <p>You should see a matrix representation of our Hamiltonian.</p> <p>Now we know how to define Hamiltonian, we can use them to create QAOA circuits with PennyLane. Let's import <code>qaoa</code> module, which will give us access to the <code>cost_layer</code> and <code>mixer_layer</code> functions. There are two kinds of layers that we will be going to define:</p> <ol> <li>The <code>cost_layer</code>: for encoding our problem.</li> <li>The <code>mixer_layr</code>: for $\\sum_{j} X_{j}$ = $H_{0}$, which is sometimes called the mixer Hamiltonian in QAOA structure.</li> </ol> <p>By combining these two layers, we can construct our QAOA problem and calculate its energy of the state wrt $H_1$. This can be done esaily in Pennylane through <code>expval</code> function. Please see the following code for defining our QAOA problem.</p> <p>The following code consist of these elements:</p> <ol> <li>Defining our $H_{0}$ as $X_{0} + X_{1}$ with <code>qml.PauliX(0) + qml.PauliX(1)</code>.</li> <li>Defining $H_1$ by using <code>1.0*qml.PauliZ(0) @ qml.PauliZ(1)</code>.<ul> <li>1.0 coefficient must be included to complete the tensor product to convert to Hamiltonian object.</li> </ul> </li> <li>The <code>energy</code> function only receives as parameters the angles for the rotation in the QAOA curcuit.</li> <li>We declared <code>p</code> as a glabal variable since we want to optimiza <code>energy</code> wrt its parameters and <code>p</code> is not something we want to optimize.</li> <li>The exponentials for $H_1$ and $H_0$ receive their parameters from the <code>angles</code> list.</li> <li>If <code>angles</code> is <code>[1.0, 2.0, 3.0, 4.0]</code>, then we would have $\\beta_{1} = 1.0$, $\\gamma_{2} = 2.0$, $\\beta_{2} = 3.0$, and $\\gamma_{2} = 4.0$.</li> </ol> In\u00a0[19]: Copied! <pre>from pennylane import qaoa\n\n# Define H0 and H1\nH0 = qml.PauliX(0) + qml.PauliX(1)\nH1 = 1.0*qml.PauliZ(0) @ qml.PauliZ(1) # 1.0 coefficient must be included to complete the tensor product to convert to Hamiltonian object.\n\nwires = range(2)\ndev = qml.device(\"default.qubit\", wires = wires)\n\n# set p = 2.\np = 2\n\n@qml.qnode(dev)\ndef energy(angles):\n    for w in wires:\n        qml.Hadamard(wires=w)\n    for i in range(p):\n        # Both H0 and H1 receive their parameters from the `angle` list.\n        qaoa.cost_layer(angles[2*i+1], H1)\n        qaoa.mixer_layer(angles[2*i], H0)\n    return qml.expval(H1)\n</pre> from pennylane import qaoa  # Define H0 and H1 H0 = qml.PauliX(0) + qml.PauliX(1) H1 = 1.0*qml.PauliZ(0) @ qml.PauliZ(1) # 1.0 coefficient must be included to complete the tensor product to convert to Hamiltonian object.  wires = range(2) dev = qml.device(\"default.qubit\", wires = wires)  # set p = 2. p = 2  @qml.qnode(dev) def energy(angles):     for w in wires:         qml.Hadamard(wires=w)     for i in range(p):         # Both H0 and H1 receive their parameters from the `angle` list.         qaoa.cost_layer(angles[2*i+1], H1)         qaoa.mixer_layer(angles[2*i], H0)     return qml.expval(H1)  <p>Now, let's run the optimization via the following code:</p> In\u00a0[23]: Copied! <pre>from pennylane import numpy as np\n\n# Choose a optimizer\noptimzer = qml.GradientDescentOptimizer()\n# Define\nsteps = 20\n# Initial angles\nangles = np.array([1.0,1.0,1.0,1.0], requires_grad = True)\n\nfor i in range(steps):\n    angles = optimzer.step(energy, angles)\n\nprint(\"Optimal angles\", angles)\n</pre> from pennylane import numpy as np  # Choose a optimizer optimzer = qml.GradientDescentOptimizer() # Define steps = 20 # Initial angles angles = np.array([1.0,1.0,1.0,1.0], requires_grad = True)  for i in range(steps):     angles = optimzer.step(energy, angles)  print(\"Optimal angles\", angles) <pre>Optimal angles [0.78884013 0.71892439 1.17959579 1.28138806]\n</pre> <p>The result shows that the optimal parameters [$\\beta_{1}$, $\\gamma_{1}$, $\\beta_{2}$, $\\gamma_{2}$].</p> <p>One of the useful function that PennyLane provides is it ability to automatically calculate the deritative of the object function. To use this, we need to ser <code>requires_grad = TRUE</code> when defining the initail angles.</p> <p>We can now sample from the QAOA circuit with the parameters that we have found to obtain condidate to our problem. Let's run the following code:</p> In\u00a0[24]: Copied! <pre>@qml.qnode(dev)\ndef sample_solutions(angles):\n    for w in wires:\n        qml.Hadamard(wires=w)\n    for i in range(p):\n        # Both H0 and H1 receive their parameters from the `angle` list.\n        qaoa.cost_layer(angles[2*i+1], H1)\n        qaoa.mixer_layer(angles[2*i], H0)\n    return qml.sample()\n\nprint(sample_solutions(angles, shots = 5))\n</pre> @qml.qnode(dev) def sample_solutions(angles):     for w in wires:         qml.Hadamard(wires=w)     for i in range(p):         # Both H0 and H1 receive their parameters from the `angle` list.         qaoa.cost_layer(angles[2*i+1], H1)         qaoa.mixer_layer(angles[2*i], H0)     return qml.sample()  print(sample_solutions(angles, shots = 5)) <pre>[[0 1]\n [0 1]\n [1 0]\n [0 1]\n [0 1]]\n</pre> <p>You can get a list of state results show the ground states of $Z_{0}Z_{1}$.</p> <p>You know how to run a QAOA problem on PennyLane and here are what you have learned so far:</p> <ol> <li>How to set up Hamiltonian in PennyLane.</li> <li>You know that PennyLane takes <code>angles</code> as input for Hamiltonian parameters.</li> <li>You can choose different classical optimizer that fit the best to your model.</li> <li>You know that PennyLane can do differentiation automatically by setting the correct code.</li> </ol>"},{"location":"QuantumOpt/jupyter_QOpt/QAOA_PennyLane/#using-qaoa-with-pennylane","title":"Using QAOA with PennyLane\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QAOA_PennyLane/#summary","title":"Summary\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_1_start/","title":"Start QUBO with Qiskit","text":"<p>First, let's import some necessary packages</p> In\u00a0[1]: Copied! <pre>from qiskit import *\n</pre> from qiskit import * In\u00a0[2]: Copied! <pre>from qiskit.quantum_info import Statevector\n\n# Defining 0\nzero = Statevector([1,0]) # Remember that the vector form for |0\\ is [1,0]!\nprint(\"zero is\", zero)\n\n# Defining 1\none = Statevector([0,1]) # Remember that the vector form for |1\\ is [0,1]!\nprint(\"one is\", one)\n</pre> from qiskit.quantum_info import Statevector  # Defining 0 zero = Statevector([1,0]) # Remember that the vector form for |0\\ is [1,0]! print(\"zero is\", zero)  # Defining 1 one = Statevector([0,1]) # Remember that the vector form for |1\\ is [0,1]! print(\"one is\", one) <pre>zero is Statevector([1.+0.j, 0.+0.j],\n            dims=(2,))\none is Statevector([0.+0.j, 1.+0.j],\n            dims=(2,))\n</pre> In\u00a0[3]: Copied! <pre># Defining 0\nzero = Statevector.from_int(0, dims =2) # 0 @position 0 in dims = 2 array\nprint(\"zero is\", zero)\n\n# Defining 1\none = Statevector.from_int(1, dims =2) # 1 @position 1 in dims = 2 array\nprint(\"one is\", one)\n</pre> # Defining 0 zero = Statevector.from_int(0, dims =2) # 0 @position 0 in dims = 2 array print(\"zero is\", zero)  # Defining 1 one = Statevector.from_int(1, dims =2) # 1 @position 1 in dims = 2 array print(\"one is\", one) <pre>zero is Statevector([1.+0.j, 0.+0.j],\n            dims=(2,))\none is Statevector([0.+0.j, 1.+0.j],\n            dims=(2,))\n</pre> <p>Now we can construct states with a higher number of qubits by computing tensor products with the <code>tensor</code> method.</p> In\u00a0[4]: Copied! <pre># Computing state by using `tensor` method.\npsi = one.tensor(zero.tensor(zero)) # |100\\\nprint (\"psi is\",psi)\n</pre> # Computing state by using `tensor` method. psi = one.tensor(zero.tensor(zero)) # |100\\ print (\"psi is\",psi) <pre>psi is Statevector([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j,\n             0.+0.j],\n            dims=(2, 2, 2))\n</pre> <p>The result should show the following:</p> <p><code>psi is Statevector([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j,              0.+0.j],             dims=(2, 2, 2))</code></p> <p>The results shows 4 means $\\lvert 100\\rangle$ in binery representation. Remember, we start our at 0 to 7 for 1 to 8 in binery form.</p> In\u00a0[5]: Copied! <pre># A more concise way\npsi = one^zero^zero\nprint (\"psi is\",psi)\npsi.draw(\"latex\")\n</pre> # A more concise way psi = one^zero^zero print (\"psi is\",psi) psi.draw(\"latex\") <pre>psi is Statevector([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j,\n             0.+0.j],\n            dims=(2, 2, 2))\n</pre> Out[5]:  $$ |100\\rangle$$  <p>The result should show it's statevector</p> <p><code>psi is Statevector([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j,              0.+0.j],             dims=(2, 2, 2))</code></p> <p>and $|100\\rangle$.</p> <p>Also, a faster way of constructing the $|100\\rangle$ is using, again, the <code>from_int</code> method:</p> In\u00a0[6]: Copied! <pre># A faster way to construct |100\\ using from_int method\npsi = Statevector.from_int(4, dims = 8)\nprint(\"psi is\", psi)\n</pre> # A faster way to construct |100\\ using from_int method psi = Statevector.from_int(4, dims = 8) print(\"psi is\", psi) <pre>psi is Statevector([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j,\n             0.+0.j],\n            dims=(2, 2, 2))\n</pre> <p>The result should show the following:</p> <p><code>psi is Statevector([0.+0.j, 0.+0.j, 0.+0.j, 0.+0.j, 1.+0.j, 0.+0.j, 0.+0.j,              0.+0.j],             dims=(2, 2, 2))</code></p> <p>We specify that we are working with three qubits by setting <code>dims = 8</code> (because we need 8 amplitudes to define a three-qubit state)</p> <p>After knowing how to create a basis, we can learn how to create a superposition state! In Qiskit, this is very easy, you just use the following command:</p> In\u00a0[7]: Copied! <pre>import numpy as np\n\nghz = 1/np.sqrt(2)*(zero^zero^zero)+1/np.sqrt(2)*(one^one^one)\nprint('ghz is:', ghz)\n</pre> import numpy as np  ghz = 1/np.sqrt(2)*(zero^zero^zero)+1/np.sqrt(2)*(one^one^one) print('ghz is:', ghz)  <pre>ghz is: Statevector([0.70710678+0.j, 0.        +0.j, 0.        +0.j,\n             0.        +0.j, 0.        +0.j, 0.        +0.j,\n             0.        +0.j, 0.70710678+0.j],\n            dims=(2, 2, 2))\n</pre> <p>You should get:</p> <p><code>ghz is: Statevector([0.70710678+0.j, 0.        +0.j, 0.        +0.j,              0.        +0.j, 0.        +0.j, 0.        +0.j,              0.        +0.j, 0.70710678+0.j],             dims=(2, 2, 2))</code></p> <p>which created a state $\\frac{1}{\\sqrt{2}}|000\\rangle + \\frac{1}{\\sqrt{2}}|111\\rangle$.</p> <p>!! in Qiskit, ^, which is a tensor operator, has a lower precedence than $+$ in python, therefore, we need to use parenthesis more carefully!</p> <p>To compute our expectation values, we need not only the state values but also Hamiltonians. So, let's work on the Hamiltonians in the next section!</p> <p>First, we intorduce <code>Pauli</code> from the <code>qiskit.quantum_info</code> object.</p> In\u00a0[8]: Copied! <pre>from qiskit.quantum_info import Pauli\n\n# Create Z0Z1I matrix mentioned before!\nZ0Z1 = Pauli(\"ZZI\")\n\n# Print some results:\nprint(\"Z0Z1 is:\", Z0Z1)\nprint(\"And its matrix is:\")\nprint(Z0Z1.to_matrix())\n</pre> from qiskit.quantum_info import Pauli  # Create Z0Z1I matrix mentioned before! Z0Z1 = Pauli(\"ZZI\")  # Print some results: print(\"Z0Z1 is:\", Z0Z1) print(\"And its matrix is:\") print(Z0Z1.to_matrix()) <pre>Z0Z1 is: ZZI\nAnd its matrix is:\n[[ 1.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j]\n [ 0.+0.j  1.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j]\n [ 0.+0.j  0.+0.j -1.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j]\n [ 0.+0.j  0.+0.j  0.+0.j -1.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j]\n [ 0.+0.j  0.+0.j  0.+0.j  0.+0.j -1.+0.j  0.+0.j  0.+0.j  0.+0.j]\n [ 0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j -1.+0.j  0.+0.j  0.+0.j]\n [ 0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  1.+0.j  0.+0.j]\n [ 0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  0.+0.j  1.+0.j]]\n</pre> <p>You should get a matrix representation of Z0Z1.</p> <p>Also, if you find the matrix hard to read, it's also welcome to use the sparse method like below:</p> In\u00a0[9]: Copied! <pre># We can also using the sparse method to demonstrate our results\nprint(\"The sparse representation of Z0Z1 is\")\nprint(Z0Z1.to_matrix(sparse=True))\n</pre> # We can also using the sparse method to demonstrate our results print(\"The sparse representation of Z0Z1 is\") print(Z0Z1.to_matrix(sparse=True)) <pre>The sparse representation of Z0Z1 is\n&lt;Compressed Sparse Row sparse matrix of dtype 'complex128'\n\twith 8 stored elements and shape (8, 8)&gt;\n  Coords\tValues\n  (0, 0)\t(1+0j)\n  (1, 1)\t(1+0j)\n  (2, 2)\t(-1+0j)\n  (3, 3)\t(-1+0j)\n  (4, 4)\t(-1+0j)\n  (5, 5)\t(-1+0j)\n  (6, 6)\t(1+0j)\n  (7, 7)\t(1+0j)\n</pre> <p>The main drawback for the <code>Pauli</code> object is that you cannot add them or multiply them by scaler. To compute something like $Z_{0}Z_{1}+Z_{1}Z_{2}$, we need to convert <code>Pauli</code> object to <code>PauliOp</code> first.</p> In\u00a0[10]: Copied! <pre>from qiskit.quantum_info import SparsePauliOp\n\nH_cut = SparsePauliOp(Pauli(\"ZZI\")) + SparsePauliOp(Pauli(\"ZIZ\"))\nprint(\"H_cut is:\", H_cut)\nprint(\"The sparse representation of H_cut is\", H_cut.to_matrix(sparse=True))\n</pre> from qiskit.quantum_info import SparsePauliOp  H_cut = SparsePauliOp(Pauli(\"ZZI\")) + SparsePauliOp(Pauli(\"ZIZ\")) print(\"H_cut is:\", H_cut) print(\"The sparse representation of H_cut is\", H_cut.to_matrix(sparse=True)) <pre>H_cut is: SparsePauliOp(['ZZI', 'ZIZ'],\n              coeffs=[1.+0.j, 1.+0.j])\nThe sparse representation of H_cut is &lt;Compressed Sparse Row sparse matrix of dtype 'complex128'\n\twith 8 stored elements and shape (8, 8)&gt;\n  Coords\tValues\n  (0, 0)\t(2+0j)\n  (1, 1)\t0j\n  (2, 2)\t0j\n  (3, 3)\t(-2+0j)\n  (4, 4)\t(-2+0j)\n  (5, 5)\t0j\n  (6, 6)\t0j\n  (7, 7)\t(2+0j)\n</pre> <p>Also we can try more complicated method using <code>parsePauliOp(pauli_strings, coef)</code> by specifying Paulis and it's coefficient of the following equation:</p> <p>$$ 0.5Z_{0}Z_{1}+2Z_{0}Z_{2}-Z_{1}Z_{2}+Z_{1}-5Z_{2} $$</p> In\u00a0[11]: Copied! <pre>from qiskit.quantum_info import SparsePauliOp\n\npauli_strings = [\"ZZI\", \"ZIZ\", \"IZZ\", \"IZI\", \"IIZ\"]\ncoef = [-0.5, 2.0, -1.0, 1.0, -1.5]\n\nH_ising = SparsePauliOp(pauli_strings, coef)\nprint(\"H_ising is:\", H_ising)\nprint(\"The sparse representation of H_ising is\", H_ising.to_matrix(sparse=True))\n</pre> from qiskit.quantum_info import SparsePauliOp  pauli_strings = [\"ZZI\", \"ZIZ\", \"IZZ\", \"IZI\", \"IIZ\"] coef = [-0.5, 2.0, -1.0, 1.0, -1.5]  H_ising = SparsePauliOp(pauli_strings, coef) print(\"H_ising is:\", H_ising) print(\"The sparse representation of H_ising is\", H_ising.to_matrix(sparse=True)) <pre>H_ising is: SparsePauliOp(['ZZI', 'ZIZ', 'IZZ', 'IZI', 'IIZ'],\n              coeffs=[-0.5+0.j,  2. +0.j, -1. +0.j,  1. +0.j, -1.5+0.j])\nThe sparse representation of H_ising is &lt;Compressed Sparse Row sparse matrix of dtype 'complex128'\n\twith 8 stored elements and shape (8, 8)&gt;\n  Coords\tValues\n  (0, 0)\t0j\n  (1, 1)\t(1+0j)\n  (2, 2)\t(1+0j)\n  (3, 3)\t(-2+0j)\n  (4, 4)\t(-3+0j)\n  (5, 5)\t(6+0j)\n  (6, 6)\t(-4+0j)\n  (7, 7)\t(1+0j)\n</pre> <p>Now, we can calculate the expectation value of our <code>H_cut</code> by using command: <code>psi.expectation_value(H_cut)</code>.</p> <p>The expectation value should be (-2+0j).</p> In\u00a0[12]: Copied! <pre>print(\"The expectation value is\", psi.expectation_value(H_cut))\n</pre> print(\"The expectation value is\", psi.expectation_value(H_cut)) <pre>The expectation value is (-2+0j)\n</pre> <p>Since the $Z_{0}Z_{1} + Z_{0}Z_{2}$ is the Hamiltonian for the Max-Cut problem for the three-node. The Hamiltonian is represented by $|100\\rangle$ (vertex 0 on one set, and 1 and 2 in the other) cuts the two edges of the graph and is an optimal solution.</p>"},{"location":"QuantumOpt/jupyter_QOpt/QUBO_1_start/#start-qubo-with-qiskit","title":"Start QUBO with Qiskit\u00b6","text":"<p>In this section, we are going to calculate some expection values in \"quantum way\".</p> <ol> <li>We will first understand how to construct our state basis such as $|100\\rangle$ using different ways in 'Define Basis' section.</li> <li>We will introduce how to calculate Hamiltonian and its expectation value.</li> </ol>"},{"location":"QuantumOpt/jupyter_QOpt/QUBO_1_start/#define-basis","title":"Define Basis\u00b6","text":"<p>As we mentioned before, we use $\\lvert xyz\\rangle$, $x,y,z\\in (0,1)$ to define the computational basis in our previous example. We can define these value in the following 3 ways.</p> <ol> <li>Define one-qubit state $\\lvert 0 \\rangle$ and $\\lvert 1 \\rangle$ and computer their tensor products by using <code>statevector</code></li> <li>Initialize <code>statevector</code> object from an integer such as <code>0</code> or <code>1</code>.</li> <li>A more concise way.</li> </ol>"},{"location":"QuantumOpt/jupyter_QOpt/QUBO_1_start/#1-define-one-qubit-to-a-statevector","title":"1. Define one-qubit to a statevector\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_1_start/#2-initialize-statevector-object-from-an-integer-such-as-0-or-1","title":"2. Initialize <code>statevector</code> object from an integer such as <code>0</code> or <code>1</code>.\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_1_start/#3-a-more-concise-way","title":"3. A more concise way\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_1_start/#hamiltonians","title":"Hamiltonians\u00b6","text":"<p>Let's work with hamiltonians in this section:</p>"},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_knapsack_qiskit/","title":"Knapsack problem with Qiskit","text":"<p>There, we will use thge example from Qiskit Knapsack.</p> In\u00a0[38]: Copied! <pre>from qiskit_optimization.applications import Knapsack\n</pre> from qiskit_optimization.applications import Knapsack <p>Here, we first set our problem to have [3,4,5,6,7] coefficient of our variables, then set the variable weights as <code>[2,3,4,5,6]</code>, following by the max_weight of <code>10</code>.</p> In\u00a0[48]: Copied! <pre># Setup our Knapsack problem\nprob = Knapsack(values=[3,4,5,6,7], weights = [2,3,4,5,6], max_weight=10)\nqp = prob.to_quadratic_program()\nprint(qp.prettyprint())\n</pre> # Setup our Knapsack problem prob = Knapsack(values=[3,4,5,6,7], weights = [2,3,4,5,6], max_weight=10) qp = prob.to_quadratic_program() print(qp.prettyprint()) <pre>Problem name: Knapsack\n\nMaximize\n  3*x_0 + 4*x_1 + 5*x_2 + 6*x_3 + 7*x_4\n\nSubject to\n  Linear constraints (1)\n    2*x_0 + 3*x_1 + 4*x_2 + 5*x_3 + 6*x_4 &lt;= 10  'c0'\n\n  Binary variables (5)\n    x_0 x_1 x_2 x_3 x_4\n\n</pre> In\u00a0[49]: Copied! <pre># Using Numpy Eignesolver \nfrom qiskit_optimization.algorithms import MinimumEigenOptimizer\nfrom qiskit_algorithms import NumPyMinimumEigensolver\n</pre> # Using Numpy Eignesolver  from qiskit_optimization.algorithms import MinimumEigenOptimizer from qiskit_algorithms import NumPyMinimumEigensolver In\u00a0[50]: Copied! <pre>meo = MinimumEigenOptimizer(min_eigen_solver = NumPyMinimumEigensolver())\nresult = meo.solve(qp)\nprint(result.prettyprint())\nprint(\"\\n solution:\", prob.interpret(result))\n#TODO We can apply constraints that at least 1.\n</pre> meo = MinimumEigenOptimizer(min_eigen_solver = NumPyMinimumEigensolver()) result = meo.solve(qp) print(result.prettyprint()) print(\"\\n solution:\", prob.interpret(result)) #TODO We can apply constraints that at least 1. <pre>objective function value: 13.0\nvariable values: x_0=1.0, x_1=1.0, x_2=0.0, x_3=1.0, x_4=0.0\nstatus: SUCCESS\n\n solution: [0, 1, 3]\n</pre> <ol> <li>An objective function value of says that we have a maximum value of 13.</li> <li>The variable values means that we can have 1 of x_0, x_1, and x_3 each.</li> <li>solution indices give states that the indices of x_0, x_1, and x_3 are the solution.</li> </ol> <p>Checking Hamiltonian</p> In\u00a0[51]: Copied! <pre>from qiskit_optimization.converters import QuadraticProgramToQubo\n</pre> from qiskit_optimization.converters import QuadraticProgramToQubo In\u00a0[52]: Copied! <pre># intermediate QUBO form of the optimization problem\nconv = QuadraticProgramToQubo()\nqubo = conv.convert(qp)\nprint(qubo.prettyprint())\n</pre> # intermediate QUBO form of the optimization problem conv = QuadraticProgramToQubo() qubo = conv.convert(qp) print(qubo.prettyprint()) <pre>Problem name: Knapsack\n\nMinimize\n  26*c0@int_slack@0^2 + 104*c0@int_slack@0*c0@int_slack@1\n  + 208*c0@int_slack@0*c0@int_slack@2 + 156*c0@int_slack@0*c0@int_slack@3\n  + 104*c0@int_slack@1^2 + 416*c0@int_slack@1*c0@int_slack@2\n  + 312*c0@int_slack@1*c0@int_slack@3 + 416*c0@int_slack@2^2\n  + 624*c0@int_slack@2*c0@int_slack@3 + 234*c0@int_slack@3^2\n  + 104*x_0*c0@int_slack@0 + 208*x_0*c0@int_slack@1 + 416*x_0*c0@int_slack@2\n  + 312*x_0*c0@int_slack@3 + 104*x_0^2 + 312*x_0*x_1 + 416*x_0*x_2 + 520*x_0*x_3\n  + 624*x_0*x_4 + 156*x_1*c0@int_slack@0 + 312*x_1*c0@int_slack@1\n  + 624*x_1*c0@int_slack@2 + 468*x_1*c0@int_slack@3 + 234*x_1^2 + 624*x_1*x_2\n  + 780*x_1*x_3 + 936*x_1*x_4 + 208*x_2*c0@int_slack@0 + 416*x_2*c0@int_slack@1\n  + 832*x_2*c0@int_slack@2 + 624*x_2*c0@int_slack@3 + 416*x_2^2 + 1040*x_2*x_3\n  + 1248*x_2*x_4 + 260*x_3*c0@int_slack@0 + 520*x_3*c0@int_slack@1\n  + 1040*x_3*c0@int_slack@2 + 780*x_3*c0@int_slack@3 + 650*x_3^2 + 1560*x_3*x_4\n  + 312*x_4*c0@int_slack@0 + 624*x_4*c0@int_slack@1 + 1248*x_4*c0@int_slack@2\n  + 936*x_4*c0@int_slack@3 + 936*x_4^2 - 520*c0@int_slack@0\n  - 1040*c0@int_slack@1 - 2080*c0@int_slack@2 - 1560*c0@int_slack@3 - 1043*x_0\n  - 1564*x_1 - 2085*x_2 - 2606*x_3 - 3127*x_4 + 2600\n\nSubject to\n  No constraints\n\n  Binary variables (9)\n    x_0 x_1 x_2 x_3 x_4 c0@int_slack@0 c0@int_slack@1 c0@int_slack@2\n    c0@int_slack@3\n\n</pre> In\u00a0[53]: Copied! <pre># qubit Hamiltonian and offset\nop, offset = qubo.to_ising()\nprint(f\"num qubits:{op.num_qubits}, offset:{offset}\\n\")\nprint(op)\n</pre> # qubit Hamiltonian and offset op, offset = qubo.to_ising() print(f\"num qubits:{op.num_qubits}, offset:{offset}\\n\") print(op) <pre>num qubits:9, offset:1417.5\n\nSparsePauliOp(['IIIIIIIIZ', 'IIIIIIIZI', 'IIIIIIZII', 'IIIIIZIII', 'IIIIZIIII', 'IIIZIIIII', 'IIZIIIIII', 'IZIIIIIII', 'ZIIIIIIII', 'IIIIIIIZZ', 'IIIIIIZIZ', 'IIIIIZIIZ', 'IIIIZIIIZ', 'IIIZIIIIZ', 'IIZIIIIIZ', 'IZIIIIIIZ', 'ZIIIIIIIZ', 'IIIIIIZZI', 'IIIIIZIZI', 'IIIIZIIZI', 'IIIZIIIZI', 'IIZIIIIZI', 'IZIIIIIZI', 'ZIIIIIIZI', 'IIIIIZZII', 'IIIIZIZII', 'IIIZIIZII', 'IIZIIIZII', 'IZIIIIZII', 'ZIIIIIZII', 'IIIIZZIII', 'IIIZIZIII', 'IIZIIZIII', 'IZIIIZIII', 'ZIIIIZIII', 'IIIZZIIII', 'IIZIZIIII', 'IZIIZIIII', 'ZIIIZIIII', 'IIZZIIIII', 'IZIZIIIII', 'ZIIZIIIII', 'IZZIIIIII', 'ZIZIIIIII', 'ZZIIIIIII'],\n              coeffs=[-258.5+0.j, -388. +0.j, -517.5+0.j, -647. +0.j, -776.5+0.j, -130. +0.j,\n -260. +0.j, -520. +0.j, -390. +0.j,   78. +0.j,  104. +0.j,  130. +0.j,\n  156. +0.j,   26. +0.j,   52. +0.j,  104. +0.j,   78. +0.j,  156. +0.j,\n  195. +0.j,  234. +0.j,   39. +0.j,   78. +0.j,  156. +0.j,  117. +0.j,\n  260. +0.j,  312. +0.j,   52. +0.j,  104. +0.j,  208. +0.j,  156. +0.j,\n  390. +0.j,   65. +0.j,  130. +0.j,  260. +0.j,  195. +0.j,   78. +0.j,\n  156. +0.j,  312. +0.j,  234. +0.j,   26. +0.j,   52. +0.j,   39. +0.j,\n  104. +0.j,   78. +0.j,  156. +0.j])\n</pre>"},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_knapsack_qiskit/#knapsack-problem-with-qiskit","title":"Knapsack problem with Qiskit\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/","title":"Max-Cut and Traveler Saleman Problem with Qiskit","text":"<p>Let's import some useful packages first</p> In\u00a0[1]: Copied! <pre>import matplotlib.pyplot as plt\nimport numpy as np\nimport networkx as nx\n\nfrom qiskit.circuit.library import TwoLocal\nfrom qiskit_optimization.applications import Maxcut, Tsp\nfrom qiskit_algorithms import SamplingVQE, NumPyMinimumEigensolver\nfrom qiskit_algorithms.optimizers import SPSA\nfrom qiskit_algorithms.utils import algorithm_globals\nfrom qiskit.primitives import Sampler\nfrom qiskit_optimization.algorithms import MinimumEigenOptimizer\n</pre> import matplotlib.pyplot as plt import numpy as np import networkx as nx  from qiskit.circuit.library import TwoLocal from qiskit_optimization.applications import Maxcut, Tsp from qiskit_algorithms import SamplingVQE, NumPyMinimumEigensolver from qiskit_algorithms.optimizers import SPSA from qiskit_algorithms.utils import algorithm_globals from qiskit.primitives import Sampler from qiskit_optimization.algorithms import MinimumEigenOptimizer  In\u00a0[2]: Copied! <pre># Generate a graph of 4 nodes \n\nn = 4\nG = nx.Graph()\nG.add_nodes_from(np.arange(0,n,1))\nelist = [(0, 1, 1.0), (0, 2, 1.0), (0, 3, 1.0), (1, 2, 1.0), (2, 3, 1.0)]\n# tuple is (i, j, weight) where (i, j) is the edge\nG.add_weighted_edges_from(elist)\n\n\n# Plot G graph\ncolors = [\"r\" for node in G.nodes()]\npos = nx.spring_layout(G)\n\ndef draw_graph(G, colors, pos):\n    default_axes = plt.axes(frameon = True)\n    nx.draw_networkx(G, node_color = colors, node_size = 600, alpha = 0.8, ax = default_axes, pos = pos)\n    edge_labels = nx.get_edge_attributes(G, \"weight\")\n    nx.draw_networkx_edge_labels(G, pos=pos, edge_labels=edge_labels)\n\ndraw_graph(G, colors, pos)\n</pre> # Generate a graph of 4 nodes   n = 4 G = nx.Graph() G.add_nodes_from(np.arange(0,n,1)) elist = [(0, 1, 1.0), (0, 2, 1.0), (0, 3, 1.0), (1, 2, 1.0), (2, 3, 1.0)] # tuple is (i, j, weight) where (i, j) is the edge G.add_weighted_edges_from(elist)   # Plot G graph colors = [\"r\" for node in G.nodes()] pos = nx.spring_layout(G)  def draw_graph(G, colors, pos):     default_axes = plt.axes(frameon = True)     nx.draw_networkx(G, node_color = colors, node_size = 600, alpha = 0.8, ax = default_axes, pos = pos)     edge_labels = nx.get_edge_attributes(G, \"weight\")     nx.draw_networkx_edge_labels(G, pos=pos, edge_labels=edge_labels)  draw_graph(G, colors, pos) In\u00a0[3]: Copied! <pre># Compute the weight matrix from the random graph\nw = np.zeros([n,n])\nfor i in range(n):\n    for j in range(n):\n        temp = G.get_edge_data(i,j,default=0)\n        if temp != 0:\n            w[i,j] = temp[\"weight\"]\n\nprint(w)\n</pre> # Compute the weight matrix from the random graph w = np.zeros([n,n]) for i in range(n):     for j in range(n):         temp = G.get_edge_data(i,j,default=0)         if temp != 0:             w[i,j] = temp[\"weight\"]  print(w) <pre>[[0. 1. 1. 1.]\n [1. 0. 1. 0.]\n [1. 1. 0. 1.]\n [1. 0. 1. 0.]]\n</pre> In\u00a0[4]: Copied! <pre>max_cut = Maxcut(w)\nqp = max_cut.to_quadratic_program()\nprint(qp.prettyprint())\n</pre> max_cut = Maxcut(w) qp = max_cut.to_quadratic_program() print(qp.prettyprint()) <pre>Problem name: Max-cut\n\nMaximize\n  -2*x_0*x_1 - 2*x_0*x_2 - 2*x_0*x_3 - 2*x_1*x_2 - 2*x_2*x_3 + 3*x_0 + 2*x_1\n  + 3*x_2 + 2*x_3\n\nSubject to\n  No constraints\n\n  Binary variables (4)\n    x_0 x_1 x_2 x_3\n\n</pre> In\u00a0[5]: Copied! <pre>qubitOp, offset = qp.to_ising()\nprint(\"Offset:\", offset)\nprint(\"Ising Hamiltonian\")\nprint(str(qubitOp))\n</pre> qubitOp, offset = qp.to_ising() print(\"Offset:\", offset) print(\"Ising Hamiltonian\") print(str(qubitOp)) <pre>Offset: -2.5\nIsing Hamiltonian\nSparsePauliOp(['IIZZ', 'IZIZ', 'ZIIZ', 'IZZI', 'ZZII'],\n              coeffs=[0.5+0.j, 0.5+0.j, 0.5+0.j, 0.5+0.j, 0.5+0.j])\n</pre> In\u00a0[6]: Copied! <pre># Solving Quadratic Program using exact calssical eigensolver \nexact = MinimumEigenOptimizer(NumPyMinimumEigensolver())\nresult = exact.solve(qp)\nprint(result.prettyprint())\n</pre> # Solving Quadratic Program using exact calssical eigensolver  exact = MinimumEigenOptimizer(NumPyMinimumEigensolver()) result = exact.solve(qp) print(result.prettyprint()) <pre>objective function value: 4.0\nvariable values: x_0=1.0, x_1=0.0, x_2=1.0, x_3=0.0\nstatus: SUCCESS\n</pre> In\u00a0[7]: Copied! <pre>algorithm_globals.random_seed = 123\nseed = 12345\n</pre> algorithm_globals.random_seed = 123 seed = 12345 In\u00a0[8]: Copied! <pre># Construct SamplingVQE\noptimzer = SPSA(maxiter=300)\nry = TwoLocal(qubitOp.num_qubits, \"ry\", \"cz\", reps=5, entanglement=\"linear\")\nvqe = SamplingVQE(sampler=Sampler(), ansatz=ry, optimizer=optimzer)\n\n# Run SamplingVQE\nresult = vqe.compute_minimum_eigenvalue(qubitOp)\n\n# Print results\nx = max_cut.sample_most_likely(result.eigenstate)\nprint(\"energy:\", result.eigenvalue.real)\nprint(\"time:\", result.optimizer_time)\nprint(\"max-cut objective:\", result.eigenvalue.real + offset)\nprint(\"solution:\", x)\nprint(\"solution: objective\", qp.objective.evaluate(x))\n\n# plot results \ncolors = [\"r\" if x[i]==0 else \"c\" for i in range(n)]\ndraw_graph(G, colors, pos)\n</pre> # Construct SamplingVQE optimzer = SPSA(maxiter=300) ry = TwoLocal(qubitOp.num_qubits, \"ry\", \"cz\", reps=5, entanglement=\"linear\") vqe = SamplingVQE(sampler=Sampler(), ansatz=ry, optimizer=optimzer)  # Run SamplingVQE result = vqe.compute_minimum_eigenvalue(qubitOp)  # Print results x = max_cut.sample_most_likely(result.eigenstate) print(\"energy:\", result.eigenvalue.real) print(\"time:\", result.optimizer_time) print(\"max-cut objective:\", result.eigenvalue.real + offset) print(\"solution:\", x) print(\"solution: objective\", qp.objective.evaluate(x))  # plot results  colors = [\"r\" if x[i]==0 else \"c\" for i in range(n)] draw_graph(G, colors, pos) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_20742/3196901592.py:4: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  vqe = SamplingVQE(sampler=Sampler(), ansatz=ry, optimizer=optimzer)\n</pre> <pre>energy: -1.4996861455587298\ntime: 2.816987991333008\nmax-cut objective: -3.99968614555873\nsolution: [0 1 0 1]\nsolution: objective 4.0\n</pre> <p>We can plot out the ansatz by running the following code</p> In\u00a0[9]: Copied! <pre>ry.decompose().draw(\"mpl\")\n</pre> ry.decompose().draw(\"mpl\") Out[9]: In\u00a0[10]: Copied! <pre># Generating a graph of 4 nodes\nn = 3\nnum_qubits = n**2\ntsp = Tsp.create_random_instance(n, seed=1234)\nadj_matrix = nx.to_numpy_array(tsp.graph)\nprint(\"distance\\n\", adj_matrix)\n\ncolors = [\"r\" for node in tsp.graph.nodes]\npos = [tsp.graph.nodes[node][\"pos\"] for node in tsp.graph.nodes]\ndraw_graph(tsp.graph, colors, pos)\n</pre> # Generating a graph of 4 nodes n = 3 num_qubits = n**2 tsp = Tsp.create_random_instance(n, seed=1234) adj_matrix = nx.to_numpy_array(tsp.graph) print(\"distance\\n\", adj_matrix)  colors = [\"r\" for node in tsp.graph.nodes] pos = [tsp.graph.nodes[node][\"pos\"] for node in tsp.graph.nodes] draw_graph(tsp.graph, colors, pos) <pre>distance\n [[ 0. 13. 71.]\n [13.  0. 62.]\n [71. 62.  0.]]\n</pre> In\u00a0[11]: Copied! <pre>qp = tsp.to_quadratic_program()\nprint(qp.prettyprint())\n</pre> qp = tsp.to_quadratic_program() print(qp.prettyprint()) <pre>Problem name: TSP\n\nMinimize\n  13*x_0_0*x_1_1 + 13*x_0_0*x_1_2 + 71*x_0_0*x_2_1 + 71*x_0_0*x_2_2\n  + 13*x_0_1*x_1_0 + 13*x_0_1*x_1_2 + 71*x_0_1*x_2_0 + 71*x_0_1*x_2_2\n  + 13*x_0_2*x_1_0 + 13*x_0_2*x_1_1 + 71*x_0_2*x_2_0 + 71*x_0_2*x_2_1\n  + 62*x_1_0*x_2_1 + 62*x_1_0*x_2_2 + 62*x_1_1*x_2_0 + 62*x_1_1*x_2_2\n  + 62*x_1_2*x_2_0 + 62*x_1_2*x_2_1\n\nSubject to\n  Linear constraints (6)\n    x_0_0 + x_0_1 + x_0_2 == 1  'c0'\n    x_1_0 + x_1_1 + x_1_2 == 1  'c1'\n    x_2_0 + x_2_1 + x_2_2 == 1  'c2'\n    x_0_0 + x_1_0 + x_2_0 == 1  'c3'\n    x_0_1 + x_1_1 + x_2_1 == 1  'c4'\n    x_0_2 + x_1_2 + x_2_2 == 1  'c5'\n\n  Binary variables (9)\n    x_0_0 x_0_1 x_0_2 x_1_0 x_1_1 x_1_2 x_2_0 x_2_1 x_2_2\n\n</pre> In\u00a0[12]: Copied! <pre>from qiskit_optimization.converters import QuadraticProgramToQubo\n\nqp2qubo = QuadraticProgramToQubo()\nqubo = qp2qubo.convert(qp)\nqubitOp, offset = qubo.to_ising()\nprint(\"Offset:\", offset)\nprint(\"Ising Hamiltonian:\")\nprint(str(qubitOp))\n</pre> from qiskit_optimization.converters import QuadraticProgramToQubo  qp2qubo = QuadraticProgramToQubo() qubo = qp2qubo.convert(qp) qubitOp, offset = qubo.to_ising() print(\"Offset:\", offset) print(\"Ising Hamiltonian:\") print(str(qubitOp)) <pre>Offset: 5481.0\nIsing Hamiltonian:\nSparsePauliOp(['IIIIIIIIZ', 'IIIIIIIZI', 'IIIIIIZII', 'IIIIIZIII', 'IIIIZIIII', 'IIIZIIIII', 'IIZIIIIII', 'IZIIIIIII', 'ZIIIIIIII', 'IIIIIIIZZ', 'IIIIIIZIZ', 'IIIIIZIIZ', 'IIIIZIIIZ', 'IIIZIIIIZ', 'IIZIIIIIZ', 'IZIIIIIIZ', 'ZIIIIIIIZ', 'IIIIIIZZI', 'IIIIIZIZI', 'IIIIZIIZI', 'IIIZIIIZI', 'IIZIIIIZI', 'IZIIIIIZI', 'ZIIIIIIZI', 'IIIIIZZII', 'IIIIZIZII', 'IIIZIIZII', 'IIZIIIZII', 'IZIIIIZII', 'ZIIIIIZII', 'IIIIZZIII', 'IIIZIZIII', 'IIZIIZIII', 'IZIIIZIII', 'ZIIIIZIII', 'IIIZZIIII', 'IIZIZIIII', 'IZIIZIIII', 'ZIIIZIIII', 'IIZZIIIII', 'IZIZIIIII', 'ZIIZIIIII', 'IZZIIIIII', 'ZIZIIIIII', 'ZZIIIIIII'],\n              coeffs=[-919.  +0.j, -919.  +0.j, -919.  +0.j, -914.5 +0.j, -914.5 +0.j,\n -914.5 +0.j, -943.5 +0.j, -943.5 +0.j, -943.5 +0.j,  438.5 +0.j,\n  438.5 +0.j,  438.5 +0.j,    3.25+0.j,    3.25+0.j,  438.5 +0.j,\n   17.75+0.j,   17.75+0.j,  438.5 +0.j,    3.25+0.j,  438.5 +0.j,\n    3.25+0.j,   17.75+0.j,  438.5 +0.j,   17.75+0.j,    3.25+0.j,\n    3.25+0.j,  438.5 +0.j,   17.75+0.j,   17.75+0.j,  438.5 +0.j,\n  438.5 +0.j,  438.5 +0.j,  438.5 +0.j,   15.5 +0.j,   15.5 +0.j,\n  438.5 +0.j,   15.5 +0.j,  438.5 +0.j,   15.5 +0.j,   15.5 +0.j,\n   15.5 +0.j,  438.5 +0.j,  438.5 +0.j,  438.5 +0.j,  438.5 +0.j])\n</pre> In\u00a0[13]: Copied! <pre>result = exact.solve(qubo)\nprint(result.prettyprint())\n</pre> result = exact.solve(qubo) print(result.prettyprint()) <pre>objective function value: 146.0\nvariable values: x_0_0=0.0, x_0_1=0.0, x_0_2=1.0, x_1_0=1.0, x_1_1=0.0, x_1_2=0.0, x_2_0=0.0, x_2_1=1.0, x_2_2=0.0\nstatus: SUCCESS\n</pre> In\u00a0[14]: Copied! <pre>def draw_tsp_solution(G, order, colors, pos):\n    G2 = nx.DiGraph()\n    G2.add_nodes_from(G)\n    n = len(order)\n    for i in range(n):\n        j = (i + 1) % n\n        G2.add_edge(order[i], order[j], weight=G[order[i]][order[j]][\"weight\"])\n    default_axes = plt.axes(frameon=True)\n    nx.draw_networkx(G2, node_color=colors, edge_color=\"b\", node_size=600, alpha=0.8, ax=default_axes, pos=pos)\n    edge_labels = nx.get_edge_attributes(G2, \"weight\")\n    nx.draw_networkx_edge_labels(G2, pos, font_color=\"b\", edge_labels=edge_labels)\n</pre> def draw_tsp_solution(G, order, colors, pos):     G2 = nx.DiGraph()     G2.add_nodes_from(G)     n = len(order)     for i in range(n):         j = (i + 1) % n         G2.add_edge(order[i], order[j], weight=G[order[i]][order[j]][\"weight\"])     default_axes = plt.axes(frameon=True)     nx.draw_networkx(G2, node_color=colors, edge_color=\"b\", node_size=600, alpha=0.8, ax=default_axes, pos=pos)     edge_labels = nx.get_edge_attributes(G2, \"weight\")     nx.draw_networkx_edge_labels(G2, pos, font_color=\"b\", edge_labels=edge_labels) In\u00a0[15]: Copied! <pre># making the Hamiltonian in its full form and getting the lowest eigenvalue and eigenvector\nee = NumPyMinimumEigensolver()\nresult = ee.compute_minimum_eigenvalue(qubitOp)\n\nprint(\"energy:\", result.eigenvalue.real)\nprint(\"tsp objective:\", result.eigenvalue.real + offset)\nx = tsp.sample_most_likely(result.eigenstate) # Compute the most likely binary string from state vector.\nprint(\"feasible:\", qubo.is_feasible(x))\nz = tsp.interpret(x)\nprint(\"solution:\",z)\nprint(\"solution objective:\", tsp.tsp_value(z, adj_matrix))\ndraw_tsp_solution(tsp.graph, z, colors, pos)\n</pre> # making the Hamiltonian in its full form and getting the lowest eigenvalue and eigenvector ee = NumPyMinimumEigensolver() result = ee.compute_minimum_eigenvalue(qubitOp)  print(\"energy:\", result.eigenvalue.real) print(\"tsp objective:\", result.eigenvalue.real + offset) x = tsp.sample_most_likely(result.eigenstate) # Compute the most likely binary string from state vector. print(\"feasible:\", qubo.is_feasible(x)) z = tsp.interpret(x) print(\"solution:\",z) print(\"solution objective:\", tsp.tsp_value(z, adj_matrix)) draw_tsp_solution(tsp.graph, z, colors, pos)  <pre>energy: -5335.0\ntsp objective: 146.0\nfeasible: True\nsolution: [1, 2, 0]\nsolution objective: 146.0\n</pre> In\u00a0[16]: Copied! <pre>algorithm_globals.random_seed = 5678\nseed = 56789\n</pre> algorithm_globals.random_seed = 5678 seed = 56789 In\u00a0[17]: Copied! <pre>optimizer = SPSA(maxiter=300)\nry = TwoLocal(qubitOp.num_qubits, \"ry\", \"cz\", reps=5, entanglement=\"linear\")\nvqe = SamplingVQE(sampler=Sampler(), ansatz=ry, optimizer=optimizer)\n\nresult = vqe.compute_minimum_eigenvalue(qubitOp)\n\nprint(\"energy:\", result.eigenvalue.real)\nprint(\"time:\", result.optimizer_time)\nx = tsp.sample_most_likely(result.eigenstate)\nprint(\"feasible:\", qubo.is_feasible(x))\nz = tsp.interpret(x)\nprint(\"solution:\", z)\nprint(\"solution objective:\", tsp.tsp_value(z, adj_matrix))\ndraw_tsp_solution(tsp.graph, z, colors, pos)\n</pre> optimizer = SPSA(maxiter=300) ry = TwoLocal(qubitOp.num_qubits, \"ry\", \"cz\", reps=5, entanglement=\"linear\") vqe = SamplingVQE(sampler=Sampler(), ansatz=ry, optimizer=optimizer)  result = vqe.compute_minimum_eigenvalue(qubitOp)  print(\"energy:\", result.eigenvalue.real) print(\"time:\", result.optimizer_time) x = tsp.sample_most_likely(result.eigenstate) print(\"feasible:\", qubo.is_feasible(x)) z = tsp.interpret(x) print(\"solution:\", z) print(\"solution objective:\", tsp.tsp_value(z, adj_matrix)) draw_tsp_solution(tsp.graph, z, colors, pos) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_20742/3509499864.py:3: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  vqe = SamplingVQE(sampler=Sampler(), ansatz=ry, optimizer=optimizer)\n</pre> <pre>energy: -5311.55356836324\ntime: 14.188351154327393\nfeasible: True\nsolution: [0, 1, 2]\nsolution objective: 146.0\n</pre> In\u00a0[21]: Copied! <pre>algorithm_globals.random_seed = 3456\nseed = 76543\n</pre> algorithm_globals.random_seed = 3456 seed = 76543 In\u00a0[22]: Copied! <pre># create minimum eigen optimizer based on SamplingVQE\nvqe_optimizer = MinimumEigenOptimizer(vqe)\n\n# solve quadratic program\nresult = vqe_optimizer.solve(qp)\nprint(result.prettyprint())\n\nz = tsp.interpret(x)\nprint(\"solution:\", z)\nprint(\"solution objective:\", tsp.tsp_value(z, adj_matrix))\ndraw_tsp_solution(tsp.graph, z, colors, pos)\n</pre> # create minimum eigen optimizer based on SamplingVQE vqe_optimizer = MinimumEigenOptimizer(vqe)  # solve quadratic program result = vqe_optimizer.solve(qp) print(result.prettyprint())  z = tsp.interpret(x) print(\"solution:\", z) print(\"solution objective:\", tsp.tsp_value(z, adj_matrix)) draw_tsp_solution(tsp.graph, z, colors, pos) <pre>objective function value: 146.0\nvariable values: x_0_0=0.0, x_0_1=1.0, x_0_2=0.0, x_1_0=0.0, x_1_1=0.0, x_1_2=1.0, x_2_0=1.0, x_2_1=0.0, x_2_2=0.0\nstatus: SUCCESS\nsolution: [0, 1, 2]\nsolution objective: 146.0\n</pre> <p>References:</p> <ul> <li>Max-Cut and Traveling Salesman Problem [Qiskit Optimization]</li> </ul>"},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#max-cut-and-traveler-saleman-problem-with-qiskit","title":"Max-Cut and Traveler Saleman Problem with Qiskit\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#max-cut-problem","title":"Max-Cut problem\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#mapping-into-the-ising-problem","title":"Mapping into the Ising problem\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#running-it-on-quantum-computer","title":"Running it on quantum computer\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#traveling-salesman-problem","title":"Traveling Salesman Problem\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#mapping-to-the-ising-problem","title":"Mapping to the Ising problem\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#checking-that-the-full-hamiltonian-gives-the-right-cost","title":"Checking that the full Hamiltonian gives the right cost\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/QUBO_example_max_cut_and_tsp_qiskit/#running-it-on-quantum-computer","title":"Running it on quantum computer\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/","title":"Using VQE with Qiskit","text":"<p>In this Jupyter notebook, we are going to demonstrate how to use VQE (Variational Quantum Eigensolver) on both simulator and real quantum machine.</p> <p>We will consider a simple quantum chemistry problem. We will imagine that we have two atoms of hydrogen forming an $H_2$ moledule and that we want to compute its ground state and its energy. We will accomplish this by using Qiskit Nature package.</p> <p>List of content:</p> <ol> <li>Finding the ground state</li> <li>Finding excited states with Qiskit</li> <li>Molecular problems</li> <li>Running VQE on quantum computers</li> </ol> In\u00a0[1]: Copied! <pre>#! pip install qiskit-nature\n#! pip install --prefer-binary pyscf\n</pre> #! pip install qiskit-nature #! pip install --prefer-binary pyscf <p>We first define out molecule. Our molecule have two hydrogen atoms located at coordinates (0,0,-0.37) and (0,0,0.37)(measured in angstroms), which is close to an equilibrium state for this molecle. We are using the default parameters, such as establishing that the molecule is not charged. Then we defin an electronic structure problem by using <code>PySCF</code> library. This library helps us computing the fermionic Hamiltonian taht takes into account the different possible configurations for the electrons of the two hydrogen atoms. This is accomplished by second quantization.</p> <p>Reference:</p> <ol> <li>Tutorial: Electronic structure (Qiskit Nature 0.7.2)</li> </ol> In\u00a0[2]: Copied! <pre>from qiskit_nature.units import DistanceUnit\nfrom qiskit_nature.second_q.drivers import PySCFDriver\n\n# Use PySCF, a classical computational chemistry software\n# package, to compute the one-body and two-body integrals in\n# electronic-orbital basis, necessary to form the Fermionic operator\ndriver = PySCFDriver(\n    atom=\"H 0 0 -.37; H 0 0 0.37\",\n    basis=\"sto3g\",\n    charge=0,\n    spin=0,\n    unit=DistanceUnit.ANGSTROM,\n)\n\nproblem = driver.run()\nprint(problem)\n</pre> from qiskit_nature.units import DistanceUnit from qiskit_nature.second_q.drivers import PySCFDriver  # Use PySCF, a classical computational chemistry software # package, to compute the one-body and two-body integrals in # electronic-orbital basis, necessary to form the Fermionic operator driver = PySCFDriver(     atom=\"H 0 0 -.37; H 0 0 0.37\",     basis=\"sto3g\",     charge=0,     spin=0,     unit=DistanceUnit.ANGSTROM, )  problem = driver.run() print(problem) <pre>&lt;qiskit_nature.second_q.problems.electronic_structure_problem.ElectronicStructureProblem object at 0x11f016a50&gt;\n</pre> <p>Running this driver, will yield an <code>ElectronicStructureProblem</code>, Qiskit Nature\u2019s representation of the electronic structure problem which we are interested in solving. For further information about the drivers, see https://qiskit-community.github.io/qiskit-nature/apidocs/qiskit_nature.second_q.drivers.html</p> In\u00a0[3]: Copied! <pre>hamiltonian = problem.hamiltonian\n\ncoefficients = hamiltonian.electronic_integrals\nprint(coefficients.alpha)\n</pre> hamiltonian = problem.hamiltonian  coefficients = hamiltonian.electronic_integrals print(coefficients.alpha)  <pre>Polynomial Tensor\n \"+-\":\narray([[-1.25330979e+00, -2.63594031e-16],\n       [-2.58579021e-16, -4.75068849e-01]])\n \"++--\":\narray([ 6.74755927e-01, -2.94385769e-17,  1.81210462e-01,  6.63711401e-01,\n        3.72896665e-16,  6.97651504e-01])\n</pre> In\u00a0[4]: Copied! <pre>fermionic_op = hamiltonian.second_q_op()\nprint(fermionic_op)\n</pre> fermionic_op = hamiltonian.second_q_op() print(fermionic_op) <pre>Fermionic Operator\nnumber spin orbitals=4, number terms=36\n  -1.2533097866459777 * ( +_0 -_0 )\n+ -0.4750688487721779 * ( +_1 -_1 )\n+ -1.2533097866459777 * ( +_2 -_2 )\n+ -0.4750688487721779 * ( +_3 -_3 )\n+ 0.33737796340722426 * ( +_0 +_0 -_0 -_0 )\n+ 0.33185570067540693 * ( +_0 +_1 -_1 -_0 )\n+ 0.33737796340722426 * ( +_0 +_2 -_2 -_0 )\n+ 0.33185570067540693 * ( +_0 +_3 -_3 -_0 )\n+ 0.09060523100759854 * ( +_0 +_0 -_1 -_1 )\n+ 0.09060523100759854 * ( +_0 +_1 -_0 -_1 )\n+ 0.09060523100759854 * ( +_0 +_2 -_3 -_1 )\n+ 0.09060523100759854 * ( +_0 +_3 -_2 -_1 )\n+ 0.09060523100759854 * ( +_1 +_0 -_1 -_0 )\n+ 0.09060523100759854 * ( +_1 +_1 -_0 -_0 )\n+ 0.09060523100759854 * ( +_1 +_2 -_3 -_0 )\n+ 0.09060523100759854 * ( +_1 +_3 -_2 -_0 )\n+ 0.33185570067540693 * ( +_1 +_0 -_0 -_1 )\n+ 0.34882575224523166 * ( +_1 +_1 -_1 -_1 )\n+ 0.33185570067540693 * ( +_1 +_2 -_2 -_1 )\n+ 0.34882575224523166 * ( +_1 +_3 -_3 -_1 )\n+ 0.33737796340722426 * ( +_2 +_0 -_0 -_2 )\n+ 0.33185570067540693 * ( +_2 +_1 -_1 -_2 )\n+ 0.33737796340722426 * ( +_2 +_2 -_2 -_2 )\n+ 0.33185570067540693 * ( +_2 +_3 -_3 -_2 )\n+ 0.09060523100759854 * ( +_2 +_0 -_1 -_3 )\n+ 0.09060523100759854 * ( +_2 +_1 -_0 -_3 )\n+ 0.09060523100759854 * ( +_2 +_2 -_3 -_3 )\n+ 0.09060523100759854 * ( +_2 +_3 -_2 -_3 )\n+ 0.09060523100759854 * ( +_3 +_0 -_1 -_2 )\n+ 0.09060523100759854 * ( +_3 +_1 -_0 -_2 )\n+ 0.09060523100759854 * ( +_3 +_2 -_3 -_2 )\n+ 0.09060523100759854 * ( +_3 +_3 -_2 -_2 )\n+ 0.33185570067540693 * ( +_3 +_0 -_0 -_3 )\n+ 0.34882575224523166 * ( +_3 +_1 -_1 -_3 )\n+ 0.33185570067540693 * ( +_3 +_2 -_2 -_3 )\n+ 0.34882575224523166 * ( +_3 +_3 -_3 -_3 )\n</pre> <p>This is a truncated view of the fermionic Hamiltonian, invloving something called creation and annihilation operators that describe how electrons move from one orbital to another.</p> In\u00a0[5]: Copied! <pre># setup the qubit mapper\nfrom qiskit_nature.second_q.mappers import JordanWignerMapper\n\nmapper = JordanWignerMapper()\nqhamiltonian = mapper.map(fermionic_op)\nprint(\"Qubit Hamiltonian:\")\nprint(qhamiltonian)\n</pre> # setup the qubit mapper from qiskit_nature.second_q.mappers import JordanWignerMapper  mapper = JordanWignerMapper() qhamiltonian = mapper.map(fermionic_op) print(\"Qubit Hamiltonian:\") print(qhamiltonian) <pre>Qubit Hamiltonian:\nSparsePauliOp(['IIII', 'IIIZ', 'IIZI', 'IZII', 'ZIII', 'IIZZ', 'IZIZ', 'ZIIZ', 'YYYY', 'XXYY', 'YYXX', 'XXXX', 'IZZI', 'ZIZI', 'ZZII'],\n              coeffs=[-0.81217061+0.j,  0.17141283+0.j, -0.22343154+0.j,  0.17141283+0.j,\n -0.22343154+0.j,  0.12062523+0.j,  0.16868898+0.j,  0.16592785+0.j,\n  0.04530262+0.j,  0.04530262+0.j,  0.04530262+0.j,  0.04530262+0.j,\n  0.16592785+0.j,  0.17441288+0.j,  0.12062523+0.j])\n</pre> <p>Now we have successfully transformed fermionic Hamiltonian into our familiar qubit Hamiltonian! We can observe that there are 4 qubits , involving tensor products of $I$, $X$, $Y$, and $Z$ gates.</p> In\u00a0[6]: Copied! <pre># setup the classical optimizer for the VQE\nfrom qiskit_algorithms.optimizers import L_BFGS_B, COBYLA, SLSQP\n\noptimizer_L_BFGS_B = L_BFGS_B()\noptimizer_COBYLA = COBYLA()\noptimizer_SLSQP = SLSQP()\n</pre> # setup the classical optimizer for the VQE from qiskit_algorithms.optimizers import L_BFGS_B, COBYLA, SLSQP  optimizer_L_BFGS_B = L_BFGS_B() optimizer_COBYLA = COBYLA() optimizer_SLSQP = SLSQP() In\u00a0[7]: Copied! <pre># setup the estimator primitive for the VQE\nfrom qiskit.primitives import Estimator\n\nestimator = Estimator()\n</pre> # setup the estimator primitive for the VQE from qiskit.primitives import Estimator  estimator = Estimator() <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_77405/2872279188.py:4: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n  estimator = Estimator()\n</pre> In\u00a0[8]: Copied! <pre>from qiskit.circuit.library import EfficientSU2\n\nansatz_Eff = EfficientSU2(num_qubits=4, reps=1, entanglement=\"linear\", insert_barriers=True)\nansatz_Eff.decompose().draw(\"mpl\")\n</pre> from qiskit.circuit.library import EfficientSU2  ansatz_Eff = EfficientSU2(num_qubits=4, reps=1, entanglement=\"linear\", insert_barriers=True) ansatz_Eff.decompose().draw(\"mpl\") Out[8]: <p>As you can see, we are using 16 different tunable parameters, represented by $\\theta[0], \\cdots, \\theta[15]$ in the figure.</p> In\u00a0[9]: Copied! <pre># set up our actual VQE instance with EfficientU2 solver\nfrom qiskit_algorithms import VQE\n\nvqe_optimizer_SLSQP = VQE(estimator, ansatz_Eff, optimizer_SLSQP)\n</pre> # set up our actual VQE instance with EfficientU2 solver from qiskit_algorithms import VQE  vqe_optimizer_SLSQP = VQE(estimator, ansatz_Eff, optimizer_SLSQP) <p>We can try to use <code>compute_minimum_eigenvalue</code> and <code>NumPyMinimumEigensolver</code> to solve our problem by the following two examples. We start with the <code>compute_minimum_eigenvalue</code> first.</p> In\u00a0[10]: Copied! <pre>result = vqe_optimizer_SLSQP.compute_minimum_eigenvalue(qhamiltonian)\nprint(result)\n</pre> result = vqe_optimizer_SLSQP.compute_minimum_eigenvalue(qhamiltonian) print(result) <pre>{   'aux_operators_evaluated': None,\n    'cost_function_evals': 478,\n    'eigenvalue': np.float64(-1.8318632765251293),\n    'optimal_circuit': &lt;qiskit.circuit.library.n_local.efficient_su2.EfficientSU2 object at 0x120d79bd0&gt;,\n    'optimal_parameters': {   ParameterVectorElement(\u03b8[12]): np.float64(2.751523847789954),\n                              ParameterVectorElement(\u03b8[3]): np.float64(-1.5706955122871569),\n                              ParameterVectorElement(\u03b8[2]): np.float64(1.0654359386453427),\n                              ParameterVectorElement(\u03b8[13]): np.float64(-1.2181093289273772),\n                              ParameterVectorElement(\u03b8[0]): np.float64(3.141592653589793),\n                              ParameterVectorElement(\u03b8[15]): np.float64(-2.9413089677398734),\n                              ParameterVectorElement(\u03b8[7]): np.float64(-3.141592653589793),\n                              ParameterVectorElement(\u03b8[14]): np.float64(3.1264224104305742),\n                              ParameterVectorElement(\u03b8[4]): np.float64(1.117173931225686),\n                              ParameterVectorElement(\u03b8[11]): np.float64(-1.570633725382053),\n                              ParameterVectorElement(\u03b8[5]): np.float64(-3.141592653589793),\n                              ParameterVectorElement(\u03b8[9]): np.float64(3.141592653589793),\n                              ParameterVectorElement(\u03b8[1]): np.float64(-0.0008984959367315058),\n                              ParameterVectorElement(\u03b8[8]): np.float64(-0.00011990857708739323),\n                              ParameterVectorElement(\u03b8[10]): np.float64(1.0653944129600097),\n                              ParameterVectorElement(\u03b8[6]): np.float64(0.0014324083643769102)},\n    'optimal_point': array([ 3.14159265e+00, -8.98495937e-04,  1.06543594e+00, -1.57069551e+00,\n        1.11717393e+00, -3.14159265e+00,  1.43240836e-03, -3.14159265e+00,\n       -1.19908577e-04,  3.14159265e+00,  1.06539441e+00, -1.57063373e+00,\n        2.75152385e+00, -1.21810933e+00,  3.12642241e+00, -2.94130897e+00]),\n    'optimal_value': np.float64(-1.8318632765251293),\n    'optimizer_evals': None,\n    'optimizer_result': &lt;qiskit_algorithms.optimizers.optimizer.OptimizerResult object at 0x120ae2f90&gt;,\n    'optimizer_time': 2.2097599506378174}\n</pre> <p>As you can see, we have obtain the optimal values for the circuit parameters, the state that is generated with those parameters (the <code>eigenstate</code> field) and what we were looking for: the energy state, which ihappens to be about $-1.8524$ hartree (the unit of energy commonly used in molecular orbital calculation). This means that we have solved our problem. How can we make sure these values are correct?</p> <p>In this case, since we have only used 4 qubits, therefore, we can check directly with the classical solver,<code>NumPyMinimumEigensolver</code>, that finds the exact ground state.</p> <p>Next we try the <code>NumPyMinimumEigensolver</code>.</p> In\u00a0[11]: Copied! <pre>from qiskit_algorithms.minimum_eigensolvers import NumPyMinimumEigensolver\n\nsolver = NumPyMinimumEigensolver()\nresult = solver.compute_minimum_eigenvalue(qhamiltonian)\nprint(result)\n</pre> from qiskit_algorithms.minimum_eigensolvers import NumPyMinimumEigensolver  solver = NumPyMinimumEigensolver() result = solver.compute_minimum_eigenvalue(qhamiltonian) print(result) <pre>{   'aux_operators_evaluated': None,\n    'eigenstate': Statevector([ 3.05311332e-16+7.04731412e-19j,\n             -2.22044605e-16-1.11022302e-16j,\n              3.46944695e-17-8.32667268e-17j,\n              1.11022302e-16-2.77555756e-17j,\n              2.77555756e-17-4.16333634e-17j,\n             -6.67316913e-01-7.36221442e-01j,\n             -1.11022302e-16-1.66533454e-16j,\n             -9.71445147e-17+1.38777878e-16j,\n             -1.66533454e-16-3.46944695e-17j,\n              9.62771529e-17+1.38777878e-16j,\n              7.55826341e-02+8.33870007e-02j,\n             -1.52655666e-16+4.71844785e-16j,\n             -1.66533454e-16+8.32667268e-17j,\n              2.77555756e-17-1.66533454e-16j,\n             -4.44089210e-16+5.55111512e-16j,\n             -2.49800181e-16+1.66533454e-16j],\n            dims=(2, 2, 2, 2)),\n    'eigenvalue': np.float64(-1.8523881735695835)}\n</pre> <p>This is more concise than the VQE output, but the final energy is almost equal to the one we had obtained previously. Congrats! we have successfully solved a molecular problem with VQE!!</p> <p>Back to the VQE page, we have already know not only how to use VQE iteratively to find the ground state, but also states of higher energy (excited states). The algorithm we are about to introduce is the Variational Quantum Deflation (VQD) and how to implement it by using Qiskit.</p> <p>Reference:</p> <ol> <li>Qiskit VQD</li> <li>Qiskit-nature 04_excited_states_solvers.ipynb</li> </ol> In\u00a0[12]: Copied! <pre>from qiskit_algorithms.state_fidelities import ComputeUncompute\nfrom qiskit.primitives import Sampler\n\nsampler2 = Sampler()\nfidelity = ComputeUncompute(sampler2)\n</pre> from qiskit_algorithms.state_fidelities import ComputeUncompute from qiskit.primitives import Sampler  sampler2 = Sampler() fidelity = ComputeUncompute(sampler2) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_77405/1466006858.py:4: DeprecationWarning: The class ``qiskit.primitives.sampler.Sampler`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseSamplerV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Sampler` class is `StatevectorSampler`.\n  sampler2 = Sampler()\n</pre> In\u00a0[13]: Copied! <pre>from qiskit_algorithms import VQD\n\nvqd = VQD(ansatz=ansatz_Eff,\n          optimizer=optimizer_SLSQP,\n          fidelity=fidelity,\n          k=3,\n          estimator = Estimator())\n\nresult = vqd.compute_eigenvalues(qhamiltonian)\nprint(result)\n</pre> from qiskit_algorithms import VQD  vqd = VQD(ansatz=ansatz_Eff,           optimizer=optimizer_SLSQP,           fidelity=fidelity,           k=3,           estimator = Estimator())  result = vqd.compute_eigenvalues(qhamiltonian) print(result) <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_77405/3226737995.py:7: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n  estimator = Estimator())\n</pre> <pre>{   'aux_operators_evaluated': None,\n    'cost_function_evals': array([204, 547, 823]),\n    'eigenvalues': array([-1.83186342+0.j, -1.24587581+0.j, -1.253305  +0.j]),\n    'optimal_circuits': [   &lt;qiskit.circuit.library.n_local.efficient_su2.EfficientSU2 object at 0x120c2f9d0&gt;,\n                            &lt;qiskit.circuit.library.n_local.efficient_su2.EfficientSU2 object at 0x120d78f50&gt;,\n                            &lt;qiskit.circuit.library.n_local.efficient_su2.EfficientSU2 object at 0x120d79090&gt;],\n    'optimal_parameters': [   {   ParameterVectorElement(\u03b8[12]): np.float64(-1.4116592079695565),\n                                  ParameterVectorElement(\u03b8[3]): np.float64(1.570752192086874),\n                                  ParameterVectorElement(\u03b8[2]): np.float64(-0.63957631081702),\n                                  ParameterVectorElement(\u03b8[13]): np.float64(-0.0349151200774026),\n                                  ParameterVectorElement(\u03b8[0]): np.float64(-7.620858351464622e-05),\n                                  ParameterVectorElement(\u03b8[15]): np.float64(-0.9767527436944802),\n                                  ParameterVectorElement(\u03b8[7]): np.float64(-3.141592653589793),\n                                  ParameterVectorElement(\u03b8[14]): np.float64(-1.50711440680488),\n                                  ParameterVectorElement(\u03b8[4]): np.float64(-0.8149273268788126),\n                                  ParameterVectorElement(\u03b8[11]): np.float64(1.5701473618183963),\n                                  ParameterVectorElement(\u03b8[5]): np.float64(-1.4471541607420164),\n                                  ParameterVectorElement(\u03b8[9]): np.float64(3.141466963055234),\n                                  ParameterVectorElement(\u03b8[1]): np.float64(-3.141387867568042),\n                                  ParameterVectorElement(\u03b8[8]): np.float64(3.141592653589793),\n                                  ParameterVectorElement(\u03b8[10]): np.float64(-0.6405556639737032),\n                                  ParameterVectorElement(\u03b8[6]): np.float64(-3.141592653589793)},\n                              {   ParameterVectorElement(\u03b8[12]): np.float64(-0.9656204581554705),\n                                  ParameterVectorElement(\u03b8[3]): np.float64(3.136483562076127),\n                                  ParameterVectorElement(\u03b8[2]): np.float64(3.141592653589793),\n                                  ParameterVectorElement(\u03b8[13]): np.float64(-0.48171339639983024),\n                                  ParameterVectorElement(\u03b8[0]): np.float64(-1.966374775332858),\n                                  ParameterVectorElement(\u03b8[15]): np.float64(-0.3291449119177894),\n                                  ParameterVectorElement(\u03b8[7]): np.float64(-0.8156167687482708),\n                                  ParameterVectorElement(\u03b8[14]): np.float64(-2.1555646099950305),\n                                  ParameterVectorElement(\u03b8[4]): np.float64(-1.5158564553246359),\n                                  ParameterVectorElement(\u03b8[11]): np.float64(3.141592653589793),\n                                  ParameterVectorElement(\u03b8[5]): np.float64(-1.5108896461298735),\n                                  ParameterVectorElement(\u03b8[9]): np.float64(-0.0002816832214784042),\n                                  ParameterVectorElement(\u03b8[1]): np.float64(-3.140946235362168),\n                                  ParameterVectorElement(\u03b8[8]): np.float64(3.141592653589793),\n                                  ParameterVectorElement(\u03b8[10]): np.float64(-0.00038817039225475707),\n                                  ParameterVectorElement(\u03b8[6]): np.float64(-1.5666245865665964)},\n                              {   ParameterVectorElement(\u03b8[12]): np.float64(-2.10039329590607),\n                                  ParameterVectorElement(\u03b8[3]): np.float64(1.5778006373204776),\n                                  ParameterVectorElement(\u03b8[2]): np.float64(0.0006816236798737885),\n                                  ParameterVectorElement(\u03b8[13]): np.float64(-0.09424157995709447),\n                                  ParameterVectorElement(\u03b8[0]): np.float64(-0.003647982566520439),\n                                  ParameterVectorElement(\u03b8[15]): np.float64(-0.6891040732682753),\n                                  ParameterVectorElement(\u03b8[7]): np.float64(-3.141592653589793),\n                                  ParameterVectorElement(\u03b8[14]): np.float64(-1.0473945812582302),\n                                  ParameterVectorElement(\u03b8[4]): np.float64(-1.6717489070160687),\n                                  ParameterVectorElement(\u03b8[11]): np.float64(1.5671729595688655),\n                                  ParameterVectorElement(\u03b8[5]): np.float64(-2.5378042377006524),\n                                  ParameterVectorElement(\u03b8[9]): np.float64(-3.141592653589793),\n                                  ParameterVectorElement(\u03b8[1]): np.float64(-3.1338312765840297),\n                                  ParameterVectorElement(\u03b8[8]): np.float64(3.141592653589793),\n                                  ParameterVectorElement(\u03b8[10]): np.float64(-3.141592653589793),\n                                  ParameterVectorElement(\u03b8[6]): np.float64(-2.8162863382456185)}],\n    'optimal_points': array([[-7.62085835e-05, -3.14138787e+00, -6.39576311e-01,\n         1.57075219e+00, -8.14927327e-01, -1.44715416e+00,\n        -3.14159265e+00, -3.14159265e+00,  3.14159265e+00,\n         3.14146696e+00, -6.40555664e-01,  1.57014736e+00,\n        -1.41165921e+00, -3.49151201e-02, -1.50711441e+00,\n        -9.76752744e-01],\n       [-1.96637478e+00, -3.14094624e+00,  3.14159265e+00,\n         3.13648356e+00, -1.51585646e+00, -1.51088965e+00,\n        -1.56662459e+00, -8.15616769e-01,  3.14159265e+00,\n        -2.81683221e-04, -3.88170392e-04,  3.14159265e+00,\n        -9.65620458e-01, -4.81713396e-01, -2.15556461e+00,\n        -3.29144912e-01],\n       [-3.64798257e-03, -3.13383128e+00,  6.81623680e-04,\n         1.57780064e+00, -1.67174891e+00, -2.53780424e+00,\n        -2.81628634e+00, -3.14159265e+00,  3.14159265e+00,\n        -3.14159265e+00, -3.14159265e+00,  1.56717296e+00,\n        -2.10039330e+00, -9.42415800e-02, -1.04739458e+00,\n        -6.89104073e-01]]),\n    'optimal_values': array([-1.83186342, -1.24587581, -1.253305  ]),\n    'optimizer_results': [   &lt;qiskit_algorithms.optimizers.optimizer.OptimizerResult object at 0x120c2f390&gt;,\n                             &lt;qiskit_algorithms.optimizers.optimizer.OptimizerResult object at 0x120d787d0&gt;,\n                             &lt;qiskit_algorithms.optimizers.optimizer.OptimizerResult object at 0x120ad35c0&gt;],\n    'optimizer_times': array([ 1.14658213,  6.74860024, 10.84398675])}\n</pre> <p>The <code>k</code> parameter is the one that we use to specify the number of eigenstates.</p> <p>We get the ground state energy $-1.85238735+0.j$ and the first excited state energy of $-1.25330263+0.j$. Let's the first excited state energy value with the direct <code>NumPyEigensolver</code> and <code>ExcitedStatesEigensolver</code>!</p> In\u00a0[14]: Copied! <pre>from qiskit_nature.second_q.algorithms  import QEOM, EvaluationRule, GroundStateEigensolver\n\ngse = GroundStateEigensolver(mapper, solver)\n# The qEOM algorithm is simply instantiated with the chosen ground state solver and Estimator primitive\nqeom_excited_states_solver = QEOM(gse, estimator, \"sd\", EvaluationRule.ALL)\n</pre> from qiskit_nature.second_q.algorithms  import QEOM, EvaluationRule, GroundStateEigensolver  gse = GroundStateEigensolver(mapper, solver) # The qEOM algorithm is simply instantiated with the chosen ground state solver and Estimator primitive qeom_excited_states_solver = QEOM(gse, estimator, \"sd\", EvaluationRule.ALL)  In\u00a0[15]: Copied! <pre>from qiskit_algorithms import NumPyEigensolver\n\nnumpy_solver = NumPyEigensolver(k=2, filter_criterion=problem.get_default_filter_criterion())\n</pre> from qiskit_algorithms import NumPyEigensolver  numpy_solver = NumPyEigensolver(k=2, filter_criterion=problem.get_default_filter_criterion()) In\u00a0[16]: Copied! <pre>from qiskit_nature.second_q.algorithms import ExcitedStatesEigensolver\n\nnumpy_excited_states_solver = ExcitedStatesEigensolver(mapper, numpy_solver)\nnumpy_results = numpy_excited_states_solver.solve(problem)\n\nqeom_results = qeom_excited_states_solver.solve(problem)\n\nprint(\"numpy_results:\\n\", numpy_results)\nprint(\"\\n\\n\")\nprint(\"qeom_results:\\n\", qeom_results)\n</pre> from qiskit_nature.second_q.algorithms import ExcitedStatesEigensolver  numpy_excited_states_solver = ExcitedStatesEigensolver(mapper, numpy_solver) numpy_results = numpy_excited_states_solver.solve(problem)  qeom_results = qeom_excited_states_solver.solve(problem)  print(\"numpy_results:\\n\", numpy_results) print(\"\\n\\n\") print(\"qeom_results:\\n\", qeom_results) <pre>numpy_results:\n === GROUND STATE ENERGY ===\n \n* Electronic ground state energy (Hartree): -1.85238817357\n  - computed part:      -1.85238817357\n~ Nuclear repulsion energy (Hartree): 0.715104339081\n&gt; Total ground state energy (Hartree): -1.137283834489\n \n=== EXCITED STATE ENERGIES ===\n \n  1: \n* Electronic excited state energy (Hartree): -0.883456772052\n&gt; Total excited state energy (Hartree): -0.168352432971\n \n=== MEASURED OBSERVABLES ===\n \n  0:  # Particles: 2.000 S: 0.000 S^2: 0.000 M: 0.000\n  1:  # Particles: 2.000 S: 0.000 S^2: 0.000 M: 0.000\n \n=== DIPOLE MOMENTS ===\n \n~ Nuclear dipole moment (a.u.): [0.0  0.0  0.0]\n \n  0: \n  * Electronic dipole moment (a.u.): [0.0  0.0  0.0]\n    - computed part:      [0.0  0.0  0.0]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.0]  Total: 0.0\n                 (debye): [0.0  0.0  0.0]  Total: 0.0\n \n  1: \n  * Electronic dipole moment (a.u.): [0.0  0.0  0.0]\n    - computed part:      [0.0  0.0  0.0]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.0]  Total: 0.0\n                 (debye): [0.0  0.0  0.0]  Total: 0.0\n \n\n\n\nqeom_results:\n === GROUND STATE ENERGY ===\n \n* Electronic ground state energy (Hartree): -1.85238817357\n  - computed part:      -1.85238817357\n~ Nuclear repulsion energy (Hartree): 0.715104339081\n&gt; Total ground state energy (Hartree): -1.137283834489\n \n=== EXCITED STATE ENERGIES ===\n \n  1: \n* Electronic excited state energy (Hartree): -1.245877696083\n&gt; Total excited state energy (Hartree): -0.530773357001\n  2: \n* Electronic excited state energy (Hartree): -0.883456772052\n&gt; Total excited state energy (Hartree): -0.168352432971\n  3: \n* Electronic excited state energy (Hartree): -0.231961665962\n&gt; Total excited state energy (Hartree): 0.483142673119\n \n=== MEASURED OBSERVABLES ===\n \n  0:  # Particles: 2.000 S: 0.000 S^2: 0.000 M: 0.000\n  1:  # Particles: 2.000 S: 1.000 S^2: 2.000 M: 0.000\n  2:  # Particles: 2.000 S: 0.000 S^2: 0.000 M: 0.000\n  3:  # Particles: 2.000 S: 0.000 S^2: -0.000 M: 0.000\n \n=== DIPOLE MOMENTS ===\n \n~ Nuclear dipole moment (a.u.): [0.0  0.0  0.0]\n \n  0: \n  * Electronic dipole moment (a.u.): [0.0  0.0  0.0]\n    - computed part:      [0.0  0.0  0.0]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.0]  Total: 0.0\n                 (debye): [0.0  0.0  0.0]  Total: 0.0\n \n  1: \n  * Electronic dipole moment (a.u.): [0.0  0.0  0.0]\n    - computed part:      [0.0  0.0  0.0]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.0]  Total: 0.0\n                 (debye): [0.0  0.0  0.0]  Total: 0.0\n \n  2: \n  * Electronic dipole moment (a.u.): [0.0  0.0  0.0]\n    - computed part:      [0.0  0.0  0.0]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.0]  Total: 0.0\n                 (debye): [0.0  0.0  0.0]  Total: 0.0\n \n  3: \n  * Electronic dipole moment (a.u.): [0.0  0.0  0.0]\n    - computed part:      [0.0  0.0  0.0]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.0]  Total: 0.0\n                 (debye): [0.0  0.0  0.0]  Total: 0.0\n \n</pre> <p>Here is the result from <code>NumPyEigensolver</code>:</p> <p>=== EXCITED STATE ENERGIES ===</p> <p>The 1st excited state:</p> <ul> <li>Electronic excited state energy (Hartree): -0.883456772052</li> </ul> <p>Total excited state energy (Hartree): -0.168352432971</p> <p>and these are the result from <code>ExcitedStatesEigensolver</code>:</p> <p>=== EXCITED STATE ENERGIES ===</p> <p>The 1st excited state:</p> <ul> <li>Electronic excited state energy (Hartree): -1.245877696083</li> </ul> <p>Total excited state energy (Hartree): -0.530773357001</p> <p>The 2nd excited state:</p> <ul> <li>Electronic excited state energy (Hartree): -0.883456772052</li> </ul> <p>Total excited state energy (Hartree): -0.168352432971</p> <p>We can also use VQE directly with molecular problems that we define with the help of the Qiskit Nature utilities. For example, we can use a VQE instance to solve the electronic problem that we defined in the previous subsection.</p> <p>The choose of the ansatz should take into account information from the problem domain. This is the case of the Unitary Coupled-Cluster Singles and Doubles or UCCSD ansatz, which is widely used for molecular computations. Let's construct this ansatz!</p> In\u00a0[17]: Copied! <pre># setup the ansatz for VQE\nfrom qiskit_nature.second_q.circuit.library import HartreeFock, UCCSD\n\nansatz = UCCSD(\n    problem.num_spatial_orbitals,\n    problem.num_particles,\n    mapper,\n    initial_state=HartreeFock(\n        problem.num_spatial_orbitals,\n        problem.num_particles,\n        mapper,\n    ),\n)\nansatz.decompose().draw(\"mpl\")\n</pre> # setup the ansatz for VQE from qiskit_nature.second_q.circuit.library import HartreeFock, UCCSD  ansatz = UCCSD(     problem.num_spatial_orbitals,     problem.num_particles,     mapper,     initial_state=HartreeFock(         problem.num_spatial_orbitals,         problem.num_particles,         mapper,     ), ) ansatz.decompose().draw(\"mpl\")  Out[17]: <p>As you can see, the ansatz invloves exponential funcitons of tensor products of Pauli matrices. There are also two $X$ gates at the beginning of the circuit that set the initial state to which the variational form is later applied. In this case, the state is called the Hartree-Fock state, again a widely used option when solving molecular problems with quantum computer.</p> <p>Once we have selected out ansatz, we can define a VQE instance by the following instructions</p> In\u00a0[18]: Copied! <pre># set up our actual VQE instance\nfrom qiskit_algorithms import VQE\n\nvqe_optimizer_L_BFGS_B = VQE(estimator, ansatz, optimizer_L_BFGS_B)\n# ensure that the optimizer starts in the all-zero state which corresponds to\n# the Hartree-Fock starting point\nvqe_optimizer_L_BFGS_B.initial_point = [0] * ansatz.num_parameters\n</pre> # set up our actual VQE instance from qiskit_algorithms import VQE  vqe_optimizer_L_BFGS_B = VQE(estimator, ansatz, optimizer_L_BFGS_B) # ensure that the optimizer starts in the all-zero state which corresponds to # the Hartree-Fock starting point vqe_optimizer_L_BFGS_B.initial_point = [0] * ansatz.num_parameters In\u00a0[19]: Copied! <pre>from qiskit_nature.second_q.algorithms import GroundStateEigensolver\n\ncalc = GroundStateEigensolver(mapper, vqe_optimizer_L_BFGS_B)\nres = calc.solve(problem)\nprint(res)\n</pre> from qiskit_nature.second_q.algorithms import GroundStateEigensolver  calc = GroundStateEigensolver(mapper, vqe_optimizer_L_BFGS_B) res = calc.solve(problem) print(res) <pre>=== GROUND STATE ENERGY ===\n \n* Electronic ground state energy (Hartree): -1.85238817357\n  - computed part:      -1.85238817357\n~ Nuclear repulsion energy (Hartree): 0.715104339081\n&gt; Total ground state energy (Hartree): -1.137283834488\n \n=== MEASURED OBSERVABLES ===\n \n  0:  # Particles: 2.000 S: 0.000 S^2: 0.000 M: 0.000\n \n=== DIPOLE MOMENTS ===\n \n~ Nuclear dipole moment (a.u.): [0.0  0.0  0.0]\n \n  0: \n  * Electronic dipole moment (a.u.): [0.0  0.0  -0.000000039235]\n    - computed part:      [0.0  0.0  -0.000000039235]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.000000039235]  Total: 0.000000039235\n                 (debye): [0.0  0.0  0.000000099726]  Total: 0.000000099726\n \n</pre> <p>We are providing the solver not only with the Hamiltonian, but with the whole problem, and it cab use that information to reconstruct the meaning of the calculations in the physical terms. For instance, we now get some bonus information such as the total ground state energy, which is the sum of the energy due to the electronic structure (the one that we had computed previously) and the energy due to nuclear repulsion.</p> In\u00a0[20]: Copied! <pre>from qiskit_ibm_runtime import QiskitRuntimeService\nfrom qiskit.primitives import Estimator\n\nestimator_real_Q = Estimator()\n</pre> from qiskit_ibm_runtime import QiskitRuntimeService from qiskit.primitives import Estimator  estimator_real_Q = Estimator() <pre>/var/folders/kz/_mr3r3b55qd2r5hd025yvpfw0000gn/T/ipykernel_77405/2808333328.py:4: DeprecationWarning: The class ``qiskit.primitives.estimator.Estimator`` is deprecated as of qiskit 1.2. It will be removed no earlier than 3 months after the release date. All implementations of the `BaseEstimatorV1` interface have been deprecated in favor of their V2 counterparts. The V2 alternative for the `Estimator` class is `StatevectorEstimator`.\n  estimator_real_Q = Estimator()\n</pre> In\u00a0[21]: Copied! <pre># Get the real machine\nservice = QiskitRuntimeService(instance=\"ibm-q/open/main\")\nbackend_name = service.least_busy(operational=True, simulator=False)\nprint(backend_name)\n</pre> # Get the real machine service = QiskitRuntimeService(instance=\"ibm-q/open/main\") backend_name = service.least_busy(operational=True, simulator=False) print(backend_name) <pre>&lt;IBMBackend('ibm_kyiv')&gt;\n</pre> In\u00a0[22]: Copied! <pre>vqe_optimizer_L_BFGS_B_real_Q = VQE(estimator_real_Q, ansatz, optimizer_L_BFGS_B)\n\nsolver_real_Q = GroundStateEigensolver(mapper, vqe_optimizer_L_BFGS_B_real_Q)\nres_real_Q = solver_real_Q.solve(problem)\nprint(res_real_Q)\n</pre> vqe_optimizer_L_BFGS_B_real_Q = VQE(estimator_real_Q, ansatz, optimizer_L_BFGS_B)  solver_real_Q = GroundStateEigensolver(mapper, vqe_optimizer_L_BFGS_B_real_Q) res_real_Q = solver_real_Q.solve(problem) print(res_real_Q) <pre>=== GROUND STATE ENERGY ===\n \n* Electronic ground state energy (Hartree): -1.852388173569\n  - computed part:      -1.852388173569\n~ Nuclear repulsion energy (Hartree): 0.715104339081\n&gt; Total ground state energy (Hartree): -1.137283834488\n \n=== MEASURED OBSERVABLES ===\n \n  0:  # Particles: 2.000 S: 0.000 S^2: 0.000 M: 0.000\n \n=== DIPOLE MOMENTS ===\n \n~ Nuclear dipole moment (a.u.): [0.0  0.0  0.0]\n \n  0: \n  * Electronic dipole moment (a.u.): [0.0  0.0  -0.000000417982]\n    - computed part:      [0.0  0.0  -0.000000417982]\n  &gt; Dipole moment (a.u.): [0.0  0.0  0.000000417982]  Total: 0.000000417982\n                 (debye): [0.0  0.0  0.000001062405]  Total: 0.000001062405\n \n</pre> <p>You can see the some noise in this result.</p>"},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#using-vqe-with-qiskit","title":"Using VQE with Qiskit\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#1-finding-the-ground-state","title":"1.   Finding the ground state\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#hamiltonians","title":"Hamiltonians\u00b6","text":"<p>The Hamiltonians that we have considered so far are called qubit Hamiltonian, while the one that we need to describe the energy of the $H_2$ molecule is called a fermionic Hamiltonian.</p> <p>To obtain the fermionic Hamiltonian for the dihydrogen molecule with Qiskit, we need to install the <code>Qiskit Nature package</code> and <code>pyscf</code> library, which is used for the computational chemistry calculations.</p>"},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#packages","title":"Packages\u00b6","text":"<p>Please run the following code incase you haven't installed <code>Qiskit Nature package</code> yet.</p> <ol> <li>Qiskit Nature<ul> <li>Installation: https://qiskit-community.github.io/qiskit-nature/getting_started.html</li> <li>Overview: https://qiskit-community.github.io/qiskit-nature/index.html</li> </ul> </li> <li>PySCF:<ul> <li>Installation: https://pyscf.org/install.html#install-with-pip</li> <li>Quickstart: https://pyscf.org/index.html</li> </ul> </li> </ol>"},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#getting-start-obtaining-an-initial-hartree-fock-solution","title":"Getting Start: Obtaining an initial Hartree-Fock solution\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#the-electronicstructureproblem-and-its-components","title":"The ElectronicStructureProblem and its components\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#mapping","title":"Mapping\u00b6","text":"<p>To use the quantum computer, we need to transform the fermionic Hamiltonian into a qubit Hamiltonian, involving Pauli gates. See references for more info.</p>"},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#the-solvers","title":"The Solvers\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#using-vqe-with-qubit-hamiltonians","title":"Using VQE with qubit Hamiltonians\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#2-finding-excited-states-with-qiskit","title":"2.   Finding excited states with Qiskit\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#3-molecular-problems","title":"3.   Molecular problems\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#4-running-vqe-on-quantum-computers","title":"4.   Running VQE on Quantum computers\u00b6","text":""},{"location":"QuantumOpt/jupyter_QOpt/VQE_Qiskit_molecule/#references","title":"References\u00b6","text":"<p>[1]  Tutorial: Electronic structure (Qiskit Nature 0.7.2).  [2]  Qiskit-Nature Tutorials-03_ground_state_solvers.  [3]  Qiskit-Nature Getting Started.</p>"},{"location":"Quantum_Algorithm_101/Bloch_sphere/","title":"Bloch sphere","text":""},{"location":"Quantum_Algorithm_101/Bloch_sphere/#basic-introduction","title":"Basic introduction","text":"<p>Bloch sphere representation of a \"single qubit state\".</p> <p>         Bloch shpere     </p> <p>If we ahve any qubit state |\\psi\\rangle \\in \\mathbb{C}^{2} can be mapped to a point on the bloch sphere. Assume state |\\psi\\rangle such that </p>  |\\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle, \\ \\alpha, \\beta \\ \\in \\mathbb{C}, \\ \\alpha^{2}+\\beta^{2} = 1  <p>We set </p>  \\alpha = \\text{cos} \\frac{\\theta}{2} e^{i\\delta}, \\ \\beta = \\text{sin} \\frac{\\theta}{2} e^{i(\\delta+\\phi)}  <p>thus,</p>  \\begin{array}{ll} |\\psi\\rangle &amp; = \\text{cos} \\frac{\\theta}{2} e^{i\\delta}|0\\rangle + \\text{sin}\\frac{\\theta}{2} e^{i(\\delta+\\phi)}|1\\rangle \\\\ &amp; = e^{i\\delta}(\\text{cos}\\frac{\\theta}{2}|0\\rangle + \\text{sin}e^{i\\phi}\\frac{\\theta}{2}|1\\rangle) \\end{array}  <p>where e^{i\\delta} is a global phase, somce it has same effects on |0\\rangle and |1\\rangle and cannot measure duing experiment, we can ignore it.</p> <p>For the relative phase, e^{i\\phi}, can canont ignore it. We set \\text{sin} and \\text{cos} a non-negative \\mathbb{R}. From the bloch sphere, we can have </p>  \\begin{array}{ll} x = \\text{sin}\\theta\\text{cos}\\phi\\\\ y = \\text{sin}\\theta\\text{sin}\\phi\\\\ z = \\text{cos}\\theta \\end{array}  <p>where </p>  \\begin{array}{ll} 0 \\leq \\theta \\leq \\pi\\\\ 0 \\leq \\phi &lt; 2\\pi\\\\ \\end{array}  <p>thus,</p>  |\\psi\\rangle = \\text{cos} \\frac{\\theta}{2}|0\\rangle + \\text{sin} \\frac{\\theta}{2}e^{i\\theta}|1\\rangle."},{"location":"Quantum_Algorithm_101/Bloch_sphere/#common-representations","title":"Common representations","text":""},{"location":"Quantum_Algorithm_101/Bloch_sphere/#z-basis-computational-basis","title":"Z-basis (computational basis)","text":"<ul> <li>|0\\rangle: North pole (z = 1)</li> <li>|1\\rangle: South pole (z = -1)</li> </ul>"},{"location":"Quantum_Algorithm_101/Bloch_sphere/#x-basis","title":"X-basis","text":"<ul> <li>|+\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + |1\\rangle) (x axis)</li> <li>|-\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle - |1\\rangle) (-x axis)</li> </ul>"},{"location":"Quantum_Algorithm_101/Bloch_sphere/#y-basis","title":"Y-basis","text":"<ul> <li>|i+\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + i|1\\rangle) (y axis)</li> <li>|i-\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle - i|1\\rangle) (-y axis)</li> </ul>"},{"location":"Quantum_Algorithm_101/Bloch_sphere/#references","title":"References","text":"<p>[1]. https://en.wikipedia.org/wiki/Bloch_sphere</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/","title":"Linear Algebra","text":"<p>This page gives some of the basic linear algebra fundation of a quantum information.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#bases-and-linear-independence","title":"Bases and linear independence","text":"<p>A spinning set for the vector space \\mathbb{C}^{2} is the set </p>  |v_{1}\\rangle \\equiv \\begin{bmatrix} 1\\\\0 \\end{bmatrix}; \\ |v_{2}\\rangle \\equiv \\begin{bmatrix} 0\\\\1 \\end{bmatrix};  <p>since any vector </p>  |v\\rangle = \\begin{bmatrix} a_{1}\\\\a_{2} \\end{bmatrix}  <p>in \\mathbb{C}^{2} can be written as a linear combination |v\\rangle = a_{1}|v_{1}\\rangle + a_{2}|v_{2}\\rangle of the vectors |v_{1}\\rangle and |v_{2}\\rangle. We say that </p> <p>Vector v_{1} and v_{2} span the vector space \\mathbb{C}^{2}</p> <p>A set of non-zero vectors |v_{1}\\rangle, ..., |v_{n}\\rangle are linearly dependent if there exists a set of complex numbers a_{1},...,a_{n} with a_{i} \\neq 0 for at least one value of i, such that </p>  a_{1}|v_{1}\\rangle + a_{2}|v_{2}\\rangle + ... + a_{n}|v_{n}\\rangle = 0"},{"location":"Quantum_Algorithm_101/Linear_algebra/#linear-operators-and-matrices","title":"Linear operators and matrices","text":"<p>A linear operator between vector spaces V and W is defined to be any function A:V \\mapsto W which is linear in its inputs,</p>  A\\bigg(\\sum_{i}a_{i}|v_{i}\\rangle\\bigg) = \\sum_{i}a_{i}A (|v_{i}\\rangle).  <p>We usually write A|v\\rangle instead of A(|v\\rangle). A is defeined on a vector space, V, we mean that A is a linear operator from V to V. </p> <ul> <li>An important linear operator on any vector space V is the identity operator, I_{V}, defined by the equation I_{V}|v\\rangle \\equiv |v\\rangle for all vectors |v\\rangle.</li> <li>Another important linear operator is the zero operator, which we denote 0, which maps all vectors to the zero vector, 0|v\\rangle \\equiv |0\\rangle.</li> </ul> <p>Suppose V,W, and X are vector spaces, and A: V \\mapsto W and B: W\\mapsto X are linear operators. Then we use the notation BA to denote the composition of B with A, defined by (BA)|v\\rangle \\equiv B(A|v\\rangle) \\equiv BA|v\\rangle.</p> <p>The most common way to understand linear operator is in terms of their matirx representation. In fact, the linear opreator and matrix viewpoints turns out to be common completely equivalant. more precisely, the claim that the matrix A is a linear operator means</p>  A\\bigg( \\sum_{i}a_{i}|v_{i}\\rangle\\bigg) = \\sum_{i}a_{i}A_{ij}|v_{i}\\rangle  <p>is true as an equation where the operation is matrix multiplication of A by column vectors. A_{ij} is just a matrix representation of the operator A.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#the-pauli-matrices","title":"The Pauli matrices","text":"<p>Four extremely useful matrices which we should know are the Pauli matrices.</p>  \\begin{array}{rr} \\sigma_{0} \\equiv I \\equiv \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp;1 \\end{bmatrix} &amp;  \\sigma_{1} \\equiv \\sigma_{x} \\equiv X \\equiv \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp;0 \\end{bmatrix} \\\\ \\sigma_{2} \\equiv \\sigma_{y} \\equiv Y \\equiv \\begin{bmatrix} 0 &amp; -i \\\\ i &amp;0 \\end{bmatrix} &amp; \\sigma_{3} \\equiv \\sigma_{z} \\equiv Z \\equiv \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp;-1 \\end{bmatrix} \\\\ \\end{array}"},{"location":"Quantum_Algorithm_101/Linear_algebra/#inner-products","title":"Inner products","text":"<p>In quantum mechanical notation for the inner product (|v\\rangle,|w\\rangle) is \\langle v|w\\rangle, where |v\\rangle and |w\\rangle are vectors in the inner product sapce. A function (\\cdot,\\cdot) from V\\times V to \\mathbb{C} is an inner product if </p> <ol> <li>(\\cdot,\\cdot) is linear in the second argument,</li> </ol>  \\bigg(|v\\rangle , \\sum_{i}\\lambda_{i}|w_{i}\\rangle \\bigg) = \\sum_{i}\\lambda_{i}(|v\\rangle,|w]\\rangle) = \\sum_{i}\\lambda_{i}\\langle v|w\\rangle.  <ol> <li>(|v\\rangle,|w\\rangle) = (|w\\rangle,|v\\rangle)^{*}.</li> <li>(|v\\rangle,|v\\rangle) \\geq 0 with equality if and only if |v\\rangle = 0.</li> </ol> <p>For example, \\mathbb{C}^{n} has an inner product defeined by </p>  ((y_{1},...,y_{n}),((z_{1},...,z_{n}))) \\equiv \\sum_{i}y_{i}^{*}z_{i} = \\begin{bmatrix} y_{1}^{*} ... y_{n}^{*} \\end{bmatrix} \\begin{bmatrix} z_{1}\\\\ \\vdots\\\\ z_{n} \\end{bmatrix}."},{"location":"Quantum_Algorithm_101/Linear_algebra/#orthogonal","title":"Orthogonal","text":"<p>Vectors |w\\rangle and |v\\rangle are orthogonal if their inner product is zero.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#norm","title":"Norm","text":"<p>The norm of a vector |v\\rangle is defined by </p>  |||v\\rangle|| = \\sqrt{\\langle v|v\\rangle}."},{"location":"Quantum_Algorithm_101/Linear_algebra/#unit-vector","title":"Unit vector","text":"<p>A unit vector is a vector |v\\rangle such that its norm is 1. We also say taht |v\\rangle is normalized if its norm is 1.</p> <p>Suppose |w_{1}\\rangle,...,|w_{d}\\rangle is a basis set for some vector space V with an inner product. The GRAM-Schmidt procedure can produce an orthonormal basis set |v_{1}\\rangle,...,|v_{d}\\rangle for the vector space V. Define |v_{1}\\rangle \\equiv |w_{1}\\rangle/|||w_{1}\\rangle||, and for 1\\leq k \\leq d-1 define v_{k+1} by</p>  v_{k+1} = \\frac{|w_{k+1}\\rangle - \\sum_{i=1}^{k}\\langle v_{i}|w_{k+1}\\rangle|v_{i}\\rangle}{|||w_{k+1}\\rangle - \\sum_{i=1}^{k}\\langle v_{i}|w_{k+1}\\rangle|v_{i}\\rangle||}."},{"location":"Quantum_Algorithm_101/Linear_algebra/#matrix-representation","title":"Matrix representation","text":"<p>The inner product on a Hilbert space can given a convenient matrix representation. Let |w\\rangle = \\sum_{i}w_{i}|i\\rangle and |v\\rangle = \\sum_{j}v_{j}|j\\rangle be representations of vector |w\\rangle and |v\\rangle with respect to some orthonormal basis |i\\rangle. Then, since \\langle i |j\\rangle = \\delta_{ij},</p>  \\begin{array}{rl} \\langle v|w\\rangle = &amp; \\bigg( \\sum_{i}v_{i}|i\\rangle, \\sum_{j}w_{j}|j\\rangle\\bigg) = \\sum_{ij}v_{i}^{*}w_{j}\\delta_{ij} = \\sum_{i}v_{i}^{*}w_{i} \\\\ \\ = &amp; \\begin{bmatrix} v_{1}^{*} ... v_{n}^{*} \\end{bmatrix} \\begin{bmatrix} w_{1} \\\\ \\vdots \\\\ w_{n}\\end{bmatrix} \\end{array}  <p>The inner product of two vectors is equal to the vector inner product between two matrix representations of those vectors, provided the representations are written with respect to the same orthonormal basis.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#outer-product","title":"Outer product","text":"<p>We can also represent linear operators which makes use of the inner product, known as the inner product representation. Suppose |v\\rangle is a vector in an inner product spave V, and |w\\rangle is a vector in an inner product space W. Define |w\\rangle\\langle v| to be the linear operator from V to W whose action is defined by </p>  (|w\\rangle \\langle v|)(|v'\\rangle) \\equiv |w\\rangle \\langle v|v'\\rangle = \\langle v|v' \\rangle|w\\rangle.  <p>When the operator |w\\rangle \\langle v| acts on |v'\\rangle, it results of multiplying |w\\rangle by the complex number \\langle v|v' \\rangle.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#completness-relation","title":"Completness relation","text":"<p>Let |i\\rangle be any orthonormal basis for the vector space V, so an arbitrary vector |v\\rangle can be written |v\\rangle = \\sum_{i}v_{i}|i\\rangle for some set of complex number v_{i}. Since \\langle i|v\\rangle,</p>  \\bigg( \\sum_{i}|i\\rangle\\langle i|\\bigg)|v\\rangle = \\sum_{i}|i\\rangle\\langle i|v\\rangle = \\sum_{i}v_{i}|i\\rangle = |v\\rangle.  <p>since the last equation is true for all |v\\rangle it follows that </p>  \\sum_{i}|i\\rangle\\langle i | = I, \\ \\text{completness relation}.  <p>Suppose A: V \\rightarrow W is a linear operator, |v_{i}\\rangle is an orthonormal basis for V, and |w_{j}\\rangle and orthonormal basis for W. Using the completeness reltaion twice we obtain</p>  \\begin{array}{rl} A = &amp; I_{W}AI_{V}\\\\ \\ = &amp; \\sum_{ij}|w_{j}\\rangle\\langle w_{j}|A|v_{i}\\rangle\\langle v_{i}|\\\\ \\ = &amp; \\sum_{ij}\\langle w_{j}|A|v_{i}\\rangle|w_{j}\\rangle\\langle v_{i}| \\end{array}  <p>which is the outer product representation for A. An A has matrix element \\langle w_{j}|A|v_{i}\\rangle in the i-th column and j-th row, respect to the inpur basis |v_{i}\\rangle and output basis |w_{j}\\rangle.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#cauchy-schwarz-inequality","title":"Cauchy-Schwarz inequality","text":"<p>%TODO</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#eigenvectors-and-eigenvalues","title":"Eigenvectors and eigenvalues","text":""},{"location":"Quantum_Algorithm_101/Linear_algebra/#adjoints-and-hermitian-operators","title":"Adjoints and Hermitian operators","text":"<p>Suppose A is any linear opeartor on a Hilbert space, V. It turns out that there exist a unique linear operator A^{\\dagger} on V such that for all vectors |v\\rangle, |w\\rangle \\in V,</p>  (|v\\rangle,A|w\\rangle) = (A^{\\dagger}|v\\rangle,|w\\rangle).  <p>This operator is known as the adjoint or Hermitian conjugate of the operator A. </p> <p>(AB)^{\\dagger} = B^{\\dagger}A^{\\dagger}. </p> <p>By convention, if |v\\rangle is a vector then we know |v\\rangle^{\\dagger} \\equiv \\langle v|. Then we know that (A|v\\rangle)^{\\dagger} = \\langle v|A^{\\dagger}.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#projectors","title":"Projectors","text":"<p>An operator A whose adjoint is A is known as a Hermitian or self-adjoint operator. An important class of Hermitian operators is the projectors. Suppose W is a k-dimensional vector subspace of the i-dimentional vector space V.</p> <p>By using Gram-Schmidt procedure it is possible to construct an orthonormal basis |1\\rangle,...,|d\\rangle for V such that |1\\rangle,...,|k\\rangle is an orthonormal basis for W. By definition,</p>  P \\equiv \\sum_{i=1}^{k}|i\\rangle\\langle i|  <p>is the projector onth the subspace W. </p> <p>The orthogonal complement of P is the operator Q\\equiv I-P. Q is a projector onto the vector space spanned by |k+1\\rangle,...,|d\\rangle, which we also refer to as the orthogonal complement of P, and may denote by Q. </p> <p>Any projector P satisfies P^{2} = P.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#normal","title":"Normal","text":"<p>An operator A is said to be normal if AA^{\\dagger} = A^{\\dagger}A. A spectral decomposition theorm states that an operator is a normal operator if and only if it is diagonalizable.</p> <p>A normal matrix is Hermitian if and only if it has real eigenvales.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#unitary","title":"Unitary","text":"<p>A operator/matrix U is said to be unitary if U^{\\dagger}U = I. A unitary operator also satisfies UU^{\\dagger} = I, and therefore U is normal has a spectral decompostion. An unitary operators are important since they preserve inner products between vectors. To see this, let |v\\rangle and |w\\rangle be any two vectors. Then the inner product of U|v\\rangle and U|w\\rangle is the same as the inner product of |v\\rangle and |w\\rangle,</p>  (U|v\\rangle,U|w\\rangle) = \\langle v|U^{\\dagger}U|w\\rangle = \\langle v|I|w\\rangle = \\langle v|w\\rangle.  <p>since (U|v\\rangle)^{\\dagger} = \\langle v|U^{\\dagger}. This result suggests the following outer product representation of any unitary U. Let |v_{i}\\rangle be any orthonormal basis set. Define |w_{i}\\rangle \\equiv U|v_{i}\\rangle, so |w_{i}\\rangle is also an orthonormal basis set, since unitary operators preserve inner products. Note that U = \\sum_{i}|w_{i}\\rangle\\langle v_{i}|.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#positive-operator","title":"Positive operator","text":"<p>A positive operator A is defined to be an operator such that for any vector |v\\rangle, (|v,\\rangle, A|v\\rangle) is a real, non-negative number. If (|v,\\rangle, A|v\\rangle) is strictly greater than zero for all |v\\rangle \\neq 0 then we say A is positive defininte. </p> <p>Any positive operator is automatically Hermitian, and therefore by the spectral decomposition has diagonal representation \\sum_{i}\\lambda_{i}|r\\rangle\\langle i|. with non-negative eigenvalues \\lambda_{i}.</p> <p>Any operator A, A^{\\dagger}A is positive.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#tensor-products","title":"Tensor products","text":"<p>The tensor product is a way of putting vector spaces together to form larger vector spaces. </p> <p>Suppose V and W are vector spaces of dimension m and n respectively. For convenience we also suppose that V and W are Hilbert spaces. Then V\\otimes W is an mn dimensional vector space. In particular, if |i\\rangle and |j\\rangle are orthonormal bases for the spaces V and W then |i\\rangle \\otimes |j\\rangle is a basis for V\\otimes W. Be often use the abbriviationd notations for |v\\rangle|w\\rangle as |vw\\rangle. Here are some of the basic tensor properties:</p> <ol> <li> <p>For an arbitrary scaler z and elements |v\\rangle of V and |w\\rangle for W, $$ z(|v\\rangle\\otimes|w\\rangle) = (z|v\\rangle)\\otimes |w\\rangle = |v\\rangle \\otimes (z|w\\rangle). $$</p> </li> <li> <p>For arbitrary |v_{1}\\rangle and |v_{2}\\rangle in V and |w\\rangle in W, $$ (|v_{1}\\rangle + |v_{2}\\rangle) \\otimes |w\\rangle = |v_{1}\\rangle \\otimes |w\\rangle + |v_{2}\\rangle \\otimes |w\\rangle. $$</p> </li> <li> <p>For arbitrary |v\\rangle in V and |w_{1}\\rangle and |w_{2}\\rangle in W, $$ |v\\rangle \\otimes (|w_{1}\\rangle + |w_{2}\\rangle) = |v\\rangle \\otimes |w_{1}\\rangle + |v\\rangle \\otimes w_{2}\\rangle. $$</p> </li> <li> <p>Suppose we have operators A and B and v\\rangle and |w\\rangle are vectors in V and W, respectively. Then we can defiine a linear operator A\\otimes B on V\\otimes W by the equation $$ (A\\otimes B)(|v\\rangle \\otimes |w\\rangle) \\equiv A|v\\rangle \\otimes B|w\\rangle. $$ The definition of A\\otimes B is then extended to all elements of V\\otimes W, that is, $$ (A\\otimes B)\\bigg(\\sum_{i}a_{i}|v_{i}\\rangle \\otimes |w_{i}\\rangle\\bigg) \\equiv \\sum_{i}a_{i}A|v_{i}\\rangle \\otimes B|w_{i}\\rangle. $$</p> </li> </ol> <p>%TODO, Adding an exmple </p> <p>An arbitrary linear opeartor C mapping V\\otimes W to V'\\otimes W' can be represented as a linear combination of tensor products of operators mapping V to V' and W to W', $$ C = \\sum_{i}c_{i}A_{i}\\otimes B_{i} $$ by definition $$ \\bigg(\\sum_{i}c_{i}A_{i}\\otimes B_{i} \\bigg)|v\\rangle \\otimes |w\\rangle \\equiv \\sum_{i}c_{i}A_{i}|v\\rangle \\otimes B_{i}|w\\rangle. $$</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#kronecker-product","title":"Kronecker product","text":"<p>Suppose A is an m by n matrix, and B is a p by q matrix. Then we have the matrix representation for A\\otimes B:</p>  A\\otimes B =  \\begin{bmatrix} A_{11}B &amp; A_{11}B &amp; ... &amp; A_{1n}B \\\\ A_{11}B &amp; A_{11}B &amp; ... &amp; A_{2n}B \\\\ \\vdots &amp; \\vdots &amp; \\vdots &amp; \\vdots \\\\ A_{m1}B &amp; A_{m1}B &amp; ... &amp; A_{mn}B  \\end{bmatrix}  <p>For example, the tensor product of vectors (1,2) and (2,3) is the vector </p>  \\begin{bmatrix} 1\\\\ 2 \\end{bmatrix} \\otimes \\begin{bmatrix} 2\\\\ 3 \\end{bmatrix} =  \\begin{bmatrix} 1 \\times 2 \\\\ 1\\times 3\\\\ 2 \\times 2\\\\ 2\\times 3 \\end{bmatrix} = \\begin{bmatrix} 2\\\\ 3\\\\ 4\\\\ 6 \\end{bmatrix}   <p>The tensor of the Pauli-X and Pauli-Y is</p>  X\\otimes Y = \\begin{bmatrix} 0\\cdot Y &amp; 1\\cdot Y \\\\ 1\\cdot Y &amp; 0\\cdot Y  \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0 &amp; 0 &amp; -i \\\\ 0 &amp; 0 &amp; i &amp; 0 \\\\ 0 &amp; -i &amp; 0 &amp; 0 \\\\ i &amp; 0 &amp; 0 &amp; 0 \\\\ \\end{bmatrix}  <p>Finally, We introduce the useful notation |\\psi\\rangle^{\\otimes k}, which means |\\psi\\rangle tensored with itself k times. For example, |\\psi\\rangle^{\\otimes 2} = |\\psi\\rangle |\\psi\\rangle.</p> <p>(A\\otimes B)* = A* \\otimes B*; (A \\otimes B)^{T} = A^{T} \\otimes B^{T}; (A\\otimes B)^{\\dagger} = A^{\\dagger} \\otimes B^{\\dagger}.</p> <p>The tensor product of two unitary operators is unitary.</p> <p>The tensor product of two Hermitian operators is Hermitian.</p> <p>The tensor product of two positive operators is positive.</p> <p>The tensor product of two projectors is a projector.</p> <p>A Hadamard operator on one qubit may be written as </p>  H = \\frac{1}{\\sqrt{2}} \\bigg[ (|0\\rangle +|1\\rangle) \\langle 0| + (|0\\rangle -|1\\rangle) \\langle 1|\\bigg].  <p>The Hadamard transform on n qubits, H^{\\otimes n}, can be written as </p>  H^{\\otimes n} = \\frac{1}{\\sqrt{2^{n}}}\\sum_{x,y}(-1)^{x\\cdot y}|x\\rangle \\langle y|."},{"location":"Quantum_Algorithm_101/Linear_algebra/#operator-functions","title":"Operator functions","text":"<p>%TODO Given a function f from the complex numbers to the complex numbers, it is possible to define a corresponding matrix function on normal matrices by the following construction. Let A = \\sum_{a}a|a\\rangle\\langle a| be a spectral decomposition for a normal operator A. Define  $$ f(A)\\equiv \\sum_{a}f(a)|a\\rangle \\langle a| $$ Since f(A) is uniquely defined. </p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#trace","title":"Trace","text":"<p>The trace of A is defined to be the sum of its diagonal elements, $$ \\text{tr}(A) \\equiv \\sum_{i} A_{ii}. $$</p> <p>The trace is easily seen to be cyclic, \\text{tr}(AB) = \\text{tr}(BA), and linear, \\text{tr}(A+B) = \\text{tr}(A) + \\text{tr}(B), \\text{tr}(zA) = z\\text{A}, where A and B are arbitrary matrices and z is a complex number. From the cyclic property it follows that the trace of a matrix is invariant under the unitary similarity transformation A \\mapsto UAU^{\\dagger}, as \\text{tr}(UAU^{\\dagger}) = \\text{tr}(UU^{\\dagger}A) = \\text{tr} = \\text{tr}(A). Thus, it makes sense to define the trace of an operator A to be the trace of any matrix representation of A. </p> <p>Suppose |\\psi\\rangle is a unit vector and A us an arbitrary operator. To evaluate \\text{tr}(A|\\psi\\rangle\\langle\\psi|) use the Gram-Schmidt procedure to extend |\\psi\\rangle to an orthonormal basis |i\\rangle which includes |\\psi\\rangle as the first element. Then we have </p>  \\begin{array}{rl} \\text{tr}(A|\\psi\\rangle\\langle\\psi|) &amp; = \\sum_{i}\\langle i|A|\\psi\\rangle\\langle\\psi|i\\rangle\\\\ \\ &amp; = \\langle \\psi|A|\\psi\\rangle. \\end{array}  <p>The result \\text{tr}(A|\\psi\\rangle\\langle\\psi|) = \\langle \\psi|A|\\rangle is useful in evaluating the trace of an operator.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#the-commutator-and-anti-commutator","title":"The commutator and anti-commutator","text":"<p>The commutator between two operators A and B is defined to be </p>  [A,B] \\equiv AB-BA.  <p>If [A,B] = 0, then we say A commutes with B.</p> <p>The anti-commutator of two operators A and B is defined by </p>  \\{A,B \\} \\equiv AB+BA  <p>We say A anti-commutes with B if \\{A,B\\} = 0</p> <p>It turns out that many important properties of pairs of operators can be deducted from their commutator and anti-commutator. The most useful relation is the following connection between the commutator and the property of being able to simultaneously diagonalize Hermitian operators A and B.</p> <p>Hertimian operators A and B, write A = \\sum_{i}a_{i}|i\\rangle\\langle i|, B = \\sum_{i}b_{i}|i\\rangle\\langle i|, where |i\\rangle is some common orthonormal set of eigenvectors for A and B.</p> <p>(Simultaneous diagonalization theorem) Suppose A and B are Hermitian operators. Then [A,B] =0 if and only if there exists an orthonormal basis such that A and B are diagonal with respect to that basis. We say that A and B are simultaneous diagonalizable in this case. </p> <p>In plain text, if [A,B] = 0 there exist an orthonormal basis such that both A and B are diagonal with respect to that basis.</p> <p>For example, if we want to determine if Pauli-X and Pauli-Y matrix are commute=.</p>  \\begin{array}{rl} [X,Y] &amp; = XY-YX\\\\  &amp; = 2iZ, \\end{array}  <p>so X and Y do not commute. Any we know that X and Y doesn't have common eigenvectors, as we expect from the simultaneous diagonalization theorm.</p> <p>If A and B are diagonal in the same orthonormal basis then [A,B] =0</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#commutation-relations-for-the-pauli-matrices","title":"Commutation relations for the Pauli matrices","text":"<p>We have </p> <ol> <li>[X,Y] = 2iZ</li> <li>[Y,Z] = 2iX</li> <li>[Z,X] = 2iY</li> </ol> <p>we can use \\epsilon_{jkl}, the antisymmetric tensor on three indices, for which \\epsilon_{jkl} =0 expect  for \\epsilon_{123} = \\epsilon_{231} = \\epsilon_{312} = 1, and \\epsilon_{321} = \\epsilon_{213} = \\epsilon_{132} = -1:</p>  [\\sigma_{j},\\sigma_{k}] = 2i\\sum_{l=1}^{3}\\epsilon_{jkl}\\sigma_{l}.  <p>\\{\\sigma_{i}, \\sigma_{j}\\} = 0 where i\\neq j are both chosen from the set 1,2,3. For i = (0,1,2,3), \\sigma_{i}^{2} = I</p> <p>Here are some properties:</p> <p>AB = \\frac{[A,B]+\\{A,B\\}}{2}.</p> <p>Forj,k = 1,2,3, \\sigma_{j}\\sigma_{k} = \\delta_{jk}I + i\\sum_{l=1}^{3} \\epsilon_{jkl}\\sigma_{l}.</p> <p>[A,B]^{\\dagger} = [B^{\\dagger}, A^{\\dagger}].</p> <p>If A and B are Hermitian operators, i[A,B] is also a Hermitian.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#the-polar-and-singular-value-decomposition","title":"The polar and singular value decomposition","text":""},{"location":"Quantum_Algorithm_101/Linear_algebra/#polar-decomposition","title":"Polar decomposition","text":"<p>The polar and singular value decompositions are useful ways of breaking linear operators up into simpler parts. In particular, these decompositions allow us to break general linear operators up into products of unitary operators and positive operators.</p> <p>Polar decomposition</p> <p>Let A be a linear operator on a vector space V. Then there exists unitary U and positive operators J and K such that </p>  A = UJ = KU,  <p>where the unique positive operators J and K satisfying these equations are defined by J\\equiv \\sqrt{A^{\\dagger}A} and K\\equiv \\sqrt{A^{\\dagger}A}. If A is invertible then U is unique.</p> <p>We call the expression A=UJ the left polar decomposition of A, and A=KU the right polar decomposition. For example, give A,</p>  A =  \\begin{bmatrix} 0 &amp; 2 \\\\ 0 &amp; 0 \\end{bmatrix}  <p>We can calcualte J = \\sqrt{A^{\\dagger}A},</p>  A^{\\dagger}A = \\begin{bmatrix} 0 &amp; 0\\\\ 2 &amp; 0 \\end{bmatrix} \\begin{bmatrix} 0 &amp; 2\\\\ 0 &amp; 0 \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0\\\\ 0 &amp; 4 \\end{bmatrix}   J = \\sqrt{A^{\\dagger}A} = \\begin{bmatrix} 0 &amp; 0\\\\ 0 &amp; 2 \\end{bmatrix}  <p>Since A = UJ, we know </p>  \\begin{array}{rl} U = AJ^{-1} = &amp; \\begin{bmatrix} 0 &amp; 2\\\\ 0 &amp; 0 \\end{bmatrix} = \\begin{bmatrix} 0 &amp; 0\\\\ 0 &amp; \\frac{1}{2} \\end{bmatrix}\\\\ \\ = &amp; \\begin{bmatrix} 0 &amp; 0\\\\ 1 &amp; 0 \\end{bmatrix} \\end{array}  <p>The matrix U must be a unitary matrix.</p>"},{"location":"Quantum_Algorithm_101/Linear_algebra/#singluar-decompostion","title":"Singluar Decompostion","text":"<p>Singluar Decompostion</p> <p>Let A be a square matrix. Then there exist unitary matrices U and V , and a diagonal matrix D with non-negative entries such that</p>  A = UDV  <p>The diagonal elements of D are called the singular values of A. SVD works for all matrices, real or complex.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/","title":"Quantum gates","text":""},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#single-qubit-gates","title":"Single qubit gates","text":"<p>Classical computer circuits consist of wires and logic gates.</p> <p>Suppose we define a matrix X ro represent the quantum <code>NOT</code> gate as follows:</p>  X \\equiv \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}.  <p>If the quantum state \\alpha|0\\rangle + \\beta|1\\rangle is written in a vector notation as </p>  \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix}  <p>with teh top entry corresponding to teh amplitude for |0\\rangle and the bottom entry the amplitude for |1\\rangle, then the corresponding output from the quantum <code>NOT</code> gate is </p>  X \\begin{bmatrix} \\alpha \\\\ \\beta \\end{bmatrix} = \\begin{bmatrix} \\beta \\\\ \\alpha \\end{bmatrix}.  <p>So we know that quantum gates on a single qubit can be described by 2-2 matrices. The appropriate condition on the matirx representing the gate is taht the matrix U describing the single qubit be unitary, that is, U^{\\dagger}U = I, where U^{\\dagger} is an adjoint of U (obtained by transponsing and then complex conjugating U), and I is the 2-2 identity matrix. For example, X^{\\dagger}X = I. And this is the only constrain on quantum gates.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#z-gate","title":"Z gate","text":"<p>The Z gate</p>  Z \\equiv \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; -1 \\end{bmatrix}.  <p>We can clearly see that Z gate flips the sign of the state |1\\rangle. Given </p>  \\begin{array}{lll} Z|\\psi\\rangle &amp; = &amp; \\alpha Z|0\\rangle + \\beta Z|1\\rangle \\\\  &amp; = &amp; \\alpha |0\\rangle - \\beta |1\\rangle \\\\  &amp; = &amp; \\text{cos}(\\frac{\\theta}{2})|0\\rangle - e^{i\\phi} \\text{sin}(\\frac{\\theta}{2})|1\\rangle \\\\  &amp; = &amp; \\text{cos}(\\frac{\\theta}{2})|0\\rangle + e^{i(\\phi + \\pi)} \\text{sin}(\\frac{\\theta}{2})|1\\rangle \\\\ \\end{array}  <p>where </p>  e^{i\\pi} + 1 = 0 \\ (\\text{Euler's formula})  <p>by Euler's formula. We can tell that Z gates rotate the state along Z axis on XY-plane (\\phi) with \\pi degrees in a Bloch shpere.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#hadamard-gate","title":"Hadamard gate","text":"H \\equiv \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 &amp; 1 \\\\ 1 &amp; -1 \\end{bmatrix}.  <p>It turns a |0\\rangle into (|0\\rangle + |1\\rangle)/\\sqrt{2} (first column of H), 'halfway' bewteen |0\\rangle and |1\\rangle, and it turns |0\\rangle into (|0\\rangle - |1\\rangle)/\\sqrt{2} (second column of H), which is also 'halfway' bewteen |0\\rangle and |1\\rangle. The Hadamard gate is one of the most useful quantum gates, it turns out that single qubit gates correspond to ratations and reflections of the sphere. The Hadamard operation is just a roatation of the spohere about the y axis by \\pi/2, followed by a rotation about x axis by \\pi.</p>  \\begin{array}{lll} H|0\\rangle &amp; = &amp; \\frac{(|0\\rangle + |1\\rangle)}{\\sqrt{2}} = |+\\rangle\\\\ H|1\\rangle &amp; = &amp; \\frac{(|0\\rangle - |1\\rangle)}{\\sqrt{2}} = |-\\rangle \\end{array}  <p>         Single qubit gate examples of X, Z, and H gate.     </p> <p>An arbitrary singel qubit unitary gate can be decompsed as a product of rotations </p>  \\begin{bmatrix}  \\text{cos}\\frac{\\gamma}{2} &amp; -\\text{sin}\\frac{\\gamma}{2} \\\\  \\text{sin}\\frac{\\gamma}{2} &amp; \\text{cos}\\frac{\\gamma}{2}  \\end{bmatrix},  <p>and a gate being rotation about the z axis.</p>  \\begin{bmatrix} e^{-i\\beta/2} &amp; 0 \\\\  0 &amp; e^{i\\beta/2} \\end{bmatrix},  <p>together with a (global) phase shift - a constand multiplier of the form e^{i\\alpha}. We don't need to be able to do these gates for arbitrary \\alpha, \\beta, \\gamma but can build arbitrarily good approximations to such gates using only certain special fixed values of \\alpha, \\beta and \\gamma. An arbitrary 2\\times 2 unitary matrix may be decomposed as </p>  U = e^{i\\alpha} \\begin{bmatrix} e^{-i\\beta/2} &amp; 0 \\\\  0 &amp; e^{i\\beta/2} \\end{bmatrix} \\begin{bmatrix}  \\text{cos}\\frac{\\gamma}{2} &amp; -\\text{sin}\\frac{\\gamma}{2} \\\\  \\text{sin}\\frac{\\gamma}{2} &amp; \\text{cos}\\frac{\\gamma}{2}  \\end{bmatrix} \\begin{bmatrix} e^{-i\\delta/2} &amp; 0 \\\\  0 &amp; e^{i\\delta/2} \\end{bmatrix},  <p>where \\alpha, \\beta, \\gamma and \\gamma are real-valued. Notice that the second matrix is just an ordinary rotation. It turns out that the first and last matrices can also be understood as rotations in a different plane.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#cnot-gate","title":"CNOT gate","text":"<p>A controlled-NOT gate, also called CNOT gate, which has two input qubits, known as the control and target qubit, respectively. The action of the gate can be summarized as </p>  |A,B\\rangle \\rightarrow |A, B\\oplus A\\rangle  <p>where \\oplus is addition modulo two. The results of a two-qubit input can be </p>  \\begin{array}{c} |00\\rangle \\rightarrow |00\\rangle \\\\ |01\\rangle \\rightarrow |01\\rangle \\\\ |10\\rangle \\rightarrow |11\\rangle \\\\ |11\\rangle \\rightarrow |10\\rangle  \\end{array}  <p>in a matrix format</p>  \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0  \\end{bmatrix}  <p>Of course, <code>CNOT</code> gate is also a unitary matrix where U^{\\dagger}_{CNOT}U_{CNOT} = I. However, in a sense the <code>CNOT</code> and single qubit gates are the prototypes for all other gates because of the following remarkable universality result: Any multiple qubit logic gate may be composed from <code>CNOT</code> and single qubit gates.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#swap-gate","title":"SWAP gate","text":"<p>The SWAP gate swaps the states of the two qubits. To see that this circuit accomplishes the swap operation, note that the sequence of gates has the following sequence of effects on a computational basis state</p> <p>         SWAP gate for 2-qubit state     </p> <p>where all additions are done modulo 2. Mathematically, the SWAP gate's action on a quantum state is </p>  \\text{SWAP}(|\\psi_{1}\\rangle|\\psi_{2}\\rangle) = |\\psi_{2}\\rangle|\\psi_{1}\\rangle  <p>The matrix fomat is </p>  \\text{SWAP} =  \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1  \\end{bmatrix}  <p>The SWAP gate is extremely useful in hardware settings; if two qubits are not physically connected, we can simply swap one of those qubits with another that is physically connected to the other qubit. The SWAP gate may also appear as a necessary part in building the quantum Fourier transform or in other routines such as the SWAP test.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#toffoli-gate","title":"Toffoli Gate","text":"<p>         Toffoli gate and its truth table     </p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#basic","title":"Basic","text":"<p>we can write the vector representation for 2 qubits as</p>  \\lvert \\psi \\rangle = v_{00} \\lvert 00 \\rangle + v_{01}\\lvert 01 \\rangle + v_{10} \\lvert 10 \\rangle + v_{11} \\lvert 11 \\rangle\\ \\rightarrow  \\begin{bmatrix} v_{00} \\\\ v_{01} \\\\ v_{10} \\\\ v_{11} \\\\ \\end{bmatrix}"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#unitary-matrices","title":"Unitary Matrices","text":"<p>From the quantum mechanics, the only matrics that we can use are the unitary matrices, which are the matrices U such that: $$ U^{\\dagger}U = UU^{\\dagger} = I, $$ where I is the identity matrix and u^{\\dagger} is the adjoint of U, that is, the matrix obtained by transposing U and replaing each element by its complex conjugate. This means that any unitary matrix U is invertible and its inverse is given by U^\\dagger. in quantum mechanics, the operations represented by these matrices are called quantum gates.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#hadamard-gate_1","title":"Hadamard Gate","text":"<p>The Hadamard gate is a single-qubit operation that maps the basis state \\lvert 0 \\rangle to \\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}} and \\lvert 1 \\rangle to \\frac{\\lvert 0 \\rangle - \\lvert 1 \\rangle}{\\sqrt{2}}, which creates an equal superposition of the basis states.</p>  H = \\frac{1}{\\sqrt{2}}  \\begin{bmatrix} 1 &amp; 1  \\\\ 1 &amp; -1  \\\\ \\end{bmatrix}  <p>if we apply H gate on a qubits in state \\lvert 0 \\rangle and \\lvert 1 \\rangle, we have:</p>  H\\lvert0\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle+\\lvert1\\rangle)  <p>which is called mplus state and it is denoted as \\lvert+\\rangle; and </p>  H\\lvert1\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle-\\lvert1\\rangle)  <p>which is called minus state and it is denoted as \\lvert-\\rangle.</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#pauli-x-gate","title":"Pauli-X gate","text":"<p>The pauli-X gate is a single-qubis rotation through \\pi radians around the X-axis. X gate is also called <code>NOT</code> gate, since it performs like a <code>NOT</code> gate in classical digital circuits. Here's why:</p>  X =  \\begin{bmatrix} 0 &amp; 1  \\\\ 1 &amp; 0 \\\\ \\end{bmatrix}  <p>Apply X gate to \\lvert 0 \\rangle and \\lvert 1 \\rangle, we have:</p>  X\\lvert0\\rangle =   \\begin{array}{cc} \\begin{bmatrix} 0 &amp; 1  \\\\ 1 &amp; 0 \\\\ \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 1 \\\\ \\end{bmatrix} = \\lvert 1 \\rangle ,&amp;  X\\lvert1\\rangle =   \\begin{bmatrix} 0 &amp; 1  \\\\ 1 &amp; 0 \\\\ \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\\\ \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ \\end{bmatrix} = \\lvert 0 \\rangle \\end{array}"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#pauli-y-gate","title":"Pauli-Y gate","text":"<p>The Pauli-Y gate is a single-qubit rotation through \u03c0 radians around the y-axis.</p>   Y = \\sigma_{y} = \\sigma_{2} = \\begin{bmatrix} 0 &amp; -i  \\\\ i &amp; 0  \\\\ \\end{bmatrix}"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#pauli-z-gate","title":"Pauli-Z gate","text":"<p>The Pauli-Z gate is a single-qubit rotation through \u03c0 radians around the z-axis.</p>   Z = \\sigma_{z} = \\sigma_{3} = \\begin{bmatrix} 1 &amp; 0  \\\\ 0 &amp; -1 \\\\ \\end{bmatrix}  <p>What if we apply an H gate, then an X gate and, finally, another H gate. we have:</p>  Z =  \\begin{bmatrix} 1 &amp; 0\\\\ 0 &amp; -1 \\\\ \\end{bmatrix}  <p>and we have the following properties for when we apply Z on \\lvert 0 \\rangle and \\lvert 1 \\rangle:</p>  \\begin{array}{ccc} Z \\lvert0\\rangle = \\lvert0\\rangle &amp; \\text{and} &amp; Z\\lvert1\\rangle = -\\lvert1\\rangle \\end{array}"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#s-gates","title":"S gates","text":"<p>S gate is given by:</p>  S =  \\begin{bmatrix} 1 &amp; 0  \\\\ 0 &amp; e^{i\\frac{\\pi}{2}} \\\\ \\end{bmatrix}"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#t-gates","title":"T gates","text":"<p>T gate is also called as a \\pi/8 gate. T gate is given by:</p>  T =  \\begin{bmatrix} 1 &amp; 0  \\\\ 0 &amp; e^{i\\frac{\\pi}{4}} \\\\ \\end{bmatrix}  <p>You may wonder why T gate is called the \\pi/8 gate when it is \\pi/4 that apperas in the definition. The reason is that the gate has historically often been referred to as the \\pi/8 gate, simply because up to an unimportant global phase T is equal to a gate which has \\text{exp}(\\pm i\\pi/8) appearing on its diagonals</p>  T = e^{i\\pi/8}\\begin{bmatrix} e^{-i\\pi/8} &amp; 0 \\\\ 0 &amp; e^{i\\pi/8}  \\end{bmatrix}.  <p>Here are useful algebraic facts to keep in mind are </p>  H = \\frac{X+Z}{\\sqrt{2}} \\ \\text{and} \\ S = T^{2}."},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#controlled-x-cnot-gate","title":"Controlled-X (CNOT) Gate","text":"<p>CNOT gate: The value of the second qubit is flipped if and only if the value of the first qubit is 1.</p> <p> </p> <p>Matrix Representation of the CNOT Gate In the computational basis \\{\\lvert 00 \\rangle,\\lvert 01 \\rangle, \\lvert 10 \\rangle, \\lvert 11 \\rangle\\}, the CONT gate is represented as a 4x4 matrix:</p>  \\text{CNOT} = \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{bmatrix}  <ul> <li>The first qubit is the control qubit.</li> <li>The second qubit is the target qubit.</li> </ul> <p>And, if we apply <code>CNOT</code> gate on the element of the two-qubit computational basis, we can get,</p>  \\begin{array}{cccc}     \\text{CNOT}\\lvert00\\rangle = \\lvert00\\rangle,&amp;      \\text{CNOT}\\lvert01\\rangle = \\lvert01\\rangle,&amp;      \\text{CNOT}\\lvert10\\rangle = \\lvert11\\rangle,&amp;      \\text{CNOT}\\lvert11\\rangle = \\lvert10\\rangle \\end{array}"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#controlled-y-cy-gate","title":"Controlled-Y (CY) Gate","text":""},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#controlled-z-cz-gate","title":"Controlled-Z (CZ) Gate","text":""},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#controlled-h-ch-gate","title":"Controlled-H (CH) Gate","text":""},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#rotation-operatos","title":"Rotation operatos","text":"<p>The Pauli matrices give rise to three useful classes of unitary matrices when they are exponentiated, the rotation operaots about x,y, and z axes, defined by the equations:</p>  \\begin{array}{ll} R_{x}(\\theta) \\equiv e^{-i\\theta X/2} = \\text{cos}\\frac{\\theta}{2}I - i \\text{sin}\\frac{\\theta}{2}X &amp;= \\begin{bmatrix} \\text{cos}\\frac{\\theta}{2} &amp; -i\\text{sin}\\frac{\\theta}{2} \\\\ -i\\text{sin}\\frac{\\theta}{2} &amp; \\text{cos}\\frac{\\theta}{2} \\end{bmatrix}\\\\ R_{y}(\\theta) \\equiv e^{-i\\theta X/2} = \\text{cos}\\frac{\\theta}{2}I - i \\text{sin}\\frac{\\theta}{2}Y &amp;= \\begin{bmatrix} \\text{cos}\\frac{\\theta}{2} &amp; -\\text{sin}\\frac{\\theta}{2} \\\\ \\text{sin}\\frac{\\theta}{2} &amp; \\text{cos}\\frac{\\theta}{2} \\end{bmatrix}\\\\ R_{z}(\\theta) \\equiv e^{-i\\theta X/2} = \\text{cos}\\frac{\\theta}{2}I - i \\text{sin}\\frac{\\theta}{2}Z &amp;= \\begin{bmatrix} e^{-i\\theta/2} &amp; 0 \\\\ 0 &amp; e^{i\\theta/2} \\end{bmatrix} \\end{array}  <p>Theorem 4.1 (Z-Y decomposition for a single qubit)</p> <p>suppose U is a unitary operation on a single qubit. Then there exist real numbers \\alpha, \\beta, \\gamma, and \\delta such that  $$ U = e^{i\\alpha}R_{z}(\\beta)R_{y}(\\gamma)R_{z}(\\delta). $$ Since U is unitary, the rows and columns of U are orthonormal, from which it folow that there exist real numbers \\alpha, \\beta, \\gamma, and \\delta such that  $$ U =  \\begin{bmatrix} e^{i(\\alpha - \\beta)/2-\\delta/2}\\text{cos}\\frac{\\gamma}{2} &amp; -e^{i(\\alpha - \\beta)/2+\\delta/2}\\text{sin}\\frac{\\gamma}{2} \\  e^{i(\\alpha + \\beta)/2-\\delta/2}\\text{sin}\\frac{\\gamma}{2} &amp; -e^{i(\\alpha + \\beta)/2+\\delta/2}\\text{cos}\\frac{\\gamma}{2} \\end{bmatrix} $$</p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#exercises","title":"Exercises","text":"<p>Exercises 4.4</p> <p>Express the Hadamard gate H as a product of R_x and R_z rotations and e^{i\\phi} for some \\phi <p> </p> </p> <p>Exercises 4.5</p> <p>Proof that (\\widehat{n}\\cdot \\overrightarrow{\\sigma}) = I.  <p> </p> <p> </p> </p> <p>Exercises 4.7</p> <p>Show that XYX = -Y and use this rto prove that XR_{y}(\\theta)X = R_{y}(-\\theta).  <p> </p> </p> <p>Exercises 4.8</p> <p>An arbitrary single qubit unitary operator can be written in the form </p>  U = e^{i\\alpha}R_{\\widehat{n}}(\\theta)  <p>please find values for \\alpha, \\theta, and \\widehat{n} giving the Hadamard gate H.</p> <p> <p> </p> </p>"},{"location":"Quantum_Algorithm_101/Quantum_logic_gates/#references","title":"References","text":"<p>[1] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p> <p>[2]. https://pennylane.ai/qml/glossary/what-is-a-swap-gate</p>"},{"location":"Quantum_Algorithm_101/Qubit/","title":"Qubit(s)","text":""},{"location":"Quantum_Algorithm_101/Qubit/#dirac-notation-and-inner-products","title":"Dirac notation and inner products","text":"<p>with each ket we can associate a bra that is its adjoint or conjugate transpose or Hermitian transpose.</p>  \\begin{array}{cc}     \\langle 0 \\lvert = \\lvert 0 \\rangle^{\\dagger} = \\bigg(     \\begin{array}{c}     1 \\\\ 0     \\end{array}     \\bigg)^{\\dagger}     =     \\bigg(     \\begin{array}{c}     1 &amp; 0     \\end{array}     \\bigg)     ,&amp;     \\langle 0 \\lvert = \\lvert 0 \\rangle^{\\dagger} = \\bigg(     \\begin{array}{c}     0 \\\\ 1     \\end{array}     \\bigg)^{\\dagger}     =     \\bigg(     \\begin{array}{c}     1 &amp; 0     \\end{array}     \\bigg) \\end{array}  <p>and, in gernal, $$ a\\langle 0 \\lvert + b\\langle 1 \\lvert = a\\lvert 0 \\rangle^{\\dagger} + b\\lvert 1 \\rangle^{\\dagger} = a \\bigg(\\begin{array}{c} 1 &amp; 0 \\end{array} \\bigg) + b \\bigg(\\begin{array}{c} 0 &amp; 1 \\end{array} \\bigg) = \\bigg(\\begin{array}{c} a &amp; b \\end{array} \\bigg) $$ More, we can also compute the following properties:</p> <p>--inner product properties--</p> <p>This proves that \\lvert 0 \\rangle and \\lvert 1 \\rangle are not just elements of any basis but of an orthonormal one, since \\lvert 0 \\rangle and \\lvert 0 \\rangle are orthogonal and of length 1. Thus we can calcualte the inner product of two states \\lvert \\psi_{1} \\rangle = a\\lvert 0 \\rangle + b\\lvert 1 \\rangle and \\lvert \\psi_{2} \\rangle = c\\lvert 0 \\rangle + d\\lvert 1 \\rangle as:</p>  \\begin{array}{cll} \\langle \\psi_{1}\\lvert\\psi_{2} \\rangle^{\\dagger} &amp; = &amp; (a^{*}\\langle0\\lvert+b^{*}\\langle1\\lvert)(c^{*}\\lvert0\\rangle+d^{*}\\lvert1\\rangle)\\\\  &amp; = &amp; a^{*}c\\langle0\\lvert0\\rangle+a^{*}d\\langle0\\lvert1\\rangle+b^{*}c\\langle1\\lvert0\\rangle+b^{*}d\\langle1\\lvert1\\rangle\\\\  &amp; = &amp; a^{*}b+c^{*}d \\end{array}  <p>where a^{*} and b^{*} are the complex cpmjugates of a and b</p>"},{"location":"Quantum_Algorithm_101/Qubit/#one-qubit-quantum-gates","title":"One-Qubit Quantum gates","text":""},{"location":"Quantum_Algorithm_101/Qubit/#the-schrodinger-equation","title":"The Schrodinger equation","text":"<p>The time-dependent Schr\u00f6dinger equation is given by:</p>  \\hat{H} \\lvert\\psi(t)\\rangle = i \\hbar \\frac{\\partial \\lvert\\psi(t)\\rangle}{\\partial t}  <p>where:</p> <ol> <li>\\hbar is the reduced Planck's constant,</li> <li>\\lvert\\psi(t)\\rangle = \\psi(x,t) is the wave function,</li> <li>\\hat{H} is the Hamiltonian operator.</li> </ol> <p>To program a quantum computer, you don\u2019t need to know how to solve Schr\u00f6dinger\u2019s equation. In fact, the only thing that you need to know is that its solutions are always a special type of linear transformations. For the purposes of the quantum circuit model, since we are working in finite-dimensional spaces and we have fixed a basis, the operations can be described by matrices that are applied to the vectors that represent the states of the qubits.</p>"},{"location":"Quantum_Algorithm_101/Qubit/#two-qubits-and-entanglement","title":"Two qubits and entanglement","text":""},{"location":"Quantum_Algorithm_101/Qubit/#two-qubit-state","title":"Two-qubit state","text":"<p>For a two-qubit state system, we have four possibilities form a basis(computational basis) of a 4-dimensional space,</p>  \\begin{array}{cccc} \\lvert0\\rangle \\otimes \\lvert0\\rangle,&amp; \\lvert0\\rangle \\otimes \\lvert1\\rangle,&amp; \\lvert1\\rangle \\otimes \\lvert0\\rangle,&amp; \\lvert1\\rangle \\otimes \\lvert1\\rangle \\end{array}  <p>The symbol \\otimes is a tensor product. The tensor product of two column vectors is defined by</p>"},{"location":"Quantum_Algorithm_101/Qubit/#tensor-product","title":"Tensor Product","text":"<p>The tensor product of two vectors is defined as:</p>  \\begin{pmatrix} a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_n \\end{pmatrix} \\otimes \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} = \\begin{pmatrix} a_1 \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} \\\\ a_2 \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} \\\\ \\vdots \\\\ a_n \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} a_1 b_1 \\\\ a_1 b_2 \\\\ \\vdots \\\\ a_1 b_m \\\\ a_2 b_1 \\\\ a_2 b_2 \\\\ \\vdots \\\\ a_2 b_m \\\\ \\vdots \\\\ a_n b_1 \\\\ a_n b_2 \\\\ \\vdots \\\\ a_n b_m \\end{pmatrix}  <p>Therefore, we expand four states</p>  \\begin{array}{cccc} \\lvert0\\rangle \\otimes \\lvert0\\rangle = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}, &amp;  \\lvert0\\rangle \\otimes \\lvert1\\rangle = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, &amp;  \\lvert1\\rangle \\otimes \\lvert0\\rangle = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\\\ 0 \\end{pmatrix}, &amp;  \\lvert1\\rangle \\otimes \\lvert1\\rangle = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}  \\end{array}  <p>We usually omit the \\otimes and just write,</p>  \\begin{array}{cccc} \\lvert00\\rangle, &amp; \\lvert01\\rangle, &amp; \\lvert10\\rangle, &amp; \\lvert11\\rangle &amp; \\end{array}  <p>The general expression for the state of such system is </p>  \\lvert\\psi\\rangle = a_{00}\\lvert00\\rangle+a_{01}\\lvert01\\rangle+a_{10}\\lvert10\\rangle+a_{11}\\lvert11\\rangle  <p>where a_{00}, a_{01}, a_{10}, a_{11} are complex numbers or amplitudes such that \\sum_{x, y=0}^{1}|a_{xy}|^{2} = 1. If we measure in the computational basis both qubits at this generic state that we are considering, we will obtain \\gamma with probability |a_{\\gamma}|^{2} where \\gamma \\in [00, 01, 10, 11].</p>"},{"location":"Quantum_Algorithm_101/Qubit/#what-if-we-only-measure-one-computational-basis-0","title":"What if we only measure one computational basis 0?","text":"<p>The result will show that the system is not collapse completely, but it will remain in the state</p>  \\frac{a_{00}\\lvert00\\rangle+a_{01}\\lvert01\\rangle}{\\sqrt{|a_{00}|^{2} + |a_{01}|^{2}}}  <p>Also, recall the inner product of the one qubit case, we can apply inner product to </p>  (\\langle\\psi_{2}\\lvert\\otimes\\langle\\psi_{2}\\lvert)(\\lvert\\phi_{1}\\rangle\\otimes\\lvert\\phi_{2}\\rangle) = \\langle\\phi_{1}\\lvert\\phi_{1}\\rangle\\langle\\phi_{2}\\lvert\\phi_{2}\\rangle"},{"location":"Quantum_Algorithm_101/Qubit/#two-qubit-gate-tensor-products","title":"Two-qubit gate: tensor products","text":"<p>The tensor product of two matrices is defined as:</p>  \\begin{pmatrix} a_{11} &amp; a_{12} \\\\ a_{21} &amp; a_{22} \\end{pmatrix} \\otimes \\begin{pmatrix} b_{11} &amp; b_{12} \\\\ b_{21} &amp; b_{22} \\end{pmatrix} = \\begin{pmatrix} a_{11} \\begin{pmatrix} b_{11} &amp; b_{12} \\\\ b_{21} &amp; b_{22} \\end{pmatrix} &amp; a_{12} \\begin{pmatrix} b_{11} &amp; b_{12} \\\\ b_{21} &amp; b_{22} \\end{pmatrix} \\\\ a_{21} \\begin{pmatrix} b_{11} &amp; b_{12} \\\\ b_{21} &amp; b_{22} \\end{pmatrix} &amp; a_{22} \\begin{pmatrix} b_{11} &amp; b_{12} \\\\ b_{21} &amp; b_{22} \\end{pmatrix} \\end{pmatrix}   = \\begin{pmatrix} a_{11} b_{11} &amp; a_{11} b_{12} &amp; a_{12} b_{11} &amp; a_{12} b_{12} \\\\ a_{11} b_{21} &amp; a_{11} b_{22} &amp; a_{12} b_{21} &amp; a_{12} b_{22} \\\\ a_{21} b_{11} &amp; a_{21} b_{12} &amp; a_{22} b_{11} &amp; a_{22} b_{12} \\\\ a_{21} b_{21} &amp; a_{21} b_{22} &amp; a_{22} b_{21} &amp; a_{22} b_{22} \\end{pmatrix}."},{"location":"Quantum_Algorithm_101/Qubit/#cnot-gate","title":"CNOT Gate","text":"<p>CNOT gate: The value of the second qubit is flipped if and only if the value of the first qubit is 1. The application of a NOT gate on the second qubit (that we call the target) is controlled by the first qubit.</p> <p></p> <p>Notice that the control qubit is indicated by a solid black circle and the target qubit is indicated by the \\oplus symbol (the symbol for an X gate can also be used instead of \\oplus).</p>  \\text{CNOT} = \\begin{pmatrix} 1 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 \\end{pmatrix}.  <p>And, if we apply <code>CNOT</code> gate on the element of the two-qubit computational basis, we can get,</p>  \\begin{array}{cccc} \\text{CNOT}\\lvert00\\rangle = \\lvert00\\rangle,&amp;  \\text{CNOT}\\lvert01\\rangle = \\lvert01\\rangle,&amp;  \\text{CNOT}\\lvert10\\rangle = \\lvert11\\rangle,&amp;  \\text{CNOT}\\lvert11\\rangle = \\lvert10\\rangle \\end{array}"},{"location":"Quantum_Algorithm_101/Qubit/#swap","title":"Swap","text":"<p>In any case, the most prominent use of the CNOT gate is, without a doubt, the ability to create entanglement.</p>"},{"location":"Quantum_Algorithm_101/Qubit/#entanglement","title":"Entanglement","text":"<pre><code>Entanglement, without doubt, is one of the most powerful resources available in quantum computing!\n</code></pre> <p>We say the a state \\lvert\\psi\\rangle is a product state if it can be written as the tensor product of two other states \\lvert\\psi_{1}\\rangle and \\lvert\\psi_{2}\\rangle, each of at least one qubit, as in</p>  \\lvert\\psi\\rangle = \\lvert\\psi_{1}\\rangle \\otimes \\lvert\\psi_{2}\\rangle  <p>If \\lvert\\psi_{1}\\rangle is not a product, we say that it is entangled. For instance, we said that \\lvert00\\rangle is a product state, since we can write it as \\lvert\\psi_{0}\\rangle\\otimes \\lvert\\psi_{0}\\rangle. In the same fashion, we can also write \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle+\\lvert10\\rangle) in a product state as:</p>  \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle+\\lvert10\\rangle) = \\frac{1}{\\sqrt{2}}\\bigg(\\lvert0\\rangle+\\lvert1\\rangle\\bigg)\\lvert0\\rangle  <p>However, state \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle+\\lvert11\\rangle) is an entangled state since no matter how hard you try you cannot factor it into a product state. here, we can try to proof this by:</p>  \\begin{array}{lll} \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle+\\lvert11\\rangle) &amp; = &amp; (a\\lvert0\\rangle+b\\lvert1\\rangle)(c\\lvert0\\rangle+d\\lvert1\\rangle)\\\\  &amp; = &amp; ac\\lvert00\\rangle + ad\\lvert01\\rangle + bc\\lvert10\\rangle + bd\\lvert11\\rangle \\end{array}  <p>we need ad and bc to be 0, because we don't have \\lvert01\\rangle element in \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle+\\lvert11\\rangle). Then, either a = 0, inwhice case ac = 0 or d=0 from which bd=0 follows. These two cases cannot reach the equality that we needed. Thus, we can say that this state is entangled.</p> <p>When we measure an entangled state, let's say, state \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle+\\lvert11\\rangle), we measure the firt qubit, we can obtain 0 or 1, with each probability of 50\\%. In this case, the state of the second qubit is detemined when we measure the first qubit, which will be the same as the first qubit. And so does the probability of the first qubit if we measure the second qubit first in our case.</p>"},{"location":"Quantum_Algorithm_101/Qubit/#the-no-cloning-therom","title":"The no-cloning therom","text":"<p>Another interesring property of quantum systems is the no-cloning theorm. Check No-cloning for proof. In short, for an example, if we would like to have a two-qubit quantum gate U that will be able to copy the first qubit into the second. we would need,</p>  U(\\lvert\\psi\\rangle \\otimes \\lvert0\\rangle) = \\lvert\\psi\\rangle \\otimes \\lvert\\psi\\rangle  <p>from above, we know that U\\lvert00\\rangle = \\lvert00\\rangle and U\\lvert10\\rangle = \\lvert11\\rangle. Therefore,</p>  U\\bigg(\\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle)\\bigg) = \\frac{1}{\\sqrt{2}}(U\\lvert00\\rangle + U\\lvert10\\rangle) = \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert11\\rangle).  <p>Then, from previous example, we also know that \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle can be written in a product form,</p>  \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle = \\frac{1}{\\sqrt{2}}\\bigg(\\lvert0\\rangle + \\lvert1\\rangle\\bigg)\\lvert0\\rangle   <p>Now, let's apply gate U, we should have,</p>  U\\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle = U\\bigg(\\frac{1}{\\sqrt{2}}\\bigg(\\lvert0\\rangle + \\lvert1\\rangle\\bigg)\\lvert0\\rangle\\bigg) =  \\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}\\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}  <p>which is a product state, and we also know have U\\bigg(\\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle)\\bigg) = \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert11\\rangle),</p>  \\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}\\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}\\neq \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert11\\rangle)  <p>therefore, no such gate U exist.</p>"},{"location":"Quantum_Algorithm_101/Qubit/#controlled-gates","title":"Controlled gates.","text":"<p>For any quantum gate U, it is possible to define a controlled-U (or CU) gate whose action on the computational basis is,</p>  \\begin{array}{cccc} CU\\lvert00\\rangle = \\lvert00\\rangle,&amp;  CU\\lvert01\\rangle = \\lvert01\\rangle,&amp;  CU\\lvert10\\rangle = \\lvert1U0\\rangle,&amp;  CU\\lvert11\\rangle = \\lvert1U1\\rangle,&amp;  \\end{array}  <p>The matrix representing the controlled U is,</p>  \\begin{bmatrix} 1 &amp; 0 &amp; 0 &amp; 0\\\\ 0 &amp; 1 &amp; 0 &amp; 0\\\\ 0 &amp; 0 &amp; u_{00} &amp; u_{01}\\\\ 0 &amp; 0 &amp; u_{10} &amp; u_{11}\\\\ \\end{bmatrix}  <p>The circuit representation of a CU gate is,</p> <p></p> <p>where the solid black circle indicates the control and the box with U inside indicates the target. For any one-qubit quantum gate U can be written in the form,</p>  U = e^{i\\theta} AXBXC  <p>for some angle \\theta and gates A, B, C such that ABC = I. Sometimes,, its easy to construct a contrelled gate. For instance, two H-gates with one $$-gate can make one controlled Z-gate.</p> <p></p> <p>Sometimes, constructing a controlled gate is mush easier. it can be shown that a controlled-Z gate.</p>"},{"location":"Quantum_Algorithm_101/Qubit/#entangled-circuit","title":"Entangled circuit","text":"<p>Let's consider the bell state. First we consider the computational basis \\lvert00\\rangle and apply and H-gate. Then we apply a CNOT gate. The state change from \\frac{\\lvert00\\rangle+\\lvert10\\rangle}{\\sqrt{2}} to \\frac{\\lvert00\\rangle+\\lvert11\\rangle}{\\sqrt{2}}, which we have already proved that is indeed an entangled state.</p> <p></p> <p>Below are the four possible Bell states:</p>  \\begin{aligned} \\lvert\\beta_{00}\\rangle = \\lvert\\Phi^+\\rangle &amp; = \\frac{\\lvert00\\rangle + \\lvert11\\rangle}{\\sqrt{2}} \\\\ \\lvert\\beta_{01}\\rangle = \\lvert\\Psi^+\\rangle &amp; = \\frac{\\lvert01\\rangle + \\lvert10\\rangle}{\\sqrt{2}} \\\\ \\lvert\\beta_{10}\\rangle = \\lvert\\Phi^-\\rangle &amp; = \\frac{\\lvert00\\rangle - \\lvert11\\rangle}{\\sqrt{2}} \\\\ \\lvert\\beta_{11}\\rangle = \\lvert\\Psi^-\\rangle &amp; = \\frac{\\lvert01\\rangle - \\lvert10\\rangle}{\\sqrt{2}} \\end{aligned}  <p>All of these four states are entangled.</p>"},{"location":"Quantum_Algorithm_101/Qubit/#multiple-qubits-and-universality","title":"Multiple qubits and universality","text":""},{"location":"Quantum_Algorithm_101/Qubit/#multi-qubit-systems","title":"Multi-qubit systems","text":"<p>If we ahve n qubits, the states that constitute the computational basis are,</p>  \\begin{array}{c} \\lvert0\\rangle \\otimes \\lvert0\\rangle \\otimes \\cdots \\otimes \\lvert0\\rangle,\\\\ \\lvert0\\rangle \\otimes \\lvert0\\rangle \\otimes \\cdots \\otimes \\lvert1\\rangle,\\\\ \\vdots\\\\ \\lvert1\\rangle \\otimes \\lvert1\\rangle \\otimes \\cdots \\otimes \\lvert1\\rangle\\\\ \\end{array}  <p>Omit the tensor symbol \\otimes,</p>  \\begin{array}{c} \\lvert0\\rangle \\lvert0\\rangle \\cdots \\lvert0\\rangle,\\\\ \\lvert0\\rangle \\lvert0\\rangle \\cdots \\lvert1\\rangle,\\\\ \\vdots\\\\ \\lvert1\\rangle \\lvert1\\rangle \\cdots \\lvert1\\rangle\\\\ \\end{array}  <p>or </p>  \\lvert00\\cdots 0\\rangle, \\lvert00\\cdots 1\\rangle, \\lvert11\\cdots 1\\rangle,   <p>or simply</p>  \\lvert0\\rangle, \\lvert1\\rangle, \\cdots, \\lvert2^{n}-1\\rangle  <p>when we use the notation \\lvert0\\rangle, \\lvert1\\rangle, \\cdots, \\lvert2^{n}-1\\rangle for the basis states, the total number of qubits must be clear from context. Otherwise, for example \\lvert2\\rangle might mean either \\lvert10\\rangle, \\lvert010\\rangle, or \\lvert0010\\rangle or any string with leading zeros and ending in 10.</p> <p>The Generic state of the system will then be if the form</p>  \\lvert\\psi\\rangle = a_{0}\\lvert0\\rangle + a_{1}\\lvert1\\rangle + \\cdots + a_{2^{n-1}}\\lvert2^{n}-1\\rangle   <p>Same, the only condition that the amplitudes a_i should be complex numbers such that \\sum_{l=0}^{2^{n}-1}|a_l|^{2} = 1, that is, the sum of the coefficient square shoud be 1 (normalization condition). </p> <p>Power of the quantum computing!</p> <p>Part of the power of quantum computing comes from this possibility of implicitly working with 2^{n} complex numbers by manipulating just n qubits.</p> <p>If we decide to measure all the qubits of the system in the computational basis, we will obtain m with probability |a_m|^{2}. If that's the case, then the state will collapse to \\lvert m\\rangle. But if we only measure one of the qubits. says the j-th one, then we will obtain 0 with probability </p>  \\sum_{l\\in J_{0}}|a_{l}|^{2}  <p>where J_{0} is the set of numbers whose j-th bit is 0. In this scenario, the state of the system after measuring 0 would be </p>  \\lvert\\psi_{0}\\rangle = \\frac{\\sum_{l\\in J_{0}}a_{l}\\lvert l\\rangle}{\\sqrt{\\sum_{l\\in J_{0}}\\lvert a_{l}\\lvert^{2}}}  <p>if we measure 1 as same as the case above, we will obtain the probability </p>  P(1) = \\sum_{l\\in J_{1}}|a_{l}|^{2}  <p>and the system state of</p>  \\lvert\\psi_{1}\\rangle = \\frac{\\sum_{l\\in J_{1}}a_{l}\\lvert l\\rangle}{\\sqrt{\\sum_{l\\in J_{1}}\\lvert a_{l}\\lvert^{2}}}  <p>As for the product operation, n-qubit systems act similarly with the two-qubit system</p>  (\\langle\\psi_{1}\\lvert\\otimes\\cdots\\otimes\\langle\\psi_{n}\\lvert)(\\langle\\phi_{1}\\lvert\\otimes\\cdots\\otimes\\langle\\phi_{n}\\lvert) = \\langle\\psi_{1}\\lvert\\phi_{1}\\rangle \\cdots \\langle\\psi_{n}\\lvert\\phi_{n}\\rangle."},{"location":"Quantum_Algorithm_101/Qubit/#example-n-3-qubits","title":"Example n = 3 qubits","text":"<p>Let's consider an example for n = 3 qubits. The state of the system is given as:</p>  \\lvert\\psi\\rangle = a_0 \\lvert000\\rangle + a_1 \\lvert001\\rangle + a_2 \\lvert010\\rangle + a_3 \\lvert011\\rangle + a_4 \\lvert100\\rangle + a_5 \\lvert101\\rangle + a_6 \\lvert110\\rangle + a_7 \\lvert111\\rangle,  <p>where a_0, a_1, \\ldots, a_7 are the complex amplitudes.</p> <p>Measurement on the 2nd Qubit (j = 2) Here, the 2nd qubit corresponds to the middle bit in each computational basis state. Let's compute the probabilities and post-measurement states for the result being 0 or 1.</p> <p>Case 1: Measuring the 2nd Qubit as 1 - J_1 is the set of all indices where the 2nd bit is 1. These are J_1 = \\{2, 3, 6, 7\\}, corresponding to the states: $$ {\\lvert010\\rangle, \\lvert011\\rangle, \\lvert110\\rangle, \\lvert111\\rangle}. $$</p> <ul> <li> <p>Probability of measuring 1: The probability of obtaining 1 is: $$ P(1) = \\sum_{l \\in J_1} |a_l|^2 = |a_2|^2 + |a_3|^2 + |a_6|^2 + |a_7|^2. $$</p> </li> <li> <p>Post-measurement state: After measuring 1, the system collapses to: $$ \\lvert\\psi_{1}\\rangle = \\frac{a_2 \\lvert010\\rangle + a_3 \\lvert011\\rangle + a_6 \\lvert110\\rangle + a_7 \\lvert111\\rangle}{\\sqrt{|a_2|^2 + |a_3|^2 + |a_6|^2 + |a_7|^2}}. $$</p> </li> </ul> <p>Case 2: Measuring the 2nd Qubit as 0 - $J_0 $ is the set of all indices where the 2nd bit is 0. These are J_0 = \\{0, 1, 4, 5\\}, corresponding to the states: $$ {\\lvert000\\rangle, \\lvert001\\rangle, \\lvert100\\rangle, \\lvert101\\rangle}. $$</p> <ul> <li> <p>Probability of measuring 0: The probability of obtaining 0 is: $$ P(0) = \\sum_{l \\in J_0} |a_l|^2 = |a_0|^2 + |a_1|^2 + |a_4|^2 + |a_5|^2. $$</p> </li> <li> <p>Post-measurement state: After measuring 0, the system collapses to: $$ \\lvert\\psi_{0}\\rangle = \\frac{a_0 \\lvert000\\rangle + a_1 \\lvert001\\rangle + a_4 \\lvert100\\rangle + a_5 \\lvert101\\rangle}{\\sqrt{|a_0|^2 + |a_1|^2 + |a_4|^2 + |a_5|^2}}. $$</p> </li> </ul> <p>Example with Numbers Let\u2019s assign specific values to the amplitudes a_0, a_1, \\ldots, a_7. Suppose: $$ a_0 = \\frac{1}{\\sqrt{8}}, \\; a_1 = \\frac{1}{\\sqrt{8}}, \\; a_2 = \\frac{1}{\\sqrt{8}}, \\; a_3 = \\frac{1}{\\sqrt{8}}, \\; a_4 = \\frac{1}{\\sqrt{8}}, \\; a_5 = \\frac{1}{\\sqrt{8}}, \\; a_6 = \\frac{1}{\\sqrt{8}}, \\; a_7 = \\frac{1}{\\sqrt{8}}. $$</p> <p>Probability of measuring 1 in the 2nd qubit: $$ P(1) = |a_2|^2 + |a_3|^2 + |a_6|^2 + |a_7|^2 = 4 \\cdot \\left(\\frac{1}{\\sqrt{8}}\\right)^2 = \\frac{4}{8} = 0.5. $$</p> <p>Post-measurement state when 1 is measured: The new state is:</p>  \\begin{array}{lll} \\lvert\\psi_{1}\\rangle &amp; = &amp; \\frac{\\frac{1}{\\sqrt{8}} \\lvert010\\rangle + \\frac{1}{\\sqrt{8}} \\lvert011\\rangle + \\frac{1}{\\sqrt{8}} \\lvert110\\rangle + \\frac{1}{\\sqrt{8}} \\lvert111\\rangle}{\\sqrt{0.5}} \\\\  &amp; = &amp; \\frac{1}{2} (\\lvert010\\rangle + \\lvert011\\rangle + \\lvert 110\\rangle + \\lvert 111\\rangle). \\end{array}"},{"location":"Quantum_Algorithm_101/Qubit/#multi-qubit-gates","title":"Multi-qubit gates","text":"<p>Since \ud835\udc5b-qubit states are represented by 2^{\ud835\udc5b}-dimensional column vectors, \ud835\udc5b-qubit gates can be identified with 2^{\ud835\udc5b} \\times 2^{\ud835\udc5b} unitary matrices. Thus,i if U_1 is an n_1-qubit gate and U_2 is an n_2-qubit gate, the U_{1}\\otimes U_{2} is an (n_{1}+n_{2})-qubit gate and its matrix is given by the tensor product of the matrices U_1 and U_2.</p> <p>Note</p> <p>An expression for the tensor product of two matices A and B is</p>  \\begin{bmatrix} a_{11} &amp; \\cdots &amp; a_{1q} \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{p1} &amp; \\cdots &amp; a_{pq} \\\\ \\end{bmatrix} \\otimes B =  \\begin{bmatrix} a_{11}B &amp; \\cdots &amp; a_{1q}B \\\\ \\vdots &amp; \\ddots &amp; \\vdots \\\\ a_{p1}B &amp; \\cdots &amp; a_{pq}B \\\\ \\end{bmatrix}  <p>However, Toffoli or CCNOT gate, a three-qubit gate that acts on the computational basis as </p>  \\text{CCNOT}\\lvert x\\rangle\\lvert y\\rangle\\lvert z\\rangle = \\lvert x\\rangle\\lvert y\\rangle\\lvert z \\otimes (x \\wedge y) \\rangle,  <p>where \\otimes is the NOR function and \\wedge is the symbol for the AND Boolean function. CCNOT applies a doubly controlled NOT gate to the thired qubit. </p> <p>The Toffoli gate is crucial in quantum computing because it allows us to simulate any classical Boolean operation using auxiliary qubits. For example, the Toffoli gate can perform logical negations (\u00acz) and conjunctions (AND operations). With this, quantum circuits can replicate any classical digital circuit by using additional ancillary qubits.</p> <p>This is surprising because all quantum gates can work in reverse (they are invertible), but not all classical logic functions (Boolean functions) can be reversed. This means we can potentially make all digital circuits reversible by using the Toffoli gate.</p>"},{"location":"Quantum_Algorithm_101/Qubit/#universal-gates-in-quantum-computing","title":"Universal gates in quantum computing","text":"<p>Current quantum computers can\u2019t implement every possible quantum gate. Instead, they rely on universality results that show how any unitary operation can be decomposed as a circuit that uses a reduced set of primitive gates.</p> <p>To us, it will be important to know that, for any unitary operation, we can construct a circuit that implements it using only one-qubit gates and the CNOT gate. For this reason, we say that those gates are universal \u2014 in the same sense that, for example, negation and conjunction are universal for Boolean logic.</p> <p>Note</p> <p>In addition to one-qubit gates plus CNOT, H and T can also be used to approcimate any unitary operation to any desired accuracy.</p> <p> The Toffoli gate can be constructed from single qubit T- and Hadamard-gates, and a minimum of six CNOTs.</p> <p>Ref: A Practical Guide to Quantum Machine Learning and Quantum Optimization_ Hands-on Approach to Modern Quantum Algorithms</p>"},{"location":"Quantum_Algorithm_101/Sup_Entg_Rev/","title":"Superposition, Entanglement and Reversibility","text":"<p>A quantum computer is a device that leverages specific properties described by quantum mechanics to perform computation.</p> <ul> <li>The Superposition Principle: The linear combination of two or more state vectors is another state vector in the same Hilbert space and describes another state of the system.</li> </ul>"},{"location":"Quantum_Algorithm_101/Sup_Entg_Rev/#superposition","title":"Superposition","text":"<p>A qubit, is a building block of quantum computers. Here we show how a property of an electron - namely spin - can be used to represent a one or zero of a qubit.</p> <p>         Pair of electrons with a spin labeled 1 and 0. Ref[1]     </p> <p>We take two of these states and labeled them as the canonical one and zero for qubits.</p> <p>         Zero and one states. Ref[1]     </p> <p>As you can see, the zero and one states are just vectors on the x and y axes with a length of one unit each. </p> <p>If we have a system that can take on one of two discrete state when measured, we can represent the two states in Dirac notation as |0\\rangle and |1\\rangle. We can then represent a superposition of states as a linear combination of these states, such as </p>  \\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle = \\frac{1}{\\sqrt{2}}|0\\rangle + \\frac{1}{\\sqrt{2}}|1\\rangle.  <p>In fact, when we measured it for a zero or one, |\\alpha| would give us the probability of getting a 0, and |\\beta| would give us the probability of getting a 1.</p> <p>The Born rule states that the sum of the squares of the amplitudes of all possible states in the superposition is equal to 1. For state |\\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle, we have  $$ |\\alpha|^{2} + |\\beta|^{2} = 1. $$</p>"},{"location":"Quantum_Algorithm_101/Sup_Entg_Rev/#references","title":"References","text":"<ol> <li>Woody III, L. S. (2021). Essential mathematics for quantum computing. Packt Publishing. https://www.packtpub.com/en-us/product/essential-mathematics-for-quantum-computing-9781801070188</li> <li>Hidary, J. D. (2019). Quantum computing: An applied approach. Springer. https://link.springer.com/book/10.1007/978-3-030-23922-0</li> </ol>"},{"location":"Quantum_Algorithm_101/TheBlochSphereAndRotation/","title":"The Bloch sphere and rotations","text":"<p>Recall that the a complex number z can be written in polar coordinates as:</p>  z = re^{i\\alpha}  <p>where r = |z| is a non-negative real number and \\alpha is an angle in [0, 2\\pi]. Consider, then a qubit in a state \\lvert\\psi\\rangle = a\\lvert0\\rangle + b\\lvert1\\rangle and write a and b in polar coordinates as:</p>  \\begin{array}{ccc} a = r_{1}e^{i\\alpha_{1}} &amp;, &amp; b = r_{2}e^{i\\alpha_{2}} \\end{array}  <p>we also know that r_{1}^{2}+r_{2}^{2}=|a|^{1}+|b|^{2}=1 and, since 0\\leq r_{1}, r_{2}\\leq 1, there must exist a angle \\theta in [0, \\pi] such that \\text{cos}(\\theta/2) = r_{1} and \\text{cos}(\\theta/2) = r_{2}. By now, we have,</p>  \\lvert \\psi\\rangle = \\text{cos}\\frac{\\theta}{2}e^{i\\alpha_{1}}\\lvert0\\rangle + \\text{sin}\\frac{\\theta}{2}e^{i\\alpha_{2}}\\lvert1\\rangle  <p>We can multiply \\lvert\\psi\\rangle by e^{-i\\alpha_{1}} to obtain the following:</p>  \\lvert\\psi\\rangle = \\text{cos}\\frac{\\theta}{2}\\lvert0\\rangle + \\text{sin}\\frac{\\theta}{2}e^{i\\phi}\\lvert1\\rangle  <p>where we have defined \\phi = \\alpha_{2} - \\alpha_{1}. In this way, we can describe the state of any qubit with just two number \\theta \\in[0, \\pi] and \\phi \\in [0, 2\\pi] that we can interpret as a polar angle and an azimuthal angle, respectively.</p>  (\\text{sin}\\theta\\text{cos}\\phi,\\text{sin}\\theta\\text{sin}\\phi,\\text{cos}\\theta)  <p>This gives us a three-dimensional point to locates the state of the qubit on the surface of a sphere, called the Bloch sphere </p> <p>In the Bloch sphere, \\lvert0\\rangle is mapped to the north pole and \\lvert1\\rangle to the South pole. In general, states that are orthogonal with repest to the inner prodcut are antipodal on the sphere. As we already know, the X gate takes \\lvert0\\rangle to \\lvert1\\rangle and \\lvert1\\rangle to \\lvert0\\rangle, but leaves \\lvert+\\rangle and \\lvert-\\rangle unchanged. This makes X gate acts like a rotation of \\pi radians around the X axis of the Bloch sphere. Imagining you are looking in to a qubit with state \\lvert\\psi\\rangle from the X axis, you wil see the qubits only rotate around the X axis. Therefore, for the X, Y, and Z axes we may define</p>  R_{X}(\\theta) = e^{-i\\frac{\\theta}{2}X} = \\text{cos}\\frac{\\theta}{2}I - i\\text{sin}\\frac{\\theta}{2}Y = \\begin{bmatrix} \\text{cos}\\frac{\\theta}{2} &amp; -i\\text{sin}\\frac{\\theta}{2}\\\\ -i\\text{sin}\\frac{\\theta}{2} &amp; \\text{cos}\\frac{\\theta}{2} \\end{bmatrix}   R_{Y}(\\theta) = e^{-i\\frac{\\theta}{2}Y} = \\text{cos}\\frac{\\theta}{2}I - i\\text{sin}\\frac{\\theta}{2}Y = \\begin{bmatrix} \\text{cos}\\frac{\\theta}{2} &amp; -\\text{sin}\\frac{\\theta}{2}\\\\ \\text{sin}\\frac{\\theta}{2} &amp; \\text{cos}\\frac{\\theta}{2} \\end{bmatrix}   R_{Z}(\\theta) = e^{-i\\frac{\\theta}{2}Z} = \\text{cos}\\frac{\\theta}{2}I - i\\text{sin}\\frac{\\theta}{2}Z = \\begin{bmatrix} e^{-i\\frac{\\theta}{2}} &amp; 0\\\\ 0 &amp; e^{i\\frac{\\theta}{2}}  \\end{bmatrix} \\equiv  \\begin{bmatrix} 1 &amp; 0\\\\ 0 &amp; e^{i\\frac{\\theta}{2}}  \\end{bmatrix}  <p>In general form, for any one-qubit gate U there exists a unit vector r = (r_{x},r_{y},r_{z}) and the angle \\theta such that</p>  U \\equiv \\text{cos}\\frac{\\theta}{2}I - i\\text{sin}\\frac{\\theta}{2}(r_{x}X,r_{y}Y,r_{z}Z)  <p>For instance, if we choose \\theta = \\pi and r = (1/\\sqrt{2},0,1/\\sqrt{2}) we can obtain the Hadamard gate,</p>  H \\equiv -i\\frac{1}{sqrt{2}}(X+Z)  <p>More, the universal one-qubit gate used by IBM, is called the U-gate, which depends on three angles and is able to generate any other one-qubit gate,</p>  U(\\theta, \\phi, \\lambda) =  \\begin{bmatrix} \\text{cos}\\frac{\\theta}{2} &amp; -e^{i\\lambda}\\text{sin}\\frac{\\theta}{2}\\\\ e^{i\\phi}\\text{sin}\\frac{\\theta}{2} &amp; e^{i(\\phi+\\lambda)}\\text{cos}\\frac{\\theta}{2} \\end{bmatrix}  <p>These can be used in Chapter 9, Quantum Support Vector Machines, and Chapter 10, Quantum Neural Networks.</p>"},{"location":"Quantum_Algorithm_101/born_rule/","title":"Born's rule","text":"<p>If a quantum state is:</p>  |\\psi\\rangle = \\sum_{i}\\alpha_{i}|i\\rangle  <p>and you measure in the computational basis \\{|i\\rangle\\}, then the probability of observing outcome i is</p>  P[i] = |\\alpha_{i}|^{2}  <p>In quantum mechanics:</p> <ul> <li>An obervable (e.g. position, energy, spin) is represented by a **Hermitian operator \\widehat{O} and it has eigenvectors |v_{j}\\rangle and real eigenvalues \\lambda_{j}. if your staet |\\psi\\rangle is decomposed as:</li> </ul>  |\\psi\\rangle = \\sum_{i}\\beta_{j}|v_{j}\\rangle  <p>then the Born rule tells that </p> <p>Measuring \\widehat{O} yields eigenvalue \\lambda_{j} with probability |\\beta_{j}|^{2}</p> <p>So let's connect betweeen eigenvalues and amplitudes. The eigenvalues are the possible outcomes you can observe and the amplitudes determine how likely each outcome is. Therefore, we can say that amplitudes encode probabilities and eigenvalues are the measured quantities (what you read on the device)</p>"},{"location":"Quantum_Algorithm_101/born_rule/#reference","title":"Reference","text":"<ol> <li>Born rule - Wikipedia: https://en.wikipedia.org/wiki/Born_rule</li> </ol>"},{"location":"Quantum_Algorithm_101/computational_basis/","title":"Computational Basis","text":"<p>The computational basis for an n-qubit Hilbert space \\mathcal{H} \\in \\mathbb{C} is the set of orthonormal vectors:</p>  \\mathcal{B} = \\{ |i\\rangle : i = 0, 1,...,2^{n}-1\\}  <p>Let |i\\rangle cprresponds to a binary string |q_{0}q_{1}...q_{n-1}\\rangle such that:</p>  |q_{0}\\rangle \\otimes |q_{1}\\rangle \\otimes \\cdots \\otimes |q_{n-1}\\rangle = \\text{1-hot vector in} \\ \\mathbb{C}^{2^{n}}.  <p>This basis forms a complete orthonomal basis for the hilbert space and it's used in measurement outcomes are reported in computational basis.</p>"},{"location":"Quantum_Algorithm_101/foundation/","title":"Sets","text":""},{"location":"Quantum_Algorithm_101/foundation/#definition","title":"Definition","text":"<p>A set is a collection of objects. This collection can be ifinte or inifinte. Mathematical objects are abstract, have properties, and can be acted upon by operations.</p>"},{"location":"Quantum_Algorithm_101/foundation/#set-builder-notation","title":"Set-builder notation","text":""},{"location":"Quantum_Algorithm_101/foundation/#other-set-notation","title":"Other set notation","text":"<p>An important symbol in set notation is \\in, which denotes membership. And \\notin means the object is not a member of the set.</p> <p>The next symbol to consider is used to denote subsets. If X and Y are sets, and every element of X is also an element of Y, then:</p> <ul> <li>X is a subset of Y, denoted by X \\subseteq Y</li> <li>Y is a superset of X, denoted by Y \\supseteq X</li> </ul>"},{"location":"Quantum_Algorithm_101/foundation/#important-sets-of-numbers","title":"Important sets of numbers","text":"<ul> <li>\\mathbb{N}, which is the set of natural numbers defined as {0, 1, 2, 3, \u2026}. This is the first set of numbers you learn as a child, and they are used for counting.</li> <li>\\mathbb{Z},</li> <li>\\mathbb{Q},</li> <li>\\mathbb{R},</li> <li>\\mathbb{C}, </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/","title":"Hilbert Space","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#hilbert-space","title":"Hilbert space","text":"<ul> <li> <p>Hilbert space, a complex vector space with an inner product. In Quantum     mechanics, the term \"Hilber space\" is often reserved for an intinite-dimentional inner product space having the property that it is copmlete or closed. Here we will use it in finite-dimensional spaces.</p> </li> <li> <p>We use Dirac notation | v \\rangle called ket. where v is a symbol of a vector. You can analogous to v or \\vec{v}. </p> </li> <li> <p>The inner product of the vector | v \\rangle with | w \\rangle is written as \\langle v | w \\rangle. Think of this as a \\vec{v}\\cdot\\vec{w} in a familiar vector form.</p> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#qubit","title":"Qubit","text":"<ul> <li> <p>Let's start with the 2-dimensional case. Every vector in the 2-dimensional Hilbert can be written as a linear combination of two vectors which form a basis for the space. The computational basis for quantum information are denoted as |0\\rangle and |0\\rangle, and it is assumed that of them are normalized and that they are mutually orthogonal</p>  \\langle 0 | 0 \\rangle = 1 = \\langle w | w \\rangle, \\ \\langle 0 | 1 \\rangle = 1 = \\langle 1 | 0 \\rangle.  </li> <li> <p>In quantum mechanics a 2-dimensional complex Hilbert space H is used for describing the angular momentum or \"spin of a spin-half particle (electron, proton, neutron, silver atom), which then provides a physical representation of a qubit. </p> </li> <li>A polarization of a photon (particle of light) is also described by d=2 (2-dimensional).</li> <li> <p>A state vector |\\psi\\rangle says something about one component of the spin of the spin half particle. The usual convention is </p> <p>$$ |0\\rangle = |z^{+}\\rangle \\leftrightarrow S_{z} = + 1/2,  |1\\rangle = |z^{-}\\rangle \\leftrightarrow S_{z} = - 1/2, $$ where S_{z} is the z component of angular momentum is measured in units of \\hbar.</p> </li> <li> <p>The general rule is that w is a direction in space correspnding to the angle \\theta and \\phi in polar coordinates,</p>  |0\\rangle + e^{i\\phi} \\tan(\\phi/2) |1\\rangle \\leftrightarrow S_{w} = +1/2, \\ |0\\rangle - e^{i\\phi} \\cot(\\phi/2) |1\\rangle \\leftrightarrow S_{w} = -1/2, \\  <p>but see the comments below on normalization.</p> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#general-dd","title":"General d","text":"<ul> <li> <p>A collection of linearly independent vectors {B_{j}} form a basis of H provided any | \\psi \\rangle in H can be written as a linear combination </p>  | \\psi \\rangle = \\sum_{j} c_{j} | B_{j} \\rangle,  <p>where c_{j} is a copmlex number.</p> </li> <li> <p>A orthonormal basis \\{|j\\rangle \\} for j = 1, 2, \\cdots, d with the property that </p>  \\langle j | k \\rangle = \\delta_{jk}.  <p>The inner product of two basis vectors is 0 for j \\neq k if they are orthogonal, and 1 if they are normalized. \\delta_{jk} is also called as a Kronecker delta.</p> </li> <li> <p>If we write a vector as a combination of a orthonormal basis \\{|j\\rangle \\} for j = 1, 2, \\cdots, d</p>  |v\\rangle = \\sum_{j} v_{j}|j\\rangle, \\ |w\\rangle = \\sum_{j} w_{j}|j\\rangle  <p>where the coefficients v_{j} and w_{j} are given by</p>  v_{j} = \\langle j | v \\rangle, \\ w_{j} = \\langle j | w \\rangle,  <p>the inner product \\langle v | w \\rangle can be written as </p>  (|v\\rangle^{\\dagger})|w\\rangle = \\langle v | w \\rangle = \\sum_{j}v_{j}^{*}w_{j},  <p>which can be thought of as the product of a \"bra\" vector</p>  \\langle v | = (|v\\rangle)^{\\dagger} = \\sum_{j}^{*}w_{j}\\langle j |  <p>with the \"ket vector | w \\rangle.</p> </li> <li> <p>It's convenient to think of | w \\rangle in a column vector </p>  | w \\rangle  \\begin{pmatrix} w_{1} \\\\ w_{2} \\\\ \\cdots \\\\ w_{d}  \\end{pmatrix} ,  <p>and \\langle v | by a row vector </p>  \\langle v | = (v_{1}^{*},v_{2}^{*},\\cdots, v_{d}^{*}).  <p>where d is a diemsnion.</p> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#kets-as-physical-properties","title":"Kets as physical properties","text":"<ul> <li> <p>In quantum mechanics, two vectors |\\psi\\rangle and c|\\psi, where c is any nonzero complex number have exactly the same physical significance. For this reason, it is sometimes helpful to say that the physical state corresponds not to a particular vector in the Hilbert space, but the ray, or one-dimensional subspace, defined by the collection of all the complex multiples of a particular vector.</p> <ul> <li>One can always choose c in such way that the | \\psi \\rangle corresponding to a particular physical situation is normalized, \\langle \\psi | \\psi \\rangle = 1 or ||\\psi|| = 1, where the norm ||\\psi|| of a state |\\psi\\rangle is the positive square root of </li> </ul>  || \\psi||^{2} = \\langle \\psi | \\psi \\rangle,  <p>and is 0 if and only if \\lvert \\psi \\rangle is the unique zero vector, which will be written as 0 instead of | \\psi \\rangle.</p> <ul> <li>Normalized vectors can always be multiplied by a phase factor, a complex number of the form e^{i\\phi} where \\phi is real, without changing the normalization or the physical interpretation.</li> </ul> </li> <li> <p>The state of a single qubit is always a linear combination of the basis vectors |0\\rangle and |1\\rangle,</p>  |\\psi\\rangle = \\alpha |0\\rangle + \\beta |1\\rangle,  <p>where \\alpha and \\beta are complex numbers.</p> </li> <li> <p>Two nonzero vectors |\\psi \\rangle and |\\phi\\rangle which are orthogonal if \\langle \\phi | \\psi \\rangle = 0, represent distinct physical properties:</p> <ul> <li>If one corresponds to a property, such as S_{z} = + 1/2, which is a correct description of a physical system at a particular time, then the other corresponds to a physical property which is not true for this system at this time. We call this mutaully exclusive.</li> </ul> </li> <li> <p>There are cases where |\\psi \\rangle is neither a multiple of | \\phi \\rangle, nor is it orthogonal to |\\phi\\rangle. For example</p>  |0\\rangle = |z^{+}\\rangle \\leftrightarrow S_{z} = +1/2 \\ \\text{and} \\ \\sqrt{2}|x^{+}\\rangle = |0\\rangle + |1\\rangle \\leftrightarrow S_{x} = +1/2  <p>These represent neither the same physical situation, nor do they represent distinct physical situations.</p> </li> <li> <p>A quantum system cannot simultaneously process two incompatible properties. For example, a spin-half particle cannot have both S_{x} = +1/2 and S_{z} = +1/2. There is nothing in the Hilbert space that could be used to represent such a combined property.</p> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#operators","title":"Operators","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#definition","title":"Definition","text":"<ul> <li> <p>Operators are linear maps of the Hilbert space H onto itself. If A is an operator, then for any |\\psi\\rangle in H, A|\\psi\\rangle is another element in H, and linearity means that </p>  A(b|\\psi\\rangle + c|\\phi\\rangle) = bA|\\psi\\rangle + cA|\\phi\\rangle  <p>for any pair |\\psi\\rangle and |\\phi\\rangle, and any two complex number b and c.</p> <ul> <li>The product AB of two operators A and B is defined by</li> </ul>  (AB)|\\psi\\rangle = A(B|\\psi\\rangle) = AB|\\psi\\rangle.  <p>In general AB \\neq BA.</p> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#dyads-and-completness","title":"Dyads and completness","text":"<ul> <li> <p>The simplest operator is a dyad, |x\\rangle \\langle w|. This action is defined by </p>  (\\color{red}{|x\\rangle} \\color{blue}{\\langle w|})|\\psi\\rangle = \\color{red}{|x\\rangle} \\color{blue}{\\langle w|} \\psi \\rangle = (\\color{blue}{\\langle w|} \\psi \\rangle)\\color{red}{|x\\rangle}.  <p>Note</p> <p>The middle term, formed by removing the parentheses and replacing two vertivle bars || with one bar |.</p> </li> <li> <p>The completness relation</p>  I = \\sum_{j}|j\\rangle \\langle j|,  <p>where I is the identity operator, I|\\psi\\rangle = |\\psi\\rangle for any |\\psi\\rangle. The sum on the right is dyads |j\\rangle \\langle j| corresponding to the elements |j\\rangle of an orthonormal basis.</p> <ul> <li>Theus, we can rewrite a state |\\psi\\rangle     $$     \\psi = (\\sum_{j} \\color{red}{|j\\rangle}\\color{blue}{\\langle j|})|\\psi\\rangle = \\sum \\color{red}{|j\\rangle}\\color{blue}{\\langle j|}\\psi\\rangle = \\sum_{j}\\color{blue}{\\langle j |}\\psi\\rangle \\color{red}{|j\\rangle}.     $$</li> </ul> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#matrices","title":"Matrices","text":"<ul> <li> <p>Given an operator A and a bisis \\{ |\\beta_{j} \\rangle\\} , which need not to be orthonormal, the matrix associated with A is the square array of numbers A_{jk} defined by</p>  A|\\beta_{k}\\rangle = \\sum{j}|\\beta_{j}\\rangle A_{jk} = \\sum_{j}A_{jk}|\\beta_{j}\\rangle.  </li> <li> <p>For an orthonormal basis, we can rewrite the completness relation</p>  A|k\\rangle = I \\cdot A|k\\rangle = (\\sum_{j}\\color{red}{|j\\rangle} \\langle j|)A|k\\rangle = \\sum_{j}\\color{red}{|j\\rangle} \\langle j| A|k\\rangle = \\sum_{j}\\langle j|A|k\\rangle\\color{red}{|j\\rangle}.  <p>In \\langle j|A|k\\rangle, the inner product of |j\\rangle with A|k\\rangle is just the A_{jk} above. Thus, \\langle j|A|k\\rangle, can be written as \\langle \\psi|A|\\omega\\rangle, is referred to as a \"matrix element\" when using Dirac notation.</p> </li> <li> <p>In a similar way the expression</p>  A = I \\cdot A \\cdot I = \\sum_{j}|j\\rangle \\langle j| \\cdot A \\cdot \\sum_{k}|k\\rangle \\langle k| = \\sum{jk}\\langle j|A|k\\rangle\\cdot|j\\rangle\\langle k|  <p>allows us to express operator A as a sum of dyads, with coefficients given by its matrix elements.</p> </li> <li> <p>When A refers to a qubit the usual wawy of writing the matrix in the standard basis is </p>  \\begin{pmatrix} \\langle 0|A|0\\rangle &amp; \\langle 0|A|1\\rangle \\\\ \\langle 1|A|0\\rangle &amp; \\langle 1|A|1\\rangle \\end{pmatrix}  </li> <li> <p>We can also write the matrix element of the product of two operators in terms of the individual matrix elements:</p>  \\langle j|AB|k\\rangle = \\langle j|A \\cdot I \\cdot B|k\\rangle = \\sum_{m}\\langle j|A|m\\rangle\\langle m|b|k\\rangle.  <p>If we write this equation in subscripts form,</p>  (AB)_{jk} = \\sum_{m}A_{jm}B_{mk}.  </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#dagger-or-adjoint","title":"Dagger or adjoint","text":"<ul> <li> <p>Here are some dagger ^\\dagger properties:</p>  \\begin{array}{c} (|\\psi\\rangle)^{\\dagger} = \\langle\\psi|,\\\\ (\\langle \\psi|)^{\\dagger} = |\\psi \\rangle,\\\\ (a|\\psi\\rangle+b|\\psi\\rangle)^{\\dagger} = a^{*}\\langle\\psi|+b^{*}\\langle\\psi|,\\\\ (|\\psi\\rangle \\langle \\omega|)^{\\dagger} = |\\omega\\rangle \\langle \\psi|,\\\\ \\langle j|A^{\\dagger}|k\\rangle = (\\langle k|A|j\\rangle)^{*},\\\\ (aA+bB)^{\\dagger} = a^{*}A + b^{*}B,\\\\ (AB)^{\\dagger} = B^{\\dagger}A^{\\dagger}, \\end{array}  <p>where a and b are complex numbers; a^{*} and b^{*} are its complex conjugate. The operator A^{\\dagger} is called the adjoint of the operator A. The matrix of A^{\\dagger} is the complex conjugate of the transpose of the matrix of A.</p> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#normal-operators","title":"Normal operators","text":"<ul> <li>A normal operator A on a Hilbert space in one that commutes with its adjoint, that is, AA^{\\dagger} = A^{\\dagger}A. </li> <li> <p>A normal operators can be diagonalized using an orthonormal basis, that is </p>  A = \\sum_{j} \\alpha_{j} |\\alpha_{j}\\rangle \\langle a_{j}|  <p>where the basis vectors |a_{j}\\rangle are eigenvectors of A and the complex numbers \\alpha_{j} are its eigenvalues. Equivalently, the matrix of A in this basis is diagonal</p>  \\langle a_{j} | A | a_{k} \\rangle = \\alpha_{j}\\delta_{jk}.  </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#hermitian-operators","title":"Hermitian operators","text":"<ul> <li>A hermitian or self-adjoint operator A is defined by the property that A = A^{\\dagger}, so it is a normal operator. It is the qunatum analog of a real (not complex) number. Its eigenvalues \\lambda_{j} are real numbers.<ul> <li>The term \"Hermitian\" and \"self-adjoint\" mean the same thing for a finite-dimensional Hilber space.</li> <li>Hermitian operators in quantum mechanics are used to represent physical variables, quantities such as energy, momentum, angular momentum, position, etc. The operator representing the energy is the Hamiltonian H.</li> <li>For example, the operator S_{z} = \\frac{1}{2}(|z^{+}\\rangle\\langle z^{+}| - |z^{-}\\rangle\\langle z^{-}|) is the z component of angular momentum of a spin-half particle.</li> </ul> </li> <li>There is no always has a well-defined value for a physical system in a particulate in quantum mechanics. Let's say a quantum state |\\psi\\rangle, the physical variable corresponding to the operator A has a well-defined value if and only if | \\psi\\rangle is an eigenvector of A, A|\\psi\\rangle = \\alpha|\\psi\\rangle, where \\alpham must be a real number since A^{\\dagger} = A.<ul> <li>The eigenstates of S_{z} for a spin-half particle are |z^{+}\\rangle and |z^{-}\\rangle, with eigenvalues of +1/2 and -1/2, respectively.</li> <li>If |\\psi\\rangle is not an eigenstate of A, then in this state the physical quantity A is undefined , or meaningless in the sense that quantum theory can assign it no meaning.</li> <li>The state |x^{+}\\rangle is an eigenstate of S_{x} but not of S_{z}. hence in this state S_{x} has well-defined value (1/2), where as S_{z} is undefined.</li> </ul> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#projectors","title":"Projectors","text":"<ul> <li> <p>A projectors, short for orthogonal projection operator, is a Hermitian operator P = P^{\\dagger} which is idempotent in the sense that P^{2} = P. It is a Hermitian operator all or whose eigenvalues are either 0 or 1. Therefore, there is always a basis in which its matrix is diagonal \\langle a_{j}|A|a_{k}\\rangle = \\alpha_{j} \\delta_{jk}, with only 0 or 1 on the diagonal. Such a matrix always represents a projector.</p> <ul> <li>There is a one-to-one correspondence between a projector P and the subspace P' of the Hilbert space that it projects onto. P' consists of all the kets |\\psi\\rangle such that P|\\psi\\rangle = |\\psi \\rangle. That is, it is the eigenspace consisting of eigenvectors a projector.</li> <li>Projector operator \"projects\" a vector in a \"perpendicular\" manner onto a subsapce.</li> <li>The dyad |\\psi\\rangle \\langle \\psi| for a normalized state |\\psi\\rangle. If |\\psi\\rangle is not normalized (and not zero), the corresponding projector is </li> </ul>  P = \\frac{|\\psi\\rangle \\langle \\psi|}{\\langle \\psi|\\psi\\rangle}  <ul> <li>If |\\psi\\rangle and |\\phi\\rangle are two normalized states orthogonal to each other, i.e., the inner product is 0. Then the sum |\\psi\\rangle\\langle\\psi|+|\\phi\\rangle\\langle\\phi| of the corresponding dyads is also a projector.</li> </ul> </li> <li> <p>The physical significance of projectors is that they represent physical properties of a quantum system that can be either true or false. </p> <ul> <li>The property P corresponding to a projector P is trueuf the physical state |\\psi\\rangle of the system is an eigenstate of P with eigenvalue of 1, and false if it is an eigenstate with eigenvalue of 0. If |\\psi\\rangle is not an eigenstate of P, then the corresponding property is undefined (meaningless) for this state.</li> </ul> </li> <li> <p>Two quantum properties represented by projectors P and Q are said to be compatible if PQ = QP (if P and Q commute). Incompatible oterwise.</p> <ul> <li>When P and Q are compatible, the product PQ is itself a projector, and represents the property \"P AND Q\". That is, the property that the system has both properties P and Q at the same time.</li> <li>The projectors |z^{+}\\rangle\\langle z^{+}| and |x^{+}\\rangle\\langle x^{+}| do not commute, and so S_{z} = +1/2 and S_{x}=+1/2 are examples of incompatible properties.</li> </ul> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#positive-operators","title":"Positive operators","text":"<ul> <li> <p>The positive operators is useful when dealing with probabilities. They are defined as that for every ket |\\psi\\rangle</p>  \\langle \\psi |A|\\psi\\rangle \\geq 0.  <p>or </p>  A = \\sum_{j} \\alpha_{j} |\\alpha_{j}\\rangle \\langle a_{j}|,  <p>where \\alpha_{j} \\geq 0. Both representations should be normalized.    </p> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#unitary-operators","title":"Unitary operators","text":"<ul> <li> <p>A unitary operator U has the property that </p>  U^{\\dagger}U = I = UU^{\\dagger}.  <ul> <li> <p>Since U commutes with its adjoints, it is a normal operator and can diagonalized using an orthonormal basis. Aboove equation also implies that all the eigenvalues of U are complex numbers of magnitude 1. That is, they lie on the unit circuile in the complex plane.</p> </li> <li> <p>In a finite-dimentional Hilbert space, with U mapping the space into itself, thus, we only have to check one of the above equation to see if U is unitary.</p> </li> <li> <p>In quantum mechnics, unitary operators are used to change from one orthonormal basis to another, to represent symmetries, such as rotational symmetry, and to describe some aspects of the dynamics or time development of a quantum system.</p> </li> </ul> </li> </ul>"},{"location":"Quantum_Algorithm_101/hilbert_space/#bloch-sphere","title":"Bloch sphere","text":"<ul> <li> <p>Any physical state \\psi of a qubit (ray or normalized vector in the two-dimensional Hilbert space) can be associated in this way with a direction w = (w_{x}, w_{y}, w_{z}) in space for which S_{w} = 1/2, i.e., the w component of angular momentum is positive. There is therefore a one-to-one coorespondence bewteen directions, or the correspondence points on the unit shpere, with rays of a two-dimensional Hilber space. This is also known as the ***Bloch sphere representation *** of qubit states.</p> <ul> <li>We often write a state </li> </ul>  \\begin{array}{c} \\cos{(\\theta/2)}|0\\rangle + e^{i\\phi}\\sin{(\\theta/2)}|1\\rangle \\leftrightarrow S_{w} = +1/2, \\\\ \\sin{(\\theta/2)}|0\\rangle - e^{i\\phi}\\cos{(\\theta/2)}|1\\rangle \\leftrightarrow S_{w} = -1/2, \\end{array}  <p>where the ket are normalized.</p> <ul> <li>Note that it is the surface of the Bloch sphere - vector w of unit length - that correspond to different rays.</li> </ul> </li> <li> <p>Two states of a qubit are orthogonal, physically distinct ot distinguishable, if they are antipodes, two points at opposite ends of a diagonal. For example, |0\\rangle |1\\rangle are the north and south pole of the Bloch sphere.</p> <ul> <li>Any orthonormal basis of a qubit is associated with a pair or antipodes of that Bloch sphere.</li> </ul> </li> <li> <p>A linear operator maps a ray onto a ray, or onto a zero vector. A linear operator on a qubit maps the Bloch sphere onto itself, or in the case of a noninvertible operator, onto a single point on the sphere.</p> </li> <li> <p>Of particular importance are rotations of 180{^\\circ} about the x, y, and z axes, obtained using the unitary operators X = \\sigma_{x}, Y = \\sigma_{y}, and Z = \\sigma_{z}, respectively. In the standard basis the corresponding matrices are the Pauli matrices:</p> </li> </ul>  X =  \\begin{pmatrix} 0 &amp; 1\\\\ 1 &amp; 0 \\end{pmatrix} , \\ Y =  \\begin{pmatrix} 0 &amp; -i\\\\ i &amp; 0 \\end{pmatrix} , \\ Z =  \\begin{pmatrix} 1 &amp; 0\\\\ 0 &amp; -1 \\end{pmatrix} ."},{"location":"Quantum_Algorithm_101/hilbert_space/#composite-systems-and-tensor-products","title":"Composite systems and tensor products","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#definition_1","title":"Definition","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#product-and-entangled-states","title":"Product and entangled states","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#operators-on-tensor-products","title":"Operators on tensor products","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#example-of-two-qubits","title":"Example of two qubits","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#multiple-systems-identical-particles","title":"Multiple systems. Identical particles.","text":""},{"location":"Quantum_Algorithm_101/hilbert_space/#reference","title":"Reference","text":"<ol> <li>Hilbert Space Quantum Mechanics</li> </ol>"},{"location":"Quantum_Algorithm_101/kronecker_product/","title":"Kronecker product","text":""},{"location":"Quantum_Algorithm_101/linear_algebr_tensor/","title":"What is a Tensor Product \\otimes ?","text":"<p>The tensor product of two vectors is defined as:</p>  \\begin{pmatrix} a_1 \\\\ a_2 \\\\ \\vdots \\\\ a_n \\end{pmatrix} \\otimes \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} = \\begin{pmatrix} a_1 \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} \\\\ a_2 \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} \\\\ \\vdots \\\\ a_n \\begin{pmatrix} b_1 \\\\ b_2 \\\\ \\vdots \\\\ b_m \\end{pmatrix} \\end{pmatrix} = \\begin{pmatrix} a_1 b_1 \\\\ a_1 b_2 \\\\ \\vdots \\\\ a_1 b_m \\\\ a_2 b_1 \\\\ a_2 b_2 \\\\ \\vdots \\\\ a_2 b_m \\\\ \\vdots \\\\ a_n b_1 \\\\ a_n b_2 \\\\ \\vdots \\\\ a_n b_m \\end{pmatrix}  <p>The tensor product is a mathematical operation that combines two quantum states into a single state describing a composite system. If you have two systems, A and B, with states \\lvert 0 \\rangle and \\lvert 0 \\rangle, their combined state is written as: $$ \\lvert a \\rangle \\otimes \\lvert b \\rangle $$ For a single qubit has a state of dimension 2 (\\lvert 0\\rangle,\\lvert 1\\rangle), for two qubis together forma a state space of dimension 2 \\times 2 = 4 \\ (\\lvert 00 \\rangle, \\lvert 01 \\rangle, \\lvert 10 \\rangle, \\lvert 11 \\rangle). </p> <ol> <li> <p>Linearity:  $$ (a\\lvert u \\rangle + b\\lvert v \\rangle) \\otimes \\lvert w \\rangle = a(\\lvert u \\rangle \\otimes \\lvert w \\rangle)+ b(\\lvert v \\rangle \\otimes \\lvert w \\rangle) $$</p> </li> <li> <p>Dimensionality: If \\lvert u \\rangle is in a d_{1}-dimensional space and \\lvert v \\rangle is in a d_{2}-dimensional space, the the combination state, $$ \\lvert d_{1} \\rangle \\otimes \\lvert d_{2} \\rangle  $$ is in a d_{1} \\times d_{2}-dimensional space.</p> </li> <li> <p>Associativity $$ (\\lvert u \\rangle \\otimes \\lvert v \\rangle) \\otimes \\lvert w \\rangle \\approxeq \\lvert u \\rangle \\otimes (\\lvert v \\rangle\\otimes \\lvert w \\rangle) $$</p> </li> <li> <p>Independence: The tensor prodict assumes that the two systems are independent and their joint state is simply the product of their individual states. For example:  $$ \\lvert 0 \\rangle \\otimes \\lvert 1 \\rangle = \\lvert 01 \\rangle $$</p> </li> </ol> <p>Here are some properties of the tensor product operation: 5. Basis States If \\lvert u \\rangle and \\lvert v \\rangle are basis states, their tensor product \\lvert 0 \\rangle \\otimes \\lvert 0 \\rangle forms a basis for the composite system. For example, the basis states \\lvert 0 \\rangle, \\lvert 1 \\rangle for a sinagle qubi combine to form the two-qubi basis \\{ \\lvert 00 \\rangle, \\lvert 01 \\rangle, \\lvert 10 \\rangle, \\lvert 11 \\rangle \\}.</p>"},{"location":"Quantum_Algorithm_101/linear_algebr_tensor/#what-lvert-00-rangle-lvert-0-rangle-otimes-lvert-0-ranglelvert-00-rangle-lvert-0-rangle-otimes-lvert-0-rangle-implies","title":"What \\lvert 00 \\rangle = \\lvert 0 \\rangle \\otimes \\lvert 0 \\rangle implies","text":"<p>This representation emphasizes:</p> <ol> <li>Individuality of Qubits:  Each qubit has its own state space, but when combined, they form a composite system.</li> <li>Non-Entangled States: The tensor product \\lvert 0 \\rangle \\otimes \\lvert 0 \\rangle imples a product state, meaning two qubits are independent and not entangled.</li> </ol>"},{"location":"Quantum_Algorithm_101/linear_algebr_tensor/#non-cloing-in-quantum-mechanics","title":"Non-cloing in quantum mechanics:","text":"<p>The expression \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle represents the tensor product of a quantum state \\lvert \\psi \\rangle with itself. In the context of cloning, this means having two identical copies of the quantum state \\lvert \\psi \\rangle.</p>"},{"location":"Quantum_Algorithm_101/linear_algebr_tensor/#understanding-tensor-products","title":"Understanding Tensor Products","text":"<p>In quantum mechanics: 1. The tensor product combines two quantum systems into a single composite system. 2. If two systems are in identical states \\lvert \\psi \\rangle, the tensor product \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle describes a system where both subsystems are in the same state \\lvert \\psi \\rangle.</p>"},{"location":"Quantum_Algorithm_101/linear_algebr_tensor/#why-lvert-psi-rangle-otimes-lvert-psi-ranglelvert-psi-rangle-otimes-lvert-psi-rangle-represents-cloning","title":"Why \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle Represents Cloning","text":"<ol> <li> <p>Single Qubit:</p> <ul> <li>A single qubit in the state \\lvert \\psi \\rangle has amplitudes \\alpha and \\beta for the basis states \\lvert 0 \\rangle and \\lvert 1 \\rangle, respectively: $$  \\lvert \\psi \\rangle = \\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle $$</li> </ul> </li> <li> <p>Cloning:</p> <ul> <li>To clone \\lvert \\psi \\rangle, we want to produce a second qubit in the exact same state, so the final system contains two qubits, both in state \\lvert \\psi \\rangle.</li> </ul> </li> <li> <p>Mathematical Representation:</p> <ul> <li>If the first qubit is \\lvert \\psi \\rangle and the second (blank) qubit starts in \\lvert 0 \\rangle, then after cloning, the system would be described as: $$  \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle = (\\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle) \\otimes (\\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle) $$</li> </ul> </li> <li> <p>Expansion:</p> <ul> <li>Expanding the tensor product: $$  \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle = \\alpha^2 \\lvert 00 \\rangle + \\alpha \\beta \\lvert 01 \\rangle + \\beta \\alpha \\lvert 10 \\rangle + \\beta^2 \\lvert 11 \\rangle $$</li> </ul> </li> <li>This describes a two-qubit system where both qubits are in the same state \\lvert \\psi \\rangle.</li> </ol>"},{"location":"Quantum_Algorithm_101/linear_algebr_tensor/#why-cloning-is-different-from-classical-duplication","title":"Why Cloning is Different from Classical Duplication","text":"<p>In classical systems: 1.  Information can be copied exactly without any loss or disturbance.</p> <p>In quantum systems: 2.  A state like \\lvert \\psi \\rangle = \\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle cannot be perfectly duplicated into \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle because of the no-cloning theorem.</p>"},{"location":"Quantum_Algorithm_101/linear_algebr_tensor/#summary","title":"Summary","text":"<ol> <li>\\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle represents a quantum system where two qubits are in the same state \\lvert \\psi \\rangle, which corresponds to a cloned system.</li> <li>Achieving this for an arbitrary \\lvert \\psi \\rangle is impossible because cloning would violate the linearity of quantum mechanics, as shown by the no-cloning theorem. </li> </ol> <p>Reference:</p> <ol> <li>Tensor product</li> </ol>"},{"location":"Quantum_Algorithm_101/matrices/","title":"Matrices","text":""},{"location":"Quantum_Algorithm_101/matrices/#column-and-row-vector","title":"Column and Row vector","text":"<p>Here are our definitions of a column vector and a row vector:</p>  \\text{column vector} = |y\\rangle =  \\begin{bmatrix} a_1 \\\\ a_2 \\\\ \\vdots\\\\ a_n \\end{bmatrix}   \\text{row vector} = \\langle x| =  \\begin{bmatrix} a_1,a_2,\\cdots,a_n \\end{bmatrix}.  <p>The vector and row vectors can be represented by one-dimenstional matrices.</p>"},{"location":"Quantum_Algorithm_101/matrices/#multiplying-vectors","title":"Multiplying Vectors","text":"<p>A bracket \\langle x|y\\rangle, is essentially matrix multiplication of a row vector and a column vector. Here is our definition</p>  \\langle x|y\\rangle =  \\begin{bmatrix} x_1,x_2,\\cdots,x_n \\end{bmatrix} \\begin{bmatrix} y_1 \\\\ y_2 \\\\ \\vdots\\\\ y_n \\end{bmatrix} =x_{1}\\cdot y_{1}+x_{2}\\cdot y_{2}+\\cdots x_{n}\\cdot y_{n}  <p>for example,</p>  \\langle y|x\\rangle =  \\begin{bmatrix} 3 \\ 2 \\ 1 \\ 4 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\\\ 4 \\end{bmatrix} =16"},{"location":"Quantum_Algorithm_101/matrices/#matrix-vector-multiplication","title":"Matrix-vector multiplication","text":"<p>If the matrix and column vector are variables, we can write out the product this way: $$ A|x\\rangle $$ This denotes the matrix A multiplying the vector |x\\rangle.</p> <p>Let's say we have </p>  A|x\\rangle =  \\begin{bmatrix} 4 &amp; 3 &amp; 2\\\\ 4 &amp; 1 &amp; 3\\\\ 2 &amp; 4 &amp; 2 \\end{bmatrix} \\cdot \\begin{bmatrix} w\\\\ y\\\\ z \\end{bmatrix} =  \\begin{bmatrix} a\\\\ b\\\\ c \\end{bmatrix}, \\quad x =  \\begin{bmatrix} w\\\\ y\\\\ z \\end{bmatrix}  <p>we can seperate matrix A into row vectors</p>  \\begin{array}{c} \\begin{bmatrix} 4 &amp; 3 &amp; 2 \\end{bmatrix} = \\langle R_{1}|, \\quad \\begin{bmatrix} 4 &amp; 3 &amp; 3 \\end{bmatrix} = \\langle R_{2}|, \\quad \\begin{bmatrix} 2 &amp; 4 &amp; 2 \\end{bmatrix} = \\langle R_{3}|. \\quad \\end{array}  <p>and we can put things together as </p>  A|x\\rangle =  \\begin{bmatrix} 4 &amp; 3 &amp; 2\\\\ 4 &amp; 1 &amp; 3\\\\ 2 &amp; 4 &amp; 2 \\end{bmatrix} \\cdot \\begin{bmatrix} w\\\\ y\\\\ z \\end{bmatrix} = \\begin{bmatrix} \\langle R_{1}|x\\rangle \\\\ \\langle R_{2}|x\\rangle\\\\ \\langle R_{3}|x\\rangle \\end{bmatrix}  <p>In the same fashion, if we perform the product on the two following matrices A and B such that </p>  A =  \\begin{bmatrix} 1 &amp; 2 \\\\ 3 &amp; 4 \\end{bmatrix} \\quad B =  \\begin{bmatrix} 1 &amp; 2 &amp; 3 \\\\ 4 &amp; 5 &amp; 6. \\end{bmatrix}  <p>Same, we rewrite matirx A into row vectors \\langle R_{1}|,\\langle R_{2},\\langle R_{3}| and B into column vectors |C_{1}\\rangle, |C_{2}\\rangle, |C_{3}\\rangle. We can have the product of A and B matrix as </p>  A \\cdot B =  \\begin{bmatrix} \\langle R_{1}|C_{1}\\rangle &amp; \\langle R_{1}|C_{2}\\rangle &amp; \\langle R_{1}|C_{3}\\rangle \\\\ \\langle R_{2}|C_{1}\\rangle &amp; \\langle R_{2}|C_{2}\\rangle &amp; \\langle R_{2}|C_{3}\\rangle \\end{bmatrix}"},{"location":"Quantum_Algorithm_101/matrices/#quantum-example","title":"Quantum example","text":"<p>in quantum circuits, the inputs are qubits (vectors), and the gates are matrices. An example quantum logic gate, <code>NOT gate</code>, is show as </p> <p>The <code>NOT</code> gate in quantum copmuting is represented by the following matrix:</p>  X = \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix}  <p>if our input qubits is a |1\\rangle, then the output would be:</p>  X|1\\rangle =  \\begin{bmatrix} 0 &amp; 1 \\\\ 1 &amp; 0 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix} = |0\\rangle"},{"location":"Quantum_Algorithm_101/matrices/#hilbert-space-quantum","title":"Hilbert space quantum","text":""},{"location":"Quantum_Algorithm_101/matrices/#hermitian-matrix","title":"Hermitian matrix","text":"<p>A Hermitian matrix is a complex square matrix that is equal to its own conjugate transpose - that is, the element in the i-th row and j-th column is equal to the complex conjugate of the element in the j-th row and i-th column, for all indices i and j. A is a Hermitian matrix A contains elements a_{ij}, then </p>  a_{ij} = \\overline{a_{ij}}  <p>or in a quantum mechanics notation</p>  A^{H} = \\overline{A^{T}} = A^{\\dagger} .  <p>For example, we have a complex square matrix A such that</p>  A =  \\begin{bmatrix} 0 &amp; a-ib &amp; c-id \\\\ a+ib &amp; 1 &amp; m-in \\\\ c+id &amp; m+in &amp; 2 \\end{bmatrix}  <p>we apply transpose, it becomes</p>  {A^{T}} = \\begin{bmatrix} 0 &amp; a+ib &amp; c+id \\\\ a-ib &amp; 1 &amp; m+in \\\\ c-id &amp; m-in &amp; 2 \\end{bmatrix}   <p>then we find its cimplex conjugate, we have </p>  \\overline{A^{T}} = \\begin{bmatrix} 0 &amp; a-ib &amp; c-id \\\\ a+ib &amp; 1 &amp; m-in \\\\ c+id &amp; m+in &amp; 2 \\end{bmatrix}  = A^{\\dagger} = A"},{"location":"Quantum_Algorithm_101/matrices/#diagonal-values","title":"Diagonal values","text":"<p>The entries on the main diagonal of any Hermitian matrix are real.</p>"},{"location":"Quantum_Algorithm_101/matrices/#symmetric","title":"Symmetric","text":"<p>A matrix that has only real entries is symmetric if and only if it is a Hermitian matrix. A real and symmetric matrix is simply a special case of a Hermitian matrix.</p>"},{"location":"Quantum_Algorithm_101/matrices/#normal","title":"Normal","text":"<p>Every Hermitian matrix is a normal matrix. AA^{\\dagger} = A^{\\dagger}A.</p>"},{"location":"Quantum_Algorithm_101/matrices/#properties","title":"Properties","text":"<p>For any Hermitian matrix A and B, we have </p> <ol> <li>(A+B)_{ij} = A_{ij}+B_{ij} = \\overline{A_{ij}}+\\overline{B_{ij}} = \\overline{A+B}_{ij} </li> <li>For an invertible Hermitian matrix. A^{-1} = (A^{-1})^{H}</li> </ol>"},{"location":"Quantum_Algorithm_101/matrices/#normal-matrix","title":"Normal matrix","text":"<p>A complex square matrix A is normalif it commutes with its conjugate transpose A^{*}. </p>  A^{*}A = AA^{*}"},{"location":"Quantum_Algorithm_101/matrices/#conjugate-transpose","title":"Conjugate transpose","text":"<p>To maintain the consistancy, symbol H has been replaced to \\dagger.</p> <p>A square matrix A with entries a_{ij} is called </p> <ol> <li>Hermitian or self-adjoint if A = A^{\\dagger}; i.e., a_{ij} = \\overline{a_{ji}}.</li> <li>Skew Hermitian if A = -A^{\\dagger}; i.e., a_{ij} = -\\overline{a_{ji}}.</li> <li>Normal if A^{\\dagger}A = AA^{\\dagger}.</li> <li>Unitary if A^{\\dagger} = A^{-1}; i.e., AA^{\\dagger} = A^{\\dagger}A = I.</li> </ol>"},{"location":"Quantum_Algorithm_101/matrices/#unitary-matrix","title":"Unitary matrix","text":"<p>In linear algebra, an invertible complex square matrix U is unitary if its inverse matrix U^{-1} equals its conjugate transpose U^{*}, that is, if </p>  U^{*}U = UU^{*} = I  <p>In quantum, we use \\dagger, that is</p>  U^{\\dagger}U = UU^{\\dagger} = I  <p>For real numbers, the analogue of a unitary matrix is an orthogonal matrix. Unitary matrices have significant importance in quantum mechanics because they preserve norms, and thus, probability.</p>"},{"location":"Quantum_Algorithm_101/matrices/#orthogonal-matrix","title":"Orthogonal matrix","text":"<p>In liner algrbra, an orthogonal matrix, or orthonormal matrix, is a real square matrix whose columns and rows are orthonormal vectors.</p> <p>Also, it holds that </p>  Q^{T}Q = QQ^{T} = I  <p>where Q^{T} is the transpose of Q and I is the identity matrix. As a result, it also holds that</p>  Q^{T} = Q^{-1}."},{"location":"Quantum_Algorithm_101/matrices/#orthonormal-basis","title":"Orthonormal basis","text":"<p>An orthonormal basis is a set of vectors have a norm of 1 and are pairwise orthogonal. ref</p>"},{"location":"Quantum_Algorithm_101/matrices/#references","title":"References:","text":"<ol> <li>Woody III, L. S. (2021). Essential mathematics for quantum computing. Packt Publishing. https://www.packtpub.com/en-us/product/essential-mathematics-for-quantum-computing-9781801070188</li> <li>Hidary, J. D. (2019). Quantum computing: An applied approach. Springer. https://link.springer.com/book/10.1007/978-3-030-23922-0</li> <li>Conjugate transpose (Wiki)</li> <li>Orthogonal matrix (Wiki)</li> <li>Hermitian matrix (Wiki)</li> <li>Orthonormal basis</li> <li>Orthonormal basis</li> <li>Hilbert Space Quantum Mechanics</li> </ol>"},{"location":"Quantum_Algorithm_101/measurement_in_quantum_mechanics/","title":"Measurement in Quantum mechanics","text":""},{"location":"Quantum_Algorithm_101/measurement_in_quantum_mechanics/#positive-operator-valued-measure-povm","title":"Positive operator-valued measure (POVM)","text":"<p>A quantum measurement can be described by a set of measurement operators {M_{m}} acting on the Hilbert space. The probability of getting result m when measuring a state |\\psi\\rangle\" </p>  p(m) = \\langle \\psi|M_{m}^{\\dagger} M_{m}|\\psi\\rangle  <p>and measurement operators must satisfies </p>  \\sum_{m}M_{m}^{\\dagger}M_{m} = I.  <p>Thus, 1 = \\sum_{m}p_{m} = \\langle \\psi|M_{m}^{\\dagger} M_{m}|\\psi\\rangle. After the measurement, our state becomes </p>  \\frac{M_{m}|\\psi\\rangle}{\\sqrt{\\langle \\psi|M_{m}^{\\dagger}M_{m}|\\psi\\rangle}}."},{"location":"Quantum_Algorithm_101/measurement_in_quantum_mechanics/#projective-measurement","title":"Projective measurement","text":"<p>Projective measurement is a special case of general quantum measurement, where the set of measurement operators \\{P_{m}\\} consists entirely of projectors.</p> <p>Given a set of projectors \\{P_{m}\\}, we can define a corrsponding obervable (measurable physical quantity):</p>  M = \\sum_{m} m P_{m}  <p>where m are the eigenvalue (measurement result) and P_{m} the projection opreator. A projector P can be expressed using an orthonotmal basis \\{|i\\rangle\\} spanning some subspace W \\subset \\mathcal{H}</p>  P = \\sum_{i=1}^{k}|i\\rangle\\langle i|  <p>This means that P projects any state vector onto the subspace W spanned by the basis vectors \\{|i\\rangle\\}.</p> <p>The porjection operator has the foloowing properties </p>  P_{m}^{\\dagger} = P_{m}, \\ P_{m}^{2} = P_{m}.  <p>The probability of obtaining outcome m when measuring state |\\psi\\rangle is: </p>  p(m) = \\langle \\psi |P_{m}|\\psi\\rangle  <p>After the measurement, the system state collapses to</p>  |\\psi'\\rangle = \\frac{P_{m}|\\psi\\rangle}{\\sqrt{p(m)}}  <p>This is a normalized projection of the original state onto the eigenspace corresponding to P_{m}. The expected value of observable M is</p>  \\langle \\psi \\bigg(\\sum_{m}mP_{m}\\bigg)\\psi\\rangle  = \\langle \\psi |M|\\psi\\rangle"},{"location":"Quantum_Algorithm_101/measurement_in_quantum_mechanics/#two-qubits-example","title":"Two qubits example","text":"<p>Suppose we have two qubits. If these were two classical bits, then there would be four possible states and four computational basis state denote |00\\rangle, |01\\rangle, |10\\rangle, and |11\\rangle. A pair of qubits can also exist in superpositions of these four states, so that quantum state of two qubits involves associating a complex coefficient (ampllitude). We can describe this two qubtis system as</p>  \\lvert\\psi\\rangle = a_{00}\\lvert00\\rangle+a_{01}\\lvert01\\rangle+a_{10}\\lvert10\\rangle+a_{11}\\lvert11\\rangle.  <p>Similiar to the single qubit case, the measurement resutls x (any of the followings: 00, 01, 10, 11) occurs with probability |\\alpha_{x}|^{2}, with the state of the qubits after the measurement being |x\\rangle. For a two-qubit system, we could measure jsut a subset of the qubits, for example, we want to measure the first qubit alone gives 0 with probability |\\alpha_{00}|^{2}+|\\alpha_{01}|^{2}, leaving the post-measurement state </p>  |\\psi'\\rangle = \\frac{\\alpha_{00}|00\\rangle+\\alpha_{01}|01\\rangle}{\\sqrt{|\\alpha_{00}|^{2}+|\\alpha_{01}|^{2}}}.  <p>Note that the post-measurement state is re-normalized by the factor \\sqrt{|\\alpha_{00}|^{2}+|\\alpha_{01}|^{2}} so that it still satisfies the normalization condition.</p>"},{"location":"Quantum_Algorithm_101/measurement_in_quantum_mechanics/#references","title":"References","text":"<p>[1] M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p> <p>[2]. https://en.wikipedia.org/wiki/Measurement_in_quantum_mechanics</p> <p>[3]. https://en.wikipedia.org/wiki/Mathematical_formulation_of_quantum_mechanics</p> <p>[4]. https://en.wikipedia.org/wiki/Born_rule</p> <p>[5]. https://en.wikipedia.org/wiki/POVM</p>"},{"location":"Quantum_Algorithm_101/modular_arithmetic/","title":"Modular","text":"<p>$$ a \\equiv b \\;(mod\\; m) $$ where a and b are integers, and m is a natual numebr N</p>"},{"location":"Quantum_Algorithm_101/modular_arithmetic/#examples","title":"Examples","text":"<p>Let's loko into 1st examples:  $$ 10 \\equiv 4 \\;(mod\\; 6) $$ can be intrepreted as 10 - 4 is divisible by 6,</p> <p>$$ 28 \\equiv 4 \\;(mod\\; 6) $$ can be intrepreted as 28 - 4 is divisible by 6,</p> <p>$$ 36 \\equiv 0 \\;(mod\\; 6) $$ can be intrepreted as 36 - 4 is divisible by 6.</p> <p>We can see that two different numbers can be represented as congruent in mod 6. Notice above that both 10 and 28 are congruent to 4 in mod 6.</p>"},{"location":"Quantum_Algorithm_101/modular_arithmetic/#moduler-2","title":"Moduler 2","text":"<p>         Moduler 2 arithemtic example     </p>"},{"location":"Quantum_Algorithm_101/modular_arithmetic/#congruence","title":"Congruence","text":""},{"location":"Quantum_Algorithm_101/modular_arithmetic/#addition","title":"Addition","text":""},{"location":"Quantum_Algorithm_101/modular_arithmetic/#multiplication","title":"Multiplication","text":""},{"location":"Quantum_Algorithm_101/modular_arithmetic/#exponentiation","title":"Exponentiation","text":""},{"location":"Quantum_Algorithm_101/modular_arithmetic/#division","title":"Division","text":""},{"location":"Quantum_Algorithm_101/modular_arithmetic/#multiplicative-inverses","title":"Multiplicative Inverses","text":""},{"location":"Quantum_Algorithm_101/probability_theory/","title":"Probability Theory","text":""},{"location":"Quantum_Algorithm_101/probability_theory/#linearity-of-expectation","title":"Linearity of Expectation","text":"<p>For random variables X and Y (which may be dependent), $$ \\mathbb{E}[X + Y] = \\mathbb{E}[X] + \\mathbb{E}[Y] $$ more generally, for random variable X_{1}, X_{2}, \\cdots, X_{n} and constants c_{1}, c_{2}, \\cdots, c_{n}, $$ \\mathbb{E}\\bigg[\\sum_{i = 0}^{N-1}c_{i}X_{i} \\bigg] = \\sum_{i = 0}^{N-1} (c_{i} \\cdot X_{i}) $$</p> <p>Also, $$ \\mathbb{E}[af(X) + b] = a\\mathbb{E}[f(X)] + b $$ this regardless of the distribution of X, and regardless of whether f is linear. </p>"},{"location":"Quantum_Algorithm_101/probability_theory/#reference","title":"reference","text":"<ol> <li>[1] Linearity of Expectation, https://brilliant.org/wiki/linearity-of-expectation/</li> </ol>"},{"location":"Quantum_Algorithm_101/qiskit_primitives/","title":"What are Qiskit primitives?","text":"<ul> <li> <p><code>Statevectorsampler</code>: can sample the output quantum state from the quantum circuit in the computational basis. For example, if we have a circuit  represented by a unitary U, <code>Statevectorsampler</code> can sampler U|0\\rangle.</p> </li> <li> <p><code>StatevectorEstimator</code>: can estimate expectation values of observables with respect to the output quantum state of the quantum circuit. For instance, if we have a circuit represented by a unitary U and an observale O we'd like to measure, <code>StatevectorEstimator</code> calculates \\langle 0|U^{\\dagger}OU|0\\rangle.</p> </li> </ul>"},{"location":"Quantum_Algorithm_101/qiskit_primitives/#reference","title":"Reference","text":"<ol> <li>PENNYLANE - Qiskit primitives: https://pennylane.ai/qml/glossary/what-are-qiskit-primitives</li> <li>Qiskit 101</li> </ol>"},{"location":"Quantum_Algorithm_101/quantum_embedding/","title":"Quantum Embedding","text":""},{"location":"Quantum_Algorithm_101/quantum_embedding/#introduction","title":"Introduction","text":"<p>A quantum embedding represtnes classical data as quantum states in Hilbert Space via a quantum feature map. With the input x, we get |x\\rangle after quantum embedding, which is a set of gate parameters in a quantum circuit.</p> <p>Let's consider classical input date with m example with N featuress each, </p>  \\mathcal{D} = x^{(1)}, \\cdots, x^{(m)}, \\cdots, x^{(M)},  <p>where x^{(1)} is the N-dimensional vector for m = 1, \\cdots, M. To embed this data into n quantum subsystems. We can use various type of embedding techniques like Basis Embedding and Amplitude Embedding we are going to talk about next.</p>"},{"location":"Quantum_Algorithm_101/quantum_embedding/#basis-embedding","title":"Basis Embedding","text":"<p>Basis Embedding associates each input with a computational basis state of a qubit subsystem. The classical data has to be in the form of binary bit strings. For example, x = 1101 is represented by the 4-qubit quantum state |1001\\rangle.</p> <p>One bit of classical information is represented by one quantum subsystem.</p> <p>Thus, x^{(m)} = (b_{1},\\cdots,b_{N}) with b_{i} \\in [0,1] for i=1,\\cdots, N. we have </p>  x^{(m)} \\mapsto |X^{(m)}\\rangle.  <p>The number of quantum subsystem (n) most at least equals to N.</p>"},{"location":"Quantum_Algorithm_101/quantum_embedding/#amplitude-embedding","title":"Amplitude Embedding","text":"<p>Data is encoded into amplitudes of quantum state. A normalized classical N-dimensional classical datapoint x is represented by the amplitude of a n-qubit quantum state |\\psi_{x}\\rangle as</p>  |\\psi_{x}\\rangle = \\sum_{i = 1}^{N}x_{i}|i\\rangle,  <p>where N = 2^{n}, x_{i} is the i-th element of x and |i\\rangle is the i-th computational basis state. x_{i} can be either float or integer. For example, we have a normalized classical data </p>  x_{\\text{norm}} = \\frac{1}{\\sqrt{31.25}}(1,0.0,-5.5,0.0),  <p>the corrosponding amplitude embedding is </p>  \\begin{array}{ll} |\\psi_{x_{\\text{norm}}}\\rangle &amp; = \\frac{1}{\\sqrt{31.25}}[1|00\\rangle + 0|01\\rangle - 5.5|10\\rangle+0|11\\rangle]\\\\ \\ &amp; = \\frac{1}{\\sqrt{31.25}}[1|00\\rangle - 5.5|10\\rangle] \\end{array}  <p>Let's consider the classical \\mathcal{D} above. Its amplitude embedding can be easily understood if we concatenate all the input example x together into one vector </p>  \\alpha = C_{\\text{norm}}x^{(1)}_{1},\\cdots,x^{(1)}_{N},x^{(2)}_{1},\\cdots,x^{(2)}_{N},\\cdots,x^{(M)}_{1},\\cdots,x^{(M)}_{N},  <p>where C_{\\text{norm}} is the normalization constant, |\\alpha|^{2} = 1. The input dataset can be represented as </p>  |\\mathcal{D}\\rangle = \\sum_{i=1}^{2^{n}}\\alpha_{i}|i\\rangle,  <p>where \\alpha_{i} are the elements of the element vector \\alpha and |i\\rangle are computational basis states. The number of amplitude to be encoded is N\\times M.</p> <ul> <li>N: N features for each m \\in 1,...,M.</li> <li>M: M examples.</li> </ul> <p>As a system of n qubit provides 2^{n} amplitude, it requires n \\geq log_{2}(NM) qubits. </p> <p>That is </p>  \\text{number of qubits} = n = \\lceil log_{2}(NM) \\rceil.  <p>More embedding methodologies from PENNYLANE - Embedding templates</p> <ul> <li>Angle Embedding</li> <li>Displacement Embedding</li> <li>IQPE Embedding</li> <li>QAOA Embedding</li> <li>Squeezing Embedding</li> </ul>"},{"location":"Quantum_Algorithm_101/quantum_embedding/#reference","title":"Reference","text":"<ol> <li>PENNYLANE - Quantum Embedding: https://pennylane.ai/qml/glossary/quantum_embedding</li> </ol>"},{"location":"Quantum_Algorithm_101/quantum_feature_map/","title":"Quantum Feature Map","text":"<p>Let \\mathcal{X} be a set of input data, we have a quantum feature map such that </p>  \\mathcal{X} \\rightarrow \\phi \\rightarrow \\mathcal{F}  <p>In general, \\mathcal{F} is just a vector space. </p> <ul> <li>A quantum feature map \\phi: \\mathcal{X} \\rightarrow \\mathcal{F} where \\mathcal{F} is a Hilbert space and the feature vectos are quantum states.</li> <li>The map transforms x \\rightarrow |\\phi(x)\\rangle by way of a unitary transformation U_{\\phi}(x). Where U_{\\phi}(x) is a variational circuit whose parameters depend on the input data.</li> </ul>"},{"location":"Quantum_Algorithm_101/quantum_feature_map/#reference","title":"Reference","text":"<ol> <li>PENNYLANE - Quantum Feature Map: https://pennylane.ai/qml/glossary/quantum_feature_map</li> </ol>"},{"location":"Quantum_Algorithm_101/quantum_postulate/","title":"Quantum Postulates","text":""},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-1-state-space","title":"Postulate 1 - State space","text":"<p>Postulate 1</p> <p>Associated to any isolated physical system is a complex vector space with inner product (that is, a Hilbert space) known as the state space of the system. The system is completely described by its state vector, which is a unit vector in the system\u2019s state space.</p> <p>A qubit has two-dimensional state. Suppose |0\\rangle and |1\\rangle form an orthonormal basis for that state space. Then an arbitrary statevector in the state space can be written </p>  |\\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle  <p>where \\alpha and \\beta are complex numebrs; \\alpha^{2} + \\beta^{2} = 1. The condition that |\\psi\\rangle be a unit vector. \\langle \\psi|\\psi\\rangle =1 is known as a normalization condition for state vectors.</p> <p>We say that any linear combination \\sum_{i}\\alpha_{i}|\\psi_{i}\\rangle is a superposition of the state |\\psi_{i}\\rangle with amplitude \\alpha_{i} for the state |\\psi_{i}\\rangle. For example,</p>  \\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}}  <p>is a superposition of the state |0\\rangle and |1\\rangle with amplitude 1/\\sqrt{2} for the state |0\\rangle and -1/\\sqrt{2} for the state |1\\rangle.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-2-evolution","title":"Postulate 2 - Evolution","text":"<p>Postulate 2</p> <p>The evolution of a closed quantum system is described by a unitary transformation. This is, the state |\\psi\\rangle of the system at time t_{1} is related to the state |\\psi'\\rangle of the system at time t_{2} by a unitary operator U which depends only on the times t_{1} and t_{2}.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-3-quantum-measurement","title":"Postulate 3 - Quantum measurement","text":"<p>Postulate 3</p> <p>Quantum measurements are described by a collection \\{M_{m}\\} of measurement operators. These are operators acting on the state space of the system being measured. The  m refers to the measurement outcomes that may occur in the experiment. If the state of the quantum system is |\\psi\\rangle immediately before the measurement then the probability that result m occurs is given by </p>  p(m) = \\langle \\psi |M_{m}^{\\dagger}M_{m}|\\psi\\rangle,  <p>and the state of the system after the measurement is </p>  \\frac{M_{m}|\\psi\\rangle}{\\sqrt{\\langle \\psi |M_{m}^{\\dagger}M_{m}|\\psi\\rangle}}.  <p>The measurement operators satisfy the completness equation,</p>  \\sum_{m}M_{m}^{\\dagger}M_{m} = I.  <p>A simple but important example of a measurement is the measurement of a qubit in the computational basis. This is a measurement on a single qubit with two outcomes defined by the two measurement opeartors M_{0} = |0\\rangle \\langle 0|, M_{2} = |1\\rangle \\langle 1|. Notice that each operator is Hermitian, and that M_{0}^{2} = M_{0}, M_{1}^{2} = M_{1}. From completness equation, \\sum_{m}M_{m}^{\\dagger}M_{m} = I, we have I = M_{0}^{\\dagger}M_{0} + M_{1}^{\\dagger}M_{1} = M_{0}+M_{1}. Suppose the state being measured is |\\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle. Then the probability of obtaining measurement outcome 0 is  $$ p(0) = \\langle \\psi|M_{0}^{\\dagger}M_{0}|\\psi\\rangle = \\langle \\psi|M_{0}|\\psi\\rangle = |\\alpha|^{2} $$ similarly, the probability of getting the result of 1 is p(1) = |\\beta|^{2}. The state after measurement in the two cases is therefore </p>  \\begin{array}{c} \\frac{M_{0}|\\psi\\rangle}{|\\alpha|} = \\frac{\\alpha}{|\\alpha|}|0\\rangle,\\\\ \\frac{M_{1}|\\psi\\rangle}{|\\beta|} = \\frac{\\beta}{|\\beta|}|1\\rangle. \\end{array}"},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-4-distinguishing-quantum-states","title":"Postulate 4 - Distinguishing quantum states","text":"<p>An important application of Postulate 3 is to the problem of distinguishing quantum states. In the classical world, distinct states of an object are usually distinguishable, at least in principle. For example, we can always identify whether a coin has landed heads or tails, at least in the ideal limit. Quantum mechanically, the situation is more complicated. For example, we say a plausible argument that non-orthogonal quantum states cannot be distinguished.</p> <p>Imagine a game between Alice and Bob. Alice has a known list of quantum states, and she picks one of them \u2014 say |\\psi_i\\rangle \u2014 and sends it to Bob. Bob's task is to figure out which state she sent.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#orthonormal-states","title":"Orthonormal States","text":"<p>If the states |\\psi_i\\rangle are orthonormal, Bob can always identify the state with certainty. He constructs a quantum measurement with operators that project onto each basis state. For example, (M_{i} \\equiv |\\psi_{i}\\rangle \\langle \\psi_{i}|), one for each possible index i, and an addtional measurement operator M_{0} defined as the positive square root of the positive operator I - \\sum_{i \\neq 0} |\\psi_{i}\\rangle\\langle\\psi_{i}|. These operators satify the completeness relation, and if the state |\\psi_{i}\\rangle is prepared then p(i) = \\langle \\psi_{i}|M_{i}|\\psi_{i} \\rangle = 1, so the result i occurs with certainty. Thus, it is possible to reliably distinguish the orthonormal states |\\psi_{i}\\rangle.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#non-orthogonal-states","title":"Non-Orthogonal States","text":"<p>If the stateS |\\psi_{i}\\rangle are not orthonormal then we can prove that there is no quantum measurement capable of distinguishing the states. The idea is that Bob will do a measurement described by measurement operators M_{j}, with outcome j. The key to why Bob cannot distinguish non-orthogonal states |\\psi_{1}\\rangle and |\\psi_{2}\\rangle is the observation that |\\psi_{2} can be decomposed into a (non-zero) component parallel to |\\psi_{1}\\rangle, and a component orthogonal to |\\psi_{1}\\rangle. Suppose j is a measurement outcome such that f(i) =1, that is, Bob guesses that the sate was |\\psi_{1}\\rangle when he observes j. but because of the component of |\\psi_{2}\\rangle parallel to |\\psi_{1}\\rangle, these is a non-zero probability of getting outcome j when |\\psi_{2}\\rangle is prepared, so sometimes bob will make an error identifying which state was prepared.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-5-projective-measurements","title":"Postulate 5 - Projective measurements","text":"<p>Projective measurements actually turn out to be equivalent to the general measurement postulate, when they are augmented with the ability to perform unitary transformations, as described in Postulate 2.</p> <p>Projective measurements</p> <p>A projective measurement is described by an observable, M, a Hermitian operator on the state space of the system being observed. The observable has a spectral decomposition,</p>  M = \\sum_{m}mP_{m},  <p>where P_{m} is the projector onto the eigenspace of M with eigenvalue m/ The possible outcomes of the measurement correspond to the eigenvalues m, of the observable. Upon measuring the state |\\psi\\rangle, the probability of getting results m is given by</p>  p(m) = \\langle \\psi|P_{m}|\\psi\\rangle  <p>Given that outcome m occurred, the state of the quantum system immediately after measurement is </p>  \\frac{P_{m}|\\psi\\rangle}{\\sqrt{p(m)}}.  <p>A projection measurement can be understoof as a special case of Postulate 3 - Quantum measurement. Suppose the measurement operator in Postulate 3, in addition to the completenss relation \\sum_{m}M^{\\dagger}M_{m} = I, also satisfy the conditions that M_{m} are orthogonal projectors, that is, the M_{m} are Hermitian, and </p>  M_{m}M_{m'} = \\delta_{m,m'}M_{m}.  <p>With these, it reduces to a projective measurement as defined.</p> <p>Of course, since the projective measurement is a special case of Postulate 3. We can also define the projectors more restrictedly</p>  P_{m}^{2} = P_{m}, P_{m}^{\\dagger} = P_{m}, \\sum_{m}P_{m} = I  <p>Projective measuremnets have many useful properties. In particular, it is very easy to calculate average for projective measurements. By definition, the average value of the measurement ([\\mathbb{E}]),</p>  \\begin{array}{rl} [\\mathbb{E}(M)] &amp; = \\sum_{m}mp(m)\\\\ \\ &amp; = \\sum_{m}m\\langle \\psi|P_{m}|\\psi\\rangle\\\\ \\ &amp; = \\langle \\psi|\\bigg(m\\sum_{m}P_{m}\\bigg)|\\psi\\rangle\\\\ \\ &amp; = \\langle \\psi|M|\\psi\\rangle\\\\ \\end{array}  <p>This is so useful that the average value of the observable M is often written \\langle M \\rangle \\equiv \\langle \\psi|M|\\psi\\rangle. From this formula, the standard deviation, a measure of the typical spread of the observed values upon measurement of M, associated to observations of M,</p>  \\begin{array}{rl} [\\Delta(M)]^{2} &amp; = \\langle (M^{2} - \\langle M \\rangle^{2}) \\rangle \\\\               \\ &amp; = \\langle M^{2} \\rangle - \\langle M \\rangle^{2}. \\end{array}  <p>For example, suppose we prepare a quantum system in an eigenstate |\\psi\\rangle of some observable M, with corresponding eigenvalue m. What is the average observed value of M, and the standard deviation?</p> <p>We have an observable M, state |\\psi\\rangle is an eigenstate of M, so:</p>  M|\\psi\\rangle = m|\\psi\\rangle  <p>The expectation value is </p>  \\langle M \\rangle = \\langle \\psi|M|\\psi \\rangle = m  <p>since |\\psi\\rangle is an eignestate of M with eigenvalue m, the measurement will always yield m. The standard deviation is </p>  [\\Delta(M)]^{2} = \\langle m^{2} - \\langle m \\rangle^{2} \\rangle = 0.  <p>Rather than giving an observable to describe a projective measurement, often people simply list a complete set of orthogonal projectors P_{m} satisfying the relations \\sum_{m}mP_{m} = I and P_{m}P_{m'} = \\delta_{mm'}P_{m}.</p> <p>The coresponding observable implicit in this usage is M = \\sum_{m}mP_{m}. Another widely used phrase, to 'measure in a basis |m\\rangle', where |m\\rangle form an otrhonormal basis, simply means to perform the projective measurement with projectors P_{m} = |m\\rangle\\langle m|. Let's look at an example of projective measurements on single qubits. </p> <p>First is the measurement of the observable Z. This has rigenvalues +1 and -1 with corresponding eigenvectors |0\\rangle and |1\\rangle. Thus, for example, measurement of Z on the state |\\psi\\rangle = (|0\\rangle + |1\\rangle)/\\sqrt{2} gives the result +1 with probability \\langle \\psi|0\\rangle \\langle 0|\\psi\\rangle = 1/2, and similarly the result -1 with probability 1/2. Suppose \\overrightarrow{v} is any real three-dimensional unit vector. Then we can define an observable:</p>  \\overrightarrow{v} \\cdot \\overrightarrow{\\sigma} \\equiv v_{1}\\sigma_{1} + v_{2}\\sigma_{2} + v_{3}\\sigma_{3}.  <p>Measurement of this observable is sometimes referred to as a 'measurement of spin along the \\overrightarrow{v}', for historical reasons.</p> <p>Exercise 1. Suppose we have qubit in the state |0\\rangle, and we measure the observable X. What is the average value of X? What is the standard deviation of X?</p> <p>Exercise 2. Calculate the probability of botaining the result +1 for a measurement of \\overrightarrow{v} \\cdot \\overrightarrow{\\sigma}, given that the state prior to measurement is |0\\rangle. What is the state of the system after the measurement if +1 is obtained?</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-6-povm-measurements","title":"Postulate 6 - POVM measurements","text":""},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-7-phase","title":"Postulate 7 - Phase","text":"<p>Phase is a commonly used term in quantum mechanics, with several different meanings depends upon context. At this point it is convenient to review a couple of these meanings. </p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#global-phase","title":"Global phase","text":"<p>Consider, for example, the state e^{i\\theta}|\\psi\\rangle, where |\\psi\\rangle is a state vector, and \\theta is a real number. We say that the state e^{i\\theta}|\\psi\\rangle is equal to |\\psi\\rangle, up to the global phase factor e^{i\\theta}. It is interesting that the statistics od measurement predicted for these two state are the same. </p> <p>For this reason we may ignore global phase factors as being irrelevanr to the observed properties of the physical system.</p> <p>Global phase doesn't change the direction of the Bloch vector at all.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#relative-phase","title":"Relative phase","text":"<p>Howeverm, relative phase, on the other hand, is not something we can ignore. It refers to the phase difference between parts of a quantum superposition. For example, we have two states</p>  \\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\ \\text{and} \\ \\frac{|0\\rangle +- |1\\rangle}{\\sqrt{2}},  <p>Both has the same amplitudes in magnitude \\frac{1}{\\sqrt{2}}, but the second state has a relative phase of -1 between |0\\rangle and |1\\rangle. More generally still, two states are said to differ by a relative phase in some basis if each of the amplitudes in that basis is realted by such a phase factor.</p> <p>Suppose you have a qubit state </p>  |\\psi\\rangle = \\alpha|0\\rangle + \\beta|0\\rangle, \\ \\alpha, \\beta \\in \\mathbb{C}  <p>since each amplitude is a complex number, we write</p>  \\alpha = |\\alpha|e^{i\\theta}  <p>from Eular identity. You already know that |\\alpha|^{2} is a measurement probability. The \\text{arg}(\\alpha) = \\text{phase}. The relative phase is defined as </p>  \\phi = \\text{arg}(\\beta) - \\text{arg}(\\alpha)  <p>where \\text{arg}(\\alpha) is a phase angle, \\text{tan}^{-1}(\\frac{b}{a}) from a complex number \\alpha = a + bi. We can easily calculate that \\alpha = 1e^{i\\pi/4} from \\alpha = \\frac{1}{\\sqrt{2}}+\\frac{1}{\\sqrt{2}}i.</p> <p>Reltaive phase</p> <p>Suppose you are given a normalized qubit state:</p>  |\\psi\\rangle = \\frac{1}{\\sqrt{2}}|0\\rangle + \\frac{i}{\\sqrt{2}}|1\\rangle  <p>we say \\alpha = 1/\\sqrt{2} and \\beta = i/\\sqrt{2}. From Eular equation,</p>  \\alpha = |\\alpha|e^{i\\theta_{0}}, \\beta = |\\beta|e^{i\\theta_{1}}  <p>we have |\\alpha| = 1/\\sqrt{2} with \\theta_{0} = 0 and |\\beta| = 1/\\sqrt{2} with \\theta_{1} = \\pi/2. The relative phase can be derived as </p>  \\phi = \\theta_{1} - \\theta_{0} = \\frac{\\pi}{2}  <p>so the state can be written as </p>  |\\psi\\rangle = \\frac{1}{\\sqrt{2}}(|0\\rangle + e^{i\\frac{\\pi}{2}}|1\\rangle)."},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-8-composite-systems","title":"Postulate 8 - Composite systems","text":"<p>Postulate 4</p> <p>The state space of a composite physical system is the tensor product of the state spaces of the component physical systems. Moreover, if we have system numbered 1 through n, and system i is prepared in the state |\\psi_{i}{\\rangle, then the joint state of the total system is |\\psi_{1}\\rangle \\otimes |\\psi_{2}\\rangle \\otimes \\cdots \\otimes |\\psi_{n}\\rangle</p> <p>Postulate 4 also enables us to define one of the most interesting and puzzling ideas assocaited with composite quantum system - entanglement. Consider the two qubit state </p>  |psi\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}}  <p>There are no such states |a\\rangle and |b\\rangle that can make |\\psi\\rangle = |a\\rangle|b\\rangle.</p> <p>Proof |\\psi\\rangle = |a\\rangle|b\\rangle doesn't exist</p> <p>Suppose </p>  |a\\rangle \\otimes |b\\rangle = \\frac{|00\\rangle + |11\\rangle}{\\sqrt{2}}  <p>write </p>  |a\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle, \\ |b\\rangle = \\gamma|0\\rangle + \\delta|1\\rangle,  <p>then</p>  |a\\rangle |b\\rangle = \\alpha\\gamma|00\\rangle + \\alpha\\delta|01\\rangle + \\beta\\gamma|10\\rangle + \\beta\\delta|11\\rangle  <p>there are no such coefficient combinations \\alpha,\\beta,\\gamma,\\delta exist.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#postulate-9-quantum-mechanics-global-view","title":"Postulate 9 - Quantum mechanics: global view","text":""},{"location":"Quantum_Algorithm_101/quantum_postulate/#composite-system-postualte","title":"Composite system postualte","text":"<p>The Hilbert space of a composite system is the Hilbert space tensor product of the state spaces associated with the component systems. For a non-relativistic system consisting of a finite number of distinguishable particles, the component systems are the individual particles.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#measurement-of-a-system","title":"Measurement of a system","text":""},{"location":"Quantum_Algorithm_101/quantum_postulate/#description-of-physical-quantutites-postulate-ii-a","title":"Description of physical quantutites - Postulate II - a","text":"<p>Every measurable physical quantity \\mathcal{A} is described by a Hermitian operator A acting in the state space \\mathcal{H}. This operator is an observable, meaning that its eigenvectors form a basis for \\mathcal{H}. The result of measuring a physical quantity \\mathcal{A} must be one of the eigenvalues of the corrosponding observable A.</p>"},{"location":"Quantum_Algorithm_101/quantum_postulate/#results-of-measurement-postulate-ii-b","title":"Results of measurement - Postulate II - b","text":"<p>By spectral theory, we can associate a probability measure to the values of A in any state \u03c8. We can also show that the possible values of the observable A in any state must belong to the spectrum of A. The expectation value (in the sense of probability theory) of the observable A for the system in state represented by the unit vector \\psi \\in \\mathcal{H} is \\langle \\psi |A|\\psi \\rangle. If we represent the state \u03c8 in the basis formed by the eigenvectors of A, then the square of the modulus of the component attached to a given eigenvector is the probability of observing its corresponding eigenvalue.</p> <p>When the physical quantity \\mathcal{A} is measured on a system in a normalized state |\\psi\\rangle, the probability of obtaining an eigenvalue (denoted a_{n} for discrete spectra and \\alpha for continuous spectra) of the corresponding observable A is given by the amplitude squared of the appropriate wave function (projection onto corrosponding eigenvector)</p> <p>Here are three cases:</p>  \\begin{array}{ll} \\mathbb{P}(a_n) = |\\langle a_{n}|\\psi\\rangle|^{2} &amp; \\text{Discrete, nondegenerate spectrum}\\\\ \\mathbb{P}(a_n) = \\sum_{i}^{g_n}|\\langle a_{n}|\\psi\\rangle|^{2} &amp; \\text{Discrete, degenerate spectrum}\\\\ d\\mathbb{P}(a_n) = |\\langle a_{n}|\\psi\\rangle|^{2}d\\alpha &amp; \\text{Continuous, nondegenerate spectrum} \\end{array}"},{"location":"Quantum_Algorithm_101/quantum_postulate/#effect-of-measurement-on-the-state-postulate-ii-c","title":"Effect of measurement on the state - Postulate II - c","text":"<p>If the measurement of the physical quantity \\mathcal{A} on the system in the state |\\psi\\rangle gives the result a_n, then the state of the system immediately after the measurement is the normalized projection of |\\psi\\rangle onto eigensubspace associated with a_n</p>  |\\psi\\rangle \\Rightarrow\\frac{P_{n}|\\psi\\rangle}{\\sqrt{\\langle \\psi |P_{n}|\\psi\\rangle}}"},{"location":"Quantum_Algorithm_101/quantum_postulate/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p> <p>[2]. https://en.wikipedia.org/wiki/Mathematical_formulation_of_quantum_mechanics</p>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/","title":"Quantum State and Space Basics","text":"<p>Quantum computing is linear algebra in a complex vector space. This guide builds intuition through geometric and vector-based thinking.</p>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/#dont-overthink-superposition-hilbert-space-and-state-vectors","title":"Don\u2019t Overthink \"Superposition\" - Hilbert Space and State Vectors","text":"<p>A quantum state is just a normalized vector, like [x, y]^T in 2D Cartesian coordinates, but in complex space.</p> <p>We can write a quantum state as:</p>  |\\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle, \\quad \\text{with } |\\alpha|^2 + |\\beta|^2 = 1.  <p>where |\\psi\\rangle, |0\\rangle, and |1\\rangle are vectors. very easy and simple. just like in 2D Cartesian coordinates. In quantum algorithms, we define:</p>  |0\\rangle =  \\begin{bmatrix} 1\\\\0 \\end{bmatrix}, \\quad  |1\\rangle =  \\begin{bmatrix} 0\\\\1 \\end{bmatrix}  <p>         State vector representation     </p> <p>We use big-endian convention, where the state |0\\rangle corresponds to index 0 (first), and |1\\rangle to index 1 (second). Similarly, if we have the basis states |0\\rangle, |1\\rangle, |2\\rangle, |3\\rangle, they map to binary-labeled states |00\\rangle, |01\\rangle, |10\\rangle, |11\\rangle, corresponding to indices 0 to 3:</p>  |0\\rangle =  \\begin{bmatrix} 1\\\\0\\\\0\\\\0 \\end{bmatrix}, \\quad  |1\\rangle =  \\begin{bmatrix} 0\\\\1\\\\0\\\\0 \\end{bmatrix}, \\quad  |2\\rangle =  \\begin{bmatrix} 0\\\\0\\\\1\\\\0 \\end{bmatrix}, \\quad  |3\\rangle =  \\begin{bmatrix} 0\\\\0\\\\0\\\\1 \\end{bmatrix}  <p>Let\u2019s go back to our original idea.</p> <p>Put simply:</p> <p>Superposition describes the position of the state vector in the 1-qubit, 2D computational basis space (spanned by |0\\rangle, |1\\rangle).</p> <p>Don\u2019t overthink \u201csuperposition.\u201d It\u2019s just like describing a vector in regular Cartesian coordinates \u2014 but now the axes are |0\\rangle and |1\\rangle; \\alpha and \\beta are just vector coefficients, a.k.a, amplitude in quantum language!</p>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/#dont-be-fooled-by-computational-basis-different-representation-in-quantum-algorithm","title":"Don't be fooled by \"Computational basis\" - Different Representation in Quantum Algorithm","text":"<p>As you dig into the quantum algorithm, you will constantly hear a term called computational basis. Don't be fooled by the name, it is just as similar as X,Y axes in our friend Cartesian coordinates. We can describe this computational basis using two methods</p> <ul> <li>Binary representation: |00\\rangle,|01\\rangle,|10\\rangle,|11\\rangle</li> <li>Decimal representation: |0\\rangle,|1\\rangle,|2\\rangle,|3\\rangle</li> </ul> <p>They are jsut different labes for the same computational basis vectors.</p>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/#tensor-products-never-heard-that-before","title":"Tensor Products? Never heard that before!","text":"<p>In quantum algorithm, you will have to deal with tensor product, which you will probally never heard this before. or maybve you just hear of inner product. But here is the thing. Tensor product in Hilbert space:</p>  \\mathcal{H}_{A} \\otimes \\mathcal{H}_{B}  <p>combines two quantum system into a joint space. It's like stacks coordinates, no interaction or entanglement.</p> <p>Let's do some exampels, </p>  |0\\rangle =  \\begin{bmatrix} 1\\\\0 \\end{bmatrix}, \\ |1\\rangle =  \\begin{bmatrix} 0\\\\1 \\end{bmatrix}  <p>we do the tensor product |0\\rangle \\otimes |0\\rangle and |0\\rangle \\otimes |1\\rangle</p>  \\begin{bmatrix} 1\\\\0 \\end{bmatrix} \\otimes  \\begin{bmatrix} 1\\\\0 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 1 \\\\ 1 \\cdot 0 \\\\ 0 \\cdot 1 \\\\ 0 \\cdot 0 \\\\ \\end{bmatrix} = \\begin{bmatrix} 1\\\\0\\\\0\\\\0 \\end{bmatrix} = |00\\rangle   \\begin{bmatrix} 1\\\\0 \\end{bmatrix} \\otimes  \\begin{bmatrix} 0\\\\1 \\end{bmatrix} = \\begin{bmatrix} 1 \\cdot 1 \\\\ 1 \\cdot 1 \\\\ 0 \\cdot 0 \\\\ 0 \\cdot 1 \\\\ \\end{bmatrix} = \\begin{bmatrix} 0\\\\1\\\\0\\\\0 \\end{bmatrix} = |01\\rangle  <p>A basic idea of tensor product of column vectors. Let</p>  u =  \\begin{bmatrix} u_{1}\\\\ u_{2} \\end{bmatrix}, \\ v =  \\begin{bmatrix} v_{1}\\\\ v_{2} \\end{bmatrix}  <p>then </p>  u\\otimes v =  \\begin{bmatrix} u_{1} \\cdot v_{1} \\\\ u_{1} \\cdot v_{2} \\\\ u_{2} \\cdot v_{1} \\\\ u_{2} \\cdot v_{2} \\\\ \\end{bmatrix} \\in \\mathbb{C}^{4\\times 1}  <p>Tensor of two n \\times 1 vectors \\rightarrow n^{2} \\times 1. The dimensional expands via Kronecker product.</p> <p>The python realization will be:</p> <pre><code>def tensor_product(a, b):\n    return [ai * bj for ai in a for bj in b]\n</code></pre>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/#inner-product","title":"Inner product","text":"<p>In Linear Algebra, Euclidean space, an inner product is </p>  \\langle v,w\\rangle = ||v|| \\cdot ||w|| \\cdot \\text{cos} \\theta  <p>If w is a unit vector, then</p>  \\langle w,v\\rangle = \\text{length of projection of} \\ v \\ \\text{onto} \\ w  <p>In Hilbert space \\mathbb{H}, the inner product between quantum state |\\psi\\rangle and |\\phi\\rangle is:</p>  \\langle \\phi|\\psi\\rangle = \\text{\"overlap\" or projection of} \\ |\\psi\\rangle \\ \\text{onto} \\ |\\phi\\rangle  <p>For example, let's say you have the state:</p>  |\\psi\\rangle = \\frac{1}{\\sqrt{5}} \\begin{bmatrix} 2\\\\1 \\end{bmatrix} = \\frac{2}{\\sqrt{5}}|0\\rangle + \\frac{1}{\\sqrt{5}}|1\\rangle,  <p>you want to find the projection onto |0\\rangle. Next we compute</p>  \\langle 0|\\psi \\rangle = [1 \\ 0] \\cdot \\frac{1}{\\sqrt{5}} \\begin{bmatrix} 2\\\\1 \\end{bmatrix} = \\frac{1}{\\sqrt{5}} \\cdot (1 \\cdot 2 + 0 \\cdot 1) = \\frac{2}{\\sqrt{5}}  <p>and we want to know the probability of measuing |0\\rangle</p>  |\\langle 0|\\psi\\rangle|^{2} = \\frac{4}{5}  <p>where \\langle0|\\psi\\rangle is the projection amplitude and |\\langle 0|\\psi\\rangle|^{2} is the porbability of observing |0\\rangle.</p> <p>Methematically, </p>  \\text{Amplitude along} \\ v = \\langle v, \\psi \\rangle  <p>In quantum mechanics:</p> <ul> <li>\\langle v_i|\\psi \\rangle is the amplitude of |\\psi\\rangle in direction |v_i \\rangle</li> <li>|\\langle 0|\\psi\\rangle|^{2} is the probability of measuring in tat basis</li> </ul> <p>Let's compare a</p>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/#observable","title":"Observable","text":"<p>In quantum mechanics, an observable tells you what you are measuring, for example, energy, spin, or position. It defines which basis (eigenvector) you are projecting into and what outcome (eigenvalue) you can get.</p> <p>Measuring state |\\psi\\rangle using observable with eigenvector |0\\rangle means computing \\langle 0 | \\psi\\rangle. This is the projection of \\psi\\rangle onto axis |0\\rangle with probability = |\\langle 0 |\\psi\\rangle|^{2}</p> <p>For an easy example, lets say you want to measure a room temperature and we will need a thomometer. The temperature is the observable in quantum analogy, and the measurement process is the tool. The observable is the operator (e.g. Hamiltonian) defining what you measure.</p>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/#quantum-gates-as-rotations","title":"Quantum Gates as Rotations","text":"<p>Quantum gates = unitary matrices, like rotation matrics in Euclidean geometry - but in complex hilbert space.</p> <p>When you talk about the rotation xyz, there are no xyz in hilbert space, its all computational basis?</p> <ul> <li>Gates = unitary transformations</li> <li>Example: Z gate, Hadamard gate</li> <li>Acts like rotation/reflection in complex space</li> </ul>"},{"location":"Quantum_Algorithm_101/quantum_state_space_basics/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"Quantum_Algorithm_101/qubit_dimensionality/","title":"Multi-Qubit Hilbert Space","text":""},{"location":"Quantum_Algorithm_101/qubit_dimensionality/#general-2n-dimensional-state","title":"General 2\u207f-Dimensional State","text":"<p>Any n-qubit quantum state is a linear combination of all computational basis states:</p>  |\\psi\\rangle = \\sum_{i=0}^{2^n - 1} \\alpha_i |i\\rangle, \\quad \\text{with } \\sum_{i=0}^{2^n - 1} |\\alpha_i|^2 = 1  <p>This is represented as a normalized column vector in \\mathbb{C}^{2^n}, where each amplitude \\alpha_i can encode probabilities, payoff values, or other structured data.</p>"},{"location":"Quantum_Algorithm_101/qubit_dimensionality/#qubit-basis-and-vector-representation","title":"Qubit Basis and Vector Representation","text":"<p>A Hilbert space is a complex vector space that represents the state of quantum systems. For a single qubit, the Hilbert space is \\mathbb{C}^2, with the computational basis:</p>  |0\\rangle = \\begin{bmatrix}1 \\\\ 0\\end{bmatrix}, \\quad |1\\rangle = \\begin{bmatrix}0 \\\\ 1\\end{bmatrix}  <p>In the standard big-endian convention (most significant bit first), the binary basis state |0\\rangle corresponds to the first index, hence it is represented by [1, 0]^T. Similarly, |1\\rangle corresponds to the second index, represented by [0, 1]^T.</p> <p>This mapping generalizes to multi-qubit systems. For example, with n = 3, the state space is \\mathbb{C}^{2^3} = \\mathbb{C}^8. The basis state |001\\rangle corresponds to index 1 in binary ordering and is represented as:</p>  |001\\rangle = \\begin{bmatrix} 0 \\\\ 1 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{bmatrix}  <p>Each basis state |i\\rangle maps to a one-hot vector of length 2^n, with a 1 at position i and 0 elsewhere.</p>"},{"location":"Quantum_Algorithm_101/test_level/","title":"Test level","text":"<p>test quantum algorithm level</p>"},{"location":"Quantum_Algorithm_101/variational_circuit/","title":"Variational Circuit","text":"<p>Variational circuits are also known as \"parameterized quantum circuits\"</p>"},{"location":"Quantum_Algorithm_101/variational_circuit/#adaptable-quantum-circuits","title":"Adaptable quantum circuits","text":"<p>Variational quantum circuit are \"quantum algorithm\" that depend on free parameters. Like standard quantum circuits, they consist of three ingredients:</p> <ul> <li>Preparation of fixed initial state.</li> <li>A quantum circuit U(\\theta), parameterized by a set of free parameters \\theta.</li> <li>Measurement of an observable \\widehat{B} at the output. </li> </ul> <p>The expectation values f(\\theta) = \\langle 0|U^{\\dagger}(\\theta)\\widehat{B}U(\\theta)|0\\rangle defines a scalar cost for a given task. The free parameters \\theta = (\\theta_{1}, \\theta_{2}, \\cdots) of the citcuit(s) are tuned to optimzed this cost function.</p> <p>Variational circuits are trained by a classical optimization algorithm that makes queries to the quantum device.</p> <p>Variational circuits have become popular as a way to think about quantum algorithms for near-term quantum devices. Such devices can only run short gate sequences, since without fault tolerance every gate increases the error in the output. Usually, a quantum algorithm is decomposed into a set of standard elementary operations, which are in turn implemented by the quantum hardware.</p> <p>The intriguing idea of variational circuit for near-term devices is to merge this two-step procedure into a single step by \"learning\" the circuit on the noisy device for a given task. This way, the \"natural\" tunable gates of a device can be used to formulate the algorithm, without the detour via a fixed elementary gate set. Furthermore, systematic errors can automatically be corrected during optimization.</p>"},{"location":"Quantum_Algorithm_101/variational_circuit/#building-circuit","title":"Building circuit","text":"<p>The variational parameters with a set of non-adaptable parameters x = (x_{1},x_{2},\\cdots) enter the quantum circuit as arguments for the circuit gates. </p> <ul> <li>This allows to convert \"classical information (\\theta and x)\" into quantum informtaion (|U(x;\\theta)|0\\rangle). </li> <li>The non-adaptable parameter usually plays a role of data inputs in quantum machine learning.</li> </ul> <p>\"Quantum information\" is turned \"back\" into classical information by evaluating the expectation value of the observable \\widehat{B}.</p>  \\begin{array}{ll} f(x;\\theta) &amp; = \\langle\\widehat{B}\\rangle\\\\ \\ &amp; = \\langle 0|U^{\\dagger}(x;\\theta)\\widehat{B}U(x;\\theta)|0\\rangle \\end{array}"},{"location":"Quantum_Algorithm_101/variational_circuit/#reference","title":"Reference","text":"<ol> <li>PENNYLANE - Variational Circuit: https://pennylane.ai/qml/glossary/variational_circuit</li> </ol>"},{"location":"cryptography/symmetric/","title":"Stream Cipher","text":""},{"location":"cryptography/symmetric/#key-topics","title":"Key Topics","text":""},{"location":"cryptography/symmetric/#211-stream-cipher-vs-block-ciphers","title":"2.1.1 Stream Cipher vs Block Ciphers","text":"<p>Stream Ciphers encrypt bits individually. This is achieved by adding a bit from a key stream to a plaintext bit. There are synchronous stream ciphers where the key stream depends only on the key, and asynchronous ones where the key stream also depends on the ciphertext. If the dotted line in Fig. 2.3 is present, the stream cipher is an asynchronous one. Most practical stream ciphers are synchronous ones and Sect. 2.3 of this chapter will deal with them. An example of an asynchronous stream cipher is the cipher feedback (CFB) mode introduced in Sect. 5.1.4.</p> <p>Block ciphers encrypt an entire block of plaintext bits at a time with the same key. This means that the encryption of any plaintext bit in a given block depends on every other plaintext bit in the same block. In practice, the vast majority of block ciphers either have a block length of 128 bits (16 bytes) such as the advanced encryption standard (AES), or a block length of 64 bits (8 bytes) such as the data encryption standard (DES) or triple DES (3DES) algorithm. All of these ciphers are introduced in later chapters.</p> <ol> <li> <p>In practice, in particular for encrypting computer communication on the Internet, block ciphers are used more often than stream ciphers.</p> </li> <li> <p>Because stream ciphers tend to be small and fast, they are particularly relevant for applications with little computational resources, e.g., for cell phones or other small embedded devices. A prominent example for a stream cipher is the A5/1 cipher, which is part of the GSM mobile phone standard and is used for voice encryption. However, stream ciphers are sometimes also used for encrypting Internet traffic, especially the stream cipher RC4.</p> </li> <li> <p>Traditionally, it was assumed that stream ciphers tended to encrypt more efficiently than block ciphers. Efficient for software-optimized stream ciphers means that they need fewer processor instructions (or processor cycles) to encrypt one bit of plaintext. For hardware-optimized stream ciphers, efficient means they need fewer gates (or smaller chip area) than a block cipher for encrypting at the same data rate. However, modern block ciphers such as AES are also very efficient in software. Moreover, for hardware, there are also highly efficient block ciphers, such as PRESENT, which are as efficient as very compact stream ciphers. </p> </li> </ol>"},{"location":"cryptography/symmetric/#212-encryption-and-decryption-with-stream-ciphers","title":"2.1.2 Encryption and Decryption with Stream Ciphers","text":"<p>Definition 2.1.1 Stream Cipher Encryption and Decryption </p> <p>Encryption: $$ y_i = e_{s_i}(x_i) \\equiv x_i + s_i\\mod 2. $$</p> <p>Decryption: $$ x_i = d_{s_i}(y_i) \\equiv y_i + s_i\\mod 2. $$</p> <p>Since encryption and decryption functions are both simple additions modulo 2, we can depict the basic operation of a stream cipher as shown in Fig. 2.4. Note that we use a circle with an addition sign as the symbol for modulo 2 additions.</p>"},{"location":"cryptography/symmetric/#stream-cipher-example","title":"Stream Cipher Example","text":"<pre><code>sequenceDiagram\n    actor Alice\n    actor Bob\n    Alice-&gt;&gt;Bob: Hi Bob\n    Bob-&gt;&gt;Alice: Hi Alice</code></pre> <ol> <li>Encryption and decryption are the same functions!</li> <li>Why can we use a simple modulo 2 addition as encryption?</li> <li>What is the nature of the key stream bits si?</li> </ol> <p>Why Is Modulo 2 Addition a Good Encryption Function?</p> <p>If we do arithmetic modulo 2, the only possible values are 0 and 1 (because if you divide by 2, the only possible remainders are 0 and 1). Thus, we can treat arithmetic modulo 2 as Boolean functions such as AND gates, OR gates, NAND gates, etc. Let\u2019s look at the truth table for modulo 2 addition:</p>   \\begin{array}{|c|c|c|} \\hline x_i &amp; s_i &amp; y_i \\equiv x_i + s_i\\mod 2 \\\\ \\hline 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ \\hline \\end{array}  <p>This should look familiar to most readers: It is the truth table of the exclusive-OR, also called XOR, gate. This is in important fact: Modulo 2 addition is equivalent to the XOR operation. The XOR operation plays a major role in modern cryptography and will be used many times in the remainder of this book.</p>  \\text{XOR Truth Table:} \\\\ \\begin{array}{|c|c|c|} \\hline A &amp; B &amp; A \\oplus B \\\\ \\hline 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 1 \\\\ 1 &amp; 0 &amp; 1 \\\\ 1 &amp; 1 &amp; 0 \\\\ \\hline \\end{array}  <p>Depending on the key bit, the ciphertext y_i is either a zero (s_i =0) or one (s_i =1). If the key bit si behaves perfectly randomly, i.e., it is unpredictable and has exactly a 50% chance to have the value 0 or 1, then both possible ciphertexts also occur with a 50% likelihood. Likewise, if we encrypt the plaintext bit xi = 1, we are on line 3 or 4 of the truth table. We just observed that the XOR function is perfectly balanced, i.e., by observingan output value, there is exactly a 50% chance for any value of the input bits. This distinguishes the XOR gate from other Boolean functions such as the OR, AND or NAND gate. Moreover, AND and NAND gates are not invertible.</p>"},{"location":"cryptography/symmetric/#example","title":"Example.","text":"<p>Alice wants to encrypt the letter <code>A</code>, where the letter is given in ASCII code. The ASCII value for <code>A</code> is 65_{10} = 1000001_2. Let's further more assume that the first key stream bits are (S_0,..., S_6) = 0101100.</p>  \\begin{array}{|c|c|c|} \\hline Alice &amp; Oscar &amp; Bob \\\\ \\hline x_0,...,x_6 = 1000001 = A &amp;  &amp;  \\\\ \\oplus &amp;  &amp;  \\\\ s_0,...,s_6 = 0101100 &amp;  &amp;  \\\\ y_0,...,y_6 = 1101101 = m &amp;   &amp;  \\\\  &amp; m = 1101101 &amp;  \\\\  &amp; &amp; y_0,...,y_6 = 1101101 = m \\\\  &amp; &amp; \\oplus \\\\  &amp; &amp; s_0,...,s_6 = 0101100 \\\\  &amp; &amp; x_0,...,x_6 = 1000001 = A \\\\ \\hline \\end{array}  <p>Note that the encryption by Alice turns the uppercase <code>A</code> into the lower case letter m. Oscar, the attacker who eavesdrops on the channel, only sees the ciphertext letter m. Decryption by Bob with the same key stream reproduces the plaintext A again.</p> <p>What Exactly Is the Nature of the Key Stream?</p> <p>It turns out that the generation of the values si, which are called the key stream, is the central issue for the security of stream ciphers. In fact, the security of a stream cipher completely depends on the key stream. The key stream bits si are not the key bits themselves. Generating the key stream is pretty much what stream ciphers are about. This is a major topic and is discussed later in this chapter. However, we can already guess that a central requirement for the key stream bits should be that they appear like a random sequence to an attacker.</p>"},{"location":"cryptography/symmetric/#221-random-number-generators","title":"2.2.1 Random Number Generators","text":"<p>First learn about the three types of random number generators (RNG) that are important for us.</p> <ol> <li> <p>Ture Random Number Generators (TRNG)</p> <p>True random number generators (TRNGs) are characterized by the fact that their output cannot be reproduced. For instance, if we flip a coin 100 times and record the resulting sequence of 100 bits, it will be virtually impossible for anyone on Earth to generate the same 100 bit sequence. In cryptography, TRNGs are often needed for generating session keys, which are then distributed between Alice and Bob, and for other purposes.</p> </li> <li> <p>(General) Pseudorandom Number Generators (PRNG)</p> <p>Pseudorandom number generators (PRNGs) generate sequences which are computed from an initial seed value. A generalization of this are generators of the form si+1 = f (si, si\u22121, . . . , si\u2212t ), where t is a fixed integer. A popular example is the linear congruential generator: $$ s_0 = seed $$ $$ s_{i+1} \\equiv a s_{si} + b\\mod m,  i = 0, 1,... $$ where a,b,m are integer constants. Here are the example of the Pseudorandom Number Generators (PRNG):</p> </li> </ol>  \\begin{array}{|c|c|} \\hline i &amp; S_i \\\\ \\hline 0 &amp; 1  \\\\ 1 &amp; (3 \\cdot 1+1) = 4 \\mod 7 = 4\\\\ 2 &amp; (3 \\cdot 4=1) = 13\\mod 7 = 6\\\\ 3 &amp; (3 \\cdot 6+1) = 19 \\mod 7 = 5\\\\ 4 &amp; (3 \\cdot 5+1) = 16\\mod 7 = 2\\\\ \\hline \\end{array}  <p>Note that PRNGs are not random in a true sense because they can be computed and are thus completely deterministic. A widely used example is the rand() function used in ANSI C. It has the parameters:</p>  s_0 = 12345   s_{i+1} \\equiv 1103515245 s_{si} + 12345\\mod 2^{31}, \\ i = 0, 1,...  <p>A common requirement of PRNGs is that they possess good statistical properties, meaning their output approximates a sequence of true random numbers. There are many mathematical tests, e.g., the chi-square test, which can verify the statistical behavior of PRNG sequences. For instance, many types of simulations or testing, e.g., of software or of VLSI chips, need random data as input. That is the reason why a PRNG is included in the ANSI C specification.</p> <ol> <li> <p>Cryptographically secure Pseudorandom Number Generators( CSPRNG)</p> <p>Cryptographically secure pseudorandom number generators (CSPRNGs) are a special type of PRNG which possess the following additional property: A CSPRNG is PRNG which is unpredictable.A more exact definition is that given n consecutive bits of the key stream, there is no polynomial time algorithm that can predict the next bit sn+1 with better than 50% chance of success. Another property of CSPRNG is that given the above sequence, it should be computationally infeasible to compute any preceding bits si\u22121, si\u22122, . . .. Note that the need for unpredictability of CSPRNGs is unique to cryptography. As a consequence, the distinction between PRNG and CSPRNG and their relevance for stream ciphers is often not clear to non-cryptographers. Almost all PRNG that were designed without the clear purpose of being stream ciphers are not CSPRNGs.</p> </li> </ol>"},{"location":"cryptography/symmetric/#the-one-time-pad","title":"The One-Time Pad","text":"<p>Definition Unconditional Security</p> <p>A cryptosystem is unconditionally or information-theoretically secure if it cannot be broken even with infinite computational resources</p> <p>Unconditional security is based on information theory and assumes no limit on the attacker\u2019s computational power. All this said, we now show a way to build an unconditionally secure cipher that is quite simple. This cipher is called the One-Time Pad.</p>"},{"location":"qcryptography/BB84/","title":"BB84","text":"<p>In the BB84 quantum key distribution protocol, Alice and Bob establish a secure key by transmitting qubits and measuring them in randomly chosen bases (Z or X). After the transmission, they compare their chosen bases over a public, authenticated channel without revealing the actual measurement results. Only qubits where their bases match are retained for the key. To detect eavesdropping, they reveal a subset of the matching qubits and compare their values. If Alice and Bob used the same basis (e.g., Z-basis), but their results differ (e.g., Alice sent 0, but Bob measured 1), they can infer that an eavesdropper (Eve) has interfered, as Eve's random basis guesses would disturb the quantum states and introduce detectable errors. This process ensures the security of the final key and the detection of any unauthorized interception.</p> <p>adding picutre</p> <p>The BB84 quantum key distribution (QKD) protocol allows two parties (Alice and Bob) to establish a shared secret key securely using quantum mechanics. Let's break down the content of the image step by step to understand the basics:</p> <ol> <li> <p>Key Strings:</p> <ul> <li>Alice starts with two binary strings,  a  and  b , each of length  n . These strings are random.</li> <li>The string  a  determines the bit values (0 or 1) Alice wants to send.</li> <li>The string  b  determines the basis (how the bits will be encoded) for each qubit.</li> </ul> </li> <li> <p>Encoding Qubits:</p> <ul> <li>Alice encodes her bits a_i and bases b_i into quantum states. For each bit, she prepares a qubit  \\lvert \\psi_{a_i b_i} \\rangle, where:<ul> <li>a_i  is the  i -th bit of  a  (0 or 1).</li> <li>b_i  is the  i -th bit of  b  (0 or 1).</li> </ul> </li> </ul> </li> <li> <p>Quantum States:</p> <ul> <li> <p>Based on  a_i  and  b_i , Alice uses the following encoding:</p> <ul> <li>\\lvert \\psi _{00}\\rangle: \\lvert 0\\rangle \u2014 A qubit in the Z-basis representing 0.</li> <li>\\lvert \\psi _{10}\\rangle: \\lvert 1\\rangle \u2014 A qubit in the Z-basis representing 1.</li> <li>\\lvert \\psi _{01}\\rangle: \\lvert+\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle + \\lvert1\\rangle)  \u2014 A qubit in the X-basis representing 0.</li> <li>\\lvert \\psi _{11}\\rangle: \\lvert-\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle - \\lvert1\\rangle)  \u2014 A qubit in the X-basis representing 1.</li> </ul> </li> <li> <p>The Z-basis (rectilinear basis) consists of \\lvert 0\\rangle and \\lvert 1\\rangle.</p> </li> <li>The X-basis (diagonal basis) consists of \\lvert +\\rangle and \\lvert -\\rangle.</li> </ul> </li> <li> <p>Tensor Product:</p> <ul> <li> <p>Alice prepares a sequence of  n  qubits, each encoded using the tensor product formula:</p> <p>\\lvert \\psi \\rangle = \\bigotimes_{i=1}^n \\lvert \\psi _{a_i b_i}\\rangle</p> <p>This means she sends a combined quantum state of all  n  qubits, where each qubit is independently encoded.</p> </li> </ul> </li> <li> <p>Purpose:</p> <ul> <li>Bob measures each qubit in a randomly chosen basis (Z-basis or X-basis).</li> <li>If Bob's measurement basis matches Alice's encoding basis ( b_i ), the measurement result will match  a_i  perfectly.</li> <li>If the bases don't match, Bob's measurement result will be random and provide no useful information.</li> </ul> </li> <li> <p>Key Extraction:</p> <ul> <li>After sending and measuring, Alice and Bob compare their bases ( b ) over a public channel.</li> <li>They discard the results where their bases don't match, leaving a shorter string of bits that they use as the secret key.</li> </ul> </li> </ol> <p>The security of BB84 relies on the principles of quantum mechanics:</p> <ol> <li>Any attempt by an eavesdropper (Eve) to intercept or measure the qubits introduces detectable disturbances in the system.</li> <li>This ensures the integrity of the communication between Alice and Bob.</li> </ol> <p>Great question! The reason I didn't initially consider  a_1 = 0  or  b_2 = 0  is because the example explicitly set  a = 10  and  b = 01 . However, you're absolutely correct that we could (and should) consider all possible cases of  a_i  and  b_i  when  n = 2 , to explore the full set of scenarios.</p> <p>Let's now revisit the problem and explicitly calculate the tensor product for all combinations of a_1, a_2 and b_1, b_2 ,instead of just one specific example.</p>"},{"location":"qcryptography/BB84/#all-possible-cases-for-n-2-general-expansion","title":"All Possible Cases for  n = 2 : General Expansion","text":"<p>For  n = 2 , we have two bits  a = a_1a_2  and  b = b_1b_2 . Each qubit state  \\lvert \\psi_{a_i b_i}\\rangle  is determined as follows:</p> <ol> <li> <p>If b_i = 0 (Z-basis):</p> <ul> <li>a_i = 0 :  \\lvert \\psi _{a_i b_i}\\rangle = \\lvert0\\rangle </li> <li>a_i = 1 :  \\lvert \\psi _{a_i b_i}\\rangle = \\lvert1\\rangle </li> </ul> </li> <li> <p>If b_i = 1 (X-basis):</p> <ul> <li>a_i = 0 :  \\lvert \\psi \\rangle_{a_i b_i}\\rangle = \\lvert+\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle + \\lvert1\\rangle) </li> <li>a_i = 1 :  \\lvert \\psi \\rangle_{a_i b_i}\\rangle = \\lvert-\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle - \\lvert1\\rangle) </li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#explicit-calculation-of-tensor-products","title":"Explicit Calculation of Tensor Products","text":"<p>We calculate the tensor product for one full combination as an example, but the method applies to all cases.</p>"},{"location":"qcryptography/BB84/#example-a-00-b-00a-00-b-00","title":"Example:  a = 00, b = 00","text":"<ol> <li>a_1 = 0, b_1 = 0 :  \\lvert \\psi \\rangle_{a_1 b_1}\\rangle = \\lvert0\\rangle</li> <li>a_2 = 0, b_2 = 0 :  \\lvert \\psi \\rangle_{a_2 b_2}\\rangle = \\lvert0\\rangle </li> </ol> <p>The total state:</p>  \\lvert \\psi \\rangle = \\lvert \\psi_{a_1 b_1}\\rangle \\otimes \\lvert \\psi_{a_2 b_2}\\rangle = \\lvert0\\rangle \\otimes \\lvert0\\rangle = \\lvert00\\rangle"},{"location":"qcryptography/BB84/#example-a-01-b-01a-01-b-01","title":"Example:  a = 01, b = 01","text":"<ol> <li>a_1 = 0, b_1 = 0 :  \\lvert \\psi_{a_1 b_1}\\rangle = \\lvert0\\rangle</li> <li>a_2 = 1, b_2 = 1 :  \\lvert \\psi_{a_2 b_2}\\rangle = \\lvert-\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle - \\lvert1\\rangle)</li> </ol> <p>The total state:</p>  \\lvert \\psi \\rangle = \\lvert0\\rangle \\otimes \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle - \\lvert1\\rangle)  <p>Expand the tensor product:</p>  \\lvert \\psi \\rangle = \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle - \\lvert01\\rangle)"},{"location":"qcryptography/BB84/#example-a-10-b-10a-10-b-10","title":"Example:  a = 10, b = 10","text":"<ol> <li>a_1 = 1, b_1 = 1 :  \\lvert \\psi _{a_1 b_1}\\rangle = \\lvert-\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle - \\lvert1\\rangle)</li> <li>a_2 = 0, b_2 = 0 :  \\lvert \\psi _{a_2 b_2}\\rangle = \\lvert0\\rangle</li> </ol> <p>The total state:</p>  \\lvert \\psi \\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle - \\lvert1\\rangle) \\otimes \\lvert0\\rangle  <p>Expand the tensor product:</p>  \\lvert \\psi \\rangle = \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle - \\lvert10\\rangle)"},{"location":"qcryptography/BB84/#general-formula","title":"General Formula","text":"<p>For  n = 2 , the state  \\lvert \\psi \\rangle\\rangle  is given by:</p>  \\lvert \\psi \\rangle = \\lvert \\psi_{a_1 b_1}\\rangle \\otimes \\lvert \\psi_{a_2 b_2}\\rangle  <p>where each  $\\lvert \\psi_{a_i b_i}\\rangle  depends on the values of a_i and b_i as:</p> <ol> <li>b_i = 0 :  \\lvert \\psi_{a_i b_i}\\rangle = \\lvert a_i\\rangle  (Z-basis).</li> <li>b_i = 1 :  \\lvert \\psi_{a_i b_i}\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle + (-1)^{a_i}\\lvert1\\rangle)  (X-basis).</li> </ol>"},{"location":"qcryptography/BB84/#base-shifting","title":"Base shifting","text":""},{"location":"qcryptography/BB84/#what-is-basis-shifting","title":"What is Basis Shifting?","text":"<p>Basis shifting refers to changing the representation or measurement basis of a quantum state. In quantum mechanics, qubits are often represented and measured in different bases. The two most commonly used bases are:</p> <ol> <li> <p>Z-basis (Computational Basis):</p> <ul> <li>States: (\\lvert 0\\rangle, \\lvert 1\\rangle).</li> <li>This is the \"classical\" binary basis used for encoding and measuring.</li> </ul> </li> <li> <p>X-basis (Diagonal Basis):</p> <ul> <li>\\lvert - \\rangle = \\frac{\\lvert 0 \\rangle - \\lvert 1 \\rangle}{\\sqrt{2}} </li> <li>\\lvert + \\rangle = \\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}}</li> <li>This basis involves superpositions of the Z-basis states.</li> </ul> </li> </ol> <p>Basis shifting occurs when:</p> <ol> <li>A quantum state encoded in one basis is measured in another basis.</li> <li>A qubit is deliberately transformed from one basis to another using quantum gates (like the Hadamard gate).</li> </ol>"},{"location":"qcryptography/BB84/#how-does-basis-shifting-happen","title":"How Does Basis Shifting Happen?","text":"<p>In the BB84 protocol, basis shifting happens due to the random choice of encoding and measurement bases by Alice and Bob:</p> <ol> <li> <p>Alice's Encoding:</p> <ul> <li>Alice randomly encodes each qubit in either the Z-basis or X-basis:<ul> <li>b_i = 0: Z-basis (\\lvert 0\\rangle, \\lvert 1\\rangle).</li> <li>b_i = 1: Z-basis (\\lvert +\\rangle, \\lvert -\\rangle).</li> </ul> </li> <li>Example: If a_i = 1, b_i = 0, she encodes \\lvert 1 \\rangle. If a_i = 1, b_i = 1 , she encodes  \\lvert-\\rangle.</li> </ul> </li> <li> <p>Bob's Measurement:</p> <ul> <li>Bob randomly chooses to measure each qubit in either the Z-basis or X-basis.</li> <li>If Bob's measurement basis matches Alice's encoding basis, the result is correct.</li> <li>If Bob's measurement basis doesn't match, the result is random.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#detecting-eavesdropping-with-basis-shifting","title":"Detecting Eavesdropping with Basis Shifting","text":"<p>The BB84 protocol uses basis shifting to detect the presence of an eavesdropper (Eve). Here's how it works:</p> <ol> <li> <p>Eve's Interception:</p> <ul> <li>Eve tries to intercept and measure the qubits in transit from Alice to Bob.</li> <li>Since Eve doesn't know Alice's encoding basis, she must randomly choose a measurement basis (Z or X) for each qubit.</li> </ul> </li> <li> <p>Eve's Disturbance:</p> <ul> <li>If Eve measures in the wrong basis (e.g., measures a qubit encoded in the X-basis using the Z-basis), her measurement collapses the quantum state.</li> <li>When the qubit is sent to Bob, it no longer matches Alice's original encoding.</li> </ul> </li> <li> <p>Key Verification:</p> <ul> <li>After Bob measures the qubits, Alice and Bob publicly compare the bases they used (but not the actual measurement results).</li> <li>They discard any qubits where their bases didn't match.</li> <li>For the remaining qubits (where their bases matched), they compare a subset of their measurement results over a public channel.</li> </ul> </li> <li> <p>Error Detection:</p> <ul> <li>If there's no eavesdropping, Bob's measurements will match Alice's encoding perfectly (no errors).</li> <li>If Eve intercepted the qubits, her random measurements will introduce detectable errors in the shared key.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#example-of-eavesdropping-detection","title":"Example of Eavesdropping Detection","text":"<p>Let's consider an example where n = 3:</p>"},{"location":"qcryptography/BB84/#without-eavesdropping","title":"Without Eavesdropping:","text":"<ol> <li>Alice's Encoding:<ul> <li>Alice sends: \\lvert 0\\rangle, \\lvert +\\rangle, \\lvert 1\\rangle (bases: Z, X, Z).</li> </ul> </li> <li>Bob's Measurement:<ul> <li>Bob measures in the same bases: Z, X, Z.</li> <li>Results: Bob gets the correct key: 0, 0, 1.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#with-eavesdropping","title":"With Eavesdropping:","text":"<ol> <li>Eve's Interception:<ul> <li>Eve intercepts and randomly measures the qubits in bases: X, Z, X.</li> <li>She collapses the qubits into new states: \\lvert +\\rangle, \\lvert 1\\rangle, \\lvert +\\rangle.</li> </ul> </li> <li>Bob's Measurement:<ul> <li>Bob measures in bases: Z, X, Z.</li> <li>Results: Errors occur because Eve altered the quantum states.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#detection","title":"Detection:","text":"<ul> <li>Alice and Bob compare the results of a subset of their key bits where their bases matched.</li> <li>If Eve intercepted, the error rate will be higher than expected, signaling eavesdropping.</li> </ul>"},{"location":"qcryptography/BB84/#key-takeaways","title":"Key Takeaways","text":"<ul> <li> <p>Why Basis Shifting Works for Security:</p> <ul> <li>Quantum states collapse when measured in the wrong basis.</li> <li>This collapse introduces detectable errors if an eavesdropper tries to intercept.</li> </ul> </li> <li> <p>How Alice and Bob Detect Eavesdropping:</p> <ul> <li>They use random basis shifting (Z-basis and X-basis) to encode and measure.</li> <li>Any tampering causes mismatches in their measurement results.</li> </ul> </li> </ul>"},{"location":"qcryptography/BB84/#q-a","title":"Q &amp; A","text":""},{"location":"qcryptography/BB84/#q1-isnt-bob-and-eve-face-the-same-challenge-they-dont-knew-the-encoding-basis-alice-used","title":"Q1. Isn't Bob and Eve face the same challenge: they don't knew the encoding basis Alice used?","text":"<p>A: Correct!: they don't know the encoding basis Alice used. However, the key distinction lies in how Bob and Eve's actions affect the quantum states. Here's a step-by-step explanation of how Bob and Alice can detect errors introduced by Eve:</p>"},{"location":"qcryptography/BB84/#key-differences-between-bob-and-eves-roles","title":"Key Differences Between Bob and Eve's Roles","text":"<ol> <li> <p>Bob's Role:</p> <ul> <li>Bob is a legitimate participant in the protocol.</li> <li>He doesn't need to know Alice's encoding basis in real-time because they later publicly compare their chosen bases after Bob measures the qubits.</li> <li>Bob's measurements are a normal part of the protocol and do not disturb the quantum state if his basis matches Alice's.</li> </ul> </li> <li> <p>Eve's Role:</p> <ul> <li>Eve is an eavesdropper who intercepts the qubits mid-transmission.</li> <li>Eve cannot communicate with Alice and Bob, so she must guess Alice's encoding basis (Z or X) for each qubit. This guess introduces errors because her measurement collapses the quantum state when she measures in the wrong basis.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#how-errors-are-introduced-by-eve","title":"How Errors Are Introduced by Eve","text":"<ol> <li> <p>Eve Intercepts and Measures:</p> <ul> <li>Eve measures each qubit in a random basis (Z or X). If her basis matches Alice's, she correctly measures the state. If not, her measurement collapses the state into a new random value in the wrong basis.</li> </ul> </li> <li> <p>Eve Resends the Qubit:</p> <ul> <li>After measuring, Eve resends the qubit to Bob. However, the qubit's state is now modified based on her measurement, not Alice's original encoding.</li> </ul> </li> <li> <p>Bob's Measurement:</p> <ul> <li>Bob measures the qubit as usual, but if the qubit was altered by Eve, the likelihood of Bob's result matching Alice's original encoding is reduced.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#error-detection-process","title":"Error Detection Process","text":"<p>Alice and Bob detect the errors introduced by Eve as follows:</p> <ol> <li> <p>Key Exchange:</p> <ul> <li>Alice and Bob exchange qubits, with Alice encoding in random bases (Z or X) and Bob measuring in random bases.</li> </ul> </li> <li> <p>Basis Comparison:</p> <ul> <li>After transmission, Alice and Bob publicly compare their bases (but not their measurement results).</li> <li>They discard any qubits where their bases don't match. For example:<ul> <li>Alice encodes in Z, Bob measures in Z \u2192 Keep.</li> <li>Alice encodes in X, Bob measures in Z \u2192 Discard.</li> </ul> </li> </ul> </li> <li> <p>Sample Check:</p> <ul> <li>For the remaining qubits (where bases matched), Alice and Bob publicly reveal the measurement results for a small subset of the key.</li> <li>If there is no eavesdropping, the results will match perfectly.</li> <li>If Eve intercepted, her random basis choices introduce detectable mismatches in the sample subset.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#why-bob-can-detect-errors","title":"Why Bob Can Detect Errors","text":"<ul> <li>Bob and Alice know the bases they used after they compare them.</li> <li>Errors introduced by Eve create discrepancies in the results for the cases where Alice and Bob used the same basis.</li> <li>Since Eve doesn't know Alice's basis when she measures, her interference causes errors in the subset of qubits Alice and Bob verify.</li> </ul>"},{"location":"qcryptography/BB84/#example","title":"Example","text":""},{"location":"qcryptography/BB84/#without-eavesdropping_1","title":"Without Eavesdropping:","text":"<ol> <li>Alice sends qubits:<ul> <li>\\lvert 0\\rangle (Z-basis), \\lvert +\\rangle (X-basis), \\lvert 1\\rangle (Z-basis).</li> </ul> </li> <li>Bob measures:<ul> <li>Z-basis: \\lvert 0\\rangle \u2192 Correct.</li> <li>X-basis: \\lvert +\\rangle \u2192 Correct.</li> <li>Z-basis: \\lvert 1\\rangle \u2192 Correct.</li> </ul> </li> <li>Sample check:<ul> <li>All results match, so no errors.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#with-eavesdropping_1","title":"With Eavesdropping:","text":"<ol> <li>Eve intercepts and measures randomly:<ul> <li>Eve measures \\lvert 0\\rangle in X-basis \u2192 Collapses to \\lvert +\\rangle or \\lvert -\\rangle.</li> <li>Eve measures \\lvert +\\rangle in Z-basis \u2192 Collapses to \\lvert 0\\rangle or \\lvert 1\\rangle.</li> <li>Eve measures \\lvert 1\\rangle in X-basis \u2192 Collapses to \\lvert +\\rangle or \\lvert -\\rangle.</li> </ul> </li> <li>Eve resends the altered qubits to Bob:<ul> <li>Bob's measurements may now mismatch Alice's original encoding.</li> </ul> </li> <li>Sample check:<ul> <li>Alice and Bob detect errors in the subset of qubits they verify.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#error-rates-and-eavesdropping-detection","title":"Error Rates and Eavesdropping Detection","text":"<p>If Eve intercepts and measures every qubit: - She guesses the correct basis with 50% probability for each qubit. - When she guesses incorrectly, the transmitted qubit is altered, introducing errors. - If Alice and Bob observe an error rate higher than the expected random noise level (e.g., from equipment imperfections), they conclude that an eavesdropper is present.</p>"},{"location":"qcryptography/BB84/#conclusion","title":"Conclusion","text":"<p>While Bob and Eve face the same initial uncertainty about Alice's encoding basis, the protocol structure ensures: - Bob's measurements don't introduce errors if his basis matches Alice's. - Eve's random basis guesses introduce detectable errors into the key. This is how basis shifting helps detect eavesdropping in quantum key distribution protocols like BB84.</p>"},{"location":"qcryptography/BB84/#q2-what-is-a-normal-part-of-the-protocol","title":"Q2 what is a normal part of the protocol?","text":"<p>The reason why the \"normal\" part of the BB84 protocol (or any quantum key distribution protocol) does not disturb the quantum state lies in quantum mechanics and the design of the protocol. Let's break this down:</p>"},{"location":"qcryptography/BB84/#1-quantum-measurement-only-disturbs-the-state-if-the-basis-is-incorrect","title":"1. Quantum Measurement Only Disturbs the State if the Basis is Incorrect","text":"<p>In quantum mechanics: - A qubit is represented in a specific basis (e.g., the Z-basis or X-basis). - If a qubit is measured in the same basis in which it was prepared, the measurement process does not disturb the state. The qubit \"collapses\" to the same state it was initially in, and the measurement result is consistent with the encoding.</p> <p>Example: - Alice sends a qubit in the Z-basis:   - \\lvert 0\\rangle: If Bob measures in the Z-basis, the result is 0 and the state is not disturbed.   - \\lvert 1\\rangle: If Bob measures in the Z-basis, the result is 1 and the state is not disturbed.</p> <p>However: - If Bob measures in a different basis (e.g., the X-basis), the quantum state is projected onto the X-basis ( \\lvert+\\rangle, \\lvert-\\rangle ). This projection collapses the original state into a new state, introducing randomness and effectively \"disturbing\" the original quantum information.</p>"},{"location":"qcryptography/BB84/#2-bobs-random-measurement-does-not-always-disturb-the-state","title":"2. Bob's Random Measurement Does Not Always Disturb the State","text":"<p>In the BB84 protocol: - Bob measures each qubit in a randomly chosen basis (Z or X). - If Bob happens to measure in the same basis that Alice used to prepare the qubit, the measurement does not disturb the state. - If Bob measures in the wrong basis, the state collapses to a random outcome in the measurement basis.</p> <p>Example: - Alice sends \\lvert +\\rangle (prepared in the X-basis). - If Bob measures in the X-basis, he gets the correct result  + , and the state remains \\lvert +\\rangle. - If Bob measures in the Z-basis, he gets a random result ( 0  or  1 ), and the state is disturbed.</p> <p>The randomness of Bob's measurement is an intentional part of the protocol design. Any mismatches in basis are discarded later during basis comparison, ensuring that only measurements in the correct basis contribute to the final key.</p>"},{"location":"qcryptography/BB84/#3-eves-measurement-always-disturbs-the-state","title":"3. Eve's Measurement Always Disturbs the State","text":"<p>Eve, unlike Bob, introduces detectable disturbances because: 1. Eve Measures First:    - Eve measures the qubit in a random basis (Z or X), collapsing the quantum state to one consistent with her chosen basis. 2. Eve Sends a New State:    - After measurement, Eve prepares and sends a new qubit to Bob. If her basis matches Alice's, the state sent to Bob will be correct.    - If her basis doesn't match Alice's, the state sent to Bob is incorrect, introducing detectable errors.</p> <p>Key Difference: - Bob's basis is publicly compared with Alice's after measurement, so mismatches can be discarded. - Eve's interference affects the quantum states, even when Alice and Bob's bases match, introducing measurable errors.</p>"},{"location":"qcryptography/BB84/#4-why-the-protocol-design-prevents-state-disturbance","title":"4. Why the Protocol Design Prevents State Disturbance","text":"<p>The BB84 protocol minimizes disturbance as part of its design: 1. Basis Matching:    - Alice and Bob only use qubits where their preparation and measurement bases matched (e.g., both Z-basis or both X-basis). This ensures the key bits come from undisturbed quantum states.</p> <ol> <li>Basis Comparison and Key Reconciliation:</li> <li> <p>The basis comparison step allows Alice and Bob to identify mismatches and discard them. Any remaining bits are guaranteed to have been measured without disturbance.</p> </li> <li> <p>Eavesdropping Detection:</p> </li> <li>Eve's measurement in the wrong basis introduces detectable errors when Alice and Bob compare a sample of their results. These errors reveal Eve's presence.</li> </ol>"},{"location":"qcryptography/BB84/#5-real-world-noise-and-error-correction","title":"5. Real-World Noise and Error Correction","text":"<p>In real implementations, noise in the quantum channel (e.g., photon loss, environmental disturbances) may introduce small errors even without an eavesdropper. These errors are mitigated using: 1. Error Correction:    - Alice and Bob reconcile their keys to correct errors caused by noise. 2. Privacy Amplification:    - They apply mathematical techniques to distill a shorter, perfectly secure key from the reconciled key, even in the presence of small errors.</p>"},{"location":"qcryptography/BB84/#summary","title":"Summary","text":"<ul> <li>Bob's measurements in the correct basis do not disturb the quantum state because the state collapses to the same value as it was prepared in.</li> <li>Mismatched bases are part of the protocol's design and are discarded later during basis comparison.</li> <li>Eve's interference is detectable because her random measurements disturb the state in a way that creates errors, even when Alice and Bob's bases match.</li> </ul>"},{"location":"qcryptography/BB84/#q3-so-bob-doesnt-know-the-basis-alice-used-before-he-measure-it","title":"Q3 So Bob doesn't know the basis Alice used before he measure it?","text":"<p>Exactly! Bob cannot know the basis Alice used to prepare the qubit before he measures it. This is a fundamental aspect of quantum mechanics and the BB84 protocol design. Here's why and how it works:</p>"},{"location":"qcryptography/BB84/#1-why-bob-cannot-know-the-basis-before-measuring","title":"1. Why Bob Cannot Know the Basis Before Measuring","text":"<p>In quantum mechanics:  1. A qubit doesn't \"carry\" classical information about the basis in which it was prepared. Instead, it exists as a quantum state.  2. To extract information from a quantum state, Bob must perform a measurement. The result of this measurement depends on the basis he chooses.</p> <p>If Bob measures in the wrong basis:</p> <ol> <li>The qubit's state will collapse to a random value in the chosen basis, and the original information will be lost.</li> </ol> <p>Example:</p> <ol> <li>Alice prepares \\lvert +\\rangle (X-basis).</li> <li>If Bob measures in the Z-basis, he gets \\lvert 0\\rangle or \\lvert 1\\rangle randomly, with equal probabilities.</li> </ol>"},{"location":"qcryptography/BB84/#2-how-bob-chooses-a-basis","title":"2. How Bob Chooses a Basis","text":"<p>In the BB84 protocol: 1. Random Choice:     - Bob chooses a measurement basis (Z or X) randomly for each qubit.     - He doesn't know if his choice matches Alice's basis until they compare later.</p> <ol> <li>After Measurement:<ul> <li>Bob records both his measurement result and the basis he used (e.g., \"Measured 1 in the Z-basis\").</li> <li>The result may or may not match Alice's encoded value, depending on whether his basis matches hers.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#3-basis-matching-in-the-bb84-protocol","title":"3. Basis Matching in the BB84 Protocol","text":"<p>After Bob measures all the qubits: 1. Classical Communication:    - Alice and Bob communicate over a public, authenticated channel to compare their bases for each qubit.    - They do not reveal the measurement results or the original values encoded.</p> <ol> <li>Discarding Mismatches:</li> <li>If Bob's basis matches Alice's basis for a given qubit, the measurement result is retained as part of the key.</li> <li>If the bases don't match, the result is discarded because it's unreliable.</li> </ol> <p>Example:</p>  \\begin{array}{\\lvertc\\lvertc\\lvertc\\lvertc\\lvertc\\lvertc\\lvert} \\hline \\text{Qubit} &amp; \\text{Alice's Basis} &amp; \\text{Bob's Basis} &amp; \\text{Alice's Bit} &amp; \\text{Bob's Result} &amp; \\text{Retain?} \\\\ \\hline 1 &amp; Z &amp; Z &amp; 0 &amp; 0 &amp; Yes \\\\ 1 &amp; X &amp; Z &amp; + &amp; \\text{Random} &amp; \\text{No} \\\\ 1 &amp; Z &amp; X &amp; 1 &amp; \\text{Random} &amp; \\text{No} \\\\ 1 &amp; X &amp; X &amp; - &amp; - &amp; \\text{Yes} \\\\ \\hline \\end{array}"},{"location":"qcryptography/BB84/#4-why-this-ensures-security","title":"4. Why This Ensures Security","text":"<p>The inability of Bob (or anyone) to know the basis before measurement is what makes the BB84 protocol secure: 1. Eve's Challenge:     - Eve, like Bob, doesn't know Alice's basis. If she tries to measure the qubits, her random basis choices will disturb the quantum states, introducing errors detectable by Alice and Bob.</p> <ol> <li> <p>Legitimate Measurement:</p> <ul> <li>Bob's random basis choices don't introduce errors because mismatched measurements are discarded during basis comparison.</li> </ul> </li> <li> <p>Quantum Uncertainty:</p> <ul> <li>The quantum no-cloning theorem prevents Eve from perfectly copying the qubit to measure it in both bases. This ensures that any eavesdropping attempt disturbs the quantum state and is detectable.</li> </ul> </li> </ol>"},{"location":"qcryptography/BB84/#5-what-happens-if-bob-always-used-a-single-basis","title":"5. What Happens if Bob Always Used a Single Basis?","text":"<p>If Bob only used one basis (e.g., always Z or always X):</p> <ol> <li>He would miss half of Alice's qubits prepared in the other basis.</li> <li>Eve could exploit this by always measuring in the same basis as Bob, reducing her detection risk.</li> <li>Randomly choosing the measurement basis ensures that mismatches with Alice's encoding are spread out, making Eve's presence detectable.</li> </ol>"},{"location":"qcryptography/BB84/#key-takeaways_1","title":"Key Takeaways","text":"<ol> <li>Bob cannot know the basis Alice used to prepare a qubit before he measures it. He chooses his basis randomly.</li> <li>After measurement, Alice and Bob publicly compare their bases and discard mismatches.</li> <li>This randomness is essential for the security of the BB84 protocol, as it ensures that any eavesdropping attempt by Eve introduces detectable errors.</li> </ol>"},{"location":"qcryptography/BB84/#q4-can-eve-copy-the-message-and-measure-it-later","title":"Q4 Can Eve copy the message and measure it later?","text":"<p>A: No, Eve cannot be in possession of a copy of the qubits sent to Bob, by the no-cloning theorem, unless she has made measurements. The no-cloning theorem is a fundamental principle in quantum mechanics that states it is impossible to create an exact copy of an arbitrary unknown quantum state. This is a cornerstone of the security in quantum key distribution protocols like BB84.</p>"},{"location":"qcryptography/BB84/#if-eve-tries-to-copy","title":"If Eve Tries to Copy:","text":"<ul> <li>Suppose Eve tries to create a copy of the qubit before deciding how to proceed.</li> <li>The no-cloning theorem prevents her from duplicating the quantum state. As a result, she cannot keep one copy and forward another to Bob without disturbing the original state.</li> </ul>"},{"location":"qcryptography/BB84/#example_1","title":"Example","text":"<p>Suppose Alice sends a qubit \\lvert+\\rangle = \\frac{1}{\\sqrt{2}}(\\lvert0\\rangle + \\lvert1\\rangle):</p> <ol> <li>Eve intercepts the qubit and wants to copy it.</li> <li>The no-cloning theorem prevents her from creating a second \\lvert+\\rangle qubit.</li> <li>If she measures \\lvert+\\rangle in the Z-basis, the qubit collapses to \\lvert0\\rangle or \\lvert1\\rangle, destroying the original \\lvert+\\rangle state.</li> <li>When Bob measures the forwarded qubit in the correct X-basis, the result will not match Alice's original encoding, introducing detectable errors.</li> </ol>"},{"location":"qcryptography/BB84/#summary_1","title":"Summary","text":"<p>The no-cloning theorem ensures that an eavesdropper (Eve) cannot copy quantum states sent by Alice to Bob. This prevents Eve from duplicating qubits to analyze later while sending identical ones to Bob. Any attempt by Eve to measure the qubits introduces disturbances, creating detectable errors when Alice and Bob compare their results. This makes quantum key distribution protocols like BB84 fundamentally secure. Let me know if you'd like further clarification!</p> <p>After Alice and Bob determine that the lundisclosed key elements have an error rate e and that a potential eavesdropper (Eve) may have acquired up to I_E bits of information about the key, they proceed with key distillation. This involves two main steps: error correction and privacy amplification. In error correction, Alice and Bob reconcile their keys using classical communication to ensure they hold identical keys, correcting any discrepancies due to noise or eavesdropping. Following this, privacy amplification reduces Eve's knowledge of the key to negligible levels by hashing the reconciled key into a shorter, secure final key. These steps ensure that even if Eve intercepted some information, the final key shared by Alice and Bob is both secret and error-free.</p>"},{"location":"qcryptography/BB84/#error-correction","title":"Error Correction","text":"<p>Error correction in quantum key distribution (QKD) ensures that Alice and Bob hold identical keys by detecting and correcting discrepancies caused by noise in the quantum channel or eavesdropping attempts. After comparing their measurement bases, Alice and Bob identify the bits where they used the same basis but may still have mismatches due to channel imperfections or interference. They use classical communication protocols, such as parity checks or advanced error-correcting codes like the Cascade protocol, to reconcile their keys without revealing the entire key. Error correction ensures that both parties share an identical key, forming the basis for further secure key distillation steps.</p> <p> resource: Cascade-python</p>"},{"location":"qcryptography/BB84/#privacy-amplification","title":"Privacy Amplification","text":"<p>Privacy amplification is the process of reducing an eavesdropper's potential knowledge of the shared key to a negligible level. After error correction, Alice and Bob assume that a potential eavesdropper (Eve) has partial information about the reconciled key due to intercepted qubits or classical leakage during error correction. To counter this, they use a publicly agreed hash function to compress the reconciled key into a shorter, final key. This hashing process eliminates any correlations between the final key and Eve's information, ensuring the shared key remains secure for cryptographic purposes.</p> <p>The price to pay for privacy amplification to work is that the output (secret) key must be smaller than the input (partially secret) key. The reduction in size is roughly equal to the number of bits known to Eve, and the resulting key size is thus l \u2212 IE \u2212 |M| bits. To maximize the key length and perhaps to avoid Eve knowing everything about the key (e.g., l \u2212 IE \u2212 |M| = 0), it is important that the reconciliation discloses as little information as possible, just enough to make Alice and Bob able to correct all their errors.</p> <ol> <li>For instance, they can statistically estimate that Eve knows no more than, say, IE bits on the l key elements</li> <li>with |M| the number of parity bits disclosed during the reconciliation.</li> <li>l undisclosed key elements</li> </ol>"},{"location":"qcryptography/fundamentals/","title":"Fundamentals","text":"<p>When the medium is of atomic scale, the carried information behaves quite differently, and all the features specific to quantum mechanics must be translated into an information-theoretic language, giving rise to quantum information theory. The first application of quantum information theory was found by Wiesner in the late sixties. He proposed using the spin of particles to make unforgeable bank notes. Roughly speaking, the spin of a particle obeys the uncertainty principle: an observer cannot get all the information about the spin of a single particle; he would irreversibly destroy some part of the information when acquiring another part.</p> <p>In a classical computer, every computation is a combination of zeroes and ones (i.e., bits). At a given time, a bit can either be zero or one. In contrast, a qubit, the quantum equivalent of a bit, can be a zero and a one at the same time</p> <p>Following the tracks of Weisner\u2019s idea, Bennett and Brassard proposed in 1984 a protocol to distribute secret keys using the principles of quantum mechanics called quantum cryptography or more precisely quantum key distribution. By again exploiting the counterintuitive properties of quantum mechanics, they developed a way to exchange a secret key whose secrecy is guaranteed by the laws of physics. Following the uncertainty principle, an eavesdropper cannot know everything about a photon that carries a key bit and will destroy a part of the information. Hence, eavesdropping causes errors on the transmission line, which can be detected by Alice and Bob.</p> <p>Quantum key distribution is not only based on the principles of quantum physics, it also relies on classical information theory. The distributed key must be both common and secret. First, the transmission errors must be corrected, whether they are caused by eavesdropping or by imperfections in the setup. Second, a potential eavesdropper must know nothing about the key. To achieve these two goals, techniques from classical information theory, collectively denoted as secret-key distillation, must be used.</p>"},{"location":"qcryptography/fundamentals/#a-first-tour-of-quantum-key-distribtion-qkd","title":"A first tour of quantum key distribtion (QKD)","text":"<p>Quantum key distribution (QKD) is a technique that allows two parties, conventionally called Alice and Bob, to share a common secret key for cryptographic purposes. To ensure the confidentiality of communications, Alice and Bob agree on a common, yet secret, piece of information called a key. Encryption is performed by combining the message with the key in such a way that the result is incomprehensible by an observer who does not know the key.</p>"},{"location":"qcryptography/fundamentals/#let-us-detail-further-how-qkd-works","title":"Let us detail further how QKD works","text":"<p>First, how is the confidentiality of the key ensured? If an eavesdropper, conventionally called Eve, tries to determine the key, she will be detected. The legitimate parties will then discard the key, while no confidential information has been transmitted yet. If, on the other hand, no tapping is detected, the secrecy of the distributed key is guaranteed.</p> <p>Quantum key distribution requires a transmission channel on which quantum carriers are transmitted from Alice to Bob. In theory, any particle obeying the laws of quantum mechanics can be used. In practice, however, the quantum carriers are usually photons, the elementary particle of light, while the channel may be an optical fiber (e.g., for telecommunication networks) or the open air (e.g., for satellite communications).</p> <p>Alice encoding only zeroes and ones. The whole point is that an eavesdropper cannot predict any of the transmitted bits. During the tranmission between Alice and Bob, Eve might listen to the quantum channel and therefore spy on potential secret key bits This does not pose a fundamental problem to the legitimate parties, as the eavesdropping is detectable by way of transmission errors. Furthermore, the secret-key distillation techniques allow Alice and Bob to recover from such errors and create a secret key out of the bits that are unknown to Eve.</p> <p>After the transmission, Alice and Bob can compare a fraction of the exchanged key to see if there are any transmission errors caused by eavesdropping.</p> <p></p> <p>Quantum key distribution comprises a quantum channel and a public classical authenticated channel.</p>"},{"location":"qcryptography/fundamentals/#encoding-random-bits-using-qubits","title":"Encoding random bits using qubits","text":"<p>We will first introduce a QKD tool BB84. In BB84, Alice encodes random (classical) bits, called key elements, using a set of four different qubits.</p> <p>The 0 can be encoded with either \\lvert 0 \\rangle or \\lvert + \\rangle = \\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}}. The bit 1 can be encoded with \\lvert 1 \\rangle or \\lvert - \\rangle = \\frac{\\lvert 0 \\rangle - \\lvert 1 \\rangle}{\\sqrt{2}}.</p> <p>When the photon arrives at bob's station, he would like to decode what Alice sent. Here is what he has to do:</p> <ol> <li>Perform a measurement. However, the laws of quantum mechanics prohibit Bob from determining the qubit completely. Actually, it's impossible to measure the exact coefficient of \\alpha and \\beta of \\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle received from Alice.</li> <li>Bob must choose a pair of orthogonal qubits and perform a measurement that distinguishes only among them. For an example we have two qubits \\lvert \\psi \\rangle = \\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle and \\lvert \\psi' \\rangle = \\alpha' \\lvert 0 \\rangle + \\beta' \\lvert 1 \\rangle such that \\alpha\\alpha'^{*} + \\beta\\beta'^{*} = 0, we said these two qubits are orthogonal.</li> </ol>"},{"location":"qcryptography/fundamentals/#detecting-eavesdropping","title":"Detecting eavesdropping","text":"<p>The key feature for detecting eavesdropping is that the information is encoded in non-orthogonal qubits. Eve can, of course, intercept the quantum carriers and try to measure them. However, like Bob, she does not know in advance which set of carriers Alice chose for each key element. Like Bob, she may unsuccessfully distinguish between |0i and |1i when Alice encodes a bit as |+i or |\u2212i, or vice versa.</p> <p>Learn more about Base shifting in BB84</p> <p>In quantum mechanics, measurement is destructive.(call out)</p> <p>Both Bob and Eve have the same difficulties in determining what Alice sent, since they do not know which encoding is used. But the situation is not symmetric in Bob and Eve: all the communications required to do the sifting are made over the classical authenticated channel. This allows Alice to make sure she is talking to Bob and not to Eve. So, the legitimate parties can guarantee that the sifting process is not influenced by Eve. Owing to this, Alice and Bob can select only the key elements which are correctly measured.</p>"},{"location":"qcryptography/fundamentals/#distilling-a-secret-key","title":"Distilling a secret key","text":""},{"location":"quantum_computation/algorithms/","title":"Quantum Algorithm","text":"<p>Q:  As pointed out earlier, the reason quantum circuits cannot be used to directly simulate classical circuits is because unitary quantum logic gates are inherently reversible, whereas many classical logic gates such as the NAND gate are inherently irreversible.</p>"},{"location":"quantum_computation/algorithms/#toffoli-gate","title":"Toffoli gate","text":"<p>Two of the bits are control bits that are unaffected by the action of the Toffoli gate. The third bit is a target bit that is flipped if both control bits are set to 1, and otherwise is left alone.</p> <p>Toffoli gate twice to a set of bits has the effect (a, b, c) \u2192 (a, b, c \u2295 ab) \u2192 (a, b, c), and thus the Toffoli gate is a reversible gate, since it has an inverse \u2013 itself.</p> <p>The Toffoli gate can be used to simulate <code>NAND</code> gates, as shown in Figure 1.15, and can also be used to do <code>FANOUT</code>, as shown in Figure 1.16. With these two operations it becomes possible to simulate all other elements in a classical circuit, and thus an arbitrary classical circuit can be simulated by an equivalent reversible circuit.</p> <p>what is a Unitary matrix??</p>"},{"location":"quantum_computation/algorithms/#quantum-parallelism","title":"Quantum Parallelism","text":"<p><pre><code>    Quantum parallelism is a fundamental feature of many quantum algorithms.\n</code></pre> Quantum parallelism allows quantum computers to evaluate a function f(x) for many different values of x simultaneously.</p> <p>Quantum parallel evaluation of a function with an n bit input x and 1 bit output, f(x), can thus be performed in the following manner.</p> <p>qubit quantum computer which starts in the state \\lvert x,y \\rangle, with and proper squence of logic gates to transfrom to state \\lvert x, y\\oplus f(x) \\rangle, where \\oplus indicates addition modulo 2. The first register is called <code>data</code> register, and the second register is the <code>target</code> register.</p> <p>Quantum circuit for evaluating f(0) and f(1) simultaneously</p> <p></p> <p>Consider the figure, which applies U_f to and input not in the computational basis. The data register is prepared in the superposition \\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}}, which can be created with Hadamard gate acting on \\lvert 0 \\rangle. Then we apply U_f, resulting in the state: $$ \\frac{\\lvert 0, f(0)\\rangle + \\lvert 1, f(1)\\rangle}{\\sqrt{2}} $$ The different terms contain information about both f(0) and f(1); it is almost as if we have evaluated f(x) for two values of x simultaneously, a feature known as \u2018quantum parallelism\u2019.</p> <p>Proof: \\frac{\\lvert 0, f(0)\\rangle + \\lvert 1, f(1)\\rangle}{\\sqrt{2}}</p> <p>The operation U_f is a unitary operation that maps: $$ \\lvert x\\rangle \\lvert y\\rangle \\rightarrow \\lvert x\\rangle \\lvert y\\oplus f(x)\\rangle  $$ where \\oplus is XOR (addition modulo 2)</p> <ol> <li>x is the value of the data register.</li> <li>y is the value of the ancilla qubit.</li> <li>f(x) is the output of the function being evaluated.</li> </ol> <p>We know that the inital state can be written as: $$ \\big( \\frac{\\lvert 0\\rangle + \\lvert 1\\rangle}{\\sqrt{2}}\\big)\\lvert 0 \\rangle = \\frac{\\lvert 0\\rangle\\lvert 0\\rangle + \\lvert 1\\rangle\\lvert 0\\rangle}{\\sqrt{2}} $$</p> <p>Apply U_f to each term from the initial state:</p> <ol> <li>For the first term \\lvert 0\\rangle\\lvert 0\\rangle: $$ \\lvert 0\\rangle\\lvert 0\\rangle \\rightarrow \\lvert 0\\rangle\\lvert 0\\oplus f(0)\\rangle = \\lvert 0\\rangle \\lvert f(0) \\rangle $$</li> <li>For the second term \\lvert 1\\rangle\\lvert 0\\rangle: $$ \\lvert 1\\rangle\\lvert 0\\rangle \\rightarrow \\lvert 1\\rangle\\lvert 0\\oplus f(1)\\rangle = \\lvert 1\\rangle \\lvert f(1) \\rangle $$ Thus, the new state: $$ \\frac{\\lvert 0, f(0)\\rangle + \\lvert 1, f(1)\\rangle}{\\sqrt{2}} $$</li> </ol> <p>Unlike classical parallelism, where multiple circuits each built to compute f(x) are executed simultaneously, here a single f(x) circuit is employed to evaluate the function for multiple values of x simultaneously</p> <p>Prepare the n + 1 qubit state \\lvert 0 \\rangle^{\\otimes n} \\lvert 0 \\rangle, then apply the Hadamard transform to the first n qubits, followed by the quantum circuit implementing U_f . This produces the state $$ \\frac{1}{\\sqrt{2^{n}}}\\sum_{x} \\lvert x \\rangle \\lvert f(x) \\rangle $$</p> <p>In some sense, quantum parallelism enables all possible values of the function f to be evaluated simultaneously, even though we apparently only evaluated f once. However, this parallelism is not immediately useful.</p> <p>in the general case, measurement of the state \\sum_{x} \\lvert x \\rangle \\lvert f(x) \\rangle would give only f(x) for a single value of x. Of course, a classical computer can do this easily!</p> <p>Quantum computation it requires the ability to extract information about more than one value of f(x) from superposition states like \\sum_{x} \\lvert x. f(x)\\rangle.</p>"},{"location":"quantum_computation/algorithms/#deutschs-algorithm","title":"Deutsch's algorithm","text":"<p>Let's see how quantum circuits can outperform classical ones by implementing Deutsch\u2019s algorithm. Deutsch\u2019s algorithm combines quantum parallelism with a property of quantum mechanics known as interference</p> <p>Build on the previous case, we apply Hadamard gate to the state \\lvert 1 \\rangle. Thus, we have \\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}} for the first qubit and \\frac{\\lvert 0 \\rangle - \\lvert 1 \\rangle}{\\sqrt{2}} for the second qubit.  The input state: $$ \\lvert \\psi_0 \\rangle = \\lvert 01 \\rangle $$ Therefore we have the state: $$ \\lvert \\psi_1 \\rangle = \\bigg[\\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}}\\bigg]\\bigg[\\frac{\\lvert 0 \\rangle - \\lvert 1 \\rangle}{\\sqrt{2}}\\bigg] $$ Then, we apply U_f on the state \\lvert x\\rangle(\\frac{\\lvert 0 \\rangle - \\lvert 1 \\rangle}{\\sqrt{2}}), we will have:</p>  \\lvert\\psi_2\\rangle = \\begin{cases} \\pm \\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}} \\frac{\\lvert0\\rangle - \\lvert1\\rangle}{\\sqrt{2}} &amp; \\text{if } f(0) = f(1), \\\\ \\pm \\frac{\\lvert0\\rangle - \\lvert1\\rangle}{\\sqrt{2}} \\frac{\\lvert0\\rangle - \\lvert1\\rangle}{\\sqrt{2}} &amp; \\text{if } f(0) \\neq f(1). \\end{cases}  <p>Then we apply one Hadamard gate on the first qubit thus gives us:</p>  \\lvert\\psi_2\\rangle = \\begin{cases} \\pm \\lvert0\\rangle \\frac{\\lvert0\\rangle - \\lvert1\\rangle}{\\sqrt{2}} &amp; \\text{if} f(0) = f(1), \\\\ \\pm \\lvert1\\rangle \\frac{\\lvert0\\rangle - \\lvert1\\rangle}{\\sqrt{2}} &amp; \\text{if} f(0) \\neq f(1). \\end{cases}  <p>Realizing that f(0) \\oplus f(1) is 0 if f(0) = f(1) and 1 otherwise, we can rewrite this result as:</p>  \\lvert \\psi_{3} \\rangle = \\pm\\lvert f(0)\\oplus f(1)\\rangle \\bigg[ \\frac{\\lvert0 \\rangle - \\lvert 1 \\rangle}{\\sqrt{2}} \\bigg]  <p>By measurign the first qubit we may determin f(0) \\oplus f(1). This is very interesting: the quantum circuit has given us the ability to determine a global property of f(x), namely f(0)\\oplus f(1), using only one evaluation of f(x). This is faster than a classical apparatus, which would require at least two evaluations.</p> <p>This example highlights the difference between quantum parallelism and classical randomized algorithms.</p> <p>The essence of the design of many quantum algorithms is that a clever choice of function and final transformation allows efficient determination of useful global information about the function \u2013 information which cannot be attained quickly on a classical computer.</p>"},{"location":"quantum_computation/algorithms/#the-deutsch-jozsa-algorithm","title":"The Deutsch-Jozsa Algorithm","text":"<p>Deutsch Algorithm is a special case for Deutsch-Jozsa Algorithm, at which n=1 for 2^{n}-1. Deutsch\u2019s algorithm is a simple case of a more general quantum algorithm, which we shall refer to as the Deutsch\u2013Jozsa algorithm. </p>"},{"location":"quantum_computation/algorithms/#algorithm-summary","title":"Algorithm Summary","text":"<p>TheDeutsch\u2013Jozsa algorithm suggests that quantum computers may be capable of solving some computational problems much more efficiently than classical computers. Unfortunately, the problem it solves is of little practical interest. Are there more interesting problems whose solution may be obtained more efficiently using quantum algorithms? What are the principles underlying such algorithms? What are the ultimate limits of a quantum computer\u2019s computational power?</p> <p>Broadly speaking, there are three classes of quantum algorithms which provide an advantage over known classical algorithms:</p> <ol> <li>The class of algorithms based upon quantum versions of the Fourier transform</li> <li>Quantum search algorithm</li> <li>Quantum simulation</li> </ol>"},{"location":"quantum_computation/algorithms/#quantum-algorithm-based-upon-the-fourier-transform","title":"Quantum Algorithm based upon the Fourier transform","text":""},{"location":"quantum_computation/algorithms/#quantum-search-algorithm","title":"Quantum search algorithm","text":"<p>The quantum search algorithm solves the following problem: Given a search space of size N, and no prior knowledge about the structure of the information in it, we want to find an element of that search space satisfying a known property. How long does it take to find an element satisfying that property?</p> <p>The quantum search algorithm and its applications are described in Chapter 6.</p>"},{"location":"quantum_computation/algorithms/#quantum-simulation","title":"Quantum simulation","text":""},{"location":"quantum_computation/algorithms/#the-power-of-quantum-computation","title":"The power of quantum computation","text":"<p>Ref: quantum-computation-and-quantum-information-nielsen-chuang</p>"},{"location":"quantum_computation/basics/","title":"Quantum bits","text":"<p>The bit is the fundamental concept of classical computation and classical information. We\u2019re going to describe qubits as mathematical objects with certain specific properties. \u2018But hang on\u2019, you say, \u2018I thought qubits were physical objects.\u2019 It\u2019s true that qubits, like bits, are realized as actual physical systems, and in Section 1.5 and Chapter 7 we describe in detail how this connection between the abstract mathematical point of view and real systems is made.</p> <p>What then is a qubit? Just as a classical bit has a state \u2013 either 0 or 1 \u2013 a qubit also has a state. Two possible states for a qubit are the states \\lvert 0 \\rangle and \\lvert 1 \\rangle. The notation $ \\lvert \\rangle $ is called Dirac notation. The difference between bits and qubits is that a qubit can be in a state other than \\lvert 0 \\rangle or \\lvert 1 \\rangle. It is also possible to form linear combinations of states, often called superpositions:</p>  \\lvert \\psi \\rangle = \\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle  <p>where numbers \\alpha and \\beta are complex numbers, although for many purposes not much is lost by thinking of them as real numbers.The special states \\lvert 0 \\rangle and \\lvert 1 \\rangle are known as computational basis states, and form an orthonormal basis for this vector space.</p> <p>Rather remarkably, we cannot examine a qubit to determine its quantum state, that is, the values of \u03b1 and \u03b2. Instead, quantum mechanics tells us that we can only acquire much more restricted information about the quantum state. When we measure a qubit we get either the result 0, with probability |\\alpha|^2, or the result 1, with probability |\\beta|^2. Naturally, |\\alpha|^2 + |\\beta|^2 = 1, since the probabilities must sum to one. Geometrically, we can interpret this as the condition that the qubit\u2019s state be normalized to length 1. Thus, in general a qubit\u2019s state is a unit vector in a two-dimensional complex vector space. </p> <p>By contrast, a qubit can exist in a continuum of states between \\lvert 0 \\rangle and \\lvert 1 \\rangle \u2013 until it is observed. Let us emphasize again that when a qubit is measured, it only ever gives \u20180\u2019 or \u20181\u2019 as the measurement result \u2013 probabilistically. For example, a qubit can be in the state $$ \\frac{1}{\\sqrt{2}} \\lvert 0 \\rangle + \\frac{1}{\\sqrt{2}} \\lvert 1 \\rangle, $$ which, when measured, gives the result 0 fifty percent |{\\frac{1}{\\sqrt{2}}}|^{2} of the time, and the result 1 fifty percent of ther time. We will return often to this state, which is sometimes denote \\lvert + \\rangle.</p>"},{"location":"quantum_computation/basics/#bloch-sphere","title":"Bloch Sphere","text":"<p>Another way that can helps us thinking about qubtis is the following geometric representation called Bloch Sphere. Since |\\alpha|^2 + |\\beta|^2 = 1, we can write $$ \\lvert \\psi \\rangle = e^{i\\gamma}(cos\\frac{\\theta}{2}\\lvert 0 \\rangle + e^{i\\phi} sin\\frac{\\theta}{2}\\lvert 1 \\rangle), $$ where \\theta, \\phi and \\gamma are real numbers. In Chapter 2 we will see that we can ignore the factor of e^{i\u03b3} out the front, because it has no observable effects, and for that reason we can effectively write $$ \\lvert \\psi \\rangle = cos\\frac{\\theta}{2}\\lvert 0 \\rangle + e^{i\\phi} sin\\frac{\\theta}{2}\\lvert 1 \\rangle, $$ The numbers \\theta and \\phi define a point on the unit three-dimensional sphere, as shown in Figure 1.3. This sphere is often called the Bloch sphere; it provides a useful means of visualizing the state of a single qubit, and often serves as an excellent testbed for ideas about quantum computation and quantum information. Many of the operations on single qubits which we describe later in this chapter are neatly described within the Bloch sphere picture. However, it must be kept in mind that this intuition is limited because there is no simple generalization of the Bloch sphere known for multiple qubits.</p> <p>Figure 1: Bloch_sphere </p> <p>How much information is represented by a qubit? Paradoxically, there are an infinite number of points on the unit sphere, so that in principle one could store an entire text of Shakespeare in the infinite binary expansion of \u03b8. However, this conclusion turns out to be misleading, because of the behavior of a qubit when observed. Recall that measurement of a qubit will give only either 0 or 1. Furthermore, measurement changes the state of a qubit, collapsing it from its superposition of \\lvert 0 \\rangle and \\lvert 1 \\rangle to the specific state consistent with the measurement result.  For example, if measurement of \\lvert 0 \\rangle gives 0, then the post-measurement state of the qubit will be \\lvert 0 \\rangle. What is relevant for our purposes is that from a single measurement one obtains only a single bit of information about the state of the qubit, thus resolving the apparent paradox. It turns out that only if infinitely many identically prepared qubits were measured would one be able to determine \\alpha and \\beta for a qubit in the state given in Equation (1.1).</p>"},{"location":"quantum_computation/basics/#multiple-qubits","title":"Multiple qubits","text":"<p>Suppose we have two qubits. If these were two classical bits, then there would be four possible states, 00, 01, 10, and 11. Correspondingly, a two qubit system has four computational basis states denoted \\lvert 00 \\rangle, \\lvert 01 \\rangle, \\lvert 10 \\rangle, \\lvert 11 \\rangle. A pair of qubits can also exist in superpositions of these four states, so the quantum state of two qubits involves associating a complex coefficient \u2013 sometimes called an amplitude \u2013 with each computational basis state, such that the state vector describing the two qubits is, $$ \\lvert \\psi \\rangle= \\alpha_{00}\\lvert 00 \\rangle + \\alpha_{01}\\lvert 01 \\rangle + \\alpha_{10}\\lvert 10 \\rangle + \\alpha_{11}\\lvert 11 \\rangle $$ Similar to the case for a single qubit, the measurement result x (= 00, 01, 10 or 11) occurs with probability |\\alpha_x|^2, with the state of the qubits after the measurement being \\lvert x \\rangle. Using normalization condition to express the probabilities sum to one is therefore \\sum^{}_{x\\in \\{0,1\\}^2}|\\alpha_{x}|^2 = 1, where the notation \\{0,1\\}^2 means <code>the set of strings of length two with each letter being either zero or one</code>. For a two qubit system, we could measure just a subset of the qubits, say the first qubit, and you can probably guess how this works: measuring the first qubit alone gives 0 with probability |\\alpha_{00}|^2 + |\\alpha_{01}|^2, leaving the post-measurement state.</p>"},{"location":"quantum_computation/basics/#measuring-the-first-qubit","title":"Measuring the First Qubit","text":"<p>When you measure only the first qubit, the system collapses based on the probability distribution derived from the amplitudes of the first qubit's states:</p> <ol> <li> <p>Probability of measuring \\lvert 0 \\rangle:     $$ P(0) =  |\\alpha_{00}|^2 + |\\alpha_{01}|^2 $$</p> </li> <li> <p>Probability of measuring \\lvert 1 \\rangle:     $$ P(1) = |\\alpha_{10}|^2 + |\\alpha_{11}|^2 $$</p> </li> </ol> <p>The state of the system adter the measurement depends on the outcome:</p> <ol> <li> <p>If the first qubit is measured as \\lvert 0 \\rangle:</p> <ul> <li>The system's post-measurement state is the projection of \\lvert \\psi \\rangle onto the subspace where the first qubit is \\lvert 0 \\rangle: $$ \\lvert \\psi' \\rangle =  \\frac{\\alpha_{00}\\lvert 00 \\rangle + \\alpha_{01}\\lvert 01 \\rangle}{\\sqrt{|\\alpha_{00}|^2 + |\\alpha_{01}|^2}} $$</li> <li>The remaining qubit (the second qubit) is now in a superposition of \\lvert 0 \\rangle and \\lvert 1 \\rangle, but normalized to reflect the probabilities conditioned on the first qubit being \\lvert 0 \\rangle.</li> </ul> </li> <li> <p>If the first qubit is measured as \\lvert 1 \\rangle:</p> <ul> <li>The post result becomes: $$ \\lvert \\psi' \\rangle =  \\frac{\\alpha_{10}\\lvert 10 \\rangle + \\alpha_{11}\\lvert 11 \\rangle}{\\sqrt{|\\alpha_{10}|^2 + |\\alpha_{11}|^2}} $$</li> <li>Again, the second qubit's state is conditioned on the first qubit being \\lvert 1 \\rangle. Notice that the post-measurment state is re-normalized by factor \\sqrt{|\\alpha_{00}|^2 + |\\alpha_{01}|^2} so that it still satisfies the normalization condition, just as we expect for a legitimate quantum state.</li> </ul> </li> </ol> <p>Q1: Why Measure Only a Subset of Qubits?</p> <p>In quantum systems, measuring a subset of qubits is often useful to: </p> <ol> <li>Extract partial information:      Measuring only some qubits allows us to gain specific information while leaving the rest of the system intact for further computation or analysis.</li> <li>Preserve entanglement:     If the qubits are entangled, the measurement of one qubit impacts the state of the others. This behavior underpins many quantum algorithms and protocols, like quantum teleportation and superdense coding.</li> <li>Enable conditional operations:      Measurement results can be used to perform conditional logic, such as applying specific quantum gates based on outcomes.</li> </ol> <p>Note: </p> <p>Intuition Behind Measurement Probabilities</p> <p>The probability of each measurement outcome reflects the \"weight\" of the corresponding component in the superposition. For example:</p> <ul> <li>If |\\alpha_{00}|^2 + |\\alpha_{01}|^2 is large, the first qubit is more likely to be measured as \\lvert 0 \\rangle.</li> <li>The remaining quantum state is renormalized to reflect the probabilities conditioned on the observed measurement outcome.</li> </ul> <p>Q2:  Why the first qubit\u2019s state is only associated with \\lvert 00 \\rangle and \\lvert 01 \\rangle? Since we know the full state is: $$ \\lvert \\psi \\rangle= \\alpha_{00}\\lvert 00 \\rangle + \\alpha_{01}\\lvert 01 \\rangle + \\alpha_{10}\\lvert 10 \\rangle + \\alpha_{11}\\lvert 11 \\rangle $$ Here:</p> <ul> <li>The first qubit is represented by the first digit of each basis stae (0 or 1).</li> <li>The second qubit is represented by the second digit of each basis stae (0 or 1).</li> </ul> <p>Q3 Why only \\lvert 00 \\rangle and \\lvert 01 \\rangle</p> <p>When measuring only the first qubit, we are effectively collapsing the system onto the subspace where the first qubit has a definite value (0 or 1).</p> <ol> <li> <p>Measurement Projects the State:     When we measure the first qubit, the system is divided into two groups:</p> <ul> <li>States where the first qubit is \\lvert 0 \\rangle: \\lvert 00 \\rangle and \\lvert 01 \\rangle</li> <li>States where the first qubit is \\lvert 1 \\rangle: \\lvert 10 \\rangle and \\lvert 11 \\rangle</li> </ul> <p>Measuring the first qubit and obtaining \\lvert 0 \\rangle projects the state into the subspace:</p>  \\ Subspace \\ for \\ \\lvert 0 \\rangle : \\{\\lvert 00 \\rangle, \\lvert 01 \\rangle\\}  <p>This means we now only consider the amplitudes \\alpha_{00} and \\alpha_{01}, which correspond to \\lvert 00 \\rangle and \\lvert 01 \\rangle.</p> </li> </ol> <p>When measuring the first qubit:</p> <ol> <li>We divide the full state into subspaces based on the first qubit's value (\\lvert 00 \\rangle or \\lvert 01 \\rangle)</li> <li>Only the amplitudes of the basis states corresponding to the observed value of the first qubit contribute to the measurement outcome and post-measurement state.</li> <li>This is because the measurement of one qubit effectively collapses the global superposition into a subset of states consistent with the measured value.</li> </ol> <p>Q4 What is \"Conditioning\" in Quantum Mechanics?</p> <p>When we say a qubit's state is \"conditioned\" on the outcome of another qubit, it means the state of the remaining qubit (or qubits) depends on the measurement result of the first qubit. This is analogous to the concept of conditional probability in classical probability theory, but here it applies to the post-measurement quantum state.</p> <p>Q5: Why Is It Called \"Conditioning\"?</p> <p>The term conditioning reflects how the state of the second qubit depends on the measurement outcome of the first qubit. This dependency can be understood as follows:</p> <ol> <li>Before Measurement:<ul> <li>The two qubits are entangled (or at least correlated) in the general superposition state \\lvert \\psi \\rangle.</li> <li>The global state doesn't assign definite states to individual qubits, only joint probabilities (e.g., the probabilities of \\lvert 00 \\rangle, \\lvert 01 \\rangle, \\lvert 10 \\rangle, \\lvert 11 \\rangle)</li> </ul> </li> <li>After Measurement of the First Qubit:<ul> <li>The measurement result \"selects\" a subspace of the original state, collapsing the first qubit into a definite state (\\lvert 0 \\rangle or \\lvert 1 \\rangle).</li> <li>The second qubit's state is updated or conditioned to reflect this result. This process is mathematically analogous to conditioning in classical probability, where:</li> </ul> </li> </ol>  P(second \\ qubit) = P(second \\ qubit \\ | first \\ qubit result) <p>Takeaway:</p> <ol> <li>The second qubit's state is conditioned on the first qubit being \\lvert 1 \\rangle: This means the measurement result of the first qubit (being \\lvert 1 \\rangle) determines the possible state and probabilities of the second qubit.</li> <li>The first qubit's state is conditioned on the first qubit being \\lvert 1 \\rangle: This is somewhat redundant and unusual phrasing, as it simply means that the first qubit is \\lvert 1 \\rangle after measurement. It's not really \"conditioned\" in the same sense since it has alreadt collapsed to a definite value.</li> </ol>"},{"location":"quantum_computation/basics/#bell-state-or-epr-pair","title":"Bell state or EPR pair","text":"<p>Let's look into two qubit state Bell state or EPR pair, $$ \\lvert \\psi \\rangle = \\frac{\\lvert 00 \\rangle + \\lvert 11 \\rangle}{\\sqrt 2} $$ This is a Bell state representing maximum entanglement.</p> <ol> <li> <p>Before Measurement:</p> <ul> <li>Neither qubit has a definte state.</li> <li>Measuring the first qubit gives \\lvert 0 \\rangle or \\lvert 1 \\rangle, each with 50% probability.</li> </ul> </li> <li> <p>Measuring the first Qubit:</p> <ul> <li>If the first Qubit is \\lvert 0 \\rangle, the second qubit collapses to \\lvert 0 \\rangle. The post-measurement state is  $$ \\lvert \\psi_{post} \\rangle = \\lvert 00 \\rangle $$</li> <li>If the first Qubit is \\lvert 1 \\rangle, the second qubit collapses to \\lvert 1 \\rangle. The post-measurement state is  $$ \\lvert \\psi_{post} \\rangle = \\lvert 11 \\rangle $$ Here, the second qubit's state depends entirely on the outcome of the first qubit, demonstrating conditional behavior. </li> </ul> </li> </ol> <p>The Bell state has the property that upon measuring the first qubit, one obtains two possible results: 0 with probability \\frac{1}{2}, leaving the post-measruement state \\lvert \\psi' \\rangle = \\lvert 00 \\rangle, and 1 with probability \\frac{1}{2}, leaving \\lvert \\psi' \\rangle = \\lvert 11 \\rangle. As a result, a measurement of the second qubit always gives the same result as the measurement of the first qubit. That's, the measurement outcomes are correlated. EPR\u2019s insights were taken up and greatly improved by John Bell, who proved an amazing result: the measurement correlations in the Bell state are stronger than could ever exist between classical systems. (Section 2.6)</p> <p>we may consider a system of n qubits. The computational basis states of this system are of the form \\lvert x_{1}x_{2}...x_{n}\\rangle, and so a quantum state of such a system is specified by 2^{2} amplitudes.</p>"},{"location":"quantum_computation/computation/","title":"1.3 Quantum Computation","text":""},{"location":"quantum_computation/computation/#single-and-multiple-qubtis","title":"Single and Multiple Qubtis","text":"<p>In order to tell what happens to s</p>"},{"location":"quantum_computation/computation/#measurements-in-bases-other-than-the-computational-basis","title":"Measurements in bases other than the computational basis","text":""},{"location":"quantum_computation/computation/#quantum-circuits","title":"Quantum Circuits","text":"<p>Changes occurring to a quantum state can be described using the language of quantum computation.</p> <p>The circuit is to be read from left-to-right. Each line in the circuit represents a wire in the quantum circuit. This wire does not necessarily correspond to a physical wire; it may correspond instead to the passage of time, or perhaps to a physical particle such as a photon.</p> <p>It's also conventional to assum that the state input to the circuit is a computational basis state, usually the state consisting of \\lvert 0 \\rangles.</p> <p>The figure accomplishes a simple but usaful task - it swaps the states of the two qubits.</p>  \\begin{array}{ll} \\lvert a, b \\rangle \\rightarrow \\lvert a, a\\oplus b \\rangle \\\\ \\lvert a, b \\rangle \\rightarrow \\lvert a \\oplus (a \\oplus b), a\\oplus b \\rangle = \\lvert b, a \\oplus b \\rangle \\\\ \\lvert a, b \\rangle \\rightarrow \\lvert b, (a\\oplus b) \\oplus b \\rangle = \\lvert b,a \\rangle \\end{array}   <p>remember XOR properties are:</p>  \\begin{array}{ll} a\\oplus b = b\\oplus a \\ (Commutative)\\\\ a\\oplus ( b \\oplus c) = (a \\oplus b) \\oplus c \\ (Associative)\\\\ a\\oplus 0 = a \\ (Identity)\\\\ a\\oplus a = 0 \\ (Self-Inverse) \\end{array}   <p>where all additions are done modulo 2. The effect of the circuit, therefore, is to interchange the state of two qubits. To review logic gate, please see Logic gate and more about Quantum logic gate (Wiki) and Quantum logic gate.</p> <p></p> <p>Figure 1: Circuit swapping two qubits and equivalent schematic symbol notation for this common and useful circuit.</p> <p>There are a few features allowed in classical circuits that are not usually present in quantum circuits.</p> <ol> <li> <p>We don\u2019t allow \u2018loops\u2019, that is, feedback from one part of the quantum circuit to another; we say the circuit is acyclic.</p> </li> <li> <p>Classical circuits allow wires to be \u2018joined\u2019 together, an operation known as <code>FANIN</code>, with the resulting single wire containing the bitwise <code>OR</code> of the inputs. Obviously this operation is not reversible and therefore not unitary, so we don\u2019t allow <code>FANIN</code> in our quantum circuits.</p> </li> <li> <p>The inverse operation, <code>FANOUT</code> , whereby several copies of a bit are produced is also not allowed in quantum circuits. This is impossible in quantum mechanics.</p> </li> </ol> <p>Thus, we introduce a so called controlled-U gate, which is a natural extension of the controlled-<code>NOT</code> gate. Such a single single control qubit, indicated by the line with the black dot, and <code>n target qubits</code>, indicated by the boxed U. If the control qubit is set to 0 then nothing happens to thetarget qubits. If the control qubit is set to 1 then the gate U is applied to the target qubits.</p> <p></p> <p>Figure 2: Controlled-U gate</p> <p></p> <p>Figure 3: Two different representations for the controlled-NOT gate</p> <p>Another important gate is the measurement. see figure 4 below.</p> <p></p> <p>Figure 4: quantum circuit symbol for measurement</p>"},{"location":"quantum_computation/computation/#quantum-copying-circuit","title":"Quantum copying circuit","text":""},{"location":"quantum_computation/computation/#example-bell-states","title":"Example: Bell states","text":"<p>Let's considering a more complicated circuit like image showed belowed The Bell state compose two state 1. Hadamard gate followed by a <code>CNOT</code>. The Hadamard gate takes the input \\lvert 00 \\rangle to \\frac{(\\lvert 0 \\rangle + \\lvert 1 \\rangle)\\lvert 0 \\rangle)}{\\sqrt{2}} and then the CNOT gives the output state \\frac{(\\lvert 00 \\rangle + \\lvert 11 \\rangle)}{\\sqrt{2}}. first the Hadamard transform puts the top qubis in a superposition; theis then acts as a control input to the <code>CNOT</code>, and the target gets inverted only when the control is 1. </p> <p>From Tensor Product, The initial state is \\lvert 00 \\rangle = \\lvert 0 \\rangle \\otimes \\lvert 0 \\rangle,</p> <p>Apply H to the first qubit, $$ H\\lvert 0 \\rangle = \\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}} $$</p> <p>Thus, the state of the system becomes: $$ (H\\lvert 0 \\rangle) \\otimes \\lvert 0 \\rangle = (\\frac{\\lvert 0 \\rangle + \\lvert 1 \\rangle}{\\sqrt{2}}) \\otimes \\lvert 0 \\rangle $$</p> <p>This can be expanded as: $$ \\frac{(\\lvert 0 \\rangle\\lvert 0 \\rangle + \\lvert 1 \\rangle\\lvert 0 \\rangle)}{\\sqrt{2}} = \\frac{(\\lvert 00 \\rangle + \\lvert 10 \\rangle)}{\\sqrt{2}} $$</p> <p>By the effect of the <code>CNOT</code>, which inverted only whe the control is 1, we have: $$ \\frac{(\\lvert 00 \\rangle + \\lvert 11 \\rangle)}{\\sqrt{2}} = \\lvert \\beta_{00} \\rangle = \\lvert \\Phi^+\\rangle $$</p> <p>we can get all the following truth table,</p>  \\begin{array}{|c|c|c|c|} \\hline \\text{Input Qubit 1 (\\( A \\))} &amp; \\text{Input Qubit 2 (\\( B \\))} &amp; \\text{Hadamard on \\( A \\)} &amp; \\text{CNOT Output (\\( \\lvert\\Phi^+\\rangle \\))} \\\\ \\hline 0 &amp; 0 &amp; \\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}} &amp; \\frac{\\lvert00\\rangle + \\lvert11\\rangle}{\\sqrt{2}} \\\\ 0 &amp; 1 &amp; \\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}} &amp; \\frac{\\lvert01\\rangle + \\lvert10\\rangle}{\\sqrt{2}} \\\\ 1 &amp; 0 &amp; \\frac{\\lvert0\\rangle - \\lvert1\\rangle}{\\sqrt{2}} &amp; \\frac{\\lvert00\\rangle - \\lvert11\\rangle}{\\sqrt{2}} \\\\ 1 &amp; 1 &amp; \\frac{\\lvert0\\rangle - \\lvert1\\rangle}{\\sqrt{2}} &amp; \\frac{\\lvert01\\rangle - \\lvert10\\rangle}{\\sqrt{2}} \\\\ \\hline \\end{array}"},{"location":"quantum_computation/computation/#bell-states","title":"Bell States:","text":"<p>Below are the four possible Bell states:</p>  \\begin{aligned} \\lvert\\beta_{00}\\rangle = \\lvert\\Phi^+\\rangle &amp; = \\frac{\\lvert00\\rangle + \\lvert11\\rangle}{\\sqrt{2}} \\\\ \\lvert\\beta_{01}\\rangle = \\lvert\\Psi^+\\rangle &amp; = \\frac{\\lvert01\\rangle + \\lvert10\\rangle}{\\sqrt{2}} \\\\ \\lvert\\beta_{10}\\rangle = \\lvert\\Phi^-\\rangle &amp; = \\frac{\\lvert00\\rangle - \\lvert11\\rangle}{\\sqrt{2}} \\\\ \\lvert\\beta_{11}\\rangle = \\lvert\\Psi^-\\rangle &amp; = \\frac{\\lvert01\\rangle - \\lvert10\\rangle}{\\sqrt{2}} \\end{aligned}"},{"location":"quantum_computation/computation/#example-quantum-teleportation","title":"Example: Quantum Teleportation","text":""},{"location":"quantum_computation/factoring/","title":"Factoring Shor's Algorithm","text":"<p>Given a positive compositve integer N, what prime numbers when multiplied together equal it? This factoring problem turns out to be equivalent to the order-finding problem. The reduction of factoring to order-finding proceeds in two basic steps. The first step is to show that we can compute a facotr of N if we can find a non-trival solution x\\neq \\pm 1(\\text{mod}\\ N) to the equation x^{2} = 1 (\\text{mod}\\ N). The second step is to show that a randmly chosen y co-prime to N is quite likely to have an order r which is evenm and such that y^{r/2}\\neq \\pm 1 (\\text{mod} \\ N), and thus x\\equiv y^{r/2} (\\text{mod}\\ N) is a non-trival solution to x^{2} = 1(\\text{mod} \\ N). </p> <p>Theorem 1: Suppose N is an L bit composite number, and x is a non-trival solution to the equation x^{2} = 1(\\text{mod}\\ N) in the range 1\\leq x \\leq N, that is , neither x = 1(\\text{mod} N) nor x = N-1 = -1(\\text{mod}\\ N). Then at least one of gcd(x-1,N) and gcd(x+1,N) is a non-trival factor of N that can be computed using O(L^{3}) operations.</p> <p>Theorem 2: Suppose N = p_{1}^{\\alpha_1}\\cdots p_{m}^{\\alpha_m} is the prime factorization of an odd composite positive integer. let x be an integer chosen uniformaly at random, subject to the requirements that 1\\leq x \\leq N-1 and x is co-prime to N. let r be the order of x \\text{mod}\\ N. Then</p>  p(r\\ \\text{is even and }x^{r/2} \\neq -1 (\\text{mod}\\ N)) \\geq 1 - \\frac{1}{2^{m}}."},{"location":"quantum_computation/factoring/#algorithm-overview","title":"Algorithm overview","text":"<p>Inputs: A composite number N.</p> <p>Outputs: A non-trival factor of N. </p> <p>Runtime: O(L^{3}) operations.</p> <p>Procedure: </p> <ol> <li>If N is even, return the factor 2.</li> <li>Deteremine whether N = a^{b} for integers a\\geq 1 and b\\geq 2, if so return the factor a.</li> <li>Randomly choose x in the range 1 to N-1. if \\text{gcd}(x,N)\\geq 1 then return the factor \\text{gcd}(x,N).</li> <li>Use the order-finding subroutine to find the order r of x \\text{mod} \\ N.</li> <li>If r is even and x^{r/2} \\neq -1(\\text{mod}\\ N)  then compute \\text{gcd}(x^{r/2}-1,N) and \\text{gcd}(x^{r/2}+1,N), and test to see if one of these is a non-trival factor, returning that factor if so. Otherwise, the algorithm fails.</li> </ol>"},{"location":"quantum_computation/factoring/#period-finding","title":"Period Finding","text":"<p>Let's first describe the quantum period finding algorithm. This algorithm takes two coprime integers, x and N, and ouputs r, the period of \\mathcal{F}(a) = x^{a}\\ \\text{mod} \\ N.</p>"},{"location":"quantum_computation/factoring/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p> <p>[2]. Quantum Fourier transform (wiki) https://en.wikipedia.org/wiki/Quantum_Fourier_transform</p> <p>[3]. Continued fraction (wiki) https://en.wikipedia.org/wiki/Continued_fraction</p> <p>[4]. Modular exponentiation (wiki) https://en.wikipedia.org/wiki/Modular_exponentiation</p> <p>[5]. Coprime integers (wiki) https://en.wikipedia.org/wiki/Coprime_integers</p> <p>[6]. Greatest common divisor (wiki) https://en.wikipedia.org/wiki/Greatest_common_divisor</p> <p>[7]. qiskit-community-tutorials/algorithms /shor_algorithm.ipynb https://github.com/qiskit-community/qiskit-community-tutorials/blob/master/algorithms/shor_algorithm.ipynb</p> <p>[8]. Realization of a scalable Shor algorithm by Thomas Monz, Daniel Nigg, Esteban A. Martinez, Matthias F. Brandl, Philipp Schindler, Richard Rines, Shannon X. Wang, Isaac L. Chuang, Rainer Blatt https://arxiv.org/abs/1507.08852</p>"},{"location":"quantum_computation/fourier_transformation/","title":"Quantum Fourier Transformation (QFT)","text":""},{"location":"quantum_computation/fourier_transformation/#introduction-of-qft","title":"Introduction of QFT","text":"<p>One of the most useful ways to solving a probllem in mathematics or computer science is to transform it into some other problem for which a solution is known. One such transformation is the discrete Fourier transform. in the usual mathematical notiation, the discrete Fourier transform takes vector is a fixed parameter. It outputs the x_{0},...,x_{N-1} where the length N of the vector is a fixed paramter. It outpus the transformed data, a vector of complex numbers y_{0},...,y_{N-1}, defined by </p>  y_{k} \\equiv \\frac{1}{\\sqrt{N}}\\sum_{j=0}^{N-1}x_{j}e^{2\\pi ijk/N}.  <p>The quantum Fourier transformation is exactly the same transformation, although the conventional notation for the quantum Fourier transformation is somewhat different. The quantum Fourier transform on an orthonormal basis |0\\rangle,...,|N-1\\rangle is defined to be a linear opearator with the following action on the basis state,</p>  |j\\rangle \\rightarrow \\frac{1}{\\sqrt{N}}\\sum_{k=0}^{N-1}e^{2\\pi ijk/N} |k\\rangle.  <p>Equivalently, the action on an arbitrary state may be written </p>  \\sum_{j=0}^{N-1}x_{j}|j\\rangle \\rightarrow \\sum_{k=0}^{N-1}x_{k}|k\\rangle,  <p>where the amplitudes y_k are the discrete Fourier transform of the amplitudes x_j. It is not obvious from the definition, but this transformation is a unitary transformation, and thus can be implmented as the dynamics for a quantum computer. </p> <p>Give a direct poof that the linear transformation defined by |j\\rangle \\rightarrow \\frac{1}{\\sqrt{N}}\\sum_{k=0}^{N-1}e^{2\\pi ijk/N} |k\\rangle is unitary</p> <p>Explicitly compute the Fourier transform of the n qubit state |00...0\\rangle</p> <p>In the following, we take N = 2^{n}, where n is some integer, and the basis |0\\rangle,...,|2^{n}-1\\rangle is the computational basis for an n qubit quantum computer. We write the state |j\\rangle using the binary representation j = j_{1}j_{2}...j_{n}. That is, j = j_{1}2^{n-1}+j_{2}2^{n-2} + \\cdots + j_{n}2^{0}. For example, |101\\rangle, where j_{1} = 1, j_{2} = 0, and j_{3} = 1. In decimal, j = 1\\cdot 2^{2} + 0\\cdot 2^{1} + 1\\cdot 2^{0} = 5.</p> <p>In the binary fraction format, 0.j_{l}j_{l+1}...j_{n} = \\frac{j_{l}}{2} + \\frac{j_{l+1}}{4} + ... \\frac{j_{m}}{2^{m-l+1}}. we have </p>  0.101 = \\frac{1}{2} + 0 + \\frac{1}{8} = \\frac{5}{8}  <p>The product representation of the quantum Fourier transformation can be shown as </p>  |j_{1},...,j_{n}\\rangle \\rightarrow \\frac{(|0\\rangle + e^{2\\pi i0.j_{n}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.j_{n-1}j_{n}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.j_{1}j_{2}\\cdots j_{n}}|1\\rangle)}{2^{n/2}}.  <p>This production representation is so useful that you amy even wish to consider this to be the definition of the Quantum Fourier transformation.</p> <p>For above example |j\\rangle = |101\\rangle,</p>  |j\\rangle \\rightarrow \\frac{1}{2^{3/2}}\\bigotimes_{k=1}^{3}(|0\\rangle + e^{2\\pi \\cdot 0.j_{k}j_{k+1}...j_{n}}|1\\rangle)  <p>We compute eacj phase using the binary fraction notation for the first qubit:</p>  0.j_{1}j_{2}j_{3} = 0.101 = \\frac{1}{2} + \\frac{0}{4} + \\frac{1}{8} = \\frac{5}{8}  <p>so the first term is |0\\rangle + e^{2\\pi i\\cdot 5/8}|1\\rangle. Similarly, the second quibit </p>  0.j_{2}j_{3} = 0.01 = \\frac{0}{2} + \\frac{1}{4}  = \\frac{1}{4}  <p>so the second term is |0\\rangle + e^{2\\pi i \\cdot 1/4} |1\\rangle. Lastly, the third qubit </p>  0.j_{3} = 0.1 = \\frac{1}{2}  <p>so the third term is |0\\rangle + e^{2\\pi i \\cdot 1/2}|1\\rangle. Putting everything together </p>  |101\\rangle \\rightarrow \\frac{1}{2^{3/2}}(|0\\rangle + e^{2\\pi i\\cdot 5/8}|1\\rangle)\\otimes(|0\\rangle + e^{2\\pi i \\cdot 1/4} |1\\rangle)\\otimes(|0\\rangle + e^{2\\pi i \\cdot 1/2}|1\\rangle)  <p>This is the QFT of |101\\rangle in product form.</p> <p>The equivalence of the product representation and the definition follows from some elementary algebra:</p> <p>TODO: eq 5.5 - 5.10</p>  \\begin{array}{ll} |j\\rangle&amp; \\rightarrow \\frac{1}{2^{n/2}}\\sum_{k=0}^{2^{n}-1} e^{2\\pi ijk/2^{n}}|k\\rangle \\\\  &amp; = d \\end{array}"},{"location":"quantum_computation/fourier_transformation/#qft-circuit","title":"QFT circuit","text":"<p>The product representation |j_{1},...,j_{n}\\rangle makes it easy to derive an efficient circuit for the quantum Fourier transform. The gate R_k denotes the unitary transformation </p>  R_{k} \\equiv \\begin{bmatrix} 1 &amp; 0\\\\ 0 &amp; e^{2\\pi i/2^{k}} \\end{bmatrix}  <p>Let's see how to derive the product form from the QFT circuit.</p> <p>         Efficient circuit for the quantum Fourier transform. Not shown are swap gates at the end of the circuit which reverse the order of the qubitsm or normalization factors of \\( 1/\\sqrt{2} \\) in the output.     </p> <p>Condsidering what happens when the state |j_{1},,,j_{n}\\rangle is input. Apply Hadamard gate to the first bit produces the state (keep your eyes on j_{1} in the circuit!)</p>  |\\psi\\rangle_{j_1|H} = \\frac{1}{2^{1/2}}(|0\\rangle + e^{2\\pi i 0.j_1}|1\\rangle)|j_{2}...J_{n}\\rangle,  <p>since e^{2\\pi i 0.j_{1}} = -1 when j_1 = 1, and is +1 otherwise. Applying the controlled-R_2 gate produces the state </p>  |\\psi\\rangle_{j_1|H,R_2} = \\frac{1}{2^{1/2}}(|0\\rangle + e^{2\\pi i 0.j_1j_2}|1\\rangle)|j_{2}...J_{n}\\rangle.  <p>where j_1|H represent system state after applying H on j_1 and j_1|H,R_2 represent system state applying R_2 on j_1|H. Then simialiry, we continue apply the controll-R_3, R_4 throug R_n gates, each of which adds an extra but to the phase of the coeffifient of the first |1\\rangle. At the end of this procedure we have the state for |\\psi\\rangle_{j_1}</p>  |\\psi\\rangle_{j_1|H,R_2,...,R_n} = \\frac{1}{2^{1/2}}(|0\\rangle + e^{2\\pi i 0.j_1j_2...j_n}|1\\rangle)|j_{2}...j_{n}\\rangle.  <p>Then, we do the same thing on the second qubit. The H gate puts us in the state </p>  \\frac{1}{2^{1/2}}(|0\\rangle + e^{2\\pi i 0.j_1j_2...j_n}|1\\rangle)(|0\\rangle + e^{2\\pi i 0.j_2}|1\\rangle)|j_{3}...j_{n}\\rangle,  <p>then, again, we apply the controll-R_2 to R_{n-1}, the system state becomes </p>  \\frac{1}{2^{1/2}}(|0\\rangle + e^{2\\pi i 0.j_1j_2...j_n}|1\\rangle)(|0\\rangle + e^{2\\pi i 0.j_2...j_n}|1\\rangle)|j_{3}...j_{n}\\rangle,  <p>We continue in this fashion for each qubit, it gives a final state </p>  \\frac{1}{2^{1/2}}(|0\\rangle + e^{2\\pi i 0.j_1j_2...j_n}|1\\rangle)(|0\\rangle + e^{2\\pi i 0.j_2...j_n}|1\\rangle)\\cdots (|0\\rangle + e^{2\\pi i 0.j_n}|1\\rangle),  <p>We omitted the Swap operation, which is used to reverse the order of the qubits, for clarity. After Swap gate, the final state will be </p>  \\frac{1}{2^{1/2}}(|0\\rangle + e^{2\\pi i 0.j_n }|1\\rangle)(|0\\rangle + e^{2\\pi i 0.j_{n-1}...j_{n}}|1\\rangle)\\cdots (|0\\rangle + e^{2\\pi i 0.j_1j_2...j_n}|1\\rangle)  <p>this form matches the product representation mentioned above. So the next question will be how many gates does this circuit ues? </p> <ol> <li>We know that we apply H to every qubit, therefore we have n \\times H gates. </li> <li>Next, we apply n-1 \\times R_{k} on the first qubit, n-2 \\times R_{k} on the second qubit, and 0 \\times R_{k} on the last qubit. Therefore, a total of (n-1) + (n-2) + \\cdots (n-n) = \\frac{n(n-1)}{2} R_k gates. Finally, we have n + \\frac{n(n-1)}{2} = \\frac{n(n+1)}{2} gates for the circuti. </li> <li>Then we require at most of n/2 swap gates, which can be represented as 3\\otimes CNOT gates. </li> </ol> <p>Therefore, the canonical QFT provides \\Theta(n^{2}) algorithm for performing the quantum Fourier transform.</p>"},{"location":"quantum_computation/fourier_transformation/#phase-estimation","title":"Phase Estimation","text":"<p>The Quantum Fourier transformation is the key to a general procedure know as phase estimation, which in turn is the key for many quantum algorithms. Suppose a unitary operator U has an eigenvector |u\\rangle with eigenvalue e^{2\\pi i\\phi},  where the value of \\phi is unknown. The goal of the phase estimation is to estimate \\phi. To perform the estimation we assume that we have available black boxes (oracles) capable of preparing the state |u\\rangle and performing the controlled-U^{2^{j}} operation, for sutible non-negative integers j.</p> <p>The quantum phase estimation procedure uses two registers. The first register contains t qubits initially in the state |0\\rangle. How we choose t depends on two things:</p> <ol> <li>The number of digits of accuracy we wish to have in our estimate for \\phi.</li> <li>With what probability we wish the phase estimation precedure to be successful. </li> </ol> <p>The second register begins in the state |u\\rangle, and contains as many qubits as is necessary to store |u\\rangle.</p> <p>Phase estimation is performed in two stages. </p> <ol> <li>First, the circuit begins by applying a Hadamard transform to the first register, followed by application of controlled-U operations on the second register, with U raised to successive powers of two. The final state of the first registers can be seen as:</li> </ol>  \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i (2^{t}-1)\\phi}|1\\rangle)(|0\\rangle + e^{2\\pi i (2^{t}-2)\\phi}|1\\rangle)...(|0\\rangle + e^{2\\pi i (2^{0})\\phi}|1\\rangle) = \\frac{1}{2^{t/2}}\\sum_{k=0}^{2^{t}-1}e^{2\\pi i \\phi k}|k\\rangle  <p>We omit the second register from this description, since it stays in the state |u\\rangle throughout the computation.</p> <p>         The frist stage of the phase estiamtion procedure. Normalization factors of \\( 1/\\sqrt{2} \\) have been omitted on the right.     </p> <ol> <li>The second stage of the phase estimation is to apply the inverse quantum Fourier transform on the first register. This is obtained by reversing the circuit for the quantum Fourier transform in the previous section, and can be done in \\Theta(t^{2}) steps. The third and final stage of phase estimation is to read out the state of the first register by doing a measurement in the computational basis. An overall schematic of the algorithm is shown below:</li> </ol> <p>To sharpen our intuition as to why phase estimation works, suppose \\phi may be expressed exactly in t bits, as \\phi = 0.\\phi{1}...\\phi{t}. Then the state </p>  \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i (2^{t}-1)\\phi}|1\\rangle)(|0\\rangle + e^{2\\pi i (2^{t}-2)\\phi}|1\\rangle)...(|0\\rangle + e^{2\\pi i (2^{0})\\phi}|1\\rangle) = \\frac{1}{2^{t/2}}\\sum_{k=0}^{2^{t}-1}e^{2\\pi i \\phi k}|k\\rangle  <p>resulting from the first state of phase estimation may be written </p>  \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i0.\\phi_{t}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.\\phi_{t-1}\\phi_{t}}|1\\rangle)...(|0\\rangle + e^{2\\pi i 0.\\phi_{1}\\phi_{2}...\\phi_{t}}|1\\rangle).  <p>The second stage of phase estimation is to apply the inverse quantum Fourier transform. By comparing the previous equation with the product form the Fourier transform, </p>  |j_{1},...,j_{n}\\rangle \\rightarrow \\frac{(|0\\rangle + e^{2\\pi i0.j_{n}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.j_{n-1}j_{n}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.j_{1}j_{2}\\cdots j_{n}}|1\\rangle)}{2^{n/2}}.  <p>we see that the output state from the second stage is the product state |\\phi_{1}...\\phi_{t}\\rangle.  $$ \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i0.\\phi_{t}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.\\phi_{t-1}\\phi_{t}}|1\\rangle)...(|0\\rangle + e^{2\\pi i 0.\\phi_{1}\\phi_{2}...\\phi_{t}}|1\\rangle) \\text{QFT}^{\\dagger}\\rightarrow |\\phi_{1}...\\phi_{t}\\rangle $$</p> <p>A measurement in the computational basis therefore gives us \\phi exactly!</p> <p>         Schematic of the overall phase estimation procedure. \\(|u\\rangle \\) is the eigenstate of \\( U \\) with eigenvalue \\( e^{2\\pi i \\phi} \\). The output of the measurement is an approximation to \\( \\phi \\) accurate to \\( \\lceil \\text{log}(2+\\frac{1}{2\\epsilon})\\rceil \\) bits, with probabiliy of success at least \\( 1-\\epsilon \\)     </p> <p>In sum, the phase estimation algorithm allows one to estiamte the phase \\phi of an eigenvalue of a unitary operator U, given the corresponding eigenvector |u\\rangle. An essential feature at the heart of this procedure is the ability of the inverse Fourier transform to perform the transformation</p>  \\frac{1}{2^{t/2}}\\sum_{j=0}^{2^{t}-1}e^{2\\pi i\\phi j}|j\\rangle|u\\rangle \\rightarrow |\\widetilde{\\phi}\\rangle |e\\rangle,  <p>where |\\widetilde{\\phi}\\rangle denotes a state which is a good estimator for \\phi when measured.</p>"},{"location":"quantum_computation/fourier_transformation/#performance-and-requriements","title":"Performance and requriements","text":""},{"location":"quantum_computation/fourier_transformation/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"quantum_computation/order_finding/","title":"Phase estimation applications: order-finding and factoring","text":"<p>The phase estimation procedure can be used to solve a variety of interesting problems.We now describe two of the most interesting of these problems: the order-finding problem, and the factoring problem.</p> <p>To understand the quantum algorithms for factoring and order-finding requires a little background in number theory.</p>"},{"location":"quantum_computation/order_finding/#order-finding","title":"Order finding","text":"<p>For positive integers x and N, x&lt;N, with no common factors, the order of x modulo N is defined to be the least positive integer r, such that x^{r} = 1 (\\text{mod} \\ N). The order-finding problem is to determine the order for some specified x and N. </p> <p>Example</p> <p>A quick review of order, showing that the order of 5^{r} = 1 (\\text{mod} \\ 21), r = 6 $$ 5^{6} = 15625, 15625/21 = 744...1. $$</p> <p>The quantum algorithm for order-finding is just the phase estimation algorithm applied to the unitary operator </p>  U|y\\rangle = |xy(\\text{mod}\\ N )\\rangle,  <p>with y \\in \\{0,1\\}^{L} (this means y is a bitstring with length L). Note that when N \\leq y\\leq 2^{L}-1, we use the convention that xy(\\text{mod}\\ N) is just y again. That is, U only acts non-trivially when 0\\leq y \\leq N-1. This means that we only use the range 0\\leq y \\leq N-1 for our phase estimation algorithm, we zero-pad or ignore when y \\geq N since it's redundent. </p> <p>From linear algebra, a eignestate of a cyclic shift of length r are </p>  |u_{s}\\rangle \\equiv \\frac{1}{\\sqrt{r}}\\sum_{k=0}^{r-1} e^{-2\\pi i sk/r} |x^{k} \\text{mod} \\ N\\rangle,  <p>|u_s\\rangle is an eigenstate of U, with U|u_{s}\\rangle = e^{2\\pi i s/r}|u_{s}\\rangle</p> <p>Applying a unitary opreator U,</p>  U|u_{s}\\rangle = \\frac{1}{\\sqrt{r}}\\sum_{k=0}^{r-1} e^{-2\\pi i sk/r} |x^{k+1} \\text{mod} \\ N\\rangle,  <p>set j = k+1, when k=0, \\ j=0, and k = r-1, \\ j = r. Thus,</p>  U|u_{s}\\rangle = \\frac{1}{\\sqrt{r}}\\sum_{j=1}^{r} e^{-2\\pi i s(j-1)/r} |x^{j} \\text{mod} \\ N\\rangle,  <p>factor out the phse term, </p>  U|u_{s}\\rangle = e^{2 \\pi i s/r}\\frac{1}{\\sqrt{r}}\\sum_{j=1}^{r} e^{-2\\pi i sj/r} |x^{j} \\text{mod} \\ N\\rangle,  <p>here is the key, since x^{r} = x^{0} \\text{mod}\\ N, we relabel j as k again. </p>  \\begin{array}{rl} U|u_{s}\\rangle &amp;= e^{2 \\pi i s/r}\\frac{1}{\\sqrt{r}}\\sum_{k=0}^{r-1} e^{-2\\pi i sk/r} |x^{k} \\text{mod} \\ N\\rangle,\\\\  &amp; = e^{2 \\pi i s/r}|u_{s}\\rangle. \\end{array}  <p>Using the phase estimation procedure allows us to obtain, with high accuracy, the corresponding eigenvalues e^{2\\pi i s/r}.</p> Relabel  j  to  k ? how? <p>You may be confused about relabeling, however, let's set </p>  k = j \\text{mod}\\ r  <p>when j = 1,2,...,r</p>  \\begin{array}{c} k = 1 \\text{mod} \\ 1, \\ k = 1\\\\ k = 2 \\text{mod} \\ 2, \\ k = 2\\\\ \\vdots \\\\ k = 3 \\text{mod} \\ r, \\ k = 0 \\end{array}  <p>thus the range of k is 0,1,...,r-1</p>"},{"location":"quantum_computation/order_finding/#requriements","title":"Requriements","text":"<p>There are two key requriements for us to be able to use phase estimation procedure:</p> <ol> <li> <p>We must have efficient procedures to implement a controlled-U^{2^{j}} operation for any integer j, and we must be able to efficiently prepare an eigenstate |u_{s}\\rangle with a non-trivial eigenvalue, or at least a superposition of such eigenstates. To achieve the first requriement, we can use a method called modular exponentiation, which we can implement the entire sequence of controll-U^{2^{j}} operations used by the phase estimation.</p> </li> <li> <p>You may already notice that: there is a r in the |u_{s}\\rangle representation already? So this is out of the question. Fortunnately, there is an observation allows us to workaround this obstacle</p> </li> </ol>  \\frac{1}{\\sqrt{r}}\\sum_{s=0}^{r-1}|u_{s}\\rangle = |1\\rangle.  <p>If we use t = 2L + 1 + \\lceil \\text{log}(2 + \\frac{1}{2\\epsilon}) \\rceil qubits in the first register (see Quantum Fourier Transform), and prepare the second register in the state |1\\rangle, it follows that for each s in the range 0 to r-1, we will obtain an estimate of the phase \\phi \\approx s/r accurate to 2L+1 bits, with probability at least (1-\\epsilon)/r.</p> <p>TODO exercise 5.13/14</p>"},{"location":"quantum_computation/order_finding/#modular-exponentiation","title":"Modular Exponentiation","text":"<p>How can we compute the sequence of controlled-U^{2^{j}} operations used by the phase estimation procedure? We wish to compute the transformation</p>  \\begin{array}{rl} |z\\rangle|y\\rangle&amp; \\mapsto |z\\rangle U^{z_{t}2^{t-1}}...U^{z_{1}2^{0}}|y\\rangle \\\\ \\ &amp; = |z\\rangle |x^{z_{t}2^{t-1}} \\times \\cdots \\times x^{z_{1}2^{0}} y \\text{mod} \\ N\\rangle \\\\ \\ &amp; = |z\\rangle |x^{z}y(\\text{mod}\\ N)\\rangle \\\\ \\end{array}  <p>Thus the sequence of controlled-U^{2^{j}} operations used in phase estimation is equivalent to multiplying the contents of the second register by the modular exponentiation x^{z}(\\text{mod}N), where z is the contents of the first register.</p> <p>This algorithm for computing the modular exponential has two stages.</p> <ol> <li> <p>Compate x^{2}(\\text{mod}N), x^{4}(\\text{mod}N), ..., x^{2^{j}}(\\text{mod}N), for all j up to t-1. We use t = 2L +1 + \\lceil\\text{log}(2+1/(2\\epsilon))\\rceil = O(L), so a total of t-1 = O(L) squaring operations is performed at a cost of O(L^{2}) each, for a total cost of O(L^{3}) for the first stage.</p> </li> <li> <p>The second stage is based on the observation we have already noted,</p>  x^{z}(\\text{mod} \\ N) = \\bigg (x^{z_{t}2^{t-1}}(\\text{mod} \\ N)\\bigg )\\bigg (x^{z_{t-1}2^{t-2}}(\\text{mod} \\ N)\\bigg )...\\bigg (x^{z_{1}2^{0}}(\\text{mod} \\ N)\\bigg ).  <p>Performing t-1 modular multiplications with a cost O(L^{2}) each, we see that this product can be computed using O(L^{2}) gates.</p> </li> </ol>"},{"location":"quantum_computation/order_finding/#the-continued-fraction-expansion","title":"The continued fraction expansion","text":"<p>The very last step of obtaining the desire r from the result of the phase estimation (PE), \\phi \\approx s/r. We only know \\phi to 2L+1 buts, but we also know a prior that it is a rational number and if we compute the neatest such fration to \\phi we might obtain r. Suppose s/r is a rational number such that </p>  |\\frac{s}{r} - \\phi|\\leq \\frac{1}{2r^{2}}.  <p>Then s/r is a convergent of the continued fration for \\phi, and thus can be computed in O(L^{3}) operations using the continued fractions algorithm. Since \\phi is an approximation of s/r accurate to 2L+1 bits, it follows that |s/r - \\phi|\\leq 2^{-2L-1}\\leq 1/2r^{2}, since r \\leq N \\leq 2^{L}. We obtain approximated \\phi, which can be written into fraction s'/r' without having commom factor for s' and r', by checking if number r' in x^{r'} (\\text{mod}N) produce result 1. If so, then we are done!</p>"},{"location":"quantum_computation/order_finding/#the-continued-fractions-algorithm-number-theory","title":"The continued fractions algorithm (number theory)","text":"<p>The idea of the continued fractions algorithm is to describe real numbers in terms of integers alone, using expressions of the form</p>  [a_{0},...,a_{M}] = a_{0} + \\frac{1}{a_{1} + \\frac{1}{a_{2} + \\frac{1}{\\cdots + \\frac{1}{a_M}}}}  <p>where a_{0},...,a_{M} are postiive integers. The continued fractions algorithm is a method for determining the continued fraction expansion of an arbitrary real number.</p> <p>Let's say you obtained a result \\phi = 31/128 from the phase estiamtion and you want to retrive the order r. We can use the continued fraction alforithm and find it's convergent. We start with inverting 31/128 to 128/31 and express as a_0 + some fraction </p>  \\frac{128}{31} = 4+\\frac{4}{31},  <p>then we can express \\frac{4}{31} by using continued fraction algorithm as,</p>  \\frac{128}{31} = 4+\\frac{1}{\\frac{31}{4}} = 4+\\frac{1}{7+\\frac{3}{4}} = 4+\\frac{1}{7+\\frac{1}{\\frac{4}{3}}},  <p>if we continue with this algorithm, we eventally obtain</p>  \\frac{128}{31} = 4+\\frac{1}{7+\\frac{1}{1+\\frac{1}{\\frac{1}{3}}}}  <p>The algorithm terminates, since \\frac{1}{3} doesn't need to invert. We have </p>  [a_{0},a_{1},a_{2},a_{3}] = [4,7,1,3]  <p>Next, we can work on the convergent based on number theory. Let's start with h_{n}/k_{n} where it's defined as</p>  \\frac{h_n}{k_n} =  \\begin{cases} h_{n} = a_{n}h_{n-1}+h_{n-2}\\\\ k_{n} = a_{n}k_{n-1}+k_{n-2}\\\\ \\end{cases} , n = 0,...,M  <p>where</p>  \\frac{h_n}{k_n} =  \\begin{cases} h_{-2} = 0,\\quad h_{-1} = 1 \\\\ k_{-2} = 1,\\quad k_{-1} = 0 \\end{cases}  <p>after a little bit of calcualtion, we have \\frac{1}{4},\\frac{7}{29},\\frac{8}{33},\\frac{1}{128} for [a_{0},a_{1},a_{2},a_{3}] = [4,7,1,3]. We can do a quick check that </p>  \\begin{array}{rccccl} a_{0} &amp; \\rightarrow &amp; \\frac{s_{0}}{r_{0}} &amp; = &amp; \\frac{1}{4} &amp; = &amp; 0.25\\\\ a_{1} &amp; \\rightarrow &amp; \\frac{s_{1}}{r_{1}} &amp; = &amp; \\frac{7}{29} &amp; = &amp; 0.241237...\\\\ a_{2} &amp; \\rightarrow &amp; \\frac{s_{2}}{r_{2}} &amp; = &amp; \\frac{8}{33} &amp; = &amp; 0.242424...\\\\ a_{3} &amp; \\rightarrow &amp; \\frac{s_{3}}{r_{3}} &amp; = &amp; \\frac{31}{128} &amp; = &amp; 0.2412875\\\\ \\end{array}  <p>they look fairy close to your result \\phi = 31/128. Then we can verify each r by </p>  x^{r} = 1\\ (\\text{mod} \\ N)  <p>then we are done! Congratulations you just find the r! Easy peasy!\ud83d\ude03</p> <p>Cost of the continued fraction algorithm</p> <p>If \\phi = s/r is a rational number, and s and r are L bit integers, then the continued fraction expansion for \\phi can be computed using O(L^3) opeartions - O(L) 'split and invert' steps, each using O(L^{2}) gates or elementary arithmetic.</p>"},{"location":"quantum_computation/order_finding/#algorithm-overview","title":"Algorithm overview","text":"<p>Inputs:</p> <ol> <li>A black bos U_{x,N} which performs the transformation |j\\rangle|k\\rangle\\mapsto |j\\rangle|x^{j}k\\ \\text{mod} N\\rangle, for x co-prime to the L-number N.</li> <li>Set <code>t = 2L + 1 + math.ceil(np.log2(2+1/epsilon))</code>, <code>t</code> qubits are used in the first register.</li> <li>L qubits initialized to the state |1\\rangle for the second register.</li> </ol> <p>Outputs: The least integer r&gt;0 such that x^{r} = 1\\ (\\text{mod}N)</p> <p>Runtime: O(L^{3}) operations.</p> <p>Procedure: </p>  \\begin{array}{lll} 1. &amp; |0\\rangle|1\\rangle &amp; \\text{initial state}\\\\ 2. &amp; \\rightarrow \\frac{1}{\\sqrt{2}}\\sum_{j=0}^{2^{t}-1}|j\\rangle|1\\rangle &amp; \\text{create superposition}\\\\ 3. &amp; \\rightarrow \\frac{1}{\\sqrt{2^{t}}}\\sum_{j=0}^{2^{t}-1}|j\\rangle|x^{j} \\ \\text{mod} N\\rangle &amp; \\text{apply} U_{x,N}\\\\  &amp; \\approx \\frac{1}{\\sqrt{r2^{t}}}\\sum_{s=0}^{r-1}\\sum_{j=0}^{2^{t}-1}e^{2\\pi isj/r}|j\\rangle|u_{s}\\rangle &amp; \\\\ 4. &amp; \\rightarrow \\frac{1}{\\sqrt{r}}\\sum_{s=0}^{r-1}|s/r\\rangle|u_{s}\\rangle &amp; \\text{apply inverse Fourier transform to first register}\\\\ 5. &amp; \\rightarrow s/r &amp; \\text{meausure the frist register}\\\\ 6. &amp; \\rightarrow r &amp; \\text{apply continued fractions algorithm} \\end{array}  Is U  a diagonal matrix in Shor's algorithm? <p>The short answer: NO. A unitary operator U is defined as </p> U \\equiv \\begin{bmatrix} 1 &amp; 0 \\\\ 0 &amp; e^{2\\pi i \\theta} \\end{bmatrix}  <p>is only valid in basic phase estimation examples where U acts on 1 qubit and has eigenstates like |1\\rangle \\rightarrow e^{2\\pi i \\theta}|1\\rangle.</p>"},{"location":"quantum_computation/order_finding/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p> <p>[2]. Quantum Fourier transform (wiki) https://en.wikipedia.org/wiki/Quantum_Fourier_transform</p> <p>[3]. Continued fraction (wiki) https://en.wikipedia.org/wiki/Continued_fraction</p> <p>[4]. Modular exponentiation (wiki) https://en.wikipedia.org/wiki/Modular_exponentiation</p> <p>[5]. Coprime integers (wiki) https://en.wikipedia.org/wiki/Coprime_integers</p> <p>[6]. Greatest common divisor (wiki) https://en.wikipedia.org/wiki/Greatest_common_divisor</p> <p>[7]. qiskit-community-tutorials/algorithms /shor_algorithm.ipynb https://github.com/qiskit-community/qiskit-community-tutorials/blob/master/algorithms/shor_algorithm.ipynb</p>"},{"location":"quantum_computation/period_finding/","title":"Period-finding","text":"<p>Suppose f is a periodic function producing a single bit as output and such that f(x+r) = f(x), for some unknown 0&lt;r&lt;2^{L}, where x,r \\in \\{0,1,2,...\\}. Given a quantum black box U which performs the unitary transform U|x\\rangle|y\\rangle \\mapsto |x\\rangle|y\\oplus f(x)\\rangle (where \\oplus denotes addition modulo 2) how many black box queries and other operations are required to determin r? </p> <p>In practice U operates on a finite domain, whose size is deteremined by the desired accuracy r. </p>"},{"location":"quantum_computation/period_finding/#algorithm-overview-one-query","title":"Algorithm overview (one query)","text":"<p>Inputs: </p> <ol> <li>A black box which performs the operation U|x\\rangle|y\\rangle = |x\\rangle|y\\oplus f(x)\\rangle.</li> <li>A state to store the function evaluation, initialized to |0\\rangle</li> <li>t=O(L+\\text{log}(1/\\epsilon)) qubits initialized to |0\\rangle.</li> </ol> <p>Outputs: The least integer r&gt;0 such that f(x+r) = f(x)</p> <p>Runtime: one use of u, and O(L^{3}) operations. Succeeds with probablility O(1)</p> <p>Procedure: </p>  \\begin{array}{lll} 1. &amp; |0\\rangle|0\\rangle &amp; \\text{initial state}\\\\ 2. &amp; \\rightarrow \\frac{1}{\\sqrt{2}}\\sum_{x=0}^{2^{t}-1}|x\\rangle|0\\rangle &amp; \\text{create superposition}\\\\ 3. &amp; \\rightarrow \\frac{1}{\\sqrt{2^{t}}}\\sum_{x=0}^{2^{t}-1}|x\\rangle|f(x)\\rangle \\ &amp; \\text{apply} U\\\\  &amp; \\approx \\frac{1}{\\sqrt{r2^{t}}}\\sum_{l=0}^{r-1}\\sum_{x=0}^{2^{t}-1}e^{2\\pi ilj/r}|x\\rangle|\\widehat{f}(l)\\rangle &amp; \\\\ 4. &amp; \\rightarrow \\frac{1}{\\sqrt{r}}\\sum_{l=0}^{r-1}|l/r\\rangle|\\widehat{f}(l)\\rangle &amp; \\text{apply inverse Fourier transform to first register}\\\\ 5. &amp; \\rightarrow s/r &amp; \\text{meausure the frist register}\\\\ 6. &amp; \\rightarrow r &amp; \\text{apply continued fractions algorithm} \\end{array}  <p>The key to understanding this algorithm, which is based on phase estimation, and its basically a order-finding problem. In step 3, we introduce the state </p>  |\\widehat{f}(l)\\rangle\\equiv \\frac{1}{\\sqrt{r}}\\sum_{x=0}^{r-1}e^{-2\\pi ilx/r}|f(x)\\rangle  <p>the Fourier transform of |f(x)\\rangle. The identity used in step 3 is based on </p>  |f(x)\\rangle = \\frac{1}{\\sqrt{r}}\\sum_{k=0}^{r-1}e^{2\\pi ilx/r}|\\widehat{f}(l)\\rangle  <p>which is a easy to verfify noting that \\sum_{k=0}^{r-1}e^{2\\pi ilx/r} = r for integer x an integer multiple of r, and zero otherwise. The approximate equality in step 3 is required since 2^t may not be an integer multiple of r in general. After applying the inverse Fourier transform at the step 4 we can get l/r, where l is chosed randomly. r can be calcualted by using a continued fraction expansion.</p>"},{"location":"quantum_computation/period_finding/#from-factorization-to-period-finding","title":"From Factorization to Period Finding","text":"<p>The number thoery that underlines Shor's algorithm relates to periodic modulo sequences. Let's have a look at an example of such a sequence. let's consider the sequence of the power of two:</p>  1,2,4,8,16,32,64,128,256,512,1024,...  <p>Now let's compute modulo 15 on each entry,</p>  1,2,4,8,1,2,4,8,1,2,4,...  <p>and we can easily see that sequence repeats every four numbers, and this is the periodic modulo sequence with a period of four.</p> <p>The reduction of factorization of N to the problem of finding the period of an integer x less than N and greater than 1 depends on the following result from number theory:</p> <p>The function \\mathcal{F}(a) = x^{a} (\\text{mod}\\ N) is periodic function, where x is an integer coprime to N and a \\geq 0.</p> <p>Note that two numers are coprime, if the only positive integer that divides both of them is 1, \\text{gcd}(2,9) = 1 and \\text{gcd}(8,15) = 1, for an examples. On the other hand, \\text{gcd}(2,8) = 2, so 2 and 8 are not coprime.</p> <p>Since \\mathcal{F}(a) is a periodic function, it has some period r. Knowing that x^{0} \\text{mod} \\ N =1, this means that x^{r} \\text{mod} \\ N =1 since the function is periodic, and thus r is just the first non-zero power where x^{r} = 1 \\text{mod} (the result that we are looking for in the order finding problem).</p> <p>Based on some basic algebras:</p>  \\begin{array}{c} x^{r} \\equiv 1\\ \\text{mod}\\\\ x^{r} = (x^{r/2})^{2} \\equiv 1\\ \\text{mod}\\\\ (x^{r/2})^{2} - 1 \\equiv 0\\ \\text{mod}\\\\ (x^{r/2} + 1)(x^{r/2} - 1) \\equiv 0\\ \\text{mod} \\end{array}  <p>The product (x^{r/2} + 1)(x^{r/2} - 1) \\equiv 0 \\text{mod} is an integer multiple of N, the number to be factored. Thus, as long as (x^{r/2} + 1) of (x^{r/2} - 1) is not a multiple of N, then at least one of (x^{r/2} + 1) or (x^{r/2} - 1) must have a nontrivial factor in common with N.</p> <p>Therefore, we can also know that calculate \\text{gcd}(x^{r/2} + 1,N) and \\text{gcd}(x^{r/2} - 1,N) will obtain a factor of N, which can be accomlished by using Euclidean algorithm.</p>"},{"location":"quantum_computation/period_finding/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p> <p>[2]. Quantum Fourier transform (wiki) https://en.wikipedia.org/wiki/Quantum_Fourier_transform</p> <p>[3]. Continued fraction (wiki) https://en.wikipedia.org/wiki/Continued_fraction</p> <p>[4]. Modular exponentiation (wiki) https://en.wikipedia.org/wiki/Modular_exponentiation</p> <p>[5]. Coprime integers (wiki) https://en.wikipedia.org/wiki/Coprime_integers</p> <p>[6]. Greatest common divisor (wiki) https://en.wikipedia.org/wiki/Greatest_common_divisor</p> <p>[7]. qiskit-community-tutorials/algorithms /shor_algorithm.ipynb https://github.com/qiskit-community/qiskit-community-tutorials/blob/master/algorithms/shor_algorithm.ipynb</p> <p>[8]. Realization of a scalable Shor algorithm by Thomas Monz, Daniel Nigg, Esteban A. Martinez, Matthias F. Brandl, Philipp Schindler, Richard Rines, Shannon X. Wang, Isaac L. Chuang, Rainer Blatt https://arxiv.org/abs/1507.08852</p>"},{"location":"quantum_computation/phase_kickback/","title":"Phase kick-back","text":"<p>Takeaway</p> <p>Phase kickback is a quantum mechanical effect where applying a controlled gate transfers the phase from a target qubit to a control qubit. This happens when the target qubit is in an eigenstate of the unitary operation being applied.</p>"},{"location":"quantum_computation/phase_kickback/#how-it-works","title":"How It Works","text":"<p>The core principle of phase kickback relies on the setup of a controlled unitary operation (controlled-U gate). This gate applies the unitary operator U to the target qubit only if the control qubit is in the state |1\\rangle.</p> <p>Let's represent the control qubit state as |\\psi\\rangle = \\alpha|0\\rangle + \\beta|1\\rangle  and the target (ancilla) qubit as |t\\rangle. The combined initial state is:</p>  |\\psi_{\\text{in}}\\rangle = (\\alpha|0\\rangle + \\beta|1\\rangle) \\otimes |t\\rangle = \\alpha|0\\rangle|t\\rangle + \\beta|1\\rangle |t\\rangle  <p>Applying the controlled-U gate gives:</p>  |\\psi_{\\text{out}}\\rangle = \\alpha|0\\rangle|t\\rangle + \\beta|1\\rangle(U|t\\rangle)  <p>Now, in order to perfrom the phase kick back, the target qubit |t\\rangle must be the eigenstate of the operator U. (An eigenstate is a state that, when acted upon by an operator, only changes by a scalar factor called the eigenvalue.) For a unitary operator, this eigenvalue is of the form e^{i\\phi}.</p> <p>So, let's assume U|t\\rangle = e^{i\\phi}|t\\rangle. We substitute this into our equation:</p>  |\\psi_{\\text{out}}\\rangle = \\alpha|0\\rangle|t\\rangle + \\beta|1\\rangle(e^{i\\phi}|t\\rangle)  <p>We can now factor out the target qubit state |t\\rangle, which is unchanged:</p>  |\\psi_{out}\\rangle = (\\alpha|0\\rangle|t\\rangle + e^{i\\phi}\\beta|1\\rangle)|t\\rangle  <p>Notice that </p> <ul> <li>The target qubit |t\\rangle is completely unaffected.</li> <li>The control qubit state has changed from \\alpha|0\\rangle|t\\rangle + \\beta|1\\rangle to \\alpha|0\\rangle|t\\rangle + e^{i\\phi}\\beta|1\\rangle. A relative phase of e^{i\\phi} has been \"kickback\" from the target to the control qubit.</li> </ul>"},{"location":"quantum_computation/phase_kickback/#example-cnot-gate","title":"Example - CNOT gate","text":"<p>Let's consider a CNOT gate where the unitary operation is the Pauli-X gate <code>X</code>. We know that <code>X</code> has two eigenstates:</p> <ul> <li>|+\\rangle = \\frac{|0\\rangle + |1\\rangle}{\\sqrt{w}}, with eigenvalue e^{i0} = +1.</li> <li>|-\\rangle = \\frac{|0\\rangle - |1\\rangle}{\\sqrt{w}}, with eigenvalue e^{i\\pi} = -1.</li> </ul> <p>Let's set state |-\\rangle as our target qubit. We are expecting to get X|-\\rangle = -|-\\rangle when we apply <code>X</code> on state |-\\rangle due to its eigenvalue. First we set our initial state as  </p>  |\\psi_{\\text{in}}\\rangle = |+\\rangle|-\\rangle  <p>the we apply the CNOT gate,</p>  \\begin{array}{ll} CNOT(|+\\rangle|-\\rangle) &amp; = CNOT \\bigg(\\frac{|0\\rangle + |1\\rangle}{\\sqrt{2}} \\otimes |-\\rangle \\bigg)\\\\ \\ &amp; = \\frac{1}{\\sqrt{2}}\\bigg(CNOT|0\\rangle|-\\rangle + CNOT|1\\rangle|-\\rangle\\bigg), \\end{array}  <p>remember that CNOT clips the target if the control is |1\\rangle. Thus,</p> <ul> <li>For the |0\\rangle|-\\rangle part, the control is |0\\rangle, so nothing happens.</li> <li>For the |1\\rangle|-\\rangle part, the control is |1\\rangle, so the <code>X</code> gate is applied to the target: |1\\rangle(X|-\\rangle) = |1\\rangle(-|-\\rangle) = -|1\\rangle|-\\rangle.</li> </ul> <p>thus the final state will be </p>  \\begin{array}{ll} |\\psi_{\\text{out}}\\rangle &amp; = \\frac{1}{\\sqrt{2}}\\bigg(|0\\rangle|-\\rangle-|1\\rangle|-\\rangle\\bigg) = \\bigg(\\frac{1}{\\sqrt{2}}(|0\\rangle - |1\\rangle)\\bigg) \\otimes |-\\rangle\\\\ \\ &amp; = |-\\rangle|-\\rangle \\end{array}  <p>The phase eigenvalue of -1 from the target qubit was kicked back, flipping the control qubit from |+\\rangle to |-\\rangle, while the target qubit remained in the |-\\rangle state.</p>"},{"location":"quantum_computation/q_computer_conditions/","title":"Conditions for quantum computation","text":""},{"location":"quantum_computation/q_computer_conditions/#physical-realizations-of-qubits","title":"Physical Realizations of Qubits","text":"<p>A quantum computer must strike a balance between two conflicting needs:</p> <p>1.\u2003 Isolation \u2013 to preserve quantum coherence. 2.\u2003 Accessibility \u2013 to allow operations and readout.</p> <p>A quantum computer has to be well isolated... but its qubits have to be accessible...</p> <p>These timescales determine how \u201cgood\u201d a quantum system is:</p> <ol> <li>\\tau_{Q}: Coherence time: how long a qubit remains quantum.  </li> <li>\\tau_{op}: Operation time: time to apply a gate.  </li> <li>\\lambda = \\tau_{op} / \\tau_{Q}: Noise strength (smaller is better).  </li> <li>n_{op} = \\lambda^{-1}: Max ops before decoherence.</li> </ol>  \\begin{array}{|l|c|c|c|} \\hline \\textbf{System} &amp; \\tau_Q &amp; \\tau_{op} &amp; n_{op} = \\lambda^{-1} \\\\ \\hline \\text{Nuclear spin} &amp; 10^{-2} \\text{ to } 10^{8} &amp; 10^{-3} \\text{ to } 10^{-6} &amp; 10^5 \\text{ to } 10^{14} \\\\ \\text{Electron spin} &amp; 10^{-3} &amp; 10^{-7} &amp; 10^4 \\\\ \\text{Ion trap (In}^+) &amp; 10^{-1} &amp; 10^{-14} &amp; 10^{13} \\\\ \\text{Electron \u2013 Au} &amp; 10^{-8} &amp; 10^{-14} &amp; 10^6 \\\\ \\text{Electron \u2013 GaAs} &amp; 10^{-10} &amp; 10^{-13} &amp; 10^3 \\\\ \\text{Quantum dot} &amp; 10^{-6} &amp; 10^{-9} &amp; 10^3 \\\\ \\text{Optical cavity} &amp; 10^{-5} &amp; 10^{-14} &amp; 10^9 \\\\ \\text{Microwave cavity} &amp; 10^{0} &amp; 10^{-4} &amp; 10^4 \\\\ \\hline \\end{array}"},{"location":"quantum_computation/q_computer_conditions/#4-basic-requirements","title":"4 basic requirements","text":"<ol> <li>Robustly represent quantum infomation</li> <li>Perform a universal family of unitary transformations</li> <li>Perpare a fiducial initial state</li> <li>Measure the output result</li> </ol>"},{"location":"quantum_computation/q_computer_conditions/#representation-of-quantum-infomation","title":"Representation of quantum infomation","text":"<p>Quantum computation is based on transforming quantum states. Qubits are two\u2010level systems that provide a convenient finite state space for computation.</p> <ol> <li> <p>Finite state space is crucial </p> <ul> <li>Continuous variables (e.g. position x) inhabit an infinite\u2010dimensional Hilbert space\u2014unrealistic once noise is included.  </li> <li>Noise limits the number of distinguishable states to a finite set.</li> </ul> <p>For example, in a perfect world, the entire texts of Shakespeare could be stored in the infinite number of digits in the binary fraction x = 0.010111011001.... What happens in reality is that the presence of noise reduces the number of distinguishable states to a finite number.</p> </li> <li> <p>Symmetry enforces finiteness </p> <ul> <li>It is generally desirable to have some aspect of symmetry dictate the finiteness of the state space, in order to minimize decoherence.</li> <li>A spin-\\tfrac12 particle lives in the two\u2010dimensional space spanned by |\\!\\!\\uparrow\\rangle and |\\!\\!\\downarrow\\rangle. When well isolated, this is an almost ideal qubit.</li> </ul> </li> <li> <p>Poor representations lead to decoherence </p> <ul> <li>Example: a finite square well with exactly two bound states still couples to the continuum\u2014transitions destroy superpositions.  </li> <li>Any leakage out of the two\u2010level subspace adds noise.</li> </ul> </li> <li> <p>Figures of merit for single qubits </p> <ul> <li>T_2 (transverse relaxation time): minimum lifetime of arbitrary superpositions (best measure of coherence).  </li> <li>T_1 (longitudinal relaxation time): lifetime of the energy eigenstate |1\\rangle (a \u201cclassical\u201d lifetime, usually &gt;T_2).</li> </ul> </li> </ol> <p>\u201cAnything which causes loss of quantum information is a noise process.\u201d</p>"},{"location":"quantum_computation/q_computer_conditions/#performance-of-unitary-transformations","title":"Performance of unitary transformations","text":"<p>Closed quantum systems evolve under their Hamiltonian, but quantum computation requires the ability to control that Hamiltonian to implement any desired gate.</p> <ol> <li> <p>Hamiltonian Control </p> <ul> <li> <p>Evolution under      $$     H = P_x(t)\\,X + P_y(t)\\,Y     $$  </p> <p>where P_{x,y}(t) are classical control parameters.</p> </li> <li> <p>By shaping P_x and P_y, one can perform arbitrary single\u2010spin rotations.</p> </li> </ul> </li> <li> <p>Universal Gate Set </p> <ul> <li>Any unitary can be decomposed into single\u2010spin rotations + <code>CNOT</code> gates.</li> <li>Requires addressability: Implicitly required also is the ability to address individual qubits, and to apply these gates to select qubits or pairs of qubits. e.g. in an ion trap you must focus a laser on individual ions (spaced \\geq one wavelength).</li> </ul> </li> <li> <p>Imperfections \u2192 Decoherence </p> <ul> <li>Unrecorded imperfections in unitary transfoms can lead to decoherence.</li> <li>Random errors: uncontrolled \u201ckicks\u201d (small rotations about \\hat z) introduce random relative phases \u2192 loss of coherence.  </li> <li>Systematic errors: calibration drifts accumulate into irreversible noise if you lose the information needed to reverse them.  </li> <li>Back\u2010action: controls are quantum too. For example, a Jaynes\u2013Cummings interaction \u2003\u2003\u2003      $$     P_x(t)=\\sum_k \\omega_k(t)\\,(a_k + a_k^\\dagger)     $$ \u2003\u2003\u2003      couples the qubit to the photon field, which can carry away state information.</li> </ul> </li> <li> <p>Figures of Merit </p> <ul> <li>Fidelity \\mathcal{F}: minimum achievable fidelity of the target unitary. </li> <li>Operation time t_{op}: maximum time needed for elementary gates (rotations, <code>CNOT</code>).</li> </ul> </li> </ol> <p>High\u2010precision control of H and suppression of all error sources are key to achieving high\u2010fidelity quantum gates. </p>"},{"location":"quantum_computation/q_computer_conditions/#preparation-of-fiducial-initial-states","title":"Preparation of fiducial initial states","text":"<p>Quantum computation requires a reliable method to prepare a known input state. This is non-trivial for quantum systems.</p> <ol> <li> <p>Classical vs Quantum Input </p> <ul> <li>In classical computers, inputs are trivial (bit switches).  </li> <li>In quantum systems, preparing a known state (e.g. all spins in |0\\rangle) is hard due to system-dependent constraints.</li> </ul> </li> <li> <p>Sufficient Input </p> <ul> <li>Only one known pure state is needed (e.g. |00\\ldots0\\rangle), since unitary evolution can generate any other state.  </li> <li>Challenge: maintaining the state due to heating or noise.</li> </ul> </li> <li> <p>Physical Realization </p> <ul> <li>Ions: prepared via laser cooling into their ground state.  </li> <li> <p>Ensembles (e.g. NMR):  </p> <ul> <li>Each molecule is a qubit.  </li> <li>Many molecules needed for a measurable signal.  </li> <li>Hard to align all in the same quantum state.</li> </ul> </li> <li> <p>In thermal equilibrium:      $$     \\rho \\approx \\frac{e^{-\\mathcal{H}/k_B T}}{\\mathcal{Z}}     $$</p> <p>where \\mathcal{Z} normalizes \\text{tr}(\\rho) = 1.</p> </li> </ul> </li> <li> <p>Figures of Merit </p> <ul> <li>Fidelity: accuracy of preparing a target state \\rho_{\\text{in}}.  </li> <li>Entropy of \\rho_{\\text{in}}:  <ul> <li>Example: \\rho_{\\text{in}} = I/2^n is easy to make, but useless (max entropy, fully mixed).  </li> <li>Ideal state = pure, zero entropy.</li> </ul> </li> </ul> </li> </ol> <p>Good computation begins with a pure input. Noise in the input reduces information accessibility.</p>"},{"location":"quantum_computation/q_computer_conditions/#measurement-of-output-result","title":"Measurement of output result","text":"<p>Quantum computation requires a way to extract classical results from quantum states.</p> <ol> <li> <p>Basic Measurement Model </p> <ul> <li>Couple qubit to classical system \u2192 observe final state.  </li> <li>Example:<ul> <li>State a|0\\rangle + b|1\\rangle measured via fluorescence:<ul> <li>Detect light \u2192 collapse to |1\\rangle with prob. |b|^2</li> <li>No light \u2192 collapse to |0\\rangle</li> </ul> </li> </ul> </li> </ul> </li> <li> <p>Wavefunction Collapse </p> <ul> <li>Projective measurement maps quantum superposition to classical value.  </li> <li>In algorithms like Shor's, output is superposition over c values; collapse gives random c to infer period r.</li> </ul> </li> <li> <p>Measurement Challenges </p> <ul> <li>Noise: Photon loss, amplifier thermal noise, inefficient detection.  </li> <li>Strong measurements: Require large, switchable coupling \u2192 technically hard and may introduce decoherence.  </li> <li>Timing: Measurement must not occur prematurely.</li> </ul> </li> <li> <p>Weak &amp; Ensemble Measurements </p> <ul> <li>Weak measurements: always-on, continuous coupling can work.  </li> <li>Ensemble readouts: large groups of qubits give a macroscopic signal, e.g. NMR systems.  </li> <li>But: ensemble returns \\langle c \\rangle, not discrete c \u2192 averaging can break algorithms needing exact integers.  </li> <li>Solution: modify algorithm for ensemble-compatible readout.</li> </ul> </li> <li> <p>Figure of Merit </p> <ul> <li>Signal-to-Noise Ratio (SNR): Measures how distinguishable the output is despite inefficiencies or weak signals.</li> </ul> </li> </ol> <p>Measurement must be precise, controllable, and not disrupt the quantum state until the computation is complete.</p>"},{"location":"quantum_computation/q_computer_conditions/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"quantum_computation/q_computer_hoscillator/","title":"Harmonic oscillator quantum computer","text":""},{"location":"quantum_computation/q_computer_neutral_atom/","title":"Neutral atom quantum computer","text":"<p>Quick overview</p> <ul> <li>Qubit: Hyperfine states (structure)</li> <li>Qubit initialization: optical pumping</li> <li>Entanglement: Rydberg blockade</li> <li>Gate: Laser</li> <li>Industry: QuEra Computing Inc.</li> <li>Glossary (Q &amp; A): see here!</li> <li>Basic idea: Using polarized laser  light to create a controlled electromagnetic field that interacts with a neutral atom.</li> </ul>"},{"location":"quantum_computation/q_computer_neutral_atom/#introduction","title":"Introduction","text":"<p>A Neutral atom quantum computer is a new type of quantum computer which is made by Rydberg atoms . It utailzes technologies such as laser cooling, magneto-optical trapping (MOT) and optical tweezers. To perfrom computation, the atoms are first trapped in a magneto-optical trapping (MOT). Qubits are then encoded in the energy level of the atoms. By manipulate laser on qubits, we can accomplish actions such as initialization and operations. The laser can accomplish arbitrary single qubi gates and a <code>CZ</code> gate for universal quantum gates. Measurement is enforced at the end of the computation with a camera that generates an image of the outcome by measueing the fluorescence of the atoms.</p>"},{"location":"quantum_computation/q_computer_neutral_atom/#architecture","title":"Architecture","text":"<p>One of the architecture [1], an array of atoms is loaded into a laser cooled at micro-kelvin temperatures. In each of these atoms, two levels of hyperfine ground subspace are isolated. The qubits are prepared in some initial state using optical pumping. Logic gates are performed using optical or microwave frequency fields and the measurements are done using resonance fluorescence. </p> <p>Common atoms types: rubidium(Ru)[4], caesium(Cs), ytterbium(Yb), and strontium(Sr) atoms.</p>"},{"location":"quantum_computation/q_computer_neutral_atom/#single-qubit-gates","title":"Single qubit gates","text":"<p>Global single qubit gates on all the atoms can be done either by applying a microwave field for qubits encoded in the hyperfine such as Rb and Cs or by applying an RF magnetic field for qubits encoded in the nuclear spin such as Yb and Sr. Focused laser beams can be used to do single-site one qubit rotation using a lambda-type three level Raman scheme (see figure). In this scheme, the rotation between the qubit states is mediated by an intermediate excited state. Single qubit gate fidelities have been shown to be as high as .999 in state-of-the-art experiments.</p>"},{"location":"quantum_computation/q_computer_neutral_atom/#entangling-gate","title":"Entangling gate","text":"<p>The first fast gate based on Rydberg states was proposed for charged atoms making use of the principle of Rydberg Blockade. The principle was later transferred and developed further for neutral atoms [2].</p>"},{"location":"quantum_computation/q_computer_neutral_atom/#rydberg-mediated-gate","title":"Rydberg mediated gate","text":"<p>Atoms that have been excited to very large principal quantum number n are known as Rydberg atoms. These highly excited atoms have several desirable properties including high decay lift-time and amplified couplings with electromagnetic fields.</p> <p>The basic principle for Rydberg mediated gates is called the Rydberg blockade[[3]]</p> <p>Consider two neutral atoms in their respective ground states. When they close to each other, their interaction potential is dominated by van Der Waals force V_{qq} \\approx \\frac{\\mu_{B}^{2}}{R^{6}} where \\mu_{B} is the Bohr Magneton and R is the distance between the atoms. This interaction is very weak, around 10^{-5} Hz for R=10\\mu m. When one of the atoms is put into a Rydberg state (again, a state that has very principle quantum number n), the interaction between the two atoms is dominated by second order dipole-dipole interaction (LibreTests Chemistry) which is also weak. When both of the atoms are excited to a Rydberg state, then the resonant dipole-dipole interaction becomes V_{rr} = \\frac{(n^{2}ea_{0})^{2}}{R^{3}} where a_{0} is the Bohr radius. This interaction is around 100MHz at R = 10 \\mu m, around twelve orders of mafnitude larger. This interaction potential induces a blockade, where-in, if one atom is excited to a Rydberg state, the other nearby atoms cannot be excited to a Rydberg state because the two-atom Rydberg state is far detuned. This phenomenon is called the Rydberg blockade. Rydberg mediated gates make use of this blockade as a control mechanism to implement two qubit controlled gates.</p>"},{"location":"quantum_computation/q_computer_neutral_atom/#rydberg-blockade","title":"Rydberg blockade","text":"<p>Suppose we are considering two isolated neutral atoms in a magneto-optical trap. Ignoring the coupling of hyperfine levels that make the qubit and motional degrees of freedom, the Hamiltonian of this system can be written as:</p>  H = H_{1} + H_{2} + V_{rr}|r\\rangle_{1}\\langle r|\\otimes |r\\rangle_{2}\\langle r|  <p>, where H_{i} = \\frac{1}{2}(\\Omega |1\\rangle_{1}\\langle r| + \\Omega^{*} |r\\angle_{r}\\langle 1|) - \\Delta|r\\rangle_{i}\\langle r| is the Hamiltonian of i-th atom, \\Omega is the Rabi frequency of coupling between the Rydberg states and the |1\\rangle state and \\Delta is the detuning. Where |V_{rr} &gt;&gt; |\\Omega|, \\ |\\Delta|, we are in the so-called Rydberg Blockade regime. The physics of this Hamiltonian can be divided into several subspaces depending on the initial state. The |00\\rangle state is decoupled and does not evolve. Suppose only one of the atom is in |1\\rangle state, i.e.,(|01\\rangle or |10\\rangle), then the Hamiltonian is given by H_i. This Hamiltonian is the standard two-level Rabi hamiltonian. it characterizes the \"light shift\" in a two level system and has eigenvalues E_{LS}^{(1)} = \\frac{1}{2}(\\Delta \\pm \\sqrt{\\Omega^{2} + \\Delta^{2}}). </p> <p>If both atoms are in the exctied state |11\\rangle, the effective system evolves in the subspace of \\{|1r\\rangle, |r1\\rangle,|11\\rangle|\\}. We define the bright and dark basic states as |b\\rangle = \\frac{1}{\\sqrt{2}}(|r1\\rangle + |1r\\rangle) and |d\\rangle = \\frac{1}{\\sqrt{2}}(|r1\\rangle - |1r\\rangle), respectively, along with state |11\\rangle, we have the Hamiltonian </p>  H = -\\Delta(|b\\rangle\\langle b|+|d\\rangle\\langle d|) + \\frac{\\sqrt{2}}{2}(\\Omega|b\\rangle\\langle11| + \\Omega^{*}|11\\rangle\\langle b|).  <p>note that the dark state is decoupled from the bright state and the |11\\rangle. Thus we can ignore it and the effective evolution reduces to a two-level system consisting of the bright state and |11\\rangle. In this basis, the dressed eigenvalues and eigenvectors of the Hamiltonian are given by:</p>  \\begin{array}{c} E_{LS}^{(2)} = \\frac{1}{2}(\\Delta \\pm \\sqrt{2\\Omega^{2}+\\Delta^{2}})\\\\ |\\widetilde{11}\\rangle = \\text{cos}(\\theta/2)|11\\rangle  + \\text{sin}(\\theta/2)|b\\rangle\\\\ |\\widetilde{b}\\rangle = \\text{cos}(\\theta/2)|b\\rangle  + \\text{sin}(\\theta/2)|11\\rangle \\end{array}  <p>where \\theta depends on the Rabi frequency and detuning. </p>"},{"location":"quantum_computation/q_computer_neutral_atom/#controll-phase-gate","title":"Controll-phase gate","text":""},{"location":"quantum_computation/q_computer_neutral_atom/#q-and-a","title":"Q and A","text":"<p>What is Rydberg atoms?</p> <ol> <li> <p>What is a Rydberg Atom?</p> <ul> <li>A Rydberg atom is an excited atom with one or more electrons that have a very high principal quantum number, n.</li> <li>High principle quantum number makes an atom becomes huge (can go to micrometer scale).</li> <li>The higher the value of n, the farther the electron is from the nucleus, on average. </li> <li>Exaggerated response to eletric and magnetic fields.</li> <li>Long decay periods and electron wavefunctions that approximate, under some conditions, classical orbits of electrons about the nuclei.</li> <li>The core electrons shield the outer electron from the electric field of the nucleus such that, from a distance, the electric potential looks identical to that experienced by the electron in a hydrogen atom. </li> <li>It behaves hydrogen-like due to shielding by inner electrons.</li> </ul> <p>Imagine the nucleus is a bright lamp, and the core electrons are layers of curtains. If you stand far enough away, the curtains diffuse the light so it seems like you're looking at a single dim bulb, not the intense original light.</p> </li> <li> <p>What makes Rydberg Atoms special for Quantunm computing? </p> <ul> <li>Strong dipole\u2013dipole / van der Waals interaction: enables fast two-qubit entangling gates.</li> <li>Rydberg Blockade: guarantees clean, high-fidelity logic gates by preventing simultaneous excitation nearby.</li> <li>Laser control: lasers can excite/de-excite states on-demand.</li> </ul> </li> <li> <p>How do we create a Rydberg atom?</p> <ol> <li>Start with a neutral atom</li> <li>Using Magneto-optical traps or optical tweezers to isolate and trap single atoms at microkelvin temperatures.</li> <li>Use lasers to excite the electron.</li> </ol> <p>You're just using light (photons) to move one electron into a Rydberg state.</p> </li> </ol> <p>More, see: Raydberg atoms (wiki) and paper [4]</p> <p>What is Laser cooling?</p> <p>Laser cooling is a technique used to slow down and cool atoms using laser light \u2014 often reaching microkelvin or even nanokelvin temperatures. Despite using lasers (which sound \"hot\"), the process reduces the atom\u2019s kinetic energy.</p> <ul> <li>The laser light hit atoms opposite to their direction to make them slow down.</li> <li>Repeated absorption and emission also slow them down.</li> </ul> <p>How does it work? </p> <ul> <li>Doppler Effect: The atom sees a laser as \"blue-shifted\" when moving toward it. So, it preferentially absorbs photons from lasers aimed against its motion.</li> <li>Every absorbed photon pushes the atom a tiny bit backwards. Repeating this slows it.</li> <li>Spontaneous Emission: The atom re-emits the photon in a random direction, averaging out to zero net push over time.</li> </ul> <p>What is magneto-optical trapping?</p> <p>In atomic, molecular, and optical physics, a magneto-optical trap (MOT) is an apparatus which uses laser cooling and a spatially varying magnetic field to create a trap which can produce samples of cold neutral atoms. Temperatures achieved in a MOT can be as low as several microkelvins, depending on the atomic species, which is two or three times below the photon-recoil limit.</p> <p> <p>         Experimental setup of the MOT [8].Jan Krieger </p> </p> <p>More, see: MOT(wiki)</p> <p>What is optical tweezers?</p> <p>Optical tweezers use a tightly focused laser beam to trap and manipulate small particles (like atoms or cells). The laser\u2019s electric field gradient exerts a force on the particle, pulling it toward the region of highest intensity \u2014 typically the laser focus point. If the particle has a higher refractive index than its surrounding, it\u2019s pulled toward the laser focus. If lower, it\u2019s pushed away.</p> <p> <p>         A photograph of a nanoparticle  103 nm  trapped by an optical tweezer [5].Bjschellenberg </p> </p> <p> <p>         Dielectric objects are attracted to the center of the beam, slightly above the beam waist, as described in the text. The force applied on the object depends linearly on its displacement from the trap center just as with a simple spring system. [6].Cr4sZz </p> </p> <p>It's just like a ball attached to invisible springy strings pulling it toward the laser focus point. The laser creates a potential well, and the particle oscillates like it's in a tiny spring-loaded bowl.    </p> <p>More, see: optical tweezers (wiki) </p> <p>What is Hyperfine Structure?</p> <p>Hyperfine structure is the tiny splitting of atomic energy levels caused by interactions between the nucleus and electrons.</p> <ul> <li> <p>Energy levles: Energy level is defined by the electron configuration and principal quantum number n.</p> <p>Main Level (e.g. 5s, 5p) \\rightarrow Fine Structure (spin-orbit) \\rightarrow Hyperfine Structure (nuclear spin)</p> </li> <li> <p>Fine structure: Each electronic level splits due to spin\u2013orbit coupling:</p> </li> <li> <p>Hyperfine structure: Each fine-structure level further splits due to interaction with the nuclear spin</p> </li> </ul> <p> <p>         Schematic illustration of fine and hyperfine structure in a neutral hydrogen atom. [9].DJIndica </p> </p> <p>More, see: Hyperfine structure (wiki)</p> <p>What is optical pumping?</p> <p>Optical pumping uses laser light to \u201cpump\u201d atoms from one state to another, often to prepare them in a specific quantum state like |0\\rangle</p> <p>How it works:</p> <ol> <li>Atoms start in a mix of quantum states</li> <li>A laser beam, tuned to a specific transition and with a specific polarization, excites only certain states.</li> <li>Atoms absorb light and jump to an excited state, then spontaneously emit and fall back down \u2014 but not always to the same state.</li> <li>After many cycles, most atoms end up in a \"dark state\" that doesn\u2019t absorb the laser anymore.</li> </ol> <p>Optical pumping is used to initialize atoms into a specific hyperfine ground state (e.g., |F=1,m_{F}\\rangle = |0\\rangle or |F=2,m_{F}\\rangle = |1\\rangle) by selectively driving transitions using polarized laser light, allowing population transfer to a dark state (the state which doesnt absorb the laser anymore.). </p> <p>More, see: Optical pumping (wiki)</p> <p>What is resonance fluorescence?</p> <p>Resonance fluorescence is the light emitted by an atom (or molecule) when it is excited by light at a frequency resonant with one of its internal transitions, and then re-emits a photon as it decays back to the same ground state.</p> <ol> <li>A laser tuned to match an atomic transition excites the atom.</li> <li>The atom absorbs the photon and transitions to an excited state.</li> <li>It spontaneously emits a photon and drops back to the same ground state.</li> <li>This cycle repeats, resulting in steady emission of light at or near the laser frequency.</li> </ol> <p>For example, if we have a state |\\psi\\rangle = \\alpha |0\\rangle + \\beta|1\\rangle. You shine resooant laser light that interacts only with one of the state, |1\\rangle for example. We then have two possibilities:</p> <ul> <li>If the atom is in state |1\\rangle, it scatter photons and you see resonance fluorescence then we know its at state |1\\rangle.</li> <li>On the other hand, if you see no scattering, we can interpret it as measured |0\\rangle.</li> </ul> <p>More, see: Resonance fluorescence (wiki)</p> <p>What is decouple?</p> <p>Decoupling means reducing or eliminating the interaction between the qubit and its environment or between different quantum systems</p> <p>What is Rabi Frequency</p> <p>The Rabi frequency \\Omega is the rate at which a two-level quantum system coherently oscillates between its two states when driven by a resonant external field (laser in our case). </p>  \\Omega = \\frac{\\mu E}{ \\hbar}  <p>where \\mu is the transition's dipole moment, E is the field's eletrci-field amplitude, and \\hbar is Plank's constant over 2\\pi.</p> <ul> <li>A \\pi-pulse of duration t = \\pi/\\Omega implements an X-gate (|0\\rangle \\mapsto |1\\rangle).</li> <li>A \\pi/2-pulse of duration t = \\pi/(2 \\Omega) implements an X-gate (|0\\rangle \\mapsto (|0\\rangle+|1\\rangle)/\\sqrt{2}).</li> </ul> <p>Trade off:</p> <ul> <li>Higher \u03a9: A shorter \\pi-pulse yields a faster X-gate, reducing exposure to decoherence. However, boosting \u03a9 requires higher laser power, which can induce unwanted transitions (crosstalk) or shift energy levels (AC Stark shifts), harming gate fidelity.</li> <li>Lower \u03a9: Longer gate times allow environmental noise to degrade your qubit.</li> </ul> <p>The Rabi frequency is literally your gate speed\u2014it tells you how fast you can rotate a qubit from |0\\rangle to |1\\rangle (or anywhere in between). </p> <p>More, see Raby frequency (wiki)</p> <p>What is Detuning?</p> <p>Detuning refers to how far the laser frequency is odd from resonance with an atomic transition.</p>  \\Delta = \\omega_{\\text{laser}} - \\omega_{\\text{atom}}  <p>where \\Delta = 0 means you are on resonance, and \\Delta \\neq 0 means you're detuned.</p> <p>What is spinning in the Neutral atom computer setup?</p> <p>The quantum spinor state of the atom \u2014 the probability amplitude of being in spin-up vs spin-down (|0\\rangle vs |1\\rangle) \u2014 that's \"rotating\" in an abstract Hilbert space.</p> <p>When we apply a pulse (using light or microwaves), we rotate the qubit\u2019s quantum state vector \u2014 meaning we change the probability amplitude and phase between |0\\rangle and |1\\rangle. This rotation happens on an abstract Bloch sphere and corresponds to a unitary gate.</p> <p>We are not spinning the atom, but rotating its internal quantum state in Hilbert space, driven by electromagnetic interaction with the laser.</p> <p>Why is a neutral atom conisdered a quantum system?</p> <p>Even a nertral atom is made of many particles (protons, neutrons, electrons), it stil behaves quatnum mechanically when we isolate and manipulate its internal degree of freedom:</p> <ol> <li>Energy level (hyperfine structure)</li> <li>Spin states (total angular momentum)</li> <li>Coherence between those states</li> </ol> <p>These states are quantized, live in a well-defined Hilbert space, and can be manipulated and measured in ways that follow quantum mechanics.</p> <p>In sum, we use neutral atom as a qubit since it follows the following rules of quantum mechanics:</p> <ol> <li>They form a two-dimensional Hilbert space.</li> <li>They support superposition and interference.</li> <li>They respond to unitary gate operations.</li> <li>They exhibit collapse upon measurement.</li> </ol>"},{"location":"quantum_computation/q_computer_neutral_atom/#references","title":"References","text":"<p>[1].    Quantum computing with atomic qubits and Rydberg interactions: Progress and challenges, M. Saffman, arxiv: https://arxiv.org/abs/1605.05207https://arxiv.org/abs/1605.05207</p> <p>[2].    Jaksch, D.; Cirac, J. I.; Zoller, P.; Rolston, S. L.; C\u00f4t\u00e9, R.; Lukin, M. D. (4 September 2000). \"Fast Quantum Gates for Neutral Atoms\". https://arxiv.org/abs/quant-ph/0004038</p> <p>[3].    Walker, Thad G.; Saffman, Mark (1 July 2012). \"Chapter 2 - Entanglement of Two Atoms Using Rydberg Blockade\". Advances in Atomic, Molecular, and Optical Physics. 61. Academic Press: 81\u2013115. arXiv:1202.5328</p> <p>[4].    Evered, Simon J.; Bluvstein, Dolev; Kalinowski, Marcin; Ebadi, Sepehr; Manovitz, Tom; Zhou, Hengyun; Li, Sophie H.; Geim, Alexandra A.; Wang, Tout T.; Maskara, Nishad; Levine, Harry; Semeghini, Giulia; Greiner, Markus; Vuleti\u0107, Vladan; Lukin, Mikhail D. (October 2023). Nature. 622 (7982): 268\u2013272. https://arxiv.org/abs/2304.05420</p> <p>[5].    By Bjschellenberg - https://stevenhoekstra.owlstown.net/projects/426-levitated-nanospheres (see doi:10.1063/5.0166136 that is CC-BY and has this image as issue-cover, with first-author matching uploader's username), CC BY-SA 4.0, Link</p> <p>[6].    By Cr4sZz - Own work, CC BY-SA 4.0, Link</p> <p>[7].    Public Domain, Link</p> <p>[8].   By Jan Krieger, translated into English by User:Dumbledore - This file was derived from: Mot aufbau.png, Public Domain, Link</p> <p>[9.]    By Original: DJIndica\u2002Vector: Edudobay - Own work based on: Fine hyperfine levels.png\u00a0by DJIndica, Public Domain, Link</p> <p>[x].    Neutral atom quantum computer (wiki):https://en.wikipedia.org/wiki/Neutral_atom_quantum_computer</p> <p>[x].    Rydberg atom (wiki): https://en.wikipedia.org/wiki/Rydberg_atom</p>"},{"location":"quantum_computation/qsa_NP_complete_problems/","title":"Quadratic Speedup for NP-Complete Problems","text":"<p>In this chapter, we show how quantum search can assist in solving the Hamiltonian cycle problem.</p> <p>The Hamiltonian cycle problem asks whether a given graph contains a cycle that visits each vertex exactly once. This problem belongs to the class of NP-complete problems. Solving it involves searching through all possible orderings of the graph\u2019s vertices:</p> <ol> <li>Generate each possible ordering (v_{1}, ..., v_{n}) of the vertices. Repetitions are allowed to simplify the analysis without changing the essential result.</li> <li>For each ordering, check whether it forms a Hamiltonian cycle. If not, continue checking the remaining orderings.</li> </ol> <p>Since there are n^n = 2^{n\\log n} possible orderings, the classical algorithm requires 2^{n\\log n} checks in the worst case.</p>"},{"location":"quantum_computation/qsa_NP_complete_problems/#how-quantum-search-speeds-up-np-problems","title":"How Quantum Search Speeds Up NP Problems","text":"<p>A quantum algorithm can accelerate this process by speeding up the search. We use the method in quantum counting to determine whether a solution to the search problem exists.</p> <p>Let:</p> <ul> <li>n: the number of vertices in the graph  </li> <li>m = \\lceil \\log n \\rceil: the number of qubits needed to represent a single vertex index</li> </ul> <p>To find a Hamiltonian cycle, we consider all sequences of n vertex labels, requiring nm qubits. The computational basis state can be written as:</p>  |v_1, v_2, ..., v_n\\rangle  <p>where each |v_i\\rangle is a string of m qubits.</p> <p>The oracle for the search algorithm applies the transformation:</p>  O|v_1, ..., v_n\\rangle = \\begin{cases} \\ \\ |v_1, ..., v_n\\rangle &amp; \\text{if } (v_1, ..., v_n) \\text{ is not a Hamiltonian cycle} \\\\ - |v_1, ..., v_n\\rangle &amp; \\text{if } (v_1, ..., v_n) \\text{ is a Hamiltonian cycle} \\end{cases}  <p>Given a description of the graph, we can construct a polynomial-size classical circuit that checks for Hamiltonian cycles. This circuit can be converted into a reversible one (still polynomial in size) that performs:</p>  (v_1, ..., v_n, q) \\mapsto (v_1, ..., v_n, q \\oplus f(v_1, ..., v_n)),  <p>where f(v_1, ..., v_n) = 1 if the sequence is a Hamiltonian cycle, and 0 otherwise.</p> <p>We initialize q to |1\\rangle and apply a Hadamard gate to create the superposition state:</p>  \\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}}  <p>This phase kickback enables the oracle to mark solutions.</p> <p>Using quantum counting, we can determine whether a Hamiltonian cycle exists using only O(2^{mn/2}) applications of the oracle \u2014 giving a quadratic speedup over brute-force search.</p> <p>To summerize:</p>  \\begin{array}{|l|l|l|} \\hline \\textbf{Feature} &amp; \\textbf{Classical Algorithm} &amp; \\textbf{Quantum Algorithm} \\\\ \\hline \\text{Time Complexity} &amp; O(p(n) \\cdot 2^{n \\lceil \\log n \\rceil}) &amp; O(p(n) \\cdot 2^{n \\lceil \\log n \\rceil / 2}) \\\\ \\hline \\text{Oracle Cost} &amp; \\text{Polynomial } p(n) &amp; \\text{Polynomial } p(n) \\\\ \\hline \\text{Success Probability} &amp; 1 \\text{ (deterministic)} &amp; \\text{At least } 5/6,\\ \\text{boosted by repeats} \\\\ \\hline \\text{Exponential Term} &amp; 2^{n \\lceil \\log n \\rceil} &amp; 2^{n \\lceil \\log n \\rceil / 2} \\\\ \\hline \\text{Error Handling} &amp; \\text{Not needed} &amp; \\text{Repeat } r\\ \\text{times} \\Rightarrow \\text{error } 1/6^r \\\\ \\hline \\end{array}"},{"location":"quantum_computation/qsa_NP_complete_problems/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"quantum_computation/qsa_black_box_limits/","title":"Black box algorithm limits","text":"<p>In this section, we will discuss for a given F, a Boolean function, how fast (measured in number of queries) can a classical and quantum computer compte these functions given an oracle for f? </p> <p>You may think its difficult to answer this question without knowing something about the function f, but in face a great deal can be determined even in thie \"black box\" model, where the mean by which the oracle accomplished its task is taken for granted, and complexity is measured only in terms of the number of required oracle queries.</p>"},{"location":"quantum_computation/qsa_black_box_limits/#method-of-polynomials","title":"Method of polynomials","text":"<p>Let's start with some useful definitions:</p> <ul> <li> <p>D(F): Deterministic query complexity: Minimum number of oracle calls a classical algorithm needs to compute F with certainty.</p> </li> <li> <p>Q_E(F): Exact quantum query complexity: Minimum number of oracle calls a quantum algorithm needs to compute F with 100% accuracy.</p> </li> <li> <p>Q_2(F): Bounded-error quantum query complexity: Minimum number of queries for a quantum algorithm to get the correct result with probability \\geq \\frac{2}{3}, where \\frac{2}{3} is an arbitrary number, the probability need only be bounded finitely away from \\frac{1}{2} to be boosted close to 1 by repetitions.</p> </li> <li> <p>Q_0(F): Zero-error quantum query complexity: The output is either correct or \"I don't know\" (inconclusive), but never wrong.</p> </li> </ul> <p>These complexities satisfy the relation:</p>  Q_2(F) \\leq Q_0(F) \\leq Q_E(F) \\leq D(F) \\leq N  <p>We can represent any Boolean function F(X) using a real-valued multilinear polynomial p(X), where each input variable X_k \\in \\{0,1\\}.</p> <p>The polynomial is defined as:</p>  p(X) = \\sum_{Y \\in \\{0,1\\}^N} F(Y) \\prod_{k=0}^{N-1} \\left[1 - (Y_k - X_k)^2 \\right]  <ul> <li>Each X_k is binary, so X_k^2 = X_k. This ensures the polynomial is multilinear.</li> <li>For a given Y, the product \\prod_{k}(1 - (Y_k - X_k)^2) evaluates to 1 only if X = Y, and 0 otherwise.</li> <li>This construction guarantees that p(X) = F(X) for all X \\in \\{0,1\\}^N.</li> </ul> <p>The minimum degree of such a representation for F, denoted as \\text{deg}(F), measures a complexity of F. Giving the fact that the degree of most function is of order N. </p>  D(F) \\leq 2\\text{ deg}(F)^{4}.  <p>This results places an upper bound on the performance of deterministic classical computation in calculating most Boolean functions.</p> <p>If a polynomial satisfies |p(X) = F(X)| \\leq 1/3 for all X \\in \\{0,1\\}^{N}, we say p approximate F, and \\text{deg}(F) denotes the minimum degree of such an approximating polynomial. It is known that </p> <ol> <li>\\text{deg(OR)} \\in \\Theta(\\sqrt{N})</li> <li>\\text{deg(AND)} \\in \\Theta(\\sqrt{N})</li> <li>D(F) \\leq 216 \\text{ deg}(F)^{6}</li> </ol>"},{"location":"quantum_computation/qsa_black_box_limits/#polynomials-and-quantum-algorithm","title":"Polynomials and quantum algorithm","text":"<p>We can use polynomials to describe the results of quantum algorithms. Let's write the output of a quantum algorithm \\mathcal{Q} which performs T queries to an oracle O as </p>  \\sum_{k=0}^{2^{n}-1} c_{k}|k\\rangle.  <p>The ampllitudes c_{k} are polynomials of degree at most T in the variables X_{0},X_{1},...,X_{N-1}. Any \\mathcal{Q} can be realized using the quantum circuit shown below.</p> <p>         General quatnum circuit for a quantum algorithm which performs \\( T \\) queries to an oracle \\( O \\). \\( U_{0}, U_{1}, ..., U_{T} \\) are arbitrary unitary transforms on \\( m \\) qubits, and the oracle acts on \\( n+1 \\) qubits.     </p> <p>The state |\\psi_{0}\\rangle right before the first oracle query can be written as </p>  |\\psi_{0}\\rangle = \\sum_{ij}\\bigg( a_{i0j}|i\\rangle|0\\rangle + a_{i1j}|i\\rangle|1\\rangle \\bigg)|j\\rangle,  <p>where the first label corresponds to the n qubit oracle query, the next to a single qubit in which the oracle leaves its result, and the last to the m-n-1 working qubits used by \\mathcal{Q}. After the first oracle query, we obtain </p>  |\\psi_{0}\\rangle = \\sum_{ij}\\bigg( a_{i0j}|i\\rangle|X_{i}\\rangle + a_{i1j}|i\\rangle|X_{i}\\oplus 1\\rangle \\bigg)|j\\rangle,  <p>but since X_{i} is either 0 or 1, we can write above equation as </p>  |\\psi_{0}\\rangle = \\sum_{ij}[\\bigg((1-X_{i})a_{i0j}X_{ia_{1}j}\\bigg)|i0\\rangle + \\bigg((1-X_{i})a_{i1j}X_{ia_{0}j}\\bigg) |i1\\rangle]|j\\rangle.  <ul> <li>The initial state \\lvert \\psi_0 \\rangle has amplitude polynomials of degree 0 in X.</li> <li>The state \\lvert \\psi_1 \\rangle (after one oracle call) has degree 1 in X.</li> <li>Unitary operations before/after the oracle do not change the polynomial degree.</li> <li>Each oracle call increases the degree by at most 1.</li> <li>After T queries, the amplitudes are polynomials of degree at most T.</li> <li> <p>Measuring the output gives a result k with probability:</p>  P_k(X) = \\lvert c_k \\rvert^2  <p>which is a real-valued polynomial in X of degree at most 2T.</p> </li> </ul> <p>The total probability P(X) of obtaining a one as the output  from the algorithm is a sum over some subset of the polynomials P_{k}(X), and thus also has degree at most 2T. </p>"},{"location":"quantum_computation/qsa_black_box_limits/#summary-polynomial-method-lower-bounds","title":"Summary: Polynomial Method Lower Bounds","text":"<ul> <li>The output probability P(X) is a real polynomial of degree at most 2T.</li> <li> <p>If a quantum algorithm gives the correct result with certainty, means P(X) = F(X), and thus \\text{ deg}(F) \\leq 2T:</p>  Q_E(F) \\ge \\frac{\\deg(F)}{2}  </li> <li> <p>If it gives the correct result with bounded error (e.g. \u2265 2/3):</p>  Q_2(F) \\ge \\frac{\\deg(F)}{2}  </li> <li> <p>Using known bounds on deterministic query complexity:</p>  Q_E(F) \\ge \\left[ \\frac{D(F)}{32} \\right]^{1/4}, \\quad Q_2(F) \\ge \\left[ \\frac{D(F)}{13824} \\right]^{1/6}  </li> </ul> <p>In sum, for Boolean functions in the black-box model, quantum algorithms offer at best polynomial speedup over classical ones \u2014 and no exponential speedup is possible in general, since \\deg(F) = \\Omega(N) for most F.</p>"},{"location":"quantum_computation/qsa_black_box_limits/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"quantum_computation/qsa_q_search_algorithm/","title":"The Quantum Search Algorithm","text":""},{"location":"quantum_computation/qsa_q_search_algorithm/#the-orcale","title":"The Orcale","text":"<p>Suppose we wish to search through a search space of N elements. Rather than search the elementes directly, we focus on the index to those elements, which is just a number in the range 0 to N-1. For convenience we assume N = 2^n, so the index can be stored in n bits, and that the search problem has exactly M solutions, with 1 \\leq M \\leq N. This can be represented by a function f, which takes as inpur an integer x, in the range 0 to N-1. By definition, </p>  f(x) =  \\begin{cases} 1 &amp; \\text{if } x \\ \\text{is a solution to the search problem} \\\\ 0  &amp; \\text{if } x \\ \\text{is not a solution to the search problem} \\end{cases}  <p>Example</p> <p>For example, we have a search problem that has N = 2^{3} elements, and a problem has M = 2 solutions of our interests, which meets the requiremnet 1 \\leq M \\leq N. Then we encode our problem, by preparing |x\\rangle|0\\rangle, into a quantum circuit and run the oracle \\mathcal{O} and obtain solution f(x = 2) = f(x = 4) = 1.</p> <p>Suppose we are supplied with a quantum oracle - a black box - with the ability to recognize solutions to the search problem. This recognition is signalled by making use of an orcale qubit. </p> <p>The orcale is a unitary operator, O, defined by its action on the computational basis:</p>  |x\\rangle|q\\rangle \\xrightarrow{\\mathcal{O}} |x\\rangle|q \\oplus f(x)\\rangle,  <p>where |x\\rangle is the index register, \\oplus denotes addition modulo 2, and the orcale qubit |q\\rangle is a single qubit which is flipped if f(x)=1, and is unchanged otherwise.</p> <p>In the quantum search algorithm it is useful to apply the orcal with the oracle qubit initially in the state \\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}}, just as was donw in the Deutsch-Jozsa algorithm. If x is not a solution to the search problem, applying the oracle to the state |x\\rangle\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}} doesn't change the state. On the other hand, if x is a solution to the seach problem, then |0\\rangle and |1\\rangle are interchanged by the action of the oracle, giving the final state -|x\\rangle\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}}. The action of the oracle is thus:</p>  |x\\rangle\\bigg(\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}} \\bigg) \\xrightarrow{\\mathcal{O}} (-1)^{f(x)} |x\\rangle\\bigg(\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}} \\bigg),  <p>where you can easily see that if solution, term becomes -|x\\rangle\\bigg(\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}} \\bigg). Notice that the state of the oracle qubit is not changed and can therefore be omitted from further discussion of the algorithm. Thus, for simplicity, we write:</p>  |x\\rangle \\xrightarrow{\\mathcal{O}} (-1)^{f(x)}|x\\rangle.  <p>We say that the oracle marks the solutions to the search problem, by shifting the phase of the solution. For an N item search problem with M solutions, it turns out that we need only apply the search oracle O(\\sqrt{N/M}) times to obtain a solution on a quantum computer.</p>"},{"location":"quantum_computation/qsa_q_search_algorithm/#the-procedure","title":"The procedure","text":"<p>The internal working of the oracle, including the possibility of it needing extra work qubits, are not important to the description of the quantum search algorithm proper. The goal of the algorithm is to find a solution to the search problem, using the smallest possible number of applications of the orcale. </p> <p>The algorithm begines with the computer in the state |0\\rangle^{\\otimes n}. The <code>H</code> gate is used to put the computer in the equal superposition state,</p>  |\\psi\\rangle = \\frac{1}{N^{1/2}}\\sum_{x=0}^{N-1}|x\\rangle.  <p>or </p>  |0\\rangle^{\\otimes n} \\xrightarrow{H^{\\otimes n}} \\frac{1}{\\sqrt{2^{n}}}\\sum_{x=0}^{2^{n}-1}|x\\rangle.  <p>Quantum computing exploits quantum parallelism \u2014 the ability to evaluate a function on many inputs simultaneously using superposition. And that's why we put qubits in an equal superposition.</p> <p>The quantum search algorithm then consists of repeated application of a quantum subroutine, known as a Grover operator, which we denote G. The Grover iteration may broken up into four steps.</p> <ol> <li>Apply the oracle O.</li> <li>Apply the <code>H</code> transform H^{\\otimes n}.</li> <li> <p>perform a conditional phase shift on the computer, with every computational basis state except |0\\rangle receiving a phase shift of -1,</p>  |x\\rangle \\rightarrow -(-1)^{\\delta_{x}0}|s\\rangle.  </li> <li> <p>Apply the <code>H</code> transform H^{\\otimes n}. </p> </li> </ol>"},{"location":"quantum_computation/qsa_q_search_algorithm/#implmentation-on-quantum-computer","title":"Implmentation on Quantum computer","text":"<p>         Schematic circuit for the quantum search algorithm.     </p> <p>         Circuit for the Grover iteration, \\( G \\).     </p> <p>         Circuit for the Grover iteration, \\( G \\).     </p> <p>Each of the operations in the Groveer iteration can be efficiently implemneted on a quantum computer. The <code>H</code> in step 2 and 4 require n = log{N} operations each. The conditional phase in step 3 can be implemented using O(n) gates. The cost of the oracle call depends upon the specific application. The combined effect of step 2,3, and 4 is </p>  H^{\\otimes n} (2|0\\rangle\\langle 0| - I)H^{\\otimes n} = 2|\\psi\\rangle\\langle\\psi| - I,  <p>where |\\psi\\rangle is the equally weighted superspoition of state </p>  |\\psi\\rangle = \\frac{1}{N^{1/2}}\\sum_{x=0}^{N-1}|x\\rangle.  <p>Thus we denote the Grover iteration, G, can be written as </p>  G = (2|\\psi\\rangle\\langle\\psi|)O."},{"location":"quantum_computation/qsa_q_search_algorithm/#geometric-visualization","title":"Geometric visualization","text":"<p>The Grover iteration, G = (2|\\psi\\rangle\\langle\\psi|)O, can be seen as a rotation in the two=dimensional space spanned by the starting vector |\\psi\\rangle and the state consisting of a uniform superposition of solutions to the search problem. Let's define \\sum_{x}^{'} as a sum over all x which are solutions to the problem, and \\sum_{x}^{''} in dicates a sum over all x which are not solutions to the search problem. Define normalized states</p>  \\begin{array}{l} |\\alpha\\rangle \\equiv \\frac{1}{\\sqrt{N-M}}\\sum_{x}^{''}|x\\rangle \\\\ |\\beta\\rangle \\equiv \\frac{1}{\\sqrt{M}}\\sum_{x}^{'}|x\\rangle \\end{array}  <p>We must know that the initial state |\\psi\\rangle may be re-expressed as </p>  |\\psi\\rangle = \\sqrt{\\frac{N-M}{N}}|\\alpha\\rangle + \\sqrt{\\frac{M}{N}}|\\beta\\rangle,  <p>so the initial state of the quantum computer is in the space spanned by |\\alpha\\rangle and |\\beta\\rangle.</p> <p>The effect of G can be understood as following:</p> <ol> <li> <p>Operation O performs a reflection about the vector |\\alpha in the plane defined by |\\alpha\\rangle and |\\beta\\rangle. </p> </li> <li> <p>2|\\psi\\rangle\\langle \\psi| - I performs a reflection in the plane defined by |\\alpha and |\\beta\\rangle, about the vector |\\psi\\rangle. And the product of two reflections is a rotation!.</p> </li> <li> <p>The state G^{k}|\\psi\\rangle remains in the space spanned by |\\alpha\\rangle and |\\beta\\rangle for all k and it also tells us the rotation angle. Let's set </p>  \\begin{array}{l} \\text{cos}\\frac{\\theta}{2} = \\sqrt{\\frac{N-M}{N}}\\\\ \\text{sin}\\frac{\\theta}{2} = \\sqrt{\\frac{M}{N}} \\end{array}  <p>thus, |\\psi\\rangle = \\text{cos}{\\theta}{2}|\\alpha\\rangle + \\text{sin}{\\theta}{2}|\\beta\\rangle.</p> </li> </ol> <p>As image shows below, the two reflections which comprise G take |\\psi\\rangle to </p>  G|\\psi\\rangle = \\text{cos}\\frac{3\\theta}{2}|\\alpha\\rangle + \\text{sin}\\frac{3\\theta}{2}|\\beta\\rangle,  <p>so the rotation angle is in fact \\theta. It follow that continued application of G takes the state to </p>  G^{k}|\\psi\\rangle = \\text{cos} \\bigg(\\frac{2k+1}{2}\\theta \\bigg) |\\alpha\\rangle + \\text{sin}\\bigg(\\frac{2k+1}{2}\\theta \\bigg) |\\beta\\rangle.  <p>         The action of single Grover iteration, \\( G \\). The sate vector \\( |\\psi\\rangle \\) is rotated by \\( \\theta \\) towards the superposition \\( \\beta \\) of all solutions to the search problem. 1. The state vector \\( |\\psi\\rangle \\) is positioned at angle of \\( \\theta/2 \\) from \\( |\\alpha\\rangle \\). 2. The oracle \\( O \\) reflects the state vector about the state \\( |\\alpha\\rangle \\). 3., the opeartor \\( 2|\\psi\\rangle\\langle \\psi| -I \\) reflects it about \\( |\\psi\\rangle \\). After repeated Grover iteration, the state vector gets close to \\( |\\beta\\rangle \\), at which point an observation in the computational basis outputs a solution to the search problem with high probability.     </p> <p> </p> <p>Only O\\sqrt{N/M} applications of G are required to rotate the state vector close to |\\beta\\rangle.</p> <p>In sum, G is a rotation in the two-dimensional space spanned by |\\alpha\\rangle and |\\beta\\rangle, rotating the sapce by \\theta radians per application of G. </p> <p>Repeated application of the computational basis produces with high probability one of the outcomes superposed in |\\beta\\rangle, that is, a solution to the search problem!</p> <p>Example</p>"},{"location":"quantum_computation/qsa_q_search_algorithm/#performance","title":"Performance","text":"<p>The question is: how many times must the Grover iteration be repeated to rotate |\\psi\\rangle near |\\beta\\rangle? The initial state |\\psi\\rangle = \\sqrt{\\frac{N-M}{N}}|\\alpha\\rangle + \\sqrt{\\frac{M}{N}}|\\beta\\rangle, so rotating through across \\sqrt{M/N} radians takes the system to |\\beta\\rangle. Let \\text{CI}{x} denote the integer closest to the real number x, where by convention we round halves down, \\text{CI}(3.5) = 3, for example. Then repeating the Grover iteration</p>  R = \\text{CI}\\bigg(\\frac{\\text{cos}^{-1}\\sqrt{M/N}}{\\theta} \\bigg)  <p>times rotates |\\psi\\rangle to within an angle \\theta/2 \\leq \\pi/4 of |\\beta\\rangle. For </p> <p>This means you only have to let the state rotates to within 45 degrees of vector |\\beta\\rangle and we will have high probability to get the solution when measure.</p> <p>If M\\leq N/2, and we know that a lower bound on \\theta will give an upper bound on $R:</p>  \\frac{\\theta}{2} \\geq \\text{sin}\\frac{\\theta}{2} = \\sqrt{\\frac{M}{N}} \\Rightarrow \\theta \\geq 2 \\sqrt{\\frac{M}{N}}  <p>then:</p>  R \\leq \\lceil\\frac{\\pi}{2\\theta} \\rceil \\leq \\lceil \\frac{\\pi}{4}\\sqrt{\\frac{N}{M}} \\rceil  <p>This gives </p>  R = O(\\sqrt{N/M})  <p>We need only O(\\sqrt{N/M}) oracle calls</p>"},{"location":"quantum_computation/qsa_q_search_algorithm/#algorithm","title":"Algorithm","text":"<ol> <li> <p>Inputs: </p> <ul> <li>A black box oracle O which performs the transformation O|x\\rangle|q\\rangle = |x\\rangle|q\\oplus f(x)\\rangle, where f(x) = 0 for all 0\\leq x &lt; 2^{n} except x_0, for which f(x_0) = 1.</li> <li>n+1 qubits in the state |0\\rangle</li> </ul> </li> <li> <p>Outputs: x_0</p> </li> <li>Runtime: O(\\sqrt{2^{n}}) operations. Succeeds with probability O(1).</li> <li> <p>Procedure:</p>  \\begin{array}{lll} 1. &amp; |0\\rangle^{\\otimes n}|0\\rangle &amp; \\text{initial state}\\\\ 2. &amp; \\rightarrow \\frac{1}{\\sqrt{2^{n}}}\\sum_{x=0}^{2^{n-1}}|x\\rangle \\bigg(\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}} \\bigg) &amp; \\text{apply} \\ H^{\\otimes n} \\text{ to the first } n \\text{ qubits, and } HX \\text{ to the last qubit.}\\\\ 3. &amp; \\rightarrow [(2|\\psi\\rangle\\langle\\psi| - I)O]^{R}\\frac{1}{\\sqrt{2^{n}}}\\sum_{x = 0}^{2^{n-1}}|x\\rangle (\\frac{|0\\rangle-|1\\rangle}{\\sqrt{2}}) &amp; \\text{apply the Grover iteration} R \\approx \\lceil \\pi\\sqrt{2^{n}/4} \\rceil \\text{times.}\\\\  &amp; \\approx |x_{0}\\rangle [\\frac{|0\\rangle - |1\\rangle}{\\sqrt{2}}] &amp; \\\\ 4. &amp; \\rightarrow x_{0} &amp; \\text{measure the first} \\ n \\ \\text{qubtis} \\end{array}  </li> </ol> <p>If M \\geq N/2, pad the search space to size 2N with dummy non-solutions so Grover\u2019s algorithm remains efficient with \\mathcal{O}(\\sqrt{N/M}) oracle calls.</p>"},{"location":"quantum_computation/qsa_q_search_algorithm/#quantum-search-as-a-quantum-siumulation-optional","title":"Quantum search as a quantum siumulation (optional)","text":"<p>This section focus on giving the intuition of why grover search works</p>"},{"location":"quantum_computation/qsa_q_search_algorithm/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"quantum_computation/qsa_quantum_counting/","title":"Quantum Counting","text":"<p>So the question is how quickly can we determine the number of solutions, M, to an N item search problem, if M is not known in advance? Compare with classical computer, which requires \\Theta(N) consultations with an oracle to determin M, a quantum computer is able to estimate number of solutions much more quickly by combining Fourier transform.</p> <p>Here are some key applications:</p> <ol> <li> <p>If we can estimate the number of solutions quickly then it is also possible to find a solution quickly, even if the number of solutions is unknown. BY first counting the number of solutions, and then applying the quantum saerch algorithm to find a solution.</p> </li> <li> <p>To decide whether the solution even exist, depending on whether the numbert of solutions is zero, or non-zero. This is useful when we are facing NP-complete problems.</p> </li> </ol> <p>The quantum counting technique only tells how many values x satisfy f(x)=1, not what the solutions are.</p> <p>To actually find a solution, you run Grovers' search, which gives one solution with high probability.</p>"},{"location":"quantum_computation/qsa_quantum_counting/#phase-estimation","title":"Phase estimation","text":"<p>Quantum counting is an application of the phase estimation procedure to estimate the eigenvalues of the Grover iteration G. Suppose |a\\rangle and |b\\rangle are two eigenvectors of the Grover iteration in the space spanned by |a\\rangle and |\\beta\\rangle. Let \\theta be the angle of rotation determined by the Grover iteration. From equation,</p> G =  \\begin{bmatrix} \\text{cos}\\theta &amp; -\\text{sin}\\theta \\\\ \\text{sin}\\theta &amp; \\text{cos}\\theta \\end{bmatrix}  <p>where \\theta is a real number in the range 0 to \\pi/2 (assuming for simplicity that M\\leq N/2), where</p>  \\text{sin}\\theta = \\frac{2\\sqrt{M(N-M)}}{N},  <p>we see that the corresponding eigenvalues are e^{i\\theta} and e^{i(2\\pi - \\theta)}. We expoand our search space to 2N to ensure that \\text{sin}^{2}(\\theta/2) = M/2N.</p> <p>See below circuit, </p> <p>         Circuit for performing approximate quantum counting on a quantum computer     </p> <ol> <li>Goal: To estimate \\theta to m bits of accuracy, with probability of success at least 1-\\epsilon</li> <li>Component: <ol> <li>The first register: t \\equiv m + \\lceil \\text{log}(2+\\frac{1}{2\\epsilon}) \\rceil qubits, as per the phase estimation algorithm.</li> <li>The second register: The second register is initialized to an equal superposition of all possible inputs \\sum_{x}|x\\rangle by a <code>H</code> gate.</li> </ol> </li> </ol> <p>Since the state is a superposition of the eigenstates |a\\rangle and |b\\rangle, so (by the results of sec 5.2) the circuit below gives us an estimate of \\theta or 2 \\pi - \\theta accurate to within |\\Delta \\theta|\\leq 2^{-m}, with probability at least 1-\\epsilon. </p> <p>An estimate for 2\\pi - \\theta is claerly equivalent to an estimate of \\theta with the same level of accuracy, so effectively the phase estiamtion algorithm determines \\theta to an accuracy 2^{-m} with probability 1-\\epsilon.</p> <p>Using the equation \\text{sin}^{2} = M/2N and our estimate for \\theta we obtain an estimate of the number of solitions, M. The error of M is </p>  \\begin{array}{ll} \\frac{|\\Delta M|}{2N} &amp; = |\\text{sin}^{2}\\bigg(\\frac{\\theta + \\Delta \\theta}{2} \\bigg) - \\text{sin}^{2}\\bigg( \\frac{\\theta}{2} \\bigg)| \\\\  &amp; =  \\bigg(\\text{sin}\\bigg( \\frac{\\theta + \\Delta \\theta}{2}\\bigg) + \\text{sin}\\bigg( \\frac{\\theta}{2} \\bigg) \\bigg)|\\text{sin}\\bigg(\\frac{\\theta + \\Delta \\theta}{2} \\bigg) - \\text{sin}\\bigg( \\frac{\\theta}{2} \\bigg)| \\end{array}  <p>From calculus |\\text{sin}(\\frac{\\theta + \\Delta \\theta}{2}) - \\text{sin}(\\frac{\\theta}{2})| \\leq \\frac{|\\Delta \\theta|}{2} and trigonometry |\\text{sin}(\\frac{\\theta + \\Delta \\theta}{2})| &lt; \\text{sin}(\\frac{\\theta}{2}) + \\frac{|\\Delta \\theta|}{2}, </p>  \\frac{|\\Delta M|}{2N} &lt; \\bigg( 2 \\text{sin}\\bigg(\\frac{\\theta}{2} \\bigg) + \\frac{|\\Delta \\theta|}{2} \\bigg) \\frac{|\\Delta \\theta|}{2}.  <p>Substituting \\text{sin}^{2}(\\frac{\\theta}{2}) = M/2N and |\\Delta \\theta| \\leq 2^{-m} gives our final estimate for the error in our estimate of M,</p>  |\\Delta M| &lt; \\bigg(\\sqrt{2MN} + \\frac{N}{2^{m+1}}\\bigg) 2^{-m}.  <p>Example</p> <p>If we have N = 1024, M = 16, and m = \\rceil n/2 \\lceil +1 = 6, so 2^{-6} = 1/64. We can calcualte |\\Delta M| as </p>  |\\Delta M| &lt; \\bigg(\\sqrt{2MN} + \\frac{N}{2^{m+1}}\\bigg) 2^{-m} \\approx 189.02 \\cdot \\frac{1}{64} \\approx 2.95  <p>Estimated error in M is &lt; 2.95, so your quantum counting outputs somesthing close to 16 (likr 15.2), it's within the expected bound.</p> <p>Note</p> <ul> <li> <p>O(\\sqrt{N}) refers to Grover search. </p> <ul> <li>This call seach over a space of size N with one unknown marked item</li> <li>It takes about R = \\frac{\\pi}{4}\\sqrt{N} iterations (oracle calls)</li> <li>Assume M = 1 when no knowledge of how many solutions </li> </ul> </li> <li> <p>O(\\sqrt{M})</p> <ul> <li>Refers to the accuracy of quantum counting</li> <li>You're trying to estimate M (number of marked items)</li> <li> <p>After running phase estimation and computing \\widehat{M}, the estimate has an error of </p>  |\\Delta M| = O(\\sqrt{M})  <p>where m \\approx 0.5\\ \\text{log }N.</p> </li> </ul> </li> </ul>"},{"location":"quantum_computation/qsa_quantum_counting/#i-dont-know-how-many-m-adhead-of-time","title":"I don't know how many M adhead of time","text":"<p>To perfoem Grover's algorithm, we need to know the number of solutions M to choose the right number of iterations R. But in many cases, you don't know M ahead of time.</p> <p>To address issue, we can first use quantum counting algorithm to first estimate \\theta and M to high accuracy using phase estimation, and then to apply the quantum search algorithm, repeating the Grover iteration a number of times determined by</p>  R = CI\\bigg(\\frac{\\text{cos}^{-1}\\sqrt{M/N}}{\\theta} \\bigg)  <p>with the estimates for \\theta and M obtained by phase estimation substituted to determine R. Although your estimated \\theta can be a little off, with m = \\lceil n/2 \\rceil +1, the angular error stays within 3\\pi/8. This gives a success probability of at least \\text{cos}^{2}(\\frac{3\\pi}{8}) \\approx 0.15. even if phse estimation only succeeds 5/6 of the time, the total success is </p>  \\frac{5}{6} \\cdot 0.15 \\approx 0.12  <p>which is still usable. We can repeat a few times to boost the probability.</p>"},{"location":"quantum_computation/qsa_quantum_counting/#references","title":"References","text":"<p>[1]. M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/","title":"Building Shor\u2019s Algorithm from Scratch: Factoring 15","text":"In\u00a0[1]: Copied! <pre># import some important packages.\nimport numpy as np\nfrom qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\nfrom qiskit.primitives import StatevectorSampler as Sampler\n</pre> # import some important packages. import numpy as np from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister from qiskit.primitives import StatevectorSampler as Sampler In\u00a0[2]: Copied! <pre>class QFTBlock:\n    def __init__(self, b):\n        #  Initialize the QFT block with the number of qubits\n        self.b = b\n\n    def build(self):\n        qr = QuantumRegister(self.b, \"x\")\n        qc = QuantumCircuit(qr, name=\"QFT\")\n        for i in reversed(range(self.b)):\n            qc.h(i)           \n            for j in reversed(range(i)):\n                qc.cp(np.pi / 2**(i-j), qr[j], qr[i])\n                \n        return qc.to_gate(label=\"QFT\")\n\n    def build_inverse(self):\n        qr = QuantumRegister(self.b, \"x\")\n        qc = QuantumCircuit(qr, name=\"QFT_dg\")\n        for i in (range(self.b)):\n            for j in (range(i)):\n                qc.cp(- np.pi / 2**(i-j), qr[j], qr[i])\n            qc.h(i)\n        return qc.to_gate(label=\"QFT_dg\")\n</pre> class QFTBlock:     def __init__(self, b):         #  Initialize the QFT block with the number of qubits         self.b = b      def build(self):         qr = QuantumRegister(self.b, \"x\")         qc = QuantumCircuit(qr, name=\"QFT\")         for i in reversed(range(self.b)):             qc.h(i)                        for j in reversed(range(i)):                 qc.cp(np.pi / 2**(i-j), qr[j], qr[i])                          return qc.to_gate(label=\"QFT\")      def build_inverse(self):         qr = QuantumRegister(self.b, \"x\")         qc = QuantumCircuit(qr, name=\"QFT_dg\")         for i in (range(self.b)):             for j in (range(i)):                 qc.cp(- np.pi / 2**(i-j), qr[j], qr[i])             qc.h(i)         return qc.to_gate(label=\"QFT_dg\") In\u00a0[3]: Copied! <pre>## Test our QFT gate\n\n# 1. Setup parameters\nn = 4 # bit length for b\nidx = 0\n\n# 2. Initialize circuit layout\nqr = QuantumRegister(n)\ncr = ClassicalRegister(n,'b')\nqc = QuantumCircuit(qr, cr)\n\n# 3. Initialize b = 5 -&gt; |0101&gt; = |b_4b_3b_2b_1&gt; = |qr[3],qr[2],qr[1],qr[0]&gt;\nqc.x(0)\nqc.x(2)\n\n# 4. Create QFT and IQFT opreations\nqft_gate = QFTBlock(n)\nqc.append(qft_gate.build(), [qr[i] for i in range(n)]) # QFT\nqc.append(qft_gate.build_inverse(), [qr[i] for i in range(n)])  # iQFT\n\n# 5. Measure register b\nqc.measure(range(n), range(n))\n\n# 5. Draw our circuit\nqc.decompose().draw('mpl', justify='none')\n</pre> ## Test our QFT gate  # 1. Setup parameters n = 4 # bit length for b idx = 0  # 2. Initialize circuit layout qr = QuantumRegister(n) cr = ClassicalRegister(n,'b') qc = QuantumCircuit(qr, cr)  # 3. Initialize b = 5 -&gt; |0101&gt; = |b_4b_3b_2b_1&gt; = |qr[3],qr[2],qr[1],qr[0]&gt; qc.x(0) qc.x(2)  # 4. Create QFT and IQFT opreations qft_gate = QFTBlock(n) qc.append(qft_gate.build(), [qr[i] for i in range(n)]) # QFT qc.append(qft_gate.build_inverse(), [qr[i] for i in range(n)])  # iQFT  # 5. Measure register b qc.measure(range(n), range(n))  # 5. Draw our circuit qc.decompose().draw('mpl', justify='none') Out[3]: In\u00a0[4]: Copied! <pre># Run our circuit via quantum simulator and print our result!\n# get_counts() will map our result using a big-endian method, that is, LSB will be displayed at rightmost side of |psi&gt;\n\n# 1. Setup quantum sampler\nsampler = Sampler()\njob1 = sampler.run([qc],shots=4096)\nresult = job1.result()\n\n# 2. Get sampling result\nprint(result[0])\nprint(result[0].data)\nprint(result[0].data._data.keys())\n\nbit_array = result[0].data['b']\ncounts = bit_array.get_counts()\n\n# We should get |0101&gt; since |b&gt; - QFT - IQFT -&gt; |b&gt; since QFT is a unitary transformation.\nprint(counts)\n</pre> # Run our circuit via quantum simulator and print our result! # get_counts() will map our result using a big-endian method, that is, LSB will be displayed at rightmost side of |psi&gt;  # 1. Setup quantum sampler sampler = Sampler() job1 = sampler.run([qc],shots=4096) result = job1.result()  # 2. Get sampling result print(result[0]) print(result[0].data) print(result[0].data._data.keys())  bit_array = result[0].data['b'] counts = bit_array.get_counts()  # We should get |0101&gt; since |b&gt; - QFT - IQFT -&gt; |b&gt; since QFT is a unitary transformation. print(counts) <pre>SamplerPubResult(data=DataBin(b=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(b=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;))\ndict_keys(['b'])\n{'0101': 4096}\n</pre> <p>Well done! \ud83c\udf89 You\u2019ve just verified that $|0101\\rangle$ is indeed the binary representation of 5 \u2014 and more importantly, you\u2019ve successfully implemented the Quantum Fourier Transform (QFT) and its inverse from scratch using only basic quantum gates!</p> <p>Now that we can move in and out of the Fourier basis, we\u2019re ready for the next essential building block of modular exponentiation: the quantum adder gate, <code>\u03c6ADD(a)</code>.</p> <p>This gate allows us to add a classical number directly to a quantum register in the QFT basis \u2014 efficiently and without the need for extra quantum registers.</p> <p>Let\u2019s dive into how it works and how to implement it step by step!</p> In\u00a0[5]: Copied! <pre>class QADDERBlock:\n    def __init__(self, n,m):\n        self.n = n\n        self.m = m\n\n    def build(self,qr_b, qr_a):\n        # check range(m) = range(n)\n        qc = QuantumCircuit(qr_b,qr_a, name=\"Q_ADDER\")\n        full_q = list(qr_b) + list(qr_a) # now full_q is a list of qubits\n        \n        for i in reversed(range(len(qr_b),len(full_q))):\n            for j in reversed(range(len(qr_b),i+1)):\n                if j == i - self.n:\n                    continue  # skip when control == target\n                k = i - j + 1\n                qc.cp(2 * np.pi / 2**(k), full_q[j], full_q[i - self.n])\n\n        return qc.to_gate(label=\"Q_ADDER\")\n\n    def build_inverse_manually(self,qr_b, qr_a):\n        return None\n\n    def build_inverse(self,qr_b, qr_a):\n        # check range(m) = range(n)\n        qc = QuantumCircuit(qr_b,qr_a, name=\"Q_ADDER_dag\")\n        full_q = list(qr_b) + list(qr_a) # now full_q is a list of qubits\n\n        for i in (range(len(qr_b),len(full_q))):\n            for j in (range(len(qr_b),i+1)):\n                if j == i - self.n:\n                    continue  # skip when control == target\n                k = i - j + 1\n                qc.cp(- 2 * np.pi / 2**(k), full_q[j], full_q[i - self.n])\n        return qc.to_gate(label=\"Q_ADDER_dag\")\n\n        \n</pre> class QADDERBlock:     def __init__(self, n,m):         self.n = n         self.m = m      def build(self,qr_b, qr_a):         # check range(m) = range(n)         qc = QuantumCircuit(qr_b,qr_a, name=\"Q_ADDER\")         full_q = list(qr_b) + list(qr_a) # now full_q is a list of qubits                  for i in reversed(range(len(qr_b),len(full_q))):             for j in reversed(range(len(qr_b),i+1)):                 if j == i - self.n:                     continue  # skip when control == target                 k = i - j + 1                 qc.cp(2 * np.pi / 2**(k), full_q[j], full_q[i - self.n])          return qc.to_gate(label=\"Q_ADDER\")      def build_inverse_manually(self,qr_b, qr_a):         return None      def build_inverse(self,qr_b, qr_a):         # check range(m) = range(n)         qc = QuantumCircuit(qr_b,qr_a, name=\"Q_ADDER_dag\")         full_q = list(qr_b) + list(qr_a) # now full_q is a list of qubits          for i in (range(len(qr_b),len(full_q))):             for j in (range(len(qr_b),i+1)):                 if j == i - self.n:                     continue  # skip when control == target                 k = i - j + 1                 qc.cp(- 2 * np.pi / 2**(k), full_q[j], full_q[i - self.n])         return qc.to_gate(label=\"Q_ADDER_dag\")           In\u00a0[6]: Copied! <pre># --- Simple Test Case for QADDERBlock ---\n\n# 1. Setup parameters\nn = 4\nm = 4\n\n# 2. Create the circuit\nqr_b = QuantumRegister(n, \"b\")\nqr_a = QuantumRegister(m, \"a\")\ncr = ClassicalRegister(n, \"c\")\nqc = QuantumCircuit(qr_b, qr_a, cr)\n\n# 3. Initialize b \nqc.x(0)  # |0011\u27e9 = 3 on b |q[3], q[2], q[1], q[0]&gt;\nqc.x(1)  \n\n# 4. Initialize a \nqc.x(4)  # |0001\u27e9 = 1 on a |q[7], q[6], q[5], q[4]&gt;\n\n# 5. Construct QADDER operations\nQADDER = QADDERBlock(n, m)\nQFT = QFTBlock(n)\nqc.append(QFT.build(), qr_b[:])                          \nqc.append(QADDER.build(qr_b, qr_a), qr_b[:] + qr_a[:])  \nqc.append(QFT.build_inverse(), qr_b[:])\n\n# 6. Measure register b\nqc.measure(qr_b, cr)\n\n# 7. Draw our quantum circuit\nqc.decompose().draw('mpl', fold=-1)\n</pre> # --- Simple Test Case for QADDERBlock ---  # 1. Setup parameters n = 4 m = 4  # 2. Create the circuit qr_b = QuantumRegister(n, \"b\") qr_a = QuantumRegister(m, \"a\") cr = ClassicalRegister(n, \"c\") qc = QuantumCircuit(qr_b, qr_a, cr)  # 3. Initialize b  qc.x(0)  # |0011\u27e9 = 3 on b |q[3], q[2], q[1], q[0]&gt; qc.x(1)    # 4. Initialize a  qc.x(4)  # |0001\u27e9 = 1 on a |q[7], q[6], q[5], q[4]&gt;  # 5. Construct QADDER operations QADDER = QADDERBlock(n, m) QFT = QFTBlock(n) qc.append(QFT.build(), qr_b[:])                           qc.append(QADDER.build(qr_b, qr_a), qr_b[:] + qr_a[:])   qc.append(QFT.build_inverse(), qr_b[:])  # 6. Measure register b qc.measure(qr_b, cr)  # 7. Draw our quantum circuit qc.decompose().draw('mpl', fold=-1)  Out[6]: In\u00a0[7]: Copied! <pre># Run our circuit via quantum simulator and print our result!\n# get_counts() will map our result using a big-endian method, that is, LSB will be displayed at rightmost side of |psi&gt;\n\n# 1. Setup quantum sampler\nsampler = Sampler()\njob3 = sampler.run([qc],shots=4096)\nresult = job3.result()\n\n# 2. Get sampling result\nprint(result[0])\nprint(result[0].data)\nprint(result[0].data._data.keys())\n\nbit_array = result[0].data['c']\ncounts = bit_array.get_counts()\n\n# We should get |0100&gt; since b + a = |0011&gt; + |0001&gt; = |0100&gt;\nprint(counts)\n</pre> # Run our circuit via quantum simulator and print our result! # get_counts() will map our result using a big-endian method, that is, LSB will be displayed at rightmost side of |psi&gt;  # 1. Setup quantum sampler sampler = Sampler() job3 = sampler.run([qc],shots=4096) result = job3.result()  # 2. Get sampling result print(result[0]) print(result[0].data) print(result[0].data._data.keys())  bit_array = result[0].data['c'] counts = bit_array.get_counts()  # We should get |0100&gt; since b + a = |0011&gt; + |0001&gt; = |0100&gt; print(counts) <pre>SamplerPubResult(data=DataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;))\ndict_keys(['c'])\n{'0100': 4096}\n</pre> In\u00a0[8]: Copied! <pre># This function can help us map our classical input on the predefined circuit by giving classical values, start and stop indices.\ndef apply_value(qc, value, start, bits):\n        for i in range(bits):\n            if (value &gt;&gt; i) &amp; 1:\n                qc.x(start + i)\n</pre> # This function can help us map our classical input on the predefined circuit by giving classical values, start and stop indices. def apply_value(qc, value, start, bits):         for i in range(bits):             if (value &gt;&gt; i) &amp; 1:                 qc.x(start + i) In\u00a0[9]: Copied! <pre>class QAdderClassicalBlock:\n    \"\"\"Adds a classical integer to a quantum register using phase rotations.\"\"\"\n    def __init__(self, n):\n        self.n = n\n\n    def build(self, a_val):\n        \"\"\"Builds the gate to add the classical value a_val.\"\"\"\n        qc = QuantumCircuit(self.n, name=f\"ADD_c({a_val})\")\n        for k in range(self.n):\n            if (a_val &gt;&gt; k) &amp; 1:\n                for j in range(k, self.n):\n                    angle = np.pi / (2**(j - k))\n                    qc.p(angle, j) # phase rotation \n        return qc.to_gate()\n\n    def build_inverse(self, a_val):\n        \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"\n        add_gate = self.build(a_val)\n        return add_gate.inverse()\n</pre> class QAdderClassicalBlock:     \"\"\"Adds a classical integer to a quantum register using phase rotations.\"\"\"     def __init__(self, n):         self.n = n      def build(self, a_val):         \"\"\"Builds the gate to add the classical value a_val.\"\"\"         qc = QuantumCircuit(self.n, name=f\"ADD_c({a_val})\")         for k in range(self.n):             if (a_val &gt;&gt; k) &amp; 1:                 for j in range(k, self.n):                     angle = np.pi / (2**(j - k))                     qc.p(angle, j) # phase rotation          return qc.to_gate()      def build_inverse(self, a_val):         \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"         add_gate = self.build(a_val)         return add_gate.inverse() In\u00a0[10]: Copied! <pre># --- Simple Test Case for QAdderClassicalBlock ---\n\n# 1. Setup parameters\nn_bits = 4\nb_val = 4   # Initial quantum value: |0010&gt;\na_val = 3   # Classical value to add\nexpected_val = b_val + a_val\n\n#2. Create the circuit\nqr = QuantumRegister(n_bits, name='b')\ncr = ClassicalRegister(n_bits, name='result')\nqc = QuantumCircuit(qr, cr)\n\napply_value(qc, b_val, 0, n_bits)\n        \nqc.barrier()\n# 4. Construct the full adder operation: QFT -&gt; Phase Add -&gt; IQFT\nqft_gate = QFTBlock(n_bits).build()\nadder_gate = QAdderClassicalBlock(n_bits).build(a_val)\niqft_gate = QFTBlock(n_bits).build_inverse()\n\nqc.append(qft_gate, qr)\nqc.append(adder_gate, qr)\nqc.append(iqft_gate, qr)\nqc.barrier()\n\n# 5. Measure the final state\nqc.measure(qr, cr)\nqc.draw('mpl')\n</pre> # --- Simple Test Case for QAdderClassicalBlock ---  # 1. Setup parameters n_bits = 4 b_val = 4   # Initial quantum value: |0010&gt; a_val = 3   # Classical value to add expected_val = b_val + a_val  #2. Create the circuit qr = QuantumRegister(n_bits, name='b') cr = ClassicalRegister(n_bits, name='result') qc = QuantumCircuit(qr, cr)  apply_value(qc, b_val, 0, n_bits)          qc.barrier() # 4. Construct the full adder operation: QFT -&gt; Phase Add -&gt; IQFT qft_gate = QFTBlock(n_bits).build() adder_gate = QAdderClassicalBlock(n_bits).build(a_val) iqft_gate = QFTBlock(n_bits).build_inverse()  qc.append(qft_gate, qr) qc.append(adder_gate, qr) qc.append(iqft_gate, qr) qc.barrier()  # 5. Measure the final state qc.measure(qr, cr) qc.draw('mpl') Out[10]: In\u00a0[11]: Copied! <pre># Run our circuit via quantum simulator and print our result!\n# get_counts() will map our result using a big-endian method, that is, LSB will be displayed at rightmost side of |psi&gt;\n\n# 1. Setup quantum sampler \nsampler = Sampler()\njob3 = sampler.run([qc],shots=4096)\nresult = job3.result()\n\n# 2. Get sampling result\nprint(result[0])\nprint(result[0].data)\nprint(result[0].data._data.keys())\nbit_array = result[0].data['result']\ncounts = bit_array.get_counts()\n\n# We should get 0111\nprint(counts)\n\n# 3. Find and print the most likely outcome\nif counts:\n    most_likely_binary_rev = max(counts, key=counts.get)\n    readable_binary = most_likely_binary_rev\n    measured_val = int(readable_binary, 2)\n    print(f\"\\nMost likely measured value: {measured_val} (binary: {readable_binary})\")\n</pre> # Run our circuit via quantum simulator and print our result! # get_counts() will map our result using a big-endian method, that is, LSB will be displayed at rightmost side of |psi&gt;  # 1. Setup quantum sampler  sampler = Sampler() job3 = sampler.run([qc],shots=4096) result = job3.result()  # 2. Get sampling result print(result[0]) print(result[0].data) print(result[0].data._data.keys()) bit_array = result[0].data['result'] counts = bit_array.get_counts()  # We should get 0111 print(counts)  # 3. Find and print the most likely outcome if counts:     most_likely_binary_rev = max(counts, key=counts.get)     readable_binary = most_likely_binary_rev     measured_val = int(readable_binary, 2)     print(f\"\\nMost likely measured value: {measured_val} (binary: {readable_binary})\") <pre>SamplerPubResult(data=DataBin(result=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(result=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;))\ndict_keys(['result'])\n{'0111': 4096}\n\nMost likely measured value: 7 (binary: 0111)\n</pre> <p>Well done again! \ud83c\udf89 You\u2019ve successfully added the classical value 3 to the quantum Fourier state $|4\\rangle$ by constructing your very own quantum adder gate!</p> <p>Next, we\u2019ll take things a step further and explore modular addition \u2014 a key ingredient for building modular arithmetic circuits in Shor\u2019s algorithm.</p> In\u00a0[12]: Copied! <pre>class add_mod_N_classic:\n    def __init__(self, n, measure_flag=False):\n        self.n = n\n        self.measure_flag = measure_flag\n\n    def build(self, a_val, N_val):\n        \"\"\"Builds the gate to add the classical value a_val.\"\"\"    \n        # circuit layout\n        # b[0]...b[n-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |\n        # l + n + m + 3 = number of qubits in the circuit\n        # l = number of bits in N, n = number of bits in b, m = number of bits in a\n        num_qubits = self.n + 3\n        \n        qc = QuantumCircuit(num_qubits, name=f\" ({a_val}) ADD MOD ({N_val})\")\n        qr_b = list(qc.qubits[0:self.n])  # b[0] (LSB) to b[n-1] (MSB)\n        \n        # These are the relative positions within the add_mod_N gate's own circuit\n        # They will be mapped to the correct global qubits when appended\n        ctrl_aux = qc.qubits[-3]        \n        ctrl_2   = qc.qubits[-2]\n        ctrl_1   = qc.qubits[-1]\n        \n        # Controlled phi add\n        add_a_qadder = QAdderClassicalBlock(self.n).build(a_val)\n        add_a_cc_adder = add_a_qadder.control(2)\n        qc.append(add_a_cc_adder, [ctrl_2, ctrl_1] + qr_b)\n        \n        # Subtract N\n        add_N_qadder_dag = QAdderClassicalBlock(self.n).build_inverse(N_val)\n        qc.append(add_N_qadder_dag, qr_b[:])\n        \n        # Inverse QFT\n        iqft_gate = QFTBlock(self.n).build_inverse()\n        qc.append(iqft_gate, qr_b)\n        \n        # Controlled flag (copy the last qubit of b to ctrl_aux)\n        # This sets vtrl_aux to 1 if qr_b[-1] is 1\n        qc.cx(qr_b[-1], ctrl_aux)\n\n        # QFT on b\n        qft_gate = QFTBlock(self.n).build()\n        qc.append(qft_gate, qr_b)\n\n        # Add N, Controlled aux, target add_N_qadder\n        add_N_qadder = QAdderClassicalBlock(self.n).build(N_val)\n        add_N_ctrl_qadder = add_N_qadder.control(1)\n        qc.append(add_N_ctrl_qadder, [ctrl_aux] + qr_b) # ctrl_aux is the control,\n        \n        # Controlled subtract a\n        sub_a_qadder_dag = QAdderClassicalBlock(self.n).build_inverse(a_val)\n        sub_a_cc_adder = sub_a_qadder_dag.control(2)\n        qc.append(sub_a_cc_adder, [ctrl_1, ctrl_2] + qr_b )\n\n        # Inverse QFT\n        iqft_gate = QFTBlock(self.n).build_inverse()\n        qc.append(iqft_gate, qr_b)\n\n        # Controlled flag\n        # Swap the last qubit of b with ctrl_aux\n        qc.x(qr_b[-1])\n        qc.cx(qr_b[-1], ctrl_aux)\n        qc.x(qr_b[-1])\n        \n        # QFT on b\n        qft_gate = QFTBlock(self.n).build()\n        qc.append(qft_gate, qr_b)\n\n        # Controlled phi add\n        add_a_qadder = QAdderClassicalBlock(self.n).build(a_val)\n        add_a_cc_adder = add_a_qadder.control(2)\n        qc.append(add_a_cc_adder, [ctrl_1, ctrl_2] + qr_b)\n        \n        return qc.to_gate()\n        \n    def build_inverse(self, a_val, N_val):\n        \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"\n        mod_add_gate = self.build(a_val, N_val)\n        return mod_add_gate.inverse()\n</pre> class add_mod_N_classic:     def __init__(self, n, measure_flag=False):         self.n = n         self.measure_flag = measure_flag      def build(self, a_val, N_val):         \"\"\"Builds the gate to add the classical value a_val.\"\"\"             # circuit layout         # b[0]...b[n-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |         # l + n + m + 3 = number of qubits in the circuit         # l = number of bits in N, n = number of bits in b, m = number of bits in a         num_qubits = self.n + 3                  qc = QuantumCircuit(num_qubits, name=f\" ({a_val}) ADD MOD ({N_val})\")         qr_b = list(qc.qubits[0:self.n])  # b[0] (LSB) to b[n-1] (MSB)                  # These are the relative positions within the add_mod_N gate's own circuit         # They will be mapped to the correct global qubits when appended         ctrl_aux = qc.qubits[-3]                 ctrl_2   = qc.qubits[-2]         ctrl_1   = qc.qubits[-1]                  # Controlled phi add         add_a_qadder = QAdderClassicalBlock(self.n).build(a_val)         add_a_cc_adder = add_a_qadder.control(2)         qc.append(add_a_cc_adder, [ctrl_2, ctrl_1] + qr_b)                  # Subtract N         add_N_qadder_dag = QAdderClassicalBlock(self.n).build_inverse(N_val)         qc.append(add_N_qadder_dag, qr_b[:])                  # Inverse QFT         iqft_gate = QFTBlock(self.n).build_inverse()         qc.append(iqft_gate, qr_b)                  # Controlled flag (copy the last qubit of b to ctrl_aux)         # This sets vtrl_aux to 1 if qr_b[-1] is 1         qc.cx(qr_b[-1], ctrl_aux)          # QFT on b         qft_gate = QFTBlock(self.n).build()         qc.append(qft_gate, qr_b)          # Add N, Controlled aux, target add_N_qadder         add_N_qadder = QAdderClassicalBlock(self.n).build(N_val)         add_N_ctrl_qadder = add_N_qadder.control(1)         qc.append(add_N_ctrl_qadder, [ctrl_aux] + qr_b) # ctrl_aux is the control,                  # Controlled subtract a         sub_a_qadder_dag = QAdderClassicalBlock(self.n).build_inverse(a_val)         sub_a_cc_adder = sub_a_qadder_dag.control(2)         qc.append(sub_a_cc_adder, [ctrl_1, ctrl_2] + qr_b )          # Inverse QFT         iqft_gate = QFTBlock(self.n).build_inverse()         qc.append(iqft_gate, qr_b)          # Controlled flag         # Swap the last qubit of b with ctrl_aux         qc.x(qr_b[-1])         qc.cx(qr_b[-1], ctrl_aux)         qc.x(qr_b[-1])                  # QFT on b         qft_gate = QFTBlock(self.n).build()         qc.append(qft_gate, qr_b)          # Controlled phi add         add_a_qadder = QAdderClassicalBlock(self.n).build(a_val)         add_a_cc_adder = add_a_qadder.control(2)         qc.append(add_a_cc_adder, [ctrl_1, ctrl_2] + qr_b)                  return qc.to_gate()              def build_inverse(self, a_val, N_val):         \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"         mod_add_gate = self.build(a_val, N_val)         return mod_add_gate.inverse() In\u00a0[13]: Copied! <pre>import math\n# --- Simple Test Case for QAdderClassicalBlock ---\n# a &lt; N and b &lt; N\n\n# 1. Setup parameters\nn_bits = 4\nb_val = 5   # Initial quantum value: |0010&gt;\na_val = 3   # Classical value to add\nN_val = 9 \n\nexpected_val =( b_val + a_val ) % N_val # (a + b) MOD N = (3 + 5) MOD 9 = 8\n\n# 2. Create the circuit\nqr = QuantumRegister(n_bits + 3, name='b')\ncr = ClassicalRegister(n_bits, name='c')\nqc = QuantumCircuit(qr, cr)\n\n# 3. Initialize b\nfor i in range(n_bits):\n    if (b_val &gt;&gt; i) &amp; 1:\n        qc.x(i)\n\n# 4. init ctrl 1 and 2\nqc.x(5)\nqc.x(6)\n\nqc.barrier()\n\n# 5. Construct the full adder operation: QFT -&gt; Phase Add -&gt; IQFT\nqft_gate = QFTBlock(n_bits).build()\nmod_adder_gate = add_mod_N_classic(n_bits).build(a_val, N_val)\niqft_gate = QFTBlock(n_bits).build_inverse()\n\nqc.append(qft_gate, qr[:n_bits]) # need one more bit for overflow\nqc.append(mod_adder_gate, qr)\nqc.append(iqft_gate, qr[:n_bits])\nqc.barrier()\n\n# 6. Measure the final state\nqc.measure(qr[:n_bits], cr)\n\n# 7. Draw our circuit\n#qc.decompose().draw('mpl')#, justify='none')\nqc.draw('mpl')\n</pre> import math # --- Simple Test Case for QAdderClassicalBlock --- # a &lt; N and b &lt; N  # 1. Setup parameters n_bits = 4 b_val = 5   # Initial quantum value: |0010&gt; a_val = 3   # Classical value to add N_val = 9   expected_val =( b_val + a_val ) % N_val # (a + b) MOD N = (3 + 5) MOD 9 = 8  # 2. Create the circuit qr = QuantumRegister(n_bits + 3, name='b') cr = ClassicalRegister(n_bits, name='c') qc = QuantumCircuit(qr, cr)  # 3. Initialize b for i in range(n_bits):     if (b_val &gt;&gt; i) &amp; 1:         qc.x(i)  # 4. init ctrl 1 and 2 qc.x(5) qc.x(6)  qc.barrier()  # 5. Construct the full adder operation: QFT -&gt; Phase Add -&gt; IQFT qft_gate = QFTBlock(n_bits).build() mod_adder_gate = add_mod_N_classic(n_bits).build(a_val, N_val) iqft_gate = QFTBlock(n_bits).build_inverse()  qc.append(qft_gate, qr[:n_bits]) # need one more bit for overflow qc.append(mod_adder_gate, qr) qc.append(iqft_gate, qr[:n_bits]) qc.barrier()  # 6. Measure the final state qc.measure(qr[:n_bits], cr)  # 7. Draw our circuit #qc.decompose().draw('mpl')#, justify='none') qc.draw('mpl')  Out[13]: In\u00a0[14]: Copied! <pre># 1. Setup quantum sampler \nsampler = Sampler()\njob_add_mod_N_classic = sampler.run([qc],shots=4096)\nresult = job_add_mod_N_classic.result()\n\n# 2. Get sampling result\nprint(result[0])\nprint(result[0].data)\nprint(result[0].data._data.keys())\nbit_array = result[0].data['c']\ncounts = bit_array.get_counts()\n\n# 3. We should get 1000\nprint(counts)\n\n# Find and print the most likely outcome\nif counts:\n    #Qiskit returns binary strings in reverse order, so we flip it\n    most_likely_binary_rev = max(counts, key=counts.get)\n    readable_binary = most_likely_binary_rev\n    measured_val = int(readable_binary, 2)\n    print(f\"\\nMost likely measured value: {measured_val} (binary: {readable_binary})\")\n</pre> # 1. Setup quantum sampler  sampler = Sampler() job_add_mod_N_classic = sampler.run([qc],shots=4096) result = job_add_mod_N_classic.result()  # 2. Get sampling result print(result[0]) print(result[0].data) print(result[0].data._data.keys()) bit_array = result[0].data['c'] counts = bit_array.get_counts()  # 3. We should get 1000 print(counts)  # Find and print the most likely outcome if counts:     #Qiskit returns binary strings in reverse order, so we flip it     most_likely_binary_rev = max(counts, key=counts.get)     readable_binary = most_likely_binary_rev     measured_val = int(readable_binary, 2)     print(f\"\\nMost likely measured value: {measured_val} (binary: {readable_binary})\") <pre>SamplerPubResult(data=DataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;))\ndict_keys(['c'])\n{'1000': 4096}\n\nMost likely measured value: 8 (binary: 1000)\n</pre> <p>\ud83c\udf89 Impressive! You\u2019ve completed the modular adder \u2014 one of the hardest parts!</p> <p>         The CMULT(a)MOD(N) gate.     </p> In\u00a0[15]: Copied! <pre>class CMULTaMODN_c:\n    # circuit layout\n    # b[0]...b[n-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |\n    \"\"\"Class to build the CMULTMaMODN quantum circuit.\"\"\"\n\n    def __init__(self, n, x, c1 = 1, ctrl_aux = 1, check_flag=False):\n        \"\"\"Initialize the stress test with parameters a, b, and N.\"\"\"\n        self.n = n # number of bits for b\n        self.c1 = c1  # number of bits for c1\n        self.x = x  # number of bits for x\n        self.ctrl_aux = ctrl_aux  # index for aux control bit\n        self.check_flag = check_flag  # Flag to check aux control bit #TODO\n\n    def build(self, a_val, N_val):\n        num_qubits = self.n + self.x + self.c1 + self.ctrl_aux  # +1 for ctrl_aux\n        qc = QuantumCircuit(num_qubits, name=f\"CMULT({a_val})MOD({N_val})\")\n        \n        idx = 0\n        qr_b = list(qc.qubits[idx : idx + self.n])\n        idx += self.n\n\n        # aux\n        qr_ctrl_aux = [idx]\n        idx += self.ctrl_aux\n        \n        # ctrl_2 = x\n        qr_x = list(qc.qubits[idx : idx + self.x]) # ctrl_2 # check x length\n        idx += self.x\n        \n        qr_ctrl_1 = list(qc.qubits[idx : idx + self.c1])\n\n        \"\"\"Build the CMULTMaMODN quantum circuit.\"\"\"\n        # QFT on b\n        qc.append(QFTBlock(self.n).build(), qr_b)\n\n        # perform controlled addition by a on the aux register in Fourier space\n        for i in range(self.x):\n            a_val_i = (a_val * 2**i) % N_val\n            mod_adder = add_mod_N_classic(n = self.n).build(a_val=a_val_i, N_val= N_val)\n            qc.append(mod_adder, qr_b + qr_ctrl_aux + [qr_x[i]] + qr_ctrl_1) \n\n        # Inverse QFT\n        qc.append(QFTBlock(self.n).build_inverse(), qr_b)\n\n        return qc.to_gate()        \n    \n    def build_inverse(self, a_val, N_val):\n        \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"\n        cm_mod_add_gate = self.build(a_val, N_val)\n        return cm_mod_add_gate.inverse()\n    \n</pre> class CMULTaMODN_c:     # circuit layout     # b[0]...b[n-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |     \"\"\"Class to build the CMULTMaMODN quantum circuit.\"\"\"      def __init__(self, n, x, c1 = 1, ctrl_aux = 1, check_flag=False):         \"\"\"Initialize the stress test with parameters a, b, and N.\"\"\"         self.n = n # number of bits for b         self.c1 = c1  # number of bits for c1         self.x = x  # number of bits for x         self.ctrl_aux = ctrl_aux  # index for aux control bit         self.check_flag = check_flag  # Flag to check aux control bit #TODO      def build(self, a_val, N_val):         num_qubits = self.n + self.x + self.c1 + self.ctrl_aux  # +1 for ctrl_aux         qc = QuantumCircuit(num_qubits, name=f\"CMULT({a_val})MOD({N_val})\")                  idx = 0         qr_b = list(qc.qubits[idx : idx + self.n])         idx += self.n          # aux         qr_ctrl_aux = [idx]         idx += self.ctrl_aux                  # ctrl_2 = x         qr_x = list(qc.qubits[idx : idx + self.x]) # ctrl_2 # check x length         idx += self.x                  qr_ctrl_1 = list(qc.qubits[idx : idx + self.c1])          \"\"\"Build the CMULTMaMODN quantum circuit.\"\"\"         # QFT on b         qc.append(QFTBlock(self.n).build(), qr_b)          # perform controlled addition by a on the aux register in Fourier space         for i in range(self.x):             a_val_i = (a_val * 2**i) % N_val             mod_adder = add_mod_N_classic(n = self.n).build(a_val=a_val_i, N_val= N_val)             qc.append(mod_adder, qr_b + qr_ctrl_aux + [qr_x[i]] + qr_ctrl_1)           # Inverse QFT         qc.append(QFTBlock(self.n).build_inverse(), qr_b)          return qc.to_gate()                  def build_inverse(self, a_val, N_val):         \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"         cm_mod_add_gate = self.build(a_val, N_val)         return cm_mod_add_gate.inverse()      In\u00a0[16]: Copied! <pre>def get_bits(val):\n        \"\"\"Calculate the maximum number of bits needed to represent N.\"\"\"\n        # This function calculates the number of bits required to represent N.\n        # This code automatically add 1 for value\n        # For example, |7&gt; will be mapped into |0111&gt;, and extra bit is to be used duing the modular addition and \n        # flag the overflow/ underflow for the ctrl_aux bit, which is initialized as |0&gt; and should be back to |0&gt; \n        # after use.\n        n = 1\n        while val &gt; 2**(n-1) - 1:\n            n += 1\n        return n\n</pre> def get_bits(val):         \"\"\"Calculate the maximum number of bits needed to represent N.\"\"\"         # This function calculates the number of bits required to represent N.         # This code automatically add 1 for value         # For example, |7&gt; will be mapped into |0111&gt;, and extra bit is to be used duing the modular addition and          # flag the overflow/ underflow for the ctrl_aux bit, which is initialized as |0&gt; and should be back to |0&gt;          # after use.         n = 1         while val &gt; 2**(n-1) - 1:             n += 1         return n  In\u00a0[17]: Copied! <pre># --- Simple Test Case for CMULTaMODN_c ---\n\nb_val = 7\nn = get_bits(b_val)\na_val = 3\nN_val = 7\nx_val = 3\nx_len = get_bits(x_val-1) # -1 since we only need n+1 for b rather than x\n\nexpected_val =( b_val + a_val * x_val ) % N_val\n\n# b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |\n# 1. Quantum + Classical Registers\nnum_qubits = n + x_len + 2 #(aux and ctrl_1)\nqr = QuantumRegister(num_qubits)\ncr = ClassicalRegister(n,'b')\nqc = QuantumCircuit(qr, cr)\n\n# 2. Initialize b\napply_value(qc, b_val, 0, n)\n\n# 3. Initialize x \napply_value(qc, x_val, n + 1, x_len)\n\n# 4. Set control bits, init Ctrl_1\nqc.x(qr[-1])\n\n# 5. Expected outcome (b + a*x) mod N = (4 + 3*3) MOD (7) = 13 MOD 7 = 6 -&gt; |0100&gt;\nqc.barrier()\n\n# 6. Build and append the multiplier \nmultiplier = CMULTaMODN_c(n=n, x = x_len).build(a_val, N_val)\nqc.append(multiplier, qr[:])\nqc.barrier()\n\n# 7. Measure the result\nqc.measure(qr[0:n], cr)\n\n# 8. Draw our circuit\nqc.decompose().draw('mpl')\n</pre> # --- Simple Test Case for CMULTaMODN_c ---  b_val = 7 n = get_bits(b_val) a_val = 3 N_val = 7 x_val = 3 x_len = get_bits(x_val-1) # -1 since we only need n+1 for b rather than x  expected_val =( b_val + a_val * x_val ) % N_val  # b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 | # 1. Quantum + Classical Registers num_qubits = n + x_len + 2 #(aux and ctrl_1) qr = QuantumRegister(num_qubits) cr = ClassicalRegister(n,'b') qc = QuantumCircuit(qr, cr)  # 2. Initialize b apply_value(qc, b_val, 0, n)  # 3. Initialize x  apply_value(qc, x_val, n + 1, x_len)  # 4. Set control bits, init Ctrl_1 qc.x(qr[-1])  # 5. Expected outcome (b + a*x) mod N = (4 + 3*3) MOD (7) = 13 MOD 7 = 6 -&gt; |0100&gt; qc.barrier()  # 6. Build and append the multiplier  multiplier = CMULTaMODN_c(n=n, x = x_len).build(a_val, N_val) qc.append(multiplier, qr[:]) qc.barrier()  # 7. Measure the result qc.measure(qr[0:n], cr)  # 8. Draw our circuit qc.decompose().draw('mpl')  Out[17]: In\u00a0[18]: Copied! <pre># 1. Setup quantum sampler \nsampler = Sampler()\njob_CMULTsMODN = sampler.run([qc],shots=4096)\nresult = job_CMULTsMODN.result()\n\n# 2. Get sampling result.\nprint(result[0])\nprint(result[0].data)\nprint(result[0].data._data.keys())\nbit_array = result[0].data['b']\ncounts = bit_array.get_counts()\nprint(counts)\n\nif counts:\n    most_likely_binary_rev = max(counts, key=counts.get)\n    readable_binary = most_likely_binary_rev\n    measured_val = int(readable_binary, 2)\n    print(\"-------------- Result summary --------------\")\n    print(f\"( {b_val} + {a_val} * {x_val} ) MOD {N_val}\")\n    print(f\"Expected value:{expected_val}\")\n    print(f\"(Most likely) measured value: {measured_val} (binary: {readable_binary}), with shot {counts}\")\n</pre> # 1. Setup quantum sampler  sampler = Sampler() job_CMULTsMODN = sampler.run([qc],shots=4096) result = job_CMULTsMODN.result()  # 2. Get sampling result. print(result[0]) print(result[0].data) print(result[0].data._data.keys()) bit_array = result[0].data['b'] counts = bit_array.get_counts() print(counts)  if counts:     most_likely_binary_rev = max(counts, key=counts.get)     readable_binary = most_likely_binary_rev     measured_val = int(readable_binary, 2)     print(\"-------------- Result summary --------------\")     print(f\"( {b_val} + {a_val} * {x_val} ) MOD {N_val}\")     print(f\"Expected value:{expected_val}\")     print(f\"(Most likely) measured value: {measured_val} (binary: {readable_binary}), with shot {counts}\") <pre>SamplerPubResult(data=DataBin(b=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(b=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;))\ndict_keys(['b'])\n{'0010': 4096}\n-------------- Result summary --------------\n( 7 + 3 * 3 ) MOD 7\nExpected value:2\n(Most likely) measured value: 2 (binary: 0010), with shot {'0010': 4096}\n</pre> <p>Incrediable! you've just built and successfully tested the <code>CMULT(a)MOD(N)</code> gate!</p> In\u00a0[19]: Copied! <pre>class Controlled_U_a:\n    def __init__(self, n, x, c1 = 1, ctrl_aux = 1, check_flag=False):\n        \"\"\"Initialize the stress test with parameters a, b, and N.\"\"\"\n        self.n = n # number of bits for b\n        self.c1 = c1  # number of bits for c1\n        self.x = x  # number of bits for x\n        self.ctrl_aux = ctrl_aux  # index for aux control bit\n        self.check_flag = check_flag  # Flag to check aux control bit #TODO\n\n    def build(self, a_val, N_val):\n        # b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |\n        num_qubits = self.n + self.x + self.c1 + self.ctrl_aux  # +1 for ctrl_aux\n        qc = QuantumCircuit(num_qubits, name=f\"CTRL_U_({a_val}) MOD {N_val}\")\n        \n        idx = 0\n        qr_b = list(qc.qubits[idx : idx + self.n])\n        idx += self.n\n\n        # aux\n        qr_ctrl_aux = list(qc.qubits[idx : idx + self.ctrl_aux])\n        idx += self.ctrl_aux\n        \n        # ctrl_2 = x\n        qr_x = list(qc.qubits[idx : idx + self.x]) # ctrl_2 # check x length\n        idx += self.x\n        \n        qr_ctrl_1 = list(qc.qubits[idx : idx + self.c1])\n        \n        \"\"\"Build the Controlled-U_a gate.\"\"\"\n        # 1) a\u00b7x mod N controlled on qr_aux\u2192qr_b register\n        mult_gate = CMULTaMODN_c(n=self.n, x=self.x).build(a_val, N_val)\n        qc.append(mult_gate, qr_b + qr_ctrl_aux + qr_x + qr_ctrl_1)\n\n        # 2) swap x &lt;-&gt; b under qr_ctrl_1[0]\n        ctrl = qr_ctrl_1[0]\n        for i in range(self.x): \n            qc.cswap(ctrl, qr_x[i], qr_b[i])\n\n        # 3) inverse multiply to uncompute b\n        a_inv = pow(a_val, -1,N_val)\n        inv_gate = CMULTaMODN_c(n=self.n, x=self.x).build_inverse(a_inv, N_val)\n        qc.append(inv_gate, qr_b + qr_ctrl_aux + qr_x + qr_ctrl_1)\n        \n        return qc.to_gate()\n    \n    def build_inverse(self, a_val, N_val):\n        \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"\n        CTRL_U_a_gate = self.build(a_val, N_val)\n        return CTRL_U_a_gate.inverse()\n</pre> class Controlled_U_a:     def __init__(self, n, x, c1 = 1, ctrl_aux = 1, check_flag=False):         \"\"\"Initialize the stress test with parameters a, b, and N.\"\"\"         self.n = n # number of bits for b         self.c1 = c1  # number of bits for c1         self.x = x  # number of bits for x         self.ctrl_aux = ctrl_aux  # index for aux control bit         self.check_flag = check_flag  # Flag to check aux control bit #TODO      def build(self, a_val, N_val):         # b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |         num_qubits = self.n + self.x + self.c1 + self.ctrl_aux  # +1 for ctrl_aux         qc = QuantumCircuit(num_qubits, name=f\"CTRL_U_({a_val}) MOD {N_val}\")                  idx = 0         qr_b = list(qc.qubits[idx : idx + self.n])         idx += self.n          # aux         qr_ctrl_aux = list(qc.qubits[idx : idx + self.ctrl_aux])         idx += self.ctrl_aux                  # ctrl_2 = x         qr_x = list(qc.qubits[idx : idx + self.x]) # ctrl_2 # check x length         idx += self.x                  qr_ctrl_1 = list(qc.qubits[idx : idx + self.c1])                  \"\"\"Build the Controlled-U_a gate.\"\"\"         # 1) a\u00b7x mod N controlled on qr_aux\u2192qr_b register         mult_gate = CMULTaMODN_c(n=self.n, x=self.x).build(a_val, N_val)         qc.append(mult_gate, qr_b + qr_ctrl_aux + qr_x + qr_ctrl_1)          # 2) swap x &lt;-&gt; b under qr_ctrl_1[0]         ctrl = qr_ctrl_1[0]         for i in range(self.x):              qc.cswap(ctrl, qr_x[i], qr_b[i])          # 3) inverse multiply to uncompute b         a_inv = pow(a_val, -1,N_val)         inv_gate = CMULTaMODN_c(n=self.n, x=self.x).build_inverse(a_inv, N_val)         qc.append(inv_gate, qr_b + qr_ctrl_aux + qr_x + qr_ctrl_1)                  return qc.to_gate()          def build_inverse(self, a_val, N_val):         \"\"\"Builds the inverse gate to subtract the classical value a_val.\"\"\"         CTRL_U_a_gate = self.build(a_val, N_val)         return CTRL_U_a_gate.inverse() In\u00a0[20]: Copied! <pre>## test code\n## Controlled_U_a\n\na_val = 3\nN_val = 4\nx_val = 3\nx_len = get_bits(x_val-1)  # what out the x length for generalization\n\nb_val = 0\nn = x_len + 1\nprint(n)\n\nexpected_val =( b_val + a_val * x_val ) % N_val\n\n# b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |\n\n# Quantum + Classical Registers\nnum_qubits = n + x_len + 2 #(aux and ctrl_1)\nqr = QuantumRegister(num_qubits)\ncr = ClassicalRegister(x_len,'x')\nqc = QuantumCircuit(qr, cr)\n\n# Initialize b\napply_value(qc, b_val, 0, n)\n\n# Initialize x \napply_value(qc, x_val, n + 1, x_len)\n\n# Set control bits\n# init Ctrl_1\nqc.x(qr[-1])\n\n# Expected outcome (b + a*x) mod N = (4 + 3*3) MOD (7) = 13 MOD 7 = 6 -&gt; |0100&gt;\nqc.barrier()\n</pre> ## test code ## Controlled_U_a  a_val = 3 N_val = 4 x_val = 3 x_len = get_bits(x_val-1)  # what out the x length for generalization  b_val = 0 n = x_len + 1 print(n)  expected_val =( b_val + a_val * x_val ) % N_val  # b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |  # Quantum + Classical Registers num_qubits = n + x_len + 2 #(aux and ctrl_1) qr = QuantumRegister(num_qubits) cr = ClassicalRegister(x_len,'x') qc = QuantumCircuit(qr, cr)  # Initialize b apply_value(qc, b_val, 0, n)  # Initialize x  apply_value(qc, x_val, n + 1, x_len)  # Set control bits # init Ctrl_1 qc.x(qr[-1])  # Expected outcome (b + a*x) mod N = (4 + 3*3) MOD (7) = 13 MOD 7 = 6 -&gt; |0100&gt; qc.barrier()   <pre>4\n</pre> Out[20]: <pre>CircuitInstruction(operation=Instruction(name='barrier', num_qubits=9, num_clbits=0, params=[]), qubits=(&lt;Qubit register=(9, \"q2\"), index=0&gt;, &lt;Qubit register=(9, \"q2\"), index=1&gt;, &lt;Qubit register=(9, \"q2\"), index=2&gt;, &lt;Qubit register=(9, \"q2\"), index=3&gt;, &lt;Qubit register=(9, \"q2\"), index=4&gt;, &lt;Qubit register=(9, \"q2\"), index=5&gt;, &lt;Qubit register=(9, \"q2\"), index=6&gt;, &lt;Qubit register=(9, \"q2\"), index=7&gt;, &lt;Qubit register=(9, \"q2\"), index=8&gt;), clbits=())</pre> In\u00a0[21]: Copied! <pre># Build and append the multiplier \nmultiplier = Controlled_U_a(n=n, x = x_len).build(a_val, N_val)\nqc.append(multiplier, qr[:])\nqc.barrier()\n\n# Measure the result @ x\nqc.measure(qr[n+ 1 : n + x_len+1], cr)\n\nqc.decompose().decompose().draw('mpl')\n#qc.draw('mpl')\n</pre> # Build and append the multiplier  multiplier = Controlled_U_a(n=n, x = x_len).build(a_val, N_val) qc.append(multiplier, qr[:]) qc.barrier()  # Measure the result @ x qc.measure(qr[n+ 1 : n + x_len+1], cr)  qc.decompose().decompose().draw('mpl') #qc.draw('mpl') Out[21]: In\u00a0[22]: Copied! <pre>sampler = Sampler()\njob_CTRL_U_a = sampler.run([qc],shots=4096)\nresult = job_CTRL_U_a.result()\n\nprint(result[0])\n\nprint(result[0].data)\nprint(result[0].data._data.keys())\n\nbit_array = result[0].data['x']\ncounts = bit_array.get_counts()\nprint(counts)\n\nif counts:\n    #Qiskit returns binary strings in reverse order, so we flip it\n    most_likely_binary_rev = max(counts, key=counts.get)\n    readable_binary = most_likely_binary_rev\n    measured_val = int(readable_binary, 2)\n    print(\"-------------- Result summary --------------\")\n    print(f\"( {b_val} + {a_val} * {x_val} ) MOD {N_val}\")\n    print(f\"Expected value:{expected_val}\")\n    print(f\"(Most likely) measured value: {measured_val} (binary: {readable_binary}), with shot {counts}\")\n</pre> sampler = Sampler() job_CTRL_U_a = sampler.run([qc],shots=4096) result = job_CTRL_U_a.result()  print(result[0])  print(result[0].data) print(result[0].data._data.keys())  bit_array = result[0].data['x'] counts = bit_array.get_counts() print(counts)  if counts:     #Qiskit returns binary strings in reverse order, so we flip it     most_likely_binary_rev = max(counts, key=counts.get)     readable_binary = most_likely_binary_rev     measured_val = int(readable_binary, 2)     print(\"-------------- Result summary --------------\")     print(f\"( {b_val} + {a_val} * {x_val} ) MOD {N_val}\")     print(f\"Expected value:{expected_val}\")     print(f\"(Most likely) measured value: {measured_val} (binary: {readable_binary}), with shot {counts}\") <pre>SamplerPubResult(data=DataBin(x=BitArray(&lt;shape=(), num_shots=4096, num_bits=3&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(x=BitArray(&lt;shape=(), num_shots=4096, num_bits=3&gt;))\ndict_keys(['x'])\n{'001': 4096}\n-------------- Result summary --------------\n( 0 + 3 * 3 ) MOD 4\nExpected value:1\n(Most likely) measured value: 1 (binary: 001), with shot {'001': 4096}\n</pre> <p>Oh my god... you made it! \ud83c\udf89 You\u2019ve just implemented the Controlled-$U_{a}$ gate \u2014 a.k.a. the modular exponentiation gate \u2014 which is hands down one of the most difficult and expensive parts of Shor\u2019s algorithm!</p> <p>This gate is the core of quantum period finding, and now that you\u2019ve built it from scratch, you\u2019re ready to put everything together.</p> <p>Let\u2019s run our handmade version of Shor\u2019s algorithm using the following code block!</p> In\u00a0[23]: Copied! <pre># circuit layout\n# b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |\n\n# --- Parameters ---\na_val = 7 \nN_val = 15\nn = get_bits(N_val)-1 # should be 4 for 15\nt = 1*n # For demonstration\n\n#   1. Create the Parent Circuit ---\ncounting_register = QuantumRegister(t, name='t') # ctrl_ 1 \ntarget_register = QuantumRegister(n, name='target') # Target, U gate, init to |1&gt;\nancilla_b_reg = QuantumRegister(n, name='ancilla_b')\nctrl_aux_reg = QuantumRegister(1, name='ctrl_aux')\n\ncr = ClassicalRegister(t,'cr')\nqc = QuantumCircuit(counting_register, target_register, ancilla_b_reg, ctrl_aux_reg, cr)\n\n#   2. Initialize the Registers ---\nprint(\"Initializing registers...\")\nqc.h(counting_register) # Put counting register in superposition\nqc.x(target_register) # Initialize target register to |1&gt;\nqc.barrier()\n\n#   3. The Core Loop: This is there t = 8 is used ---\nprint(\"Building and applying Controlled-Ua gates...\")\n\nCtrl_U_a_gate = Controlled_U_a(n=n, x=n).build(a_val=a_val, N_val=N_val)\n\nfor i in range(t): \n    U_a_power = 2**i\n    for j in range(U_a_power):\n        # b[0]...b[n-1] | a[0]...a[m-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |\n        qubit_list = ancilla_b_reg[:] + ctrl_aux_reg[:]  + target_register[:] + [counting_register[i]]\n        qc.append(Ctrl_U_a_gate, qubit_list)\n\n# Apply inverse QFT\nprint(\"Applying Inverse QFT...\")\niqft = QFTBlock(t+2*n+1)\nqc.append(iqft_gate, counting_register)\nqc.barrier()\n\n# Measure t register\nqc.measure(counting_register, cr)\n\n# Print our circuit.\nprint(\"Drawing circuit diagram...\")\nqc.draw('mpl')\n</pre> # circuit layout # b[0]...b[n-1] | a[0]...a[m-1] | N[0]...N[l-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |  # --- Parameters --- a_val = 7  N_val = 15 n = get_bits(N_val)-1 # should be 4 for 15 t = 1*n # For demonstration  #   1. Create the Parent Circuit --- counting_register = QuantumRegister(t, name='t') # ctrl_ 1  target_register = QuantumRegister(n, name='target') # Target, U gate, init to |1&gt; ancilla_b_reg = QuantumRegister(n, name='ancilla_b') ctrl_aux_reg = QuantumRegister(1, name='ctrl_aux')  cr = ClassicalRegister(t,'cr') qc = QuantumCircuit(counting_register, target_register, ancilla_b_reg, ctrl_aux_reg, cr)  #   2. Initialize the Registers --- print(\"Initializing registers...\") qc.h(counting_register) # Put counting register in superposition qc.x(target_register) # Initialize target register to |1&gt; qc.barrier()  #   3. The Core Loop: This is there t = 8 is used --- print(\"Building and applying Controlled-Ua gates...\")  Ctrl_U_a_gate = Controlled_U_a(n=n, x=n).build(a_val=a_val, N_val=N_val)  for i in range(t):      U_a_power = 2**i     for j in range(U_a_power):         # b[0]...b[n-1] | a[0]...a[m-1] | ctrl_aux | x[0]...x[x-1] | ctrl_1 |         qubit_list = ancilla_b_reg[:] + ctrl_aux_reg[:]  + target_register[:] + [counting_register[i]]         qc.append(Ctrl_U_a_gate, qubit_list)  # Apply inverse QFT print(\"Applying Inverse QFT...\") iqft = QFTBlock(t+2*n+1) qc.append(iqft_gate, counting_register) qc.barrier()  # Measure t register qc.measure(counting_register, cr)  # Print our circuit. print(\"Drawing circuit diagram...\") qc.draw('mpl') <pre>Initializing registers...\nBuilding and applying Controlled-Ua gates...\nApplying Inverse QFT...\nDrawing circuit diagram...\n</pre> Out[23]: In\u00a0[24]: Copied! <pre>sampler = Sampler()\njob_PE_MOD_15 = sampler.run([qc],shots=4096*2)\nresult = job_PE_MOD_15.result()\n\nprint(result[0])\nprint(result[0].data)\nprint(result[0].data._data.keys())\n\nbit_array = result[0].data['cr']\ncounts = bit_array.get_counts()\nprint(counts)\n\n#TODO: add historgram plot\n</pre> sampler = Sampler() job_PE_MOD_15 = sampler.run([qc],shots=4096*2) result = job_PE_MOD_15.result()  print(result[0]) print(result[0].data) print(result[0].data._data.keys())  bit_array = result[0].data['cr'] counts = bit_array.get_counts() print(counts)  #TODO: add historgram plot  <pre>SamplerPubResult(data=DataBin(cr=BitArray(&lt;shape=(), num_shots=8192, num_bits=4&gt;)), metadata={'shots': 8192, 'circuit_metadata': {}})\nDataBin(cr=BitArray(&lt;shape=(), num_shots=8192, num_bits=4&gt;))\ndict_keys(['cr'])\n{'1010': 495, '1101': 526, '1001': 526, '0100': 515, '1011': 510, '1000': 485, '0101': 485, '0111': 524, '0011': 535, '1100': 526, '0010': 550, '0000': 506, '0110': 484, '1110': 520, '1111': 501, '0001': 504}\n</pre> In\u00a0[25]: Copied! <pre>from fractions import Fraction\n# Get the most frequent measurement\nmeasured_string = max(counts, key=counts.get)\ny = int(measured_string, 2)\nprint(f\"Most frequent measurement: |{measured_string}&gt; (y = {y})\")\n\n## 5. Classical Post-Processing\nprint(\"\\nStarting classical post-processing...\")\nphase = y / (2**t)\nprint(f\"Phase (\u03c6) = y / 2^t = {y}/{2**t} = {phase}\")\n\n# Use Continued Fractions to find the period r\nfrac = Fraction(phase).limit_denominator(N_val)\ns, r = frac.numerator, frac.denominator\nprint(f\"Continued fractions result: s/r = {s}/{r}\")\n\nif r % 2 != 0:\n        print(f\"Period r={r} is odd. Algorithm fails. Please try another 'a'.\")\nelse:\n    x = pow(a_val, r // 2, N_val)\n    if (x + 1) % N_val == 0:\n        print(f\"x+1 is a multiple of N. Algorithm fails. Please try another 'a'.\")\n    else:\n        factor1 = math.gcd(x - 1, N_val)\n        factor2 = math.gcd(x + 1, N_val)\n        print(\"\\n\" + \"=\"*20)\n        print(f\"SUCCESS: Factors are {factor1} and {factor2}\")\n        print(\"=\"*20)\n</pre> from fractions import Fraction # Get the most frequent measurement measured_string = max(counts, key=counts.get) y = int(measured_string, 2) print(f\"Most frequent measurement: |{measured_string}&gt; (y = {y})\")  ## 5. Classical Post-Processing print(\"\\nStarting classical post-processing...\") phase = y / (2**t) print(f\"Phase (\u03c6) = y / 2^t = {y}/{2**t} = {phase}\")  # Use Continued Fractions to find the period r frac = Fraction(phase).limit_denominator(N_val) s, r = frac.numerator, frac.denominator print(f\"Continued fractions result: s/r = {s}/{r}\")  if r % 2 != 0:         print(f\"Period r={r} is odd. Algorithm fails. Please try another 'a'.\") else:     x = pow(a_val, r // 2, N_val)     if (x + 1) % N_val == 0:         print(f\"x+1 is a multiple of N. Algorithm fails. Please try another 'a'.\")     else:         factor1 = math.gcd(x - 1, N_val)         factor2 = math.gcd(x + 1, N_val)         print(\"\\n\" + \"=\"*20)         print(f\"SUCCESS: Factors are {factor1} and {factor2}\")         print(\"=\"*20) <pre>Most frequent measurement: |0010&gt; (y = 2)\n\nStarting classical post-processing...\nPhase (\u03c6) = y / 2^t = 2/16 = 0.125\nContinued fractions result: s/r = 1/8\n\n====================\nSUCCESS: Factors are 15 and 1\n====================\n</pre> <p>\u26a0\ufe0f You may not directly obtain 3 and 5 as the result due to the limited precision we chose. To improve accuracy, you can either use <code>t = 2n</code> or follow the textbook method:</p> <p>$$ t = 2L + 1 + \\left\\lceil \\log\\left(2 + \\frac{1}{2\\epsilon}\\right) \\right\\rceil = O(L) $$</p> <p>Fortunately, I\u2019ve implemented a loop that keeps trying until we avoid trivial or odd values of $r$, so eventually we\u2019ll recover the correct factors \u2014 3 and 5 \u2014 using the <code>gcd</code> result!</p> In\u00a0[26]: Copied! <pre># A loop that finds the non-trival solution \n\n\ndef sampling():\n    print(\"Sampling...\")\n    sampler = Sampler()\n    job = sampler.run([qc], shots=8192)\n    result = job.result()\n    counts = result[0].data['cr'].get_counts()\n    return counts\n\ndef post_processing(counts):\n    measured_string = max(counts, key=counts.get)\n    y = int(measured_string, 2)\n    print(f\"Most frequent measurement: |{measured_string}&gt; (y = {y})\")\n\n    phase = y / (2**t)\n    print(f\"Phase (\u03c6) = y / 2^t = {y}/{2**t} = {phase}\")\n\n    frac = Fraction(phase).limit_denominator(N_val)\n    s, r = frac.numerator, frac.denominator\n    print(f\"Continued fractions result: s/r = {s}/{r}\")\n    return r\n\nNon_trivial = False\nwhile not Non_trivial:\n    counts = sampling()\n    r = post_processing(counts)\n\n    if r % 2 != 0:\n        print(\"case1: r is odd\")\n        continue\n\n    x = pow(a_val, r // 2, N_val)\n    if (x + 1) % N_val == 0:\n        print(\"case2: x + 1 \u2261 0 mod N\")\n        continue\n\n    factor1 = math.gcd(x - 1, N_val)\n    factor2 = math.gcd(x + 1, N_val)\n    if factor1 == 1 or factor2 == 1:\n        print(\"case3: one factor is trivial (1)\")\n        continue\n\n    print(\"\\n\" + \"=\" * 20)\n    print(f\"SUCCESS: Factors are {factor1} and {factor2}\")\n    print(\"=\" * 20)\n    Non_trivial = True\n\n            \n</pre> # A loop that finds the non-trival solution    def sampling():     print(\"Sampling...\")     sampler = Sampler()     job = sampler.run([qc], shots=8192)     result = job.result()     counts = result[0].data['cr'].get_counts()     return counts  def post_processing(counts):     measured_string = max(counts, key=counts.get)     y = int(measured_string, 2)     print(f\"Most frequent measurement: |{measured_string}&gt; (y = {y})\")      phase = y / (2**t)     print(f\"Phase (\u03c6) = y / 2^t = {y}/{2**t} = {phase}\")      frac = Fraction(phase).limit_denominator(N_val)     s, r = frac.numerator, frac.denominator     print(f\"Continued fractions result: s/r = {s}/{r}\")     return r  Non_trivial = False while not Non_trivial:     counts = sampling()     r = post_processing(counts)      if r % 2 != 0:         print(\"case1: r is odd\")         continue      x = pow(a_val, r // 2, N_val)     if (x + 1) % N_val == 0:         print(\"case2: x + 1 \u2261 0 mod N\")         continue      factor1 = math.gcd(x - 1, N_val)     factor2 = math.gcd(x + 1, N_val)     if factor1 == 1 or factor2 == 1:         print(\"case3: one factor is trivial (1)\")         continue      print(\"\\n\" + \"=\" * 20)     print(f\"SUCCESS: Factors are {factor1} and {factor2}\")     print(\"=\" * 20)     Non_trivial = True               <pre>Sampling...\nMost frequent measurement: |0011&gt; (y = 3)\nPhase (\u03c6) = y / 2^t = 3/16 = 0.1875\nContinued fractions result: s/r = 2/11\ncase1: r is odd\nSampling...\nMost frequent measurement: |1111&gt; (y = 15)\nPhase (\u03c6) = y / 2^t = 15/16 = 0.9375\nContinued fractions result: s/r = 14/15\ncase1: r is odd\nSampling...\nMost frequent measurement: |0101&gt; (y = 5)\nPhase (\u03c6) = y / 2^t = 5/16 = 0.3125\nContinued fractions result: s/r = 4/13\ncase1: r is odd\nSampling...\nMost frequent measurement: |1100&gt; (y = 12)\nPhase (\u03c6) = y / 2^t = 12/16 = 0.75\nContinued fractions result: s/r = 3/4\n\n====================\nSUCCESS: Factors are 3 and 5\n====================\n</pre> <p>\ud83c\udf89 Congratulations! You\u2019ve just completed one of the most exciting topics in quantum computing: Shor\u2019s algorithm, built entirely from scratch using basic quantum gates. This is a major step toward understanding how quantum computers can solve problems that classical methods simply can\u2019t. You\u2019ve just unleashed quantum power where classical algorithms fall short!</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#building-shors-algorithm-from-scratch-factoring-15","title":"Building Shor\u2019s Algorithm from Scratch: Factoring 15\u00b6","text":""},{"location":"quantum_computation/jupyter_qc/Shor%27s/#notebook-overview","title":"Notebook Overview \u269b\ufe0f\u00b6","text":"<p>This notebook walks you through one of the most fascinating applications of quantum computing \u2014 Shor\u2019s algorithm \u2014 built entirely from scratch using only basic quantum gates in Qiskit, without relying on any pre-built libraries or high-level abstractions.</p> <p>In this notebook, we manually construct the quantum portion of Shor\u2019s algorithm to factor the integer $15$. Shor\u2019s algorithm efficiently factors large integers by reducing the problem to period finding, which is solved using the quantum phase estimation (QPE) subroutine.</p> <p>We assume <code>gcd(a, N) = 1</code>, so that modular inverse operations and periodicity are well-defined. The quantum routine estimates the period $r$ of the function $f(x) = a^x \\mod N$, which is then used classically to compute the factors of $N$.</p> <p>This notebook focuses only on the quantum circuit construction and skips the classical post-processing steps like computing the continued fraction or checking factor conditions. The implementation draws on techniques from the Qiskit community tutorial and the works of Draper and Beauregard.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#shors-algorithm-overview","title":"Shor's Algorithm overview \ud83d\udc40\u00b6","text":"<p>Inputs: A composite number $N$.</p> <p>Outputs: A non-trival factor of $N$.</p> <p>Procedure:</p> <ol> <li>If $N$ is even, return the factor 2.</li> <li>Deteremine whether $N = a^{b}$ for integers $a\\geq 1$ and $b\\geq 2$, if so return the factor $a$.</li> <li>Randomly choose $a$ in the range $1$ to $N-1$. if $\\text{gcd}(a,N)\\geq 1$ then return the factor $\\text{gcd}(a,N)$.</li> <li>Use the order-finding subroutine to find the order $r$ of $$ f(a) = x^{a} \\text{mod} \\ N $$</li> <li>If $r$ is even and $x^{r/2} \\neq -1(\\text{mod}\\ N)$  then compute $\\text{gcd}(x^{r/2}\\pm 1,N)$ and test to see if one of these is a non-trival factor, returning that factor if so. Otherwise, the algorithm fails and back to step 1.</li> </ol>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#from-factorization-to-period-finding","title":"From Factorization to Period Finding \u2697\ufe0f\u00b6","text":"<p>From Qiskit community tutorial, the number thoery that underlines Shor's algorithm relates to periodic modulo sequences. Let's have a look at an example of such a sequence. Let's consider the sequence of the power of two:</p> <p>$$ 1,\\ 2,\\ 4,\\ 8,\\ 16,\\ 32,\\ 64,\\ 128,\\ 256,\\ 512,\\ 1024,\\ \\dots $$</p> <p>Now compute each value modulo 15:</p> <p>$$ 1,\\ 2,\\ 4,\\ 8,\\ 1,\\ 2,\\ 4,\\ 8,\\ 1,\\ 2,\\ 4,\\ \\dots $$</p> <p>and we can easily see that sequence repeats every four numbers, and this is the periodic modulo sequence with a period of $4$.</p> <p>The reduction of factorization of $N$ to the problem of finding the period of an integer $x$ less than $N$ and greater than $1$ depends on the following result from number theory:</p> <p>The function $\\mathcal{F}(a) = x^{a} (\\text{mod}\\ N)$ is periodic function, where $x$ is an integer coprime to $N$ and $a \\geq 0$.</p> <p>Note that two numers are coprime, if the only positive integer that divides both of them is 1, for example, $\\text{gcd}(2,9) = 1$ and $\\text{gcd}(8,15) = 1$, for an examples. On the other hand, $\\text{gcd}(2,8) = 2$, so $2$ and $8$ are not coprime.</p> <p>Since $\\mathcal{F}(a)$ is a periodic function, it has some period $r$. Knowing that $x^{0} \\text{mod} \\ N =1$, this means that $x^{r} \\text{mod} \\ N =1$ since the function is periodic, and thus $r$ is just the first non-zero power where $x^{r} = 1 \\ \\text{mod}$ (the result that we are looking for in the order finding problem).</p> <p>Based on some basic algebras:</p> <p>$$ \\begin{array}{c} x^{r} \\equiv 1\\ \\text{mod}\\\\ x^{r} = (x^{r/2})^{2} \\equiv 1\\ \\text{mod}\\\\ (x^{r/2})^{2} - 1 \\equiv 0\\ \\text{mod}\\\\ (x^{r/2} + 1)(x^{r/2} - 1) \\equiv 0\\ \\text{mod} \\end{array} $$</p> <p>The product $(x^{r/2} + 1)(x^{r/2} - 1) \\equiv 0\\ \\text{mod}$ is an integer multiple of $N$, the number to be factored. Thus, as long as $(x^{r/2} + 1)$ of $(x^{r/2} - 1)$ is not a multiple of $N$, then at least one of $(x^{r/2} + 1)$ or $(x^{r/2} - 1)$ must have a nontrivial factor in common with $N$.</p> <p>Therefore, we can also know that calculate both $\\text{gcd}(x^{r/2} \\pm 1,N)$ will obtain a factor of $N$, which can be accomlished by using Euclidean algorithm.</p> <p>Please find Qiskit community tutorial for more details!</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#a-very-simple-example-trust-me","title":"A Very Simple Example! Trust Me! \u270d\ufe0f\u00b6","text":"<p>Just in case you're already a bit lost, let\u2019s walk through a super simple example to build intuition.</p> <p>Consider the sequence of powers of 2:</p> <p>$$ 1,\\ 2,\\ 4,\\ 8,\\ 16,\\ 32,\\ 64,\\ 128,\\ 256,\\ 512,\\ 1024,\\ \\dots $$</p> <p>Now compute each value modulo 15:</p> <p>$$ 1,\\ 2,\\ 4,\\ 8,\\ 1,\\ 2,\\ 4,\\ 8,\\ 1,\\ 2,\\ 4,\\ \\dots $$</p> <p>Clearly, the sequence repeats every 4 steps. This is the key idea behind Shor\u2019s algorithm: finding the period $r$ of the function:</p> <p>$$ \\mathcal{F}(a) = x^a \\bmod N $$</p> <p>Let\u2019s pick $x = 2$, so we\u2019re computing:</p> <p>$$ \\mathcal{F}(a) = 2^a \\bmod 15 $$</p> <p>From the sequence above, we see:</p> <p>$$ 2^4 \\bmod 15 = 16 \\bmod 15 = 1 $$</p> <p>Thus, the period is $r = 4$.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#finding-factors","title":"Finding Factors\u00b6","text":"<p>Now that we\u2019ve found a non-trivial period $r = 4$, we compute:</p> <p>$$ \\gcd(2^{r/2} \\pm 1,\\ 15) = \\gcd(2^2 \\pm 1,\\ 15) = \\gcd(5,15)\\ \\text{and}\\ \\gcd(3,15) $$</p> <p>That gives us:</p> <ul> <li>$\\gcd(5,15) = 5$</li> <li>$\\gcd(3,15) = 3$</li> </ul> <p>Boom! We\u2019ve factored 15 as $3 \\times 5$!</p> <p>A piece of cake \ud83c\udf70, right? Hold tight \u2014 we will talk about Quantum Phase Estumation (QPE) then begin constructing the actual quantum circuit.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#quantum-phase-estimation-qpe","title":"Quantum Phase Estimation (QPE)\u00b6","text":"<p>\ud83d\udccc Extracted from M. A. Nielsen and I. L. Chuang, *Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.*</p> <p>         Schematic of the overall phase estimation procedure.     </p> <p>The Quantum Fourier transformation is the key to a general procedure know as phase estimation, which in turn is the key for many quantum algorithms. Suppose a unitary operator $U$ has an eigenvector $|u\\rangle$ with eigenvalue $e^{2\\pi i\\phi}$,  where the value of $\\phi$ is unknown. The goal of the phase estimation is to estimate $\\phi$. To perform the estimation we assume that we have available black boxes (oracles) capable of preparing the state $|u\\rangle$ and performing the controlled-$U^{2^{j}}$ operation, for sutible non-negative integers $j$.</p> <p>The quantum phase estimation procedure uses two registers. The first register contains $t$ qubits initially in the state $|0\\rangle$. How we choose $t$ depends on two things:</p> <ol> <li>The number of digits of accuracy we wish to have in our estimate for $\\phi$.</li> <li>With what probability we wish the phase estimation precedure to be successful.</li> </ol> <p>The second register begins in the state $|u\\rangle$, and contains as many qubits as is necessary to store $|u\\rangle$.</p> <p>Phase estimation is performed in two stages.</p> <ol> <li>First, the circuit begins by applying a Hadamard transform to the first register, followed by application of controlled-$U$ operations on the second register, with $U$ raised to successive powers of two. The final state of the first registers can be seen as:</li> </ol> <p>$$ \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i (2^{t}-1)\\phi}|1\\rangle)(|0\\rangle + e^{2\\pi i (2^{t}-2)\\phi}|1\\rangle)...(|0\\rangle + e^{2\\pi i (2^{0})\\phi}|1\\rangle) = \\frac{1}{2^{t/2}}\\sum_{k=0}^{2^{t}-1}e^{2\\pi i \\phi k}|k\\rangle $$</p> <p>We omit the second register from this description, since it stays in the state $|u\\rangle$ throughout the computation.</p> <p>         The frist stage of the phase estiamtion procedure. Normalization factors of $1/\\sqrt{2}$ have been omitted on the right.     </p> <ol> <li>The second stage of the phase estimation is to apply the inverse quantum Fourier transform on the first register. This is obtained by reversing the circuit for the quantum Fourier transform in the previous section, and can be done in $\\Theta(t^{2})$ steps. The third and final stage of phase estimation is to read out the state of the first register by doing a measurement in the computational basis. An overall schematic of the algorithm is shown below:</li> </ol> <p>To sharpen our intuition as to why phase estimation works, suppose $\\phi$ may be expressed exactly in $t$ bits, as $\\phi = 0.\\phi{1}...\\phi{t}$. Then the state</p> <p>$$ \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i (2^{t}-1)\\phi}|1\\rangle)(|0\\rangle + e^{2\\pi i (2^{t}-2)\\phi}|1\\rangle)...(|0\\rangle + e^{2\\pi i (2^{0})\\phi}|1\\rangle) = \\frac{1}{2^{t/2}}\\sum_{k=0}^{2^{t}-1}e^{2\\pi i \\phi k}|k\\rangle $$</p> <p>resulting from the first state of phase estimation may be written</p> <p>$$ \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i0.\\phi_{t}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.\\phi_{t-1}\\phi_{t}}|1\\rangle)...(|0\\rangle + e^{2\\pi i 0.\\phi_{1}\\phi_{2}...\\phi_{t}}|1\\rangle). $$</p> <p>The second stage of phase estimation is to apply the inverse quantum Fourier transform. By comparing the previous equation with the product form the Fourier transform,</p> <p>$$ |j_{1},...,j_{n}\\rangle \\rightarrow \\frac{(|0\\rangle + e^{2\\pi i0.j_{n}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.j_{n-1}j_{n}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.j_{1}j_{2}\\cdots j_{n}}|1\\rangle)}{2^{n/2}}. $$</p> <p>we see that the output state from the second stage is the product state $|\\phi_{1}...\\phi_{t}\\rangle$. $$ \\frac{1}{2^{t/2}}(|0\\rangle + e^{2\\pi i0.\\phi_{t}}|1\\rangle)(|0\\rangle + e^{2\\pi i0.\\phi_{t-1}\\phi_{t}}|1\\rangle)...(|0\\rangle + e^{2\\pi i 0.\\phi_{1}\\phi_{2}...\\phi_{t}}|1\\rangle) \\text{QFT}^{\\dagger}\\rightarrow |\\phi_{1}...\\phi_{t}\\rangle $$</p> <p>A measurement in the computational basis therefore gives us $\\phi$ exactly!</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#references","title":"References\u00b6","text":"<ol> <li><p>Thomas G. Draper (2000). Addition on a Quantum Computer. arXiv:quant-ph/0008033v1 Introduces the quantum addition circuit based on the Quantum Fourier Transform.</p> </li> <li><p>St\u00e9phane Beauregard (2003). Circuit for Shor\u2019s Algorithm Using 2n+3 Qubits. arXiv:quant-ph/0205095 Optimized Shor's algorithm circuit using fewer qubits.</p> </li> <li><p>M. A. Nielsen and I. L. Chuang, Quantum Computation and Quantum Information, 10th Anniversary Ed., Cambridge: Cambridge University Press, 2010.</p> </li> <li><p>Qiskit Community. Shor's Algorithm for Integer Factorization \u2013 Tutorial Notebook. GitHub: qiskit-community-tutorials</p> </li> <li><p>Qiskit Implementation of Shor\u2019s Algorithm. Source: qiskit/algorithms/factorizers/shor.py</p> </li> <li><p>Qiskit Quantum Fourier Transform (QFT) \u2013 Circuit library documentation. API Reference</p> </li> <li><p>Qiskit Controlled Phase Gate (CPhaseGate) \u2013 Used in QFT and QADD routines. API Reference</p> </li> <li><p>Qiskit Internal QFT Decomposition Code \u2013 Shows how QFT is built from basic gates. Source code</p> </li> <li><p>Ckassiq - Shor's Algorithm - Shor's Algorithm</p> </li> </ol>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#qubit-ordering-read-me","title":"Qubit Ordering (READ ME!)\u00b6","text":"<p>Qubits used in this notebook are ordered as $|q_{n-1}, \\dots, q_0\\rangle$, where <code>q_0</code> is the least significant bit (LSB) and <code>q_{n-1}</code> is the most significant bit (MSB), following Qiskit's convention. For example, the integer 6 is encoded as $|110\\rangle$, with MSB <code>q_2</code> on the left and LSB as <code>q_0</code> on the right.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#quantum-arithmetic-circuit-blocks","title":"Quantum Arithmetic Circuit Blocks\u00b6","text":"<p>This notebook implements quantum arithmetic gates based on the methods from Draper (2000) and Beauregard (2003).</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#included-components","title":"Included Components\u00b6","text":"<ol> <li><code>QFTBlock</code> \u2013 Quantum Fourier Transform (QFT) circuit.</li> <li><code>QADDERBlock</code> \u2013 Quantum adder for adding classical constants to quantum registers using phase rotations.</li> <li><code>add_mod_N_classic</code> \u2013 Modular addition circuit computing $(a + b) \\bmod N$, where $a$ is classical.</li> <li><code>CMULTaMODN_c</code> \u2013 Controlled modular multiplier gate for classical constant $a$.</li> <li><code>Controlled_U_a</code> \u2013 Controlled modular exponentiation circuit computing $a^x \\bmod N$.</li> </ol>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#quantum-fourier-transform-qft","title":"Quantum Fourier Transform (QFT)\u00b6","text":"<p>A powerful strategy in mathematics and computer science is to transform a problem into a different domain where it becomes easier to solve. One such transformation is the discrete Fourier transform (DFT).</p> <p>In standard notation, the DFT maps a vector $x_0, x_1, \\ldots, x_{N-1}$ of complex amplitudes to another vector $y_0, y_1, \\ldots, y_{N-1}$, defined as:</p> <p>$$ y_k = \\frac{1}{\\sqrt{N}} \\sum_{j=0}^{N-1} x_j e^{2\\pi i jk / N}. $$</p> <p>The quantum Fourier transform (QFT) applies this same transformation within a quantum circuit. In the quantum context, we work over the orthonormal computational basis states $|0\\rangle, |1\\rangle, \\ldots, |N-1\\rangle$, and the QFT is defined as a linear operator acting on these basis states:</p> <p>$$ |j\\rangle \\rightarrow \\frac{1}{\\sqrt{N}} \\sum_{k=0}^{N-1} e^{2\\pi i jk / N} |k\\rangle. $$</p> <p>On an arbitrary quantum state $\\sum_{j=0}^{N-1} x_j |j\\rangle$, the QFT maps the amplitudes $x_j$ to their discrete Fourier transform $y_k$, yielding:</p> <p>$$ \\sum_{j=0}^{N-1} x_j |j\\rangle \\rightarrow \\sum_{k=0}^{N-1} y_k |k\\rangle. $$</p> <p>Though this definition involves complex exponentials, the QFT is a unitary transformation, which ensures it can be implemented on a quantum computer using a sequence of quantum gates.</p> <p>         Efficient circuit for the quantum Fourier transform. Not shown are swap gates at the end of the circuit which reverse the order of the qubitsm or normalization factors of $1/\\sqrt{2}$ in the output.     </p> <p>For a deeper dive into the mathematical structure and circuit-level implementation, see: Understanding the Quantum Fourier Transform.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#building-qft-gate","title":"Building QFT gate\u00b6","text":""},{"location":"quantum_computation/jupyter_qc/Shor%27s/#testing-our-qft-gate","title":"Testing Our QFT Gate\u00b6","text":"<p>To verify our <code>QFTBlock</code> and its inverse, we prepare a 4-qubit input state representing the binary number $b = 5$, i.e., $|0101\\rangle$.</p> <p>Following Qiskit's convention, the qubit ordering is:</p> <p>$$ |b_3\\, b_2\\, b_1\\, b_0\\rangle = |qr[3],\\, qr[2],\\, qr[1],\\, qr[0]\\rangle $$</p> <p>We apply the <code>QFTBlock</code> followed by its inverse (<code>QFTBlock.inverse()</code>). If implemented correctly, the circuit should return the system to the original state $|0101\\rangle$.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#quantum-adder-gate-adda-based-on-beauregards-construction","title":"Quantum Adder Gate (<code>\u03c6ADD(a)</code>) \u2013 Based on Beauregard's Construction\u00b6","text":"<p>In Shor\u2019s algorithm, we don't need to add two full quantum registers. Instead, we only need to add a known classical value $a$ to a quantum register $|b\\rangle$, as the goal is to compute $a^x \\mod N$, where $a$ is a fixed classical number.</p> <p>As described in Beauregard (2003), this can be done efficiently in the Fourier space, using the <code>\u03c6ADD(a)</code> gate. This circuit applies a set of single-qubit phase shift gates, where the angles are determined by the classical bits of $a$. Since $a$ is known in advance, all gate parameters can be precomputed, and no additional quantum register is needed for $a$. This minimizes both qubit count and circuit depth.</p> <p>To prevent overflow in modular arithmetic, we extend the quantum register holding $b$ from $n$ to $n+1$ qubits. The quantum state $|b\\rangle$ is first transformed using QFT, and the least significant qubit is ensured to be $|0\\rangle$ before addition. This ensures that $\\phi(b)$ behaves like the QFT of a proper $(n+1)$-bit integer.</p> <p>Beauregard introduces visual conventions in the circuit diagrams:</p> <ul> <li>A thick black bar on the right marks the inverse of the <code>\u03c6ADD(a)</code> gate.</li> <li>A thick bar on the left denotes the standard forward <code>\u03c6ADD(a)</code> gate.</li> <li>The unitary inverse $\u03c6ADD(-a)$ is used for subtraction and comparison circuits.</li> </ul> <p>These design decisions help save qubits and simplify implementation, especially for modular adders and controlled arithmetic gates required in Shor\u2019s algorithm.</p> <p>         The quantum addition as described by Draper.     </p> <p>         The circuit for addition of a classical value a to the quantum value b in the Fourier space.     </p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#adding-classical-number-directly-using-phase-rotation-optimzied-way","title":"Adding Classical Number Directly Using Phase Rotation (optimzied way)\u00b6","text":"<p>In the Fourier basis, adding a classical number $a$ to a quantum register $|b\\rangle$ can be performed efficiently without needing a second quantum register. This technique applies a sequence of single-qubit phase rotations directly to the qubits of $|b\\rangle$ in the QFT basis.</p> <p>Because $a$ is a known constant, all rotation angles can be precomputed and applied without control logic or ancillae. This eliminates the need for complex carry operations and significantly reduces both qubit count and gate depth.</p> <p>The following gate, <code>QAdderClassicalBlock</code>, implements this technique to achieve more resource-efficient and faster quantum addition.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#modular-addition-add_mod_n-using-phase-rotation-based-qft-adder","title":"Modular Addition (<code>add_mod_N</code>) Using Phase Rotation-Based QFT Adder\u00b6","text":"<p>Once we have a working <code>\u03c6ADD(a)</code> gate that adds a classical number $a$ in the Fourier basis, we can extend it to perform modular addition \u2014 that is, compute $(a + b) \\bmod N$ for a classical $a$ and a quantum register $|b\\rangle$.</p> <p>This is non-trivial because we must ensure that if $a + b \\geq N$, we subtract $N$ \u2014 but do so reversibly, without leaking any information or corrupting ancilla qubits.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#core-construction-based-on-beauregards-circuit","title":"Core Construction (Based on Beauregard\u2019s Circuit)\u00b6","text":"<ul> <li>Input: A QFT-encoded quantum register $|b\\rangle$ with $b &lt; N$, and a classical constant $a &lt; N$.</li> <li>Step 1: Apply <code>\u03c6ADD(a)</code> to obtain $\u03c6(a + b)$.</li> <li>Step 2: Apply inverse <code>\u03c6ADD(N)</code> to compute $\u03c6(a + b - N)$.</li> <li>Step 3: Introduce an ancilla qubit initialized to $|0\\rangle$ to determine if subtraction was needed:<ul> <li>Apply an inverse QFT to read out the most significant bit (MSB).</li> <li>Use a CNOT to copy the MSB into the ancilla.</li> <li>Apply QFT again to return to the Fourier basis.</li> </ul> </li> <li>Step 4: Conditionally apply <code>\u03c6ADD(N)</code> using the ancilla as control \u2014 to restore the subtracted $N$ if $a + b &lt; N$.</li> <li>Step 5: The ancilla now contains garbage; we must uncompute it:<ul> <li>Use a NOT + CNOT + inverse QFT + inverse <code>\u03c6ADD(a)</code> to bring the ancilla back to $|0\\rangle$.</li> </ul> </li> <li>Step 6: Resulting register now holds $\u03c6((a + b) \\bmod N)$ and a clean ancilla.</li> </ul> <p>\ud83d\udd25 The role of the final <code>\u03c6ADD(a)</code> and ancilla cleanup is crucial \u2014 it allows qubit reuse and ensures no unintended entanglement or decoherence.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#optimization-tip","title":"Optimization Tip\u00b6","text":"<p>Beauregard's circuit cleverly avoids excess overhead by only double-controlling the <code>\u03c6ADD(a)</code> gates, not the full modular addition circuit. This keeps depth and complexity manageable, especially for large $N$.</p> <p>\ud83d\udccc For a visual and code-based explanation of this logic, refer to: Classiq\u2019s Shor Notebook</p> <p>         The circuit for addition of a classical value a to the quantum value b in the Fourier space.     </p> <p>\ud83d\udccc Don't forget initializing <code>ctrl_1</code> and <code>ctrl_2</code> to $|1\\rangle$ otherwise you will just get $|b\\rangle$ \ud83d\ude02.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#controlled-modular-multiplier-gate-cmultamodn_c","title":"Controlled Modular Multiplier Gate (<code>CMULTaMODN_c</code>)\u00b6","text":"<p>To build the controlled modular multiplication gate needed in Shor\u2019s algorithm, we use the doubly controlled <code>\u03c6ADD(a)MOD(N)</code> gate introduced earlier.</p> <p>This gate, called <code>CMULT(a)MOD(N)</code>, takes three inputs:</p> <p>$$ |c\\rangle|x\\rangle|b\\rangle $$</p> <p>and computes the operation:</p> <ul> <li><p>If $|c\\rangle = |1\\rangle$, then the output is:</p> <p>$$ |c\\rangle|x\\rangle|b + (a \\cdot x) \\bmod N\\rangle $$</p> </li> <li><p>If $|c\\rangle = |0\\rangle$, then the input is unchanged:</p> <p>$$ |c\\rangle|x\\rangle|b\\rangle $$</p> </li> </ul>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#implementation","title":"Implementation\u00b6","text":"<p>This operation is performed by decomposing the product $a \\cdot x \\bmod N$ as a weighted sum of controlled modular additions:</p> <p>$$ \\begin{array}{c} (ax) \\bmod N = \\left(\\sum_{j=0}^{n-1} 2^j a x_j\\right) \\bmod N = \\\\ (...((2^{0}ax_{0})\\text{mod} \\ N + 2^{1}ax_{1})\\text{mod} \\ N + ... + 2^{n-1}ax_{n-1})\\text{mod} \\ N \\end{array} $$</p> <p>Each bit $x_j$ of the input register $|x\\rangle$ is used to control a doubly-controlled modular addition of $2^j a \\bmod N$ to the $|b\\rangle$ register.</p> <p>Thus, the entire <code>CMULTaMODN_c</code> gate is built from a sequence of <code>\u03c6ADD(2^j a)MOD(N)</code> gates, each doubly controlled by both the control qubit $|c\\rangle$ and the bit $x_j$.</p> <p>This structure enables controlled modular exponentiation, which is the core of Shor\u2019s algorithm\u2019s quantum speedup.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#controlled-u_a-gate-modular-exponentiation","title":"Controlled-$U_{a}$ Gate (Modular Exponentiation)\u00b6","text":"<p>How can we compute the sequence of controlled-$U^{2^{j}}$ operations used by the phase estimation procedure? We wish to compute the transformation</p> <p>$$ \\begin{array}{rl} |z\\rangle|y\\rangle&amp; \\mapsto |z\\rangle U^{z_{t}2^{t-1}}...U^{z_{1}2^{0}}|y\\rangle \\\\ \\ &amp; = |z\\rangle |x^{z_{t}2^{t-1}} \\times \\cdots \\times x^{z_{1}2^{0}} y \\text{mod} \\ N\\rangle \\\\ \\ &amp; = |z\\rangle |x^{z}y(\\text{mod}\\ N)\\rangle \\\\ \\end{array} $$</p> <p>Thus the sequence of controlled-$U^{2^{j}}$ operations used in phase estimation is equivalent to multiplying the contents of the second register by the modular exponentiation $x^{z}(\\text{mod}N)$, where $z$ is the contents of the first register.</p> <p>This algorithm for computing the modular exponential has two stages.</p> <ol> <li><p>Compute the powers $x^{2} \\bmod N,\\ x^{4} \\bmod N,\\ \\ldots,\\ x^{2^{j}} \\bmod N$ for all $j$ up to $t - 1$. In theory, as suggested in Nielsen and I. L. Chuang, we should use:</p> <p>$$ t = 2L + 1 + \\left\\lceil \\log\\left(2 + \\frac{1}{2\\epsilon}\\right) \\right\\rceil = O(L) $$</p> <p>where $L = \\lceil \\log_2 N \\rceil$ and $\\epsilon$ is the desired precision, for example 0.95 means expectation value. However, in our implementation, we choose $t$ as the minimum number of bits needed to represent the classical number, plus one extra bit to handle potential overflow.</p> </li> </ol> <p>This results in $t - 1 = O(L)$ squaring operations, each costing $O(L^2)$, for a total classical preprocessing cost of $O(L^3)$ in this stage.</p> <ol> <li><p>The second stage builds on the key observation:</p> <p>$$  x^z \\bmod N = \\left( x^{z_t 2^{t-1}} \\bmod N \\right) \\cdot \\left( x^{z_{t-1} 2^{t-2}} \\bmod N \\right) \\cdots \\left( x^{z_1 2^0} \\bmod N \\right)  $$</p> <p>Each term is a modular multiplication conditioned on the bits of $z$, and we perform $t - 1$ of them. Each multiplication costs $O(L^2)$, leading to a total quantum gate cost of $O(L^2)$.</p> </li> </ol> <p>If we follow the Nielsen and I. L. Chuang method and choose $t = O(L)$ to guarantee sufficient precision in the phase estimation step (e.g., $t = 2L + 1 + \\lceil \\log(2 + 1/(2\\epsilon)) \\rceil$), this results in a total of $O(L^2)$ controlled modular multiplications \u2014 keeping the full modular exponentiation circuit efficient and scalable.</p> <p>The final component of the quantum routine in Shor\u2019s algorithm is the controlled modular exponentiation gate, $C\\text{-}U_a$, which performs:</p> <p>$$ |x\\rangle|0\\rangle \\rightarrow |x\\rangle|(a^x \\bmod N)\\rangle $$</p> <p>This is constructed using the <code>CMULT(a)MOD(N)</code> gate as follows:</p> <ul> <li>We first apply the <code>CMULT(a)MOD(N)</code> gate to the input $|c\\rangle|x\\rangle|0\\rangle$.</li> <li>Then, we conditionally SWAP the result register with $|x\\rangle$ if $|c\\rangle = 1$.</li> <li>Finally, we apply the inverse circuit <code>CMULT(a^{-1})MOD(N)</code> to uncompute any garbage and return the ancilla to $|0\\rangle$.</li> </ul>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#properties","title":"Properties\u00b6","text":"<ul> <li><p>If $|c\\rangle = 0$, the operation is the identity.</p> </li> <li><p>If $|c\\rangle = 1$, the net effect is:</p> <p>$$ |x\\rangle|0\\rangle \\rightarrow |(a^x \\bmod N)\\rangle $$</p> <p>since the ancilla ends in $|0\\rangle$ again after uncomputation.</p> </li> </ul>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#efficiency-classical-help","title":"Efficiency &amp; Classical Help\u00b6","text":"<ul> <li>The inverse $a^{-1} \\bmod N$ is computed classically using the extended Euclidean algorithm since $\\gcd(a, N) = 1$.</li> <li>We can precompute $a^{2^j} \\bmod N$ classically for each exponent bit, and implement powers of $C\\text{-}U_a$ directly.</li> </ul> <p>This gate is essential for performing modular exponentiation under control, which is the core operation needed for the quantum period-finding subroutine in Shor\u2019s algorithm.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#eulers-totient-theorem-optional","title":"Euler's Totient Theorem (Optional)\u00b6","text":"<p>In Qiskit, quantum circuits only support integer-based unitary operations \u2014 meaning you can't perform division, use floating-point numbers, or write expressions like $1/a$ directly in a quantum gate. This becomes especially important when building arithmetic circuits like the Controlled-$U_a$, where we need to reverse a modular multiplication. To handle this, we bring in Euler's Totient Theorem.</p> <ol> <li>The Goal: We're trying to find an integer $a_{\\text{inv}}$ such that:</li> </ol> <p>$$    a \\times a_{\\text{inv}} \\mod N = 1    $$</p> <ol> <li><p>Euler's Totient Function ($\\phi(N)$): This function counts how many numbers less than $N$ are coprime to $N$. For example, $\\phi(15) = 8$ because the numbers $\\{1, 2, 4, 7, 8, 11, 13, 14\\}$ don\u2019t share any factors with 15.</p> </li> <li><p>Euler's Totient Theorem: If $a$ and $N$ are coprime (which is required for an inverse to exist), then:</p> </li> </ol> <p>$$    a^{\\phi(N)} \\equiv 1 \\mod N    $$</p> <p>In other words, raising $a$ to the power $\\phi(N)$ gives 1 modulo $N$.</p> <p>Now, with a little algebra, we can connect this to modular inverses:</p> <ul> <li>We know: $a^{\\phi(N)} \\equiv 1 \\mod N$</li> <li>Rewrite it: $a \\times a^{\\phi(N) - 1} \\equiv 1 \\mod N$</li> </ul> <p>Compare that to the definition of an inverse:</p> <ul> <li>$a \\times a^{\\phi(N) - 1} \\equiv 1 \\mod N$</li> <li>$a \\times a_{\\text{inv}} \\equiv 1 \\mod N$</li> </ul> <p>So we get:</p> <p>$$ a_{\\text{inv}} = a^{\\phi(N) - 1} \\mod N $$</p> <p>That\u2019s the mathematical definition of the modular inverse \u2014 raising $a$ to $\\phi(N) - 1$.</p> <p>But here\u2019s the thing: when you call <code>pow(a, -1, N)</code> in Python, it doesn't calculate $a^{\\phi(N)-1} \\mod N$. That would be way too slow, since you'd need to compute $\\phi(N)$ first. Instead, Python recognizes the <code>-1</code> as a request for the modular inverse and uses a much faster method: the Extended Euclidean Algorithm. It\u2019s the standard go-to algorithm for computing the inverse directly \u2014 no need to touch $\\phi(N)$ at all.</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#when-the-inverse-doesnt-exist","title":"When the Inverse Doesn't Exist\u00b6","text":"<p>The modular inverse of $a \\mod N$ only exists if $a$ and $N$ are coprime \u2014 meaning their greatest common divisor is 1.</p> <p>In Shor's algorithm, this isn't a bug \u2014 it's actually a feature. When you randomly pick an $a$, the very first thing you should do is compute <code>gcd(a, N)</code>:</p> <ol> <li>If <code>gcd(a, N) != 1</code>, then you\u2019ve already found a non-trivial factor of $N$ by pure luck \u2014 and you can stop the algorithm right there.</li> <li>If <code>gcd(a, N) = 1</code>, then a modular inverse is guaranteed to exist, and you can safely proceed with building the $U_a$ gate.</li> </ol> <p>Also note: Python\u2019s <code>pow(a, -1, N)</code> will raise a <code>ValueError</code> if the inverse does not exist. So your code should be prepared to catch this and handle it appropriately \u2014 it may just mean you got lucky and factored $N$ early!</p>"},{"location":"quantum_computation/jupyter_qc/Shor%27s/#constructing-a-period-finding-phase-estimation-circuit","title":"Constructing a Period-Finding / Phase Estimation Circuit\u00b6","text":"<p>         The order-finding circuit for quantum factorization from Beauregard.     </p> <p>\ud83d\udca1 In this notebook, we set <code>t = n</code> for faster results, instead of the recommended <code>t = 2n</code> as suggested in the original paper. Luckily, since 15 is a simple case, this shortcut still gives us pretty good results!</p> <p>\ud83c\udfaf Finally, our last step is to put everything together \u2014 the QFT, modular arithmetic, and controlled-$U_a$ \u2014 to build and run the phase estimation circuit that powers Shor\u2019s algorithm!</p> <p>The quantum part of Shor\u2019s algorithm is entirely focused on solving one key problem: finding the order of a randomly chosen number $a$ modulo $N$, where $N$ is the $n$-bit integer we want to factor.</p> <p>The order $r$ of $a \\mod N$ is the smallest positive integer such that:</p> <p>$$ a^{r} \\equiv 1 \\mod N $$</p> <p>This is a classic period-finding problem, and it's where quantum computing provides exponential speedup using phase estimation.</p>"},{"location":"quantum_computation/jupyter_qc/adder0/","title":"Calculating 1+1 using quantum gates","text":"<p>The notebook use a quantum gates to</p> <ol> <li><p>Calculating $1_{(10)}+1_{(10)}$ using quantum half adder: this section calculate...</p> </li> <li><p>Quantum addtion using technics from paper:  Vedral, V., Barenco, A., &amp; Ekert, A. (1996)</p> </li> <li><p>Calculating $5_{(10)}+3_{(10)}$ using quantum full adder: this section calculate...</p> </li> </ol> In\u00a0[215]: Copied! <pre># Qubit order:\n# |a&gt; = |a1a0&gt;\n# |b&gt; = |b1b0&gt;\n# q[0] = a1\n# q[1] = a0\n# q[2] = b1\n# q[3] = b0\n# q[4] = temp\n# q[5] = carry\n</pre> # Qubit order: # |a&gt; = |a1a0&gt; # |b&gt; = |b1b0&gt; # q[0] = a1 # q[1] = a0 # q[2] = b1 # q[3] = b0 # q[4] = temp # q[5] = carry <p>It's worth to notice that <code>Qiskit</code> default setting order for quantum state $|\\text{MSB}...\\text{LSB}\\rangle$ is $|q_{0}q_{1}q_{2}\\rangle$, this is easier for coding purpose since we starts our indexing from 0. Take Fourier transform, for example, <code>Qiskit</code> reverse the result at the end of the $\\text{QFT}^{\\dagger}$ to produce correct order we used to $|\\text{MSB}...\\text{LSB}\\rangle$.</p> <p>For example, without reversing the order, we get $5_{10} = |001_{2}\\rangle$ after measurement since its in a order of $|q_{0}q_{1}q_{2}\\rangle$ where we usually denote $5_{10} = 100$.</p> In\u00a0[216]: Copied! <pre>from qiskit import QuantumCircuit, ClassicalRegister\nfrom qiskit import QuantumRegister\n\n# Qubit order:\n# q[0] = a1\n# q[1] = a0\n# q[2] = b1\n# q[3] = b0\n# q[4] = temp\n# q[5] = carry\n\n# initialize both quantum and classical registers and combine them to construct a initial quantum circuit\nqr = QuantumRegister(6, name=\"q\")\ncr = ClassicalRegister(2, name=\"sum\")\nqc = QuantumCircuit(qr, cr, name=\"Adder_01+01\")\n\n# Initialize a = 01 \u2192 a1 = 0, a0 = 1s\nqc.x(1)\n\n# Initialize b = 01 \u2192 b1 = 0, b0 = 1\nqc.x(3)\n\n# Step 1: Save b0 to temp\nqc.cx(3, 4)\n\n# Step 2: CNOT(a0, b0) \u2192 sum\u2080\nqc.cx(1, 3)\n\n# Step 3: Toffoli(a0, temp, carry)\nqc.ccx(1, 4, 5)\n\n# Measure result: sum = b1b0\n# carefully assign qubits to classical qubit, recall taht the order of classical bit is |cr_1,cr_0&gt;!\nqc.measure(qr[5], cr[1])  # b1 = 1 = c = cr[1]\nqc.measure(qr[3], cr[0])  # b0 = 0 = sum = cr[0]\n</pre> from qiskit import QuantumCircuit, ClassicalRegister from qiskit import QuantumRegister  # Qubit order: # q[0] = a1 # q[1] = a0 # q[2] = b1 # q[3] = b0 # q[4] = temp # q[5] = carry  # initialize both quantum and classical registers and combine them to construct a initial quantum circuit qr = QuantumRegister(6, name=\"q\") cr = ClassicalRegister(2, name=\"sum\") qc = QuantumCircuit(qr, cr, name=\"Adder_01+01\")  # Initialize a = 01 \u2192 a1 = 0, a0 = 1s qc.x(1)  # Initialize b = 01 \u2192 b1 = 0, b0 = 1 qc.x(3)  # Step 1: Save b0 to temp qc.cx(3, 4)  # Step 2: CNOT(a0, b0) \u2192 sum\u2080 qc.cx(1, 3)  # Step 3: Toffoli(a0, temp, carry) qc.ccx(1, 4, 5)  # Measure result: sum = b1b0 # carefully assign qubits to classical qubit, recall taht the order of classical bit is |cr_1,cr_0&gt;! qc.measure(qr[5], cr[1])  # b1 = 1 = c = cr[1] qc.measure(qr[3], cr[0])  # b0 = 0 = sum = cr[0] Out[216]: <pre>&lt;qiskit.circuit.instructionset.InstructionSet at 0x16f86142c50&gt;</pre> <p>You will see that we set $q_{1} = q_{3} = |1\\rangle$ to make $a_{1} = b_{1} = 1$ by plotting out our circuit!</p> <p>Here, we measure the carry <code>qr[5]</code> and sum <code>qr[3]</code> and assign them into our classical register. Remember that our classical register is ordering as</p> <p>$$ |cr[1]cr[0]\\rangle $$</p> In\u00a0[217]: Copied! <pre># Let's plot our circuit!\nqc.draw('mpl', initial_state = True)\n</pre> # Let's plot our circuit! qc.draw('mpl', initial_state = True) Out[217]: <p>The following blocks is calling the Qiskit simulator and compute our measurement results using <code>StatevectorSampler</code> provided by Qiskit.</p> <p>It's worth to notice that the <code>get_count()</code> function return classic register in a order of</p> <p>$$ |\\text{cr}_{n-1}\\text{cr}_{n-2}...\\text{cr}_{1}\\text{cr}_{0}\\rangle $$</p> <p>IF NO SPECIFIC ORDER IS ASSIGNED</p> In\u00a0[218]: Copied! <pre>from qiskit.primitives import StatevectorSampler as Sampler\n# --- Step 5: Execute with Aer Sampler ---\nsampler = Sampler()\njob = sampler.run([qc],shots=4096)\nresult = job.result()\n\nprint(result[0])\n</pre> from qiskit.primitives import StatevectorSampler as Sampler # --- Step 5: Execute with Aer Sampler --- sampler = Sampler() job = sampler.run([qc],shots=4096) result = job.result()  print(result[0]) <pre>SamplerPubResult(data=DataBin(sum=BitArray(&lt;shape=(), num_shots=4096, num_bits=2&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\n</pre> In\u00a0[219]: Copied! <pre># See our resutl\nprint(result[0].data)\nprint(result[0].data._data.keys())\n</pre> # See our resutl print(result[0].data) print(result[0].data._data.keys()) <pre>DataBin(sum=BitArray(&lt;shape=(), num_shots=4096, num_bits=2&gt;))\ndict_keys(['sum'])\n</pre> In\u00a0[220]: Copied! <pre># Extract dictionary key \"sum\"\nbit_array = result[0].data['sum']\ncounts = bit_array.get_counts()\n\n# Get our final resutls!\n# Note that we have already assigned the classical bit order. We should get |10&gt; as a result.\nprint(counts)\n</pre> # Extract dictionary key \"sum\" bit_array = result[0].data['sum'] counts = bit_array.get_counts()  # Get our final resutls! # Note that we have already assigned the classical bit order. We should get |10&gt; as a result. print(counts) <pre>{'10': 4096}\n</pre> <p>Congratulations! You just implement a simple example of $1+1 = 2$ by using quantum gates! Now let's dive in into some concial method provide by paper:</p> <p>Vedral, V., Barenco, A., &amp; Ekert, A. (1996). Quantum networks for elementary arithmetic operations. Physical Review A, 54(1), 147\u2013153. https://doi.org/10.1103/PhysRevA.54.147</p> <p>We have four basic elements here</p> <ol> <li>$|c_0\\rangle$: Carry-in from previous bit, since we have nothing so this should be always $0$.</li> <li>$|a_0\\rangle$: Single qubit a.</li> <li>$|b_0\\rangle$: Single qubit b.</li> <li>$|c_1\\rangle$: Carry-out based on sum of $a_0$ and $b_0$.</li> </ol> <p>Since this type of circuit allows using addition on 2 qubits and take care of the carry-out. we'd say this is a full-adder.</p> <p>Same as before, we are trying to solve $1+1$ using quanutm arithmetic operations. Here, the qubit order of the inintal system state is labled as</p> <p>$$ |q_{0}q_{1}q_{2}q_{3}\\rangle = |c_{0}a_{0}b_{0}c_{1}\\rangle. $$</p> <p>In case of confusion, we need to assign the classical qubit when me measure the results to the order we are familir with, that is</p> <p>$$ |cr_{1}cr_{0}\\rangle = |c_{1}b_{0}\\rangle $$</p> <pre># Qubit order:\n# q[0] = co\n# q[1] = a0\n# q[2] = b0\n# q[3] = c1\n</pre> <p>Here let's consider the same $1+1 = |a_{0}\\rangle + |b_{0}\\rangle$ problem but using a different quantum circuit layout from Vedral, V., Barenco, A., &amp; Ekert, A. (1996). Quantum networks for elementary arithmetic operations. Physical Review A, 54(1), 147\u2013153. https://doi.org/10.1103/PhysRevA.54.147</p> <p>It's worth to notice that the <code>get_count()</code> function return classic register in a order of</p> <p>$$ |\\text{cr}_{n-1}\\text{cr}_{n-2}...\\text{cr}_{1}\\text{cr}_{0}\\rangle $$</p> <p>IF NO SPECIFIC ORDER IS ASSIGNED</p> <p>See <code>get_coutns()</code>:  https://docs.quantum.ibm.com/api/qiskit/qiskit.result.Result</p> <pre>#get_coutns(): https://docs.quantum.ibm.com/api/qiskit/qiskit.result.Result\n#The results are shown in the order that cr[0] on the right hand side.\n#In this example, |cr[3]cr[2]cr[1]cr[0]&gt; = |1010&gt; which is what we want for the first 2 bits |cr[3]cr[2]&gt; = |10&gt;\n</pre> In\u00a0[221]: Copied! <pre># Qubit order:\n# q[0] = co\n# q[1] = a0\n# q[2] = b0\n# q[3] = c1\n\n# initialize both quantum and classical registers and combine them to construct a initial quantum circuit\nqr = QuantumRegister(4, name=\"q\")\ncr = ClassicalRegister(2, name=\"sum\")\nqc = QuantumCircuit(qr, cr, name=\"Addeer\")\n\n# set a0 = b0 = |1&gt;\nqc.x([1,2])\n\nqc.ccx(1, 2, 3)\n\nqc.cx(1,2)\n\nqc.ccx(0, 2, 3)\n\n#qc.cx(0,2)\n#qc.swap(2,3)\n\n# get_coutns(): https://docs.quantum.ibm.com/api/qiskit/qiskit.result.Result\n# The results are shown in the order that cr[0] on the right hand side.\n# In this example, |cr[3]cr[2]cr[1]cr[0]&gt; = |1010&gt; which is what we want for the first 2 bits |cr[3]cr[2]&gt; = |10&gt;\n\n# Measure result: sum = b1b0\nqc.measure(qr[2], cr[0])  #sum\nqc.measure(qr[3], cr[1])  #carry\n\nqc.draw('mpl', initial_state = True, justify = 'none')\n</pre> # Qubit order: # q[0] = co # q[1] = a0 # q[2] = b0 # q[3] = c1  # initialize both quantum and classical registers and combine them to construct a initial quantum circuit qr = QuantumRegister(4, name=\"q\") cr = ClassicalRegister(2, name=\"sum\") qc = QuantumCircuit(qr, cr, name=\"Addeer\")  # set a0 = b0 = |1&gt; qc.x([1,2])  qc.ccx(1, 2, 3)  qc.cx(1,2)  qc.ccx(0, 2, 3)  #qc.cx(0,2) #qc.swap(2,3)  # get_coutns(): https://docs.quantum.ibm.com/api/qiskit/qiskit.result.Result # The results are shown in the order that cr[0] on the right hand side. # In this example, |cr[3]cr[2]cr[1]cr[0]&gt; = |1010&gt; which is what we want for the first 2 bits |cr[3]cr[2]&gt; = |10&gt;  # Measure result: sum = b1b0 qc.measure(qr[2], cr[0])  #sum qc.measure(qr[3], cr[1])  #carry  qc.draw('mpl', initial_state = True, justify = 'none') Out[221]: <p>As you can see, we first put the state into $|1\\rangle + |1\\rangle$ by applying <code>X</code> gate to slip qubits from 0s to 1s. Then we apply the <code>Toffoli</code> gate with two control $a_0$ and $b_0$ with the target of $c_1$.</p> <p>Then we apply the <code>CNOT</code> to compute <code>sum</code>, which is the same as we have introduced before. By following the classic adder arithmetic,</p> <p>$$ c_{1} = a \\oplus b \\oplus c_{0}. $$</p> <p>Finally, we apply a <code>CNOT</code> at the end of $b$ with <code>CNOT(c_0,b_0)</code> to calculate the final sum of $b$. Since $|q_0\\rangle = 0$ thus in this case <code>CNOT(c_0,b_0)</code> = b.</p> In\u00a0[\u00a0]: Copied! <pre>from qiskit.primitives import StatevectorSampler as Sampler\nsampler = Sampler()\njob = sampler.run([qc],shots=4096)\nresult = job.result()\n\nprint(result[0])\n\nprint(result[0].data)\nprint(result[0].data._data.keys())\n\nbit_array = result[0].data['sum']\ncounts = bit_array.get_counts()\n\nprint(counts)\n</pre> from qiskit.primitives import StatevectorSampler as Sampler sampler = Sampler() job = sampler.run([qc],shots=4096) result = job.result()  print(result[0])  print(result[0].data) print(result[0].data._data.keys())  bit_array = result[0].data['sum'] counts = bit_array.get_counts()  print(counts) <pre>SamplerPubResult(data=DataBin(sum=BitArray(&lt;shape=(), num_shots=4096, num_bits=2&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(sum=BitArray(&lt;shape=(), num_shots=4096, num_bits=2&gt;))\ndict_keys(['sum'])\n{'10': 4096}\n</pre> <p>Congratulations! You just implement a simple example of $1+1 = 2$ by following the paper from Vedral!</p> In\u00a0[223]: Copied! <pre>from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n\nqr = QuantumRegister(10, 'q')\ncr = ClassicalRegister(4, 'c')  # sum0, sum1, sum2, carry_out\nqc = QuantumCircuit(qr, cr)\n\nn = 3\n\n# a = 101, a2a1a0\nqc.x(1)\nqc.x(7)\n\n# b = 011, b2b1b0\nqc.x(2)\nqc.x(5)\n\nfor i in range(3):  # 3-bit adder\n    base = i * 3  # step by 3 (since c overlaps)\n    #print(i)\n    c_in  = base + 0\n    a     = base + 1\n    b     = base + 2\n    c_out = base + 3\n\n    # print(c_in, a, b, c_out)\n\n    qc.ccx(a, b, c_out)     # first carry term\n    qc.cx(a, b)             # xor\n    qc.ccx(c_in, b, c_out)  # second carry term\n    qc.cx(c_in, b)          # final sum in b\n\n    # Measure b0, b1, b2 and carry_out\n    qc.measure(b, i)  # sum0\n    if i == 2:\n        qc.measure(c_out, i+1)  # final carry_out (c3)\n\n\nqc.draw('mpl', initial_state = True, justify = 'none')\n</pre> from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister  qr = QuantumRegister(10, 'q') cr = ClassicalRegister(4, 'c')  # sum0, sum1, sum2, carry_out qc = QuantumCircuit(qr, cr)  n = 3  # a = 101, a2a1a0 qc.x(1) qc.x(7)  # b = 011, b2b1b0 qc.x(2) qc.x(5)  for i in range(3):  # 3-bit adder     base = i * 3  # step by 3 (since c overlaps)     #print(i)     c_in  = base + 0     a     = base + 1     b     = base + 2     c_out = base + 3      # print(c_in, a, b, c_out)      qc.ccx(a, b, c_out)     # first carry term     qc.cx(a, b)             # xor     qc.ccx(c_in, b, c_out)  # second carry term     qc.cx(c_in, b)          # final sum in b      # Measure b0, b1, b2 and carry_out     qc.measure(b, i)  # sum0     if i == 2:         qc.measure(c_out, i+1)  # final carry_out (c3)   qc.draw('mpl', initial_state = True, justify = 'none')  Out[223]: In\u00a0[224]: Copied! <pre>from qiskit.primitives import StatevectorSampler as Sampler\n# --- Step 5: Execute with Aer Sampler ---\nsampler = Sampler()\njob = sampler.run([qc],shots=4096)\nresult = job.result()\n\nprint(result[0])\n\nprint(result[0].data)\nprint(result[0].data._data.keys())\n\nbit_array = result[0].data['c']\ncounts = bit_array.get_counts()\n\nprint(counts)\n</pre> from qiskit.primitives import StatevectorSampler as Sampler # --- Step 5: Execute with Aer Sampler --- sampler = Sampler() job = sampler.run([qc],shots=4096) result = job.result()  print(result[0])  print(result[0].data) print(result[0].data._data.keys())  bit_array = result[0].data['c'] counts = bit_array.get_counts()  print(counts) <pre>SamplerPubResult(data=DataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;))\ndict_keys(['c'])\n{'1000': 4096}\n</pre> In\u00a0[225]: Copied! <pre>from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister\n\nqr = QuantumRegister(10, 'q')\ncr = ClassicalRegister(4, 'c')  # sum0, sum1, sum2, carry_out\nqc = QuantumCircuit(qr, cr)\n\nn = 3\n\n# a = 101, a2a1a0\nqc.x(1)\nqc.x(7)\n\n# b = 011, b2b1b0\nqc.x(2)\nqc.x(5)\n\nfor i in range(n):  # 3-bit adder\n    base = i * 3  # step by 3 (since c overlaps)\n    #print(i)\n    c_in  = base + 0\n    a     = base + 1\n    b     = base + 2\n    c_out = base + 3\n\n    print(c_in, a, b, c_out)\n\n    qc.ccx(a, b, c_out)     # first carry term\n    qc.cx(a, b)             # xor\n    qc.ccx(c_in, b, c_out)  # second carry term\n    #qc.cx(c_in, b)          # final sum in b\n\n    # Measure b0, b1, b2 and carry_out\n    #qc.measure(b, i)  # sum0\n    #qc.measure(c_out, i+1)  # final carry_out (c3)\n    if i == 2:\n        qc.measure(c_out, i+1)  # final carry_out (c3)\n\na_n = n * 3 - 2\nb_n = n * 3 - 1\nqc.cx(a_n,b_n)\n\n# sum gate\nc_n_1 = n * 2\nqc.cx(a_n,b_n)\nqc.cx(c_n_1,b_n)\nqc.measure(b_n, i)  # sum0\n\nfor i in reversed(range(n-1)):\n    base = i * 3  # step by 3 (since c overlaps)\n    #print(i)\n    c_in  = base + 0\n    a     = base + 1\n    b     = base + 2\n    c_out = base + 3\n\n    # Carry in reverse order \n    qc.ccx(c_in, b, c_out)  # second carry term\n    qc.cx(a, b)             # xor\n    qc.ccx(a, b, c_out)     # first carry term\n\n    qc.cx(a,b)\n    qc.cx(c_in,b)\n    qc.measure(b, i)  # sum0\n    \n\n\n\nqc.draw('mpl', initial_state = True, justify = 'none')\n</pre> from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister  qr = QuantumRegister(10, 'q') cr = ClassicalRegister(4, 'c')  # sum0, sum1, sum2, carry_out qc = QuantumCircuit(qr, cr)  n = 3  # a = 101, a2a1a0 qc.x(1) qc.x(7)  # b = 011, b2b1b0 qc.x(2) qc.x(5)  for i in range(n):  # 3-bit adder     base = i * 3  # step by 3 (since c overlaps)     #print(i)     c_in  = base + 0     a     = base + 1     b     = base + 2     c_out = base + 3      print(c_in, a, b, c_out)      qc.ccx(a, b, c_out)     # first carry term     qc.cx(a, b)             # xor     qc.ccx(c_in, b, c_out)  # second carry term     #qc.cx(c_in, b)          # final sum in b      # Measure b0, b1, b2 and carry_out     #qc.measure(b, i)  # sum0     #qc.measure(c_out, i+1)  # final carry_out (c3)     if i == 2:         qc.measure(c_out, i+1)  # final carry_out (c3)  a_n = n * 3 - 2 b_n = n * 3 - 1 qc.cx(a_n,b_n)  # sum gate c_n_1 = n * 2 qc.cx(a_n,b_n) qc.cx(c_n_1,b_n) qc.measure(b_n, i)  # sum0  for i in reversed(range(n-1)):     base = i * 3  # step by 3 (since c overlaps)     #print(i)     c_in  = base + 0     a     = base + 1     b     = base + 2     c_out = base + 3      # Carry in reverse order      qc.ccx(c_in, b, c_out)  # second carry term     qc.cx(a, b)             # xor     qc.ccx(a, b, c_out)     # first carry term      qc.cx(a,b)     qc.cx(c_in,b)     qc.measure(b, i)  # sum0         qc.draw('mpl', initial_state = True, justify = 'none') <pre>0 1 2 3\n3 4 5 6\n6 7 8 9\n</pre> Out[225]: <p>Again, we assign a classcial register order to reduce confusion, result should be shown as</p> <p>$$ |\\text{cr}_{3}\\text{cr}_{2}\\text{cr}_{1}\\text{cr}_{0}\\rangle = |1000_{2}\\rangle = |8_{10}\\rangle $$</p> <p>since function <code>get_counts()</code> already swap the order for us. How nice! \ud83d\ude03</p> In\u00a0[226]: Copied! <pre>from qiskit.primitives import StatevectorSampler as Sampler\n# --- Step 5: Execute with Aer Sampler ---\nsampler = Sampler()\njob = sampler.run([qc],shots=4096)\nresult = job.result()\n\nprint(result[0])\n\nprint(result[0].data)\nprint(result[0].data._data.keys())\n\nbit_array = result[0].data['c']\ncounts = bit_array.get_counts()\n\nprint(counts)\n</pre> from qiskit.primitives import StatevectorSampler as Sampler # --- Step 5: Execute with Aer Sampler --- sampler = Sampler() job = sampler.run([qc],shots=4096) result = job.result()  print(result[0])  print(result[0].data) print(result[0].data._data.keys())  bit_array = result[0].data['c'] counts = bit_array.get_counts()  print(counts) <pre>SamplerPubResult(data=DataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;)), metadata={'shots': 4096, 'circuit_metadata': {}})\nDataBin(c=BitArray(&lt;shape=(), num_shots=4096, num_bits=4&gt;))\ndict_keys(['c'])\n{'1000': 4096}\n</pre> <p>Wonderful!\ud83c\udfc6\ud83e\udd47 You already expertised in implementing an full adder in a quantum plus the practical way! Let's keep learning!\u270c\ufe0f</p>"},{"location":"quantum_computation/jupyter_qc/adder0/#calculating-11-using-quantum-gates","title":"Calculating 1+1 using quantum gates\u00b6","text":""},{"location":"quantum_computation/jupyter_qc/adder0/#references","title":"References\u00b6","text":"<ol> <li>Vedral, V., Barenco, A., &amp; Ekert, A. (1996). Quantum networks for elementary arithmetic operations. Physical Review A, 54(1), 147\u2013153. https://doi.org/10.1103/PhysRevA.54.147</li> </ol>"},{"location":"quantum_computation/jupyter_qc/adder0/#cnot-gate-controlled-not","title":"CNOT Gate (Controlled-NOT)\u00b6","text":"<p>Let's first introduce <code>CNOT</code> gate truth table:</p> Control (C) Target Input (T) Target Output (T $\\oplus$ C) 0 0 0 0 1 1 1 0 1 1 1 0"},{"location":"quantum_computation/jupyter_qc/adder0/#toffoli-gate-ccx-controlled-controlled-not","title":"Toffoli Gate (CCX / Controlled-Controlled-NOT)\u00b6","text":"Control 1 (C\u2081) Control 2 (C\u2082) Target Input (T) Target Output (T \u2295 (C\u2081 $\\cdot$ C\u2082)) 0 0 0 0 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 0 1 0 1 1 1 1 0 1 1 1 1 0"},{"location":"quantum_computation/jupyter_qc/adder0/#calculating-1_101_10-using-quantum-half-adder","title":"Calculating $1_{(10)}+1_{(10)}$ using quantum half adder\u00b6","text":"<p>Here we will start with a straightforward example of how to build a classical half adder by using quantum gates, specifically, only <code>CNOT</code> and <code>Toffoli</code> gate. We will use a 2-bit representation for better demonstration. Assume that we have $1_{(10)}$ that can be represented in binary form as</p> <p>$$ |a\\rangle = |a_{1}a_{0}\\rangle = |01\\rangle, $$</p> <p>and</p> <p>$$ |b\\rangle = |b_{1}b_{0}\\rangle = |01\\rangle. $$</p> <p>We introduce 2 extra qubits, <code>temp</code>, and <code>carry</code>:</p> <ol> <li>The <code>temp</code> qubit serve as a temporary storage of MSB of $b$, that is, $b_{1} = 0$.</li> <li>The carry will be controlled by the addition of $a_{0}$ and <code>temp</code> by using the <code>Toffoli</code> gate. Below shows the assigned qubits.</li> </ol> <p>This type of addition is basically made of two portions, sum and carry:</p> <ol> <li>The sum is computed by the addition of qubit $a_{0} \\oplus b_{0}$, where $\\oplus$ denotes a modulos 2 addtion.</li> <li>Carry is computed by the addition between $a_{0}$ and <code>temp</code> qubit.</li> </ol>"},{"location":"quantum_computation/jupyter_qc/adder0/#quantum-networks-for-elementary-arithmetic-operations","title":"Quantum Networks for Elementary Arithmetic Operations\u00b6","text":""},{"location":"quantum_computation/jupyter_qc/adder0/#a-more-useful-way-reversible-variation","title":"A more useful way (Reversible variation)\u00b6","text":"<p>Most of time, we want our circuit be reversieble for more practical applications</p> <p>$$ |a,b\\rangle \\rightarrow |a,a+b\\rangle $$</p> <p>we apply carries gates then</p>"},{"location":"quantum_mechanics/No-cloing/","title":"No cloing","text":"<p>The no-cloning theorem is a fundamental principle in quantum mechanics that states it is impossible to create an exact copy of an arbitrary unknown quantum state. This is a cornerstone of the security in quantum key distribution protocols like BB84.</p> <p>Another interesring property of quantum systems is the no-cloning theorm. Check No-cloning for proof. In short, for an example, if we would like to have a two-qubit quantum gate U that will be able to copy the first qubit into the second. we would need,</p>  U(\\lvert\\psi\\rangle \\otimes \\lvert0\\rangle) = \\lvert\\psi\\rangle \\otimes \\lvert\\psi\\rangle  <p>from above, we know that U\\lvert00\\rangle = \\lvert00\\rangle and U\\lvert10\\rangle = \\lvert11\\rangle. Therefore,</p>  U\\bigg(\\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle)\\bigg) = \\frac{1}{\\sqrt{2}}(U\\lvert00\\rangle + U\\lvert10\\rangle) = \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert11\\rangle).  <p>Then, from previous example, we also know that \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle can be written in a product form,</p>  \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle = \\frac{1}{\\sqrt{2}}\\bigg(\\lvert0\\rangle + \\lvert1\\rangle\\bigg)\\lvert0\\rangle   <p>Now, let's apply gate U, we should have,</p>  U\\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle = U\\bigg(\\frac{1}{\\sqrt{2}}\\bigg(\\lvert0\\rangle + \\lvert1\\rangle\\bigg)\\lvert0\\rangle\\bigg) =  \\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}\\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}  <p>which is a product state, and we also know have U\\bigg(\\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert10\\rangle)\\bigg) = \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert11\\rangle),</p>  \\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}\\frac{\\lvert0\\rangle + \\lvert1\\rangle}{\\sqrt{2}}\\neq \\frac{1}{\\sqrt{2}}(\\lvert00\\rangle + \\lvert11\\rangle)"},{"location":"quantum_mechanics/No-cloing/#therefore-no-such-gate-uu-exist","title":"therefore, no such gate U exist.","text":""},{"location":"quantum_mechanics/No-cloing/#what-is-the-no-cloning-theorem","title":"What is the No-Cloning Theorem?","text":"<p>The no-cloning theorem ensures that:</p> <p>Given a qubit in an unknown quantum state  \\lvert\\psi\\rangle = \\alpha\\lvert0\\rangle + \\beta\\lvert1\\rangle, it is impossible to produce another qubit in the exact same state  \\lvert\\psi\\rangle without disturbing the original.</p>"},{"location":"quantum_mechanics/No-cloing/#why","title":"Why?","text":"<p>The proof is rooted in the linearity of quantum mechanics:</p> <ol> <li> <p>To clone a quantum state, we would need a cloning operation U that works like this: $$ U(\\lvert\\psi\\rangle \\otimes \\lvert0\\rangle) = \\lvert\\psi\\rangle \\otimes \\lvert\\psi\\rangle $$ where  \\lvert0\\rangle  is a blank state (e.g., an auxiliary system). See Non-cloing for tensor.</p> </li> <li> <p>For two arbitrary quantum states \\lvert\\psi\\rangle and \\lvert\\phi\\rangle, linearity requires: $$ U(\\lvert\\psi\\rangle \\otimes \\lvert0\\rangle) = \\lvert\\psi\\rangle \\otimes \\lvert\\psi\\rangle $$ $$ U(\\lvert\\phi\\rangle \\otimes \\lvert0\\rangle) = \\lvert\\phi\\rangle \\otimes \\lvert\\phi\\rangle $$</p> </li> <li>If \\lvert\\psi\\rangle \\neq \\lvert\\phi\\rangle, linearity leads to a contradiction because the superposition of the states cannot preserve the cloning operation: $$ U(a\\lvert\\psi\\rangle + b\\lvert\\phi\\rangle) \\neq a\\lvert\\psi\\rangle \\otimes \\lvert\\psi\\rangle + b\\lvert\\phi\\rangle \\otimes \\lvert\\phi\\rangle $$ Thus, no such universal cloning operation U can exist.</li> </ol>"},{"location":"quantum_mechanics/No-cloing/#1-the-no-cloning-theorem","title":"1. The No-Cloning Theorem","text":"<p>The no-cloning theorem states that it is impossible to create an exact copy of an arbitrary quantum state. Given a quantum state : $$ \\lvert \\psi \\rangle = \\alpha \\lvert 0 \\rangle + \\beta \\lvert 1 \\rangle, $$ there is no operation that can produce: $$ U(\\lvert \\psi \\rangle \\otimes \\lvert 0 \\rangle) = \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle, $$ where $ \\lvert 0 \\rangle $ is an auxiliary \"blank\" state.</p>"},{"location":"quantum_mechanics/No-cloing/#2-why-cloning-is-impossible","title":"2. Why Cloning is Impossible","text":"<p>The proof relies on the linearity of quantum mechanics. </p> <p>Suppose we have two distinct quantum states \\lvert \\psi \\rangle and \\lvert \\phi \\rangle. For a universal cloning operation U, we require: $$ U(\\lvert \\psi \\rangle \\otimes \\lvert 0 \\rangle) = \\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle, $$ $$ U(\\lvert \\phi \\rangle \\otimes \\lvert 0 \\rangle) = \\lvert \\phi \\rangle \\otimes \\lvert \\phi \\rangle. $$</p> <p>Now, consider a superposition of these states: $$ \\lvert \\chi \\rangle = a \\lvert \\psi \\rangle + b \\lvert \\phi \\rangle, $$ where a and b are complex coefficients.</p> <p>By the linearity of U, applying it to $ \\lvert \\chi \\rangle $ gives: $$ U(\\lvert \\chi \\rangle \\otimes \\lvert 0 \\rangle) = U((a \\lvert \\psi \\rangle + b \\lvert \\phi \\rangle) \\otimes \\lvert 0 \\rangle). $$ Expanding this: $$ U(\\lvert \\chi \\rangle \\otimes \\lvert 0 \\rangle) = a U(\\lvert \\psi \\rangle \\otimes \\lvert 0 \\rangle) + b U(\\lvert \\phi \\rangle \\otimes \\lvert 0 \\rangle). $$</p> <p>Substituting the cloning results: $$ U(\\lvert \\chi \\rangle \\otimes \\lvert 0 \\rangle) = a (\\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle) + b (\\lvert \\phi \\rangle \\otimes \\lvert \\phi \\rangle). $$</p> <p>However, the desired cloning result would be: $$ \\lvert \\chi \\rangle \\otimes \\lvert \\chi \\rangle = (a \\lvert \\psi \\rangle + b \\lvert \\phi \\rangle) \\otimes (a \\lvert \\psi \\rangle + b \\lvert \\phi \\rangle). $$</p> <p>Expanding this: $$ \\lvert \\chi \\rangle \\otimes \\lvert \\chi \\rangle = a^2 (\\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle) + ab (\\lvert \\psi \\rangle \\otimes \\lvert \\phi \\rangle) + ab (\\lvert \\phi \\rangle \\otimes \\lvert \\psi \\rangle) + b^2 (\\lvert \\phi \\rangle \\otimes \\lvert \\phi \\rangle). $$</p>"},{"location":"quantum_mechanics/No-cloing/#3-the-contradiction","title":"3. The Contradiction","text":"<p>The two results are not equal: 1. The linearity of U only gives: $$ a (\\lvert \\psi \\rangle \\otimes \\lvert \\psi \\rangle) + b (\\lvert \\phi \\rangle \\otimes \\lvert \\phi \\rangle). $$ This result lacks the cross terms ab(\\lvert \\psi \\rangle \\otimes \\lvert \\phi \\rangle) and ab (\\lvert \\phi \\rangle \\otimes \\lvert \\psi \\rangle).</p> <p>Thus, the desired cloning result requires the cross terms because it represents the tensor product of the superposition with itself.</p> <p>This mismatch proves that a universal cloning operation U cannot exist.</p>"},{"location":"quantum_mechanics/No-cloing/#4-key-insights","title":"4. Key Insights","text":"<ul> <li>The no-cloning theorem arises because quantum mechanics is linear, and linear operations cannot replicate the behavior of classical copying.</li> <li>Quantum states cannot be duplicated without violating the mathematical structure of quantum mechanics.</li> </ul> <p>This makes cloning of arbitrary quantum states impossible, providing a foundation for the security of quantum cryptography protocols like BB84. Let me know if you'd like further clarification!</p>"}]}